{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28\n",
    "learning_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, (None,n_inputs), name = \"X\")\n",
    "y = tf.placeholder(tf.int64,(None),name = \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dimension(784)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.get_shape()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X,n_neurons,name,activation=None):\n",
    "    with tf.name_scope(\"name\"):\n",
    "        #인풋 행렬의 행을 가져온다.\n",
    "        x_inputs = int(X.get_shape()[1])\n",
    "        #절단 가우시안 분포를 쓰기 위해, 2/root(n_neurons + n_inputs)꼴의 표준편차를 정의한다.\n",
    "        std_dev = 2/np.sqrt(n_neurons + x_inputs)\n",
    "        #절단 가우시안 분포로 가중치 행렬을 초기화한다.\n",
    "        init = tf.truncated_normal((x_inputs,n_neurons),stddev=std_dev)\n",
    "        w = tf.Variable(init,name=\"kernel\")\n",
    "        #0으로 이루어진 편향 항을 추가한다. 그 차원은 1 X (열의 수)가 된다. 이렇게 되면, (샘플 수) X (열의 수)인 행렬에 (열의 수)만큼 \n",
    "        #반복해서 곱을 해준다.\n",
    "        b = tf.Variable(tf.zeros([n_neurons]),name=\"bias\")\n",
    "        #행렬곱으로 묶는다.\n",
    "        z = tf.matmul(X,w)+b\n",
    "        #활성화 함수가 지정되었다면, 해당 활성화 함수로 변환된 값을 출력한다.\n",
    "        if activation is not None:\n",
    "            return activation(z)\n",
    "        else:\n",
    "            return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델을 구성한다.\n",
    "\n",
    "with tf.name_scope(\"model\"):\n",
    "    hidden1 = neuron_layer(X,300,\"hidden1\",tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1,100,\"hidden2\",tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2,10,\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#목적함수를 정의한다. 타겟값은 1을 곱하고, 나머지 값은 0을 곱하는 크로스 엔트로피를 목적함수로 정의한다.\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    #이 함수는 출력된 로짓값에 소프트맥스를 적용하고, 소프트맥스로 변환된 확률값을 cross entropy에 집어넣어 해당 훈련의 엔트로피 값을 \n",
    "    #계산해준다.\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "    #이 때, 이 크로스 엔트로피를 전부 더하고, 평균을 낸 결과를 최소화 하는것이 목적이 된다.\n",
    "    loss = tf.reduce_mean(xentropy,name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#목적함수를 각 가중치로 미분한 그레디언트 벡터를, 각 가중치에서 계속 빼서 업데이트 하는 경사하강법을 적용한다.\n",
    "\n",
    "with tf.name_scope(\"gradient\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    #경사하강법 최적화를 optimizer로 할당한 다음, optimizer를 최소화 방법(minimize)로 목적함수를 최적화시킨다.\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 평가용 그래프를 정의한다.\n",
    "with tf.name_scope(\"eval\"):\n",
    "    # top_k함수는 어떤 출력값이 비교값(타겟값)과 비교했을 때 가장 높은 출력값을 보인 타겟값을 True로, 나머지는 False인 텐서를 반환한다.\n",
    "    correct = tf.nn.in_top_k(logits,y,1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variable_initialzier()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor36",
   "language": "python",
   "name": "tensorflow36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
