{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\never\\Anaconda3\\envs\\tensorflow35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = pd.read_csv(\"블랑1664_75.csv\",engine=\"python\",names=[\"text\"],encoding = \"cp949\",skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>혹시 1664블랑 맥주 먹어본사람있음? 먼맛이야</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>블랑1664 진짜존맛이야ㅜ맥주지린내가 안나</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>아ㅠ 기린 탈 것 얘기하시는 줄 알았자나요... 저는 블랑1664 조아해요. 아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>갓 블랑 1664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>블랑 1664 드세요 내 최애 맥주야</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text\n",
       "0                    혹시 1664블랑 맥주 먹어본사람있음? 먼맛이야\n",
       "1                       블랑1664 진짜존맛이야ㅜ맥주지린내가 안나\n",
       "2  아ㅠ 기린 탈 것 얘기하시는 줄 알았자나요... 저는 블랑1664 조아해요. 아\n",
       "3                                     갓 블랑 1664\n",
       "4                          블랑 1664 드세요 내 최애 맥주야"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#원본 데이터셋의 리뷰 수\n",
    "\n",
    "len(rawdata[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74    0\n",
       "75    0\n",
       "76    0\n",
       "77    0\n",
       "78    0\n",
       "79    0\n",
       "80    0\n",
       "81    0\n",
       "82    0\n",
       "83    0\n",
       "84    0\n",
       "85    0\n",
       "86    0\n",
       "87    0\n",
       "88    0\n",
       "89    0\n",
       "90    0\n",
       "91    0\n",
       "92    0\n",
       "93    0\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata[\"text\"][rawdata[\"text\"].duplicated()].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#중복값 제거 후의 리뷰 수\n",
    "\n",
    "len(pd.unique(rawdata[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#중복값 제거\n",
    "\n",
    "text = rawdata[\"text\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측값 제거\n",
    "\n",
    "text = rawdata[\"text\"].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter 형태소분석기를 함수로 정의\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "twitter_tag = Okt()\n",
    "\n",
    "def vect_tokenizer(text):\n",
    "    return twitter_tag.morphs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter 형태소 분석기를 통해 각 문장을 형태소로 나눈다.\n",
    "\n",
    "morph = list()\n",
    "\n",
    "for i in text:\n",
    "    raw = twitter_tag.morphs(i)\n",
    "    raw = [raw[k] for k in np.where([len(j) != 1 for j in raw])[0]]\n",
    "    morph.append(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-99070e6eeb7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorized' is not defined"
     ]
    }
   ],
   "source": [
    "#문장 길이의 평균, 표준편차를 구한다.\n",
    "\n",
    "a = 0\n",
    "b = 0\n",
    "\n",
    "for i in morph:\n",
    "    a += len(i)\n",
    "\n",
    "mu = a/len(morph)\n",
    "\n",
    "for i in morph:\n",
    "    b += (len(i) - mu)**2\n",
    "\n",
    "std_dev = (b/len(morph))**0.5\n",
    "\n",
    "print(mu,std_dev)\n",
    "\n",
    "#평균에서 1 표준편차만큼을 더한 값을 문장 길이로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#앞서 살펴본 문장길이를 maxlen에 넣어준다.\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "morph_seq = sequence.pad_sequences(morph,maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\never\\Anaconda3\\envs\\tensorflow35\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "#Word2Vec 에 앞서 분석한 형태소를 집어넣고 돌린다.\n",
    "## size = 투입되는 문장의 크기, window = 중심단어에서 앞 뒤로 확인할 단어의 갯수, worker = 컴퓨터 코어의 수, iter = 반복횟수\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "embedding_model2 = Word2Vec(morph_seq, size=50, window = 50, workers=4, iter=100, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 아래는 글자로 되어있는 문장을 숫자로 바꿔주는 벡터화 함수임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function vect_tokenizer at 0x000001FBB91C8268>,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(tokenizer = vect_tokenizer)\n",
    "\n",
    "vect.fit(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized = list()\n",
    "\n",
    "for k in morph:\n",
    "    raw = list()\n",
    "    for i in k:\n",
    "        try:\n",
    "            raw.append(vect.vocabulary_[i])\n",
    "        except:\n",
    "            pass\n",
    "    vectorized.append(raw)\n",
    "\n",
    "why = DataFrame(vectorized)\n",
    "\n",
    "why.to_csv(\"벡터화.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensorflow35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
