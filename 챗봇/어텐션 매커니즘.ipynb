{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\never\\Anaconda3\\envs\\tensorflow35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Layer\n",
    "from keras.layers import Input,Dense,Flatten,Embedding,Permute,Dot,Reshape\n",
    "from keras.layers.convolutional import Conv1D,MaxPooling1D,MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM,GRU\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = pd.read_csv(\"최종리스트_맥주 키워드 제거.csv\",engine=\"python\",encoding = \"utf-8\")\n",
    "del rawdata[\"Unnamed: 0\"]\n",
    "morphs = list()\n",
    "\n",
    "for i in range(0,len(rawdata)):\n",
    "    morphs.append(list(rawdata.loc[i,:].dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoded = pd.read_csv(\"타겟.csv\",engine=\"python\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del target_encoded[\"Unnamed: 0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphsVectored = list()\n",
    "\n",
    "\n",
    "vocabulary = pd.read_csv(\"색인사전_맥주 키워드 제거.csv\",engine=\"python\",encoding=\"utf-8\")\n",
    "del vocabulary[\"Unnamed: 0\"]\n",
    "\n",
    "vocabulary = vocabulary.to_dict(orient=\"records\")[0]\n",
    "\n",
    "for i in morphs:\n",
    "    temporailyList = list()\n",
    "    for k in i:\n",
    "        #print(k)\n",
    "        try:\n",
    "            temporailyList.append(vocabulary[k])\n",
    "        except KeyError:\n",
    "            temporailyList.append(0)\n",
    "    morphsVectored.append(temporailyList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_seq = sequence.pad_sequences(morphsVectored,maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(vectorized_seq, target_encoded)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 50, 128)      768000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 50, 128)      0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 48, 256)      98560       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 12, 256)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Encoder (GRU)                   [(None, 12, 128), (N 147840      max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Reshape_3D_for_decoder (RepeatV (None, 1, 128)       0           Encoder[0][1]                    \n",
      "__________________________________________________________________________________________________\n",
      "Decoder (GRU)                   (None, 128)          98688       Reshape_3D_for_decoder[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Reshape_3D_for_dot (RepeatVecto (None, 1, 128)       0           Decoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Cosine_similarity (Dot)         (None, 1, 12)        0           Reshape_3D_for_dot[0][0]         \n",
      "                                                                 Encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_score_from_Softmax (S (None, 1, 12)        0           Cosine_similarity[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Transpose_attention_matrix (Per (None, 128, 12)      0           Encoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "weighted_attention_matrix (Mult (None, 128, 12)      0           attention_score_from_Softmax[0][0\n",
      "                                                                 Transpose_attention_matrix[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Making_context_vector (Lambda)  (None, 128)          0           weighted_attention_matrix[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 13)           1677        Making_context_vector[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 1,114,765\n",
      "Trainable params: 1,114,765\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph\n",
    "\n",
    "## GRU 입력 전 사전처리 모듈(임베딩 -> 컨볼루션 -> 맥스풀링)\n",
    "\n",
    "inputs = Input(shape=[50])\n",
    "embed = Embedding(6000,128,input_length = 50)(inputs)\n",
    "model = Dropout(0.2)(embed)\n",
    "model = Conv1D(256,3,padding=\"valid\",activation=\"relu\",strides=1)(model)\n",
    "model = MaxPooling1D(pool_size = 4)(model)\n",
    "\n",
    "## 인코더 부분\n",
    "\n",
    "Encoder = GRU(128,return_sequences = True, return_state = True,name=\"Encoder\")\n",
    "attention_matrix,h_state = Encoder(model)\n",
    "\n",
    "#2D텐서인 출력벡터(h_state)를 3D텐서로 만들기 위해, 임의로 1회 반복을 실시한다.\n",
    "Reshape_3D_for_decoder = layers.RepeatVector(1,name=\"Reshape_3D_for_decoder\")(h_state)\n",
    "\n",
    "##디코더 부분\n",
    "\n",
    "Decoder = GRU(128,name = \"Decoder\")\n",
    "# h_state를 3D텐서로 바꾼 Reshape_3d를 입력으로 받는다.\n",
    "Decoder_output = Decoder(Reshape_3D_for_decoder)\n",
    "\n",
    "# Decoder에서 출력된 의도벡터를 1회 반복시켜 2D 텐서에서 3D 텐서로 변경한다.\n",
    "Reshape_3D_for_dot = layers.RepeatVector(1,name=\"Reshape_3D_for_dot\")(Decoder_output)\n",
    "\n",
    "\n",
    "##어텐션 메커니즘\n",
    "\n",
    "#normalize = True로 켠 상태에서, 코싸인 유사도를 구할 수 있도록 둘을 내적한다. \n",
    "Cosine_similarity = layers.dot([Reshape_3D_for_dot,attention_matrix],axes = -1,normalize=True,name=\"Cosine_similarity\")\n",
    "\n",
    "#유사도 벡터를 softmax층에 통과시켜 총합이 1인 확률로 변환한다. 이를 attention_score로 명명한다.\n",
    "attention_score_layer = layers.Softmax(axis=-1,name=\"attention_score_from_Softmax\") \n",
    "attention_score = attention_score_layer(Cosine_similarity)\n",
    "\n",
    "#변환된 attention_score를 최초의 attention_matrix)와 각각 내적한다.\n",
    "Transpose_attention_matrix = layers.Permute((2,1),name = \"Transpose_attention_matrix\")(attention_matrix)\n",
    "weighted_attention_matrix = layers.multiply([attention_score,Transpose_attention_matrix],name=\"weighted_attention_matrix\")\n",
    "\n",
    "#내적한 가중 attention_matrix의 열벡터를 모두 더해 1D 텐서인 context vector를 만들어준다.(1 * 128)\n",
    "context_vector = layers.Lambda(lambda x: K.sum(x, axis=-1),name=\"Making_context_vector\")(weighted_attention_matrix)\n",
    "\n",
    "predicts = Dense(13,activation=\"softmax\")(context_vector)\n",
    "\n",
    "GRUs = Model(inputs = [inputs], outputs = [predicts])\n",
    "GRUs.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRUs.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18430 samples, validate on 6144 samples\n",
      "Epoch 1/10\n",
      "18430/18430 [==============================] - 46s 2ms/step - loss: 1.0866 - acc: 0.6467 - val_loss: 1.5181 - val_acc: 0.5295\n",
      "Epoch 2/10\n",
      "18430/18430 [==============================] - 47s 3ms/step - loss: 0.8835 - acc: 0.7150 - val_loss: 1.6682 - val_acc: 0.5221\n",
      "Epoch 3/10\n",
      "18430/18430 [==============================] - 56s 3ms/step - loss: 0.7158 - acc: 0.7695 - val_loss: 1.8597 - val_acc: 0.5160\n",
      "Epoch 4/10\n",
      "18430/18430 [==============================] - 54s 3ms/step - loss: 0.5775 - acc: 0.8195 - val_loss: 2.0442 - val_acc: 0.5086\n",
      "Epoch 5/10\n",
      "18430/18430 [==============================] - 54s 3ms/step - loss: 0.4744 - acc: 0.8509 - val_loss: 2.2808 - val_acc: 0.5010\n",
      "Epoch 6/10\n",
      "18430/18430 [==============================] - 56s 3ms/step - loss: 0.3902 - acc: 0.8806 - val_loss: 2.5020 - val_acc: 0.5020\n",
      "Epoch 7/10\n",
      "18430/18430 [==============================] - 58s 3ms/step - loss: 0.3261 - acc: 0.9010 - val_loss: 2.6269 - val_acc: 0.4956\n",
      "Epoch 8/10\n",
      "18430/18430 [==============================] - 62s 3ms/step - loss: 0.2834 - acc: 0.9124 - val_loss: 2.8101 - val_acc: 0.5024\n",
      "Epoch 9/10\n",
      "18430/18430 [==============================] - 54s 3ms/step - loss: 0.2504 - acc: 0.9237 - val_loss: 2.9921 - val_acc: 0.4938\n",
      "Epoch 10/10\n",
      "18430/18430 [==============================] - 53s 3ms/step - loss: 0.2174 - acc: 0.9346 - val_loss: 3.1181 - val_acc: 0.4985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bebb0d8cf8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRUs.fit(X_train,y_train,epochs=10,batch_size=64,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRUs.save(\"어텐션.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아래부턴 참고용 코드들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "\n",
    "class MyLayer(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this at the end, \n",
    "        #super 함수는 공통의 부모 클래스를 단 한번만 불러오도록 한다.\n",
    "\n",
    "    def call(self, x, y):\n",
    "        bad = tf.matmul(x[0],tf.transpose(y))\n",
    "        good = tf.norm(x[0]) * tf.norm(y)\n",
    "        cossine = bad/good\n",
    "        return cossine\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 생성 \n",
    "encoder_inputs = layers.Input(shape=(max_encoder_seq_length, num_encoder_tokens)) \n",
    "encoder = layers.GRU(latent_dim, return_sequences=True, return_state=True) \n",
    "encoder_outputs, state_h = encoder(encoder_inputs) \n",
    "\n",
    "# 디코더 생성. \n",
    "decoder_inputs = layers.Input(shape=(max_decoder_seq_length, num_decoder_tokens)) \n",
    "decoder = layers.GRU(latent_dim, return_sequences=True, return_state=True) \n",
    "decoder_outputs, _ = decoder(decoder_inputs, initial_state=state_h)\n",
    "\n",
    "# max_encoder_seq_length 등등은 학습 데이터의 개수 \n",
    "\n",
    "repeat_d_layer = RepeatVectorLayer(max_encoder_seq_length, 2) \n",
    "repeat_d = repeat_d_layer(decoder_outputs) \n",
    "\n",
    "repeat_e_layer = RepeatVectorLayer(max_decoder_seq_length, 1) \n",
    "repeat_e = repeat_e_layer(encoder_outputs) \n",
    "\n",
    "## 디코더의 출력과 인코더의 출력을 하나로 합친다.\n",
    "concat_for_score_layer = layers.Concatenate(axis=-1) \n",
    "concat_for_score = concat_for_score_layer([repeat_d, repeat_e]) \n",
    "\n",
    "dense1_t_score_layer = layers.Dense(latent_dim // 2, activation='tanh') \n",
    "dense1_score_layer = layers.TimeDistributed(dense1_t_score_layer) \n",
    "dense1_score = dense1_score_layer(concat_for_score) \n",
    "\n",
    "dense2_t_score_layer = layers.Dense(1) \n",
    "dense2_score_layer = layers.TimeDistributed(dense2_t_score_layer) \n",
    "dense2_score = dense2_score_layer(dense1_score) \n",
    "dense2_score = layers.Reshape((max_decoder_seq_length, max_encoder_seq_length))(dense2_score) \n",
    "\n",
    "softmax_score_layer = layers.Softmax(axis=-1) \n",
    "softmax_score = softmax_score_layer(dense2_score) \n",
    "\n",
    "repeat_score_layer = RepeatVectorLayer(latent_dim, 2) \n",
    "repeat_score = repeat_score_layer(softmax_score) \n",
    "\n",
    "permute_e = layers.Permute((2, 1))(encoder_outputs) \n",
    "repeat_e_layer = RepeatVectorLayer(max_decoder_seq_length, 1) \n",
    "repeat_e = repeat_e_layer(permute_e) \n",
    "\n",
    "attended_mat_layer = layers.Multiply() \n",
    "attended_mat = attended_mat_layer([repeat_score, repeat_e]) \n",
    "\n",
    "context_layer = layers.Lambda(lambda x: K.sum(x, axis=-1), lambda x: tuple(x[:-1])) \n",
    "context = context_layer(attended_mat) \n",
    "\n",
    "concat_context_layer = layers.Concatenate(axis=-1) \n",
    "concat_context = concat_context_layer([context, decoder_outputs]) \n",
    "\n",
    "attention_dense_output_layer = layers.Dense(latent_dim, activation='tanh') \n",
    "attention_output_layer = layers.TimeDistributed(attention_dense_output_layer) \n",
    "attention_output = attention_output_layer(concat_context) \n",
    "\n",
    "decoder_dense = layers.Dense(num_decoder_tokens, activation='softmax') \n",
    "decoder_outputs = decoder_dense(attention_output) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = layers.Reshape((-1,1))(attention_matrix[0][0])\n",
    "b = layers.Reshape((-1,1))(attention_matrix[0][11])\n",
    "aa = layers.dot([a,b],axes=0)\n",
    "bb = layers.dot([a,b],axes=0,normalize = True)\n",
    "tf.map_fn(lambda x : x[0]/x[1],(aa,bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_3d_block(inputs):\n",
    "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what.\n",
    "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
    "    if SINGLE_ATTENTION_VECTOR:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "        a = RepeatVector(input_dim)(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul')\n",
    "    return output_attention_mul\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctivations = LSTM(units, return_sequences=True)(embedded)\n",
    "\n",
    "# compute importance for each step\n",
    "attention = Dense(1, activation='tanh')(activations)\n",
    "attention = Flatten()(attention)\n",
    "attention = Activation('softmax')(attention)\n",
    "attention = RepeatVector(units)(attention)\n",
    "attention = Permute([2, 1])(attention)\n",
    "\n",
    "sent_representation = merge([activations, attention], mode='mul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input = Input(shape=[3,3], dtype='int32')\n",
    "\n",
    "# get the embedding layer\n",
    "embedded = Embedding(\n",
    "        input_dim = 50,\n",
    "        output_dim=40,\n",
    "        trainable=False,\n",
    "        mask_zero=False\n",
    "    )(_input)\n",
    "\n",
    "activations = LSTM(units, return_sequences=True)(embedded)\n",
    "\n",
    "# compute importance for each step\n",
    "attention = Dense(1, activation='tanh')(activations)\n",
    "attention = Flatten()(attention)\n",
    "attention = Activation('softmax')(attention)\n",
    "attention = RepeatVector(units)(attention)\n",
    "attention = Permute([2, 1])(attention)\n",
    "\n",
    "\n",
    "sent_representation = merge([activations, attention], mode='mul')\n",
    "sent_representation = Lambda(lambda xin: K.sum(xin, axis=-2), output_shape=(units,))(sent_representation)\n",
    "\n",
    "probabilities = Dense(3, activation='softmax')(sent_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=[50])\n",
    "embed = Embedding(6000,128,input_length = 50)(inputs)\n",
    "model = Dropout(0.2)(embed)\n",
    "model = Conv1D(256,3,padding=\"valid\",activation=\"relu\",strides=1)(model)\n",
    "model = MaxPooling1D(pool_size = 4)(model)\n",
    "model = MyLayer(model.shape).call(model)\n",
    "\n",
    "Model(inputs = [inputs],outputs = [model])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensorflow35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
