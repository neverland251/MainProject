{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Layer\n",
    "from keras.layers import Input,Dense,Flatten,Embedding,Permute,Dot,Reshape\n",
    "from keras.layers.convolutional import Conv1D,MaxPooling1D,MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM,GRU\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "import copy\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#탑재용 모듈\n",
    "\n",
    "GRUs_weight = load_model(\"chatbot-attention_weight.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRU 입력 전 사전처리 모듈(임베딩 -> 컨볼루션 -> 맥스풀링)\n",
    "\n",
    "inputs_s = layers.Input(shape=[50],name = \"Feed_Sentence\")\n",
    "inputs_z = layers.Input(shape = [1],name = \"Feed_Zero\")\n",
    "inputs_u = layers.Input(shape = [128],name = \"Feed_User\")\n",
    "#inputs_t = layers.Input(shape = [1],name = \"Temporaily_Input\")\n",
    "\n",
    "embed = layers.Embedding(51073,128)\n",
    "\n",
    "embed_i = embed(inputs_s)\n",
    "embed_z = embed(inputs_z)\n",
    "#embed_t = embed(inputs_t)\n",
    "inputs_r = layers.Reshape((1,-1))(inputs_u)\n",
    "embed_o = layers.Concatenate(axis=1,name=\"embed_o_Doubled\")([embed_z,inputs_r])\n",
    "\n",
    "model = layers.Dropout(0.2)(embed_i)\n",
    "model = layers.Conv1D(256,3,padding=\"valid\",activation=\"relu\",strides=1)(model)\n",
    "model = layers.MaxPooling1D(pool_size = 4)(model)\n",
    "\n",
    "#Bi-GRU 인코더 - 디코더 네트워크\n",
    "Encoder1 = layers.GRU(128,return_sequences = True,return_state = True,name=\"Encoder1\")\n",
    "Encoder2 = layers.GRU(128,return_sequences = True,return_state = True,go_backwards = True,name=\"Encoder2\")\n",
    "attention_matrix1,initial_1 = Encoder1(model)\n",
    "attention_matrix2,initial_2 = Encoder2(model)\n",
    "attention_matrix = layers.Concatenate(axis=-1,name = \"attention_matrix\")([attention_matrix1,attention_matrix2])\n",
    "\n",
    "\n",
    "Decoder1 = layers.GRU(128,return_sequences = True,name=\"Decoder1\")\n",
    "Decoder2 = layers.GRU(128,return_sequences = True,name=\"Decoder2\")\n",
    "\n",
    "Decoder1_output = Decoder1(embed_o,initial_state = initial_1)\n",
    "Decoder2_output = Decoder2(embed_o,initial_state = initial_1)\n",
    "\n",
    "Decoder_output = layers.Concatenate(axis=-1,name=\"Decoder_output\")([Decoder1_output,Decoder2_output])\n",
    "\n",
    "\n",
    "##어텐션 메커니즘 부분\n",
    "\n",
    "#normalize = True로 켠 상태에서, 코싸인 유사도를 구할 수 있도록 둘을 내적한다.  \n",
    "Cosine_similarity = layers.dot([Decoder_output,attention_matrix],axes = -1,normalize=True,name=\"Cosine_similarity\")\n",
    "\n",
    "#유사도 벡터를 softmax층에 통과시켜 총합이 1인 확률로 변환한다. 이를 attention_score로 명명한다.\n",
    "attention_score_layer = layers.Softmax(axis=-1,name=\"attention_score_from_Softmax\") \n",
    "attention_score = attention_score_layer(Cosine_similarity)\n",
    "\n",
    "#Softmax 변환된 attention_score를 최초의 attention_matrix와 각각 내적한다.\n",
    "#Transpose_attention_matrix = layers.Permute((2,1),name = \"Transpose_attention_matrix\")(attention_matrix)\n",
    "weighted_attention_matrix = layers.Lambda(lambda x: K.dot(x[0],x[1]),name=\"weighted_attention_matrix\")([attention_score,attention_matrix])\n",
    "#weighted_attention_matrix = layers.multiply([attention_score,Transpose_attention_matrix],name=\"weighted_attention_matrix\")\n",
    "\n",
    "#확률과 내적한 가중 attention_matrix의 열벡터를 모두 더해 1D 텐서인 context vector를 만들어준다.(1 * 256)\n",
    "context_vector = layers.Lambda(lambda x: K.sum(x, axis=2),name=\"Making_context_vector\")(weighted_attention_matrix)\n",
    "#context_vector_reshape = layers.Reshape((1,-1),name=\"Reshape_to_3D_tensor\")(context_vector)\n",
    "\n",
    "concat = layers.Concatenate(axis=-1,name = \"Concatenate_Decoder_O_and_Context_Vector\")([Decoder_output,context_vector])\n",
    "\n",
    "Feed_forward = layers.Dense(512,activation = \"tanh\",name=\"Feed_forward\")\n",
    "finally_output = Feed_forward(concat)\n",
    "\n",
    "predicts = layers.Dense(21,activation=\"softmax\")(finally_output)\n",
    "\n",
    "GRUs = Model(inputs = [inputs_s,inputs_z,inputs_u], outputs = [predicts])\n",
    "\n",
    "GRUs.layers[2].set_weights(GRUs_weight.layers[2].get_weights())\n",
    "GRUs.layers[5].set_weights(GRUs_weight.layers[4].get_weights())\n",
    "GRUs.layers[9].set_weights(GRUs_weight.layers[6].get_weights())\n",
    "GRUs.layers[10].set_weights(GRUs_weight.layers[8].get_weights())\n",
    "GRUs.layers[11].set_weights(GRUs_weight.layers[9].get_weights())\n",
    "GRUs.layers[12].set_weights(GRUs_weight.layers[7].get_weights())\n",
    "GRUs.layers[20].set_weights(GRUs_weight.layers[17].get_weights())\n",
    "GRUs.layers[21].set_weights(GRUs_weight.layers[18].get_weights())\n",
    "\n",
    "GRUs = Model(inputs = [inputs_s,inputs_z,inputs_u], outputs = [predicts])\n",
    "\n",
    "GRUs.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Feed_Zero (InputLayer)          (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Feed_Sentence (InputLayer)      (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         multiple             6537344     Feed_Sentence[0][0]              \n",
      "                                                                 Feed_Zero[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 50, 128)      0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Feed_User (InputLayer)          (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 48, 256)      98560       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 1, 128)       0           Feed_User[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 12, 256)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embed_o_Doubled (Concatenate)   (None, 2, 128)       0           embedding_3[1][0]                \n",
      "                                                                 reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder1 (GRU)                  [(None, 12, 128), (N 147840      max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder1 (GRU)                  (None, 2, 128)       98688       embed_o_Doubled[0][0]            \n",
      "                                                                 Encoder1[0][1]                   \n",
      "__________________________________________________________________________________________________\n",
      "Decoder2 (GRU)                  (None, 2, 128)       98688       embed_o_Doubled[0][0]            \n",
      "                                                                 Encoder1[0][1]                   \n",
      "__________________________________________________________________________________________________\n",
      "Encoder2 (GRU)                  [(None, 12, 128), (N 147840      max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_output (Concatenate)    (None, 2, 256)       0           Decoder1[0][0]                   \n",
      "                                                                 Decoder2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_matrix (Concatenate)  (None, 12, 256)      0           Encoder1[0][0]                   \n",
      "                                                                 Encoder2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Cosine_similarity (Dot)         (None, 2, 12)        0           Decoder_output[0][0]             \n",
      "                                                                 attention_matrix[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_score_from_Softmax (S (None, 2, 12)        0           Cosine_similarity[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "weighted_attention_matrix (Lamb (None, 2, None, 256) 0           attention_score_from_Softmax[0][0\n",
      "                                                                 attention_matrix[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Making_context_vector (Lambda)  (None, 2, 256)       0           weighted_attention_matrix[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Concatenate_Decoder_O_and_Conte (None, 2, 512)       0           Decoder_output[0][0]             \n",
      "                                                                 Making_context_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Feed_forward (Dense)            (None, 2, 512)       262656      Concatenate_Decoder_O_and_Context\n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2, 21)        10773       Feed_forward[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 7,402,389\n",
      "Trainable params: 7,402,389\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(GRUs.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRUs.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow36\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer Decoder1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder1_4/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow36\\lib\\site-packages\\keras\\engine\\network.py:877: UserWarning: Layer Decoder2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder1_4/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "GRUs.save(\"chatbot-attention_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRUs = load_model(\"chatbot-attention_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.0303174 , -0.0213085 ,  0.0019703 , ..., -0.02288671,\n",
       "         -0.02295696, -0.05190272],\n",
       "        [ 0.07569548,  0.27911955,  0.05175299, ...,  0.05739416,\n",
       "         -0.00316349,  0.04695879],\n",
       "        [-0.16778913, -0.08834887, -0.06079618, ...,  0.0291816 ,\n",
       "         -0.04476504, -0.04778985],\n",
       "        ...,\n",
       "        [ 0.07109351,  0.1989654 , -0.00821792, ..., -0.03577812,\n",
       "          0.03068705,  0.03101453],\n",
       "        [ 0.02721507,  0.02536437,  0.03441622, ..., -0.03613219,\n",
       "         -0.03495681,  0.03053501],\n",
       "        [ 0.00539215,  0.04771877,  0.04503161, ..., -0.01801592,\n",
       "         -0.04148867,  0.02972487]], dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRUs.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.0303174 , -0.0213085 ,  0.0019703 , ..., -0.02288671,\n",
       "         -0.02295696, -0.05190272],\n",
       "        [ 0.07569548,  0.27911955,  0.05175299, ...,  0.05739416,\n",
       "         -0.00316349,  0.04695879],\n",
       "        [-0.16778913, -0.08834887, -0.06079618, ...,  0.0291816 ,\n",
       "         -0.04476504, -0.04778985],\n",
       "        ...,\n",
       "        [ 0.07109351,  0.1989654 , -0.00821792, ..., -0.03577812,\n",
       "          0.03068705,  0.03101453],\n",
       "        [ 0.02721507,  0.02536437,  0.03441622, ..., -0.03613219,\n",
       "         -0.03495681,  0.03053501],\n",
       "        [ 0.00539215,  0.04771877,  0.04503161, ..., -0.01801592,\n",
       "         -0.04148867,  0.02972487]], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRUs_weight.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor36",
   "language": "python",
   "name": "tensorflow36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
