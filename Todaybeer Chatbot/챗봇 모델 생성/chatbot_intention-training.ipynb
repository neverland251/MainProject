{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Layer\n",
    "from keras.layers import Input,Dense,Flatten,Embedding,Permute,Dot,Reshape\n",
    "from keras.layers.convolutional import Conv1D,MaxPooling1D,MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM,GRU\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토큰화 파일을 불러온다.\n",
    "\n",
    "rawdata = pd.read_csv(\"tokenize.csv\",engine=\"python\",encoding = \"cp949\")\n",
    "\n",
    "morphs = list()\n",
    "\n",
    "for i in range(0,len(rawdata)):\n",
    "    morphs.append(list(rawdata.loc[i,:].dropna()))\n",
    "\n",
    "del morphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#색인 사전을 불러온다.\n",
    "\n",
    "morphsVectored = list()\n",
    "\n",
    "\n",
    "vocabulary = pd.read_csv(\"dictionary.csv\",engine=\"python\",encoding=\"cp949\")\n",
    "#del vocabulary[\"Unnamed: 0\"]\n",
    "\n",
    "vocabulary = vocabulary.to_dict(orient=\"records\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviews</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>98년생들에게 추천하는 맛있는 맥주 \\n\\n1. 브르클린 라거\\n2. 펑크 IPA\\...</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>퇴근 후 아내가 차려준 주안상과 함께하는 듀벨~\\n\\n#beer #belgian #...</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>.\\n오랜만에 새로운 맥주 입고!\\n개인적으로 가장 좋아하는 #IPA #스컬핀 뉴시...</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>스타ㅏㅏㅏ듀벨ㄹㄹ리이ㅣ이ㅣㅣ이ㅣㅣㅣ!!!!!!!!!~!~~!~!~!~!~!~!~!!...</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>듀벨 트리플홉 2017이 입고됐습니다. 듀벨은 매년 기존 두 가지 홉 외에 하나를 ...</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            reviews   source\n",
       "0           0  98년생들에게 추천하는 맛있는 맥주 \\n\\n1. 브르클린 라거\\n2. 펑크 IPA\\...  twitter\n",
       "1           1  퇴근 후 아내가 차려준 주안상과 함께하는 듀벨~\\n\\n#beer #belgian #...  twitter\n",
       "2           2  .\\n오랜만에 새로운 맥주 입고!\\n개인적으로 가장 좋아하는 #IPA #스컬핀 뉴시...  twitter\n",
       "3           3  스타ㅏㅏㅏ듀벨ㄹㄹ리이ㅣ이ㅣㅣ이ㅣㅣㅣ!!!!!!!!!~!~~!~!~!~!~!~!~!!...  twitter\n",
       "4           4  듀벨 트리플홉 2017이 입고됐습니다. 듀벨은 매년 기존 두 가지 홉 외에 하나를 ...  twitter"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#원본 데이터셋을 불러온다.\n",
    "\n",
    "a = pd.read_csv(\"beer.csv\",engine=\"python\",encoding=\"cp949\")\n",
    "a = a[a[\"reviews\"].duplicated() == False]\n",
    "a = a.reset_index()\n",
    "\n",
    "del a[\"index\"]\n",
    "del a[\"target\"]\n",
    "\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터셋에서 source가 \"r\"인것, 즉 리뷰사이트인 ratebeer에서 가져온것이면 \"정보성(informational_index)\"로, 그 외에는 \n",
    "##\"감정성\"(emotional_index)로 각각 타겟변수로 재 설정한다.\n",
    "## 향후 재 활용때도, 정보성 데이터셋은 \"r\"로 설정하면 학습이 가능하다.\n",
    "\n",
    "informational_index = a[a[\"source\"] == \"r\"].index\n",
    "emotional_index = a[a[\"source\"] != \"r\"].index\n",
    "\n",
    "information_intent = Series([0 for i in range(0,len(informational_index))],index = informational_index)\n",
    "emotional_intent = Series([1 for i in range(0,len(emotional_index))],index = emotional_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.concat([information_intent,emotional_intent],axis=0).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#로드한 토큰화 파일에서, 색인사전을 검색하여 토큰화 문장을 숫자 문장으로 바꿔준다.\n",
    "\n",
    "for i in morphs:\n",
    "    temporailyList = list()\n",
    "    for k in i:\n",
    "        #print(k)\n",
    "        try:\n",
    "            temporailyList.append(vocabulary[k])\n",
    "        except KeyError:\n",
    "            temporailyList.append(0)\n",
    "    morphsVectored.append(temporailyList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_seq = sequence.pad_sequences(morphsVectored,maxlen = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(vectorized_seq, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(vocabulary)+1,128,input_length = 50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(256,3,padding=\"valid\",activation=\"relu\",strides=1))\n",
    "model.add(MaxPooling1D(pool_size = 4))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(2,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 50, 128)           6537344   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 48, 256)           98560     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 12, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 6,833,282\n",
      "Trainable params: 6,833,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SVG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-910ad525e845>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mSVG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"dot\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"svg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'SVG' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "SVG(model_to_dot(model,show_shapes=True).create(prog=\"dot\",format=\"svg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50487 samples, validate on 16829 samples\n",
      "Epoch 1/5\n",
      "50487/50487 [==============================] - 86s 2ms/step - loss: 0.2709 - acc: 0.8815 - val_loss: 0.2353 - val_acc: 0.8951\n",
      "Epoch 2/5\n",
      "50487/50487 [==============================] - 84s 2ms/step - loss: 0.1671 - acc: 0.9286 - val_loss: 0.2401 - val_acc: 0.8979\n",
      "Epoch 3/5\n",
      "50487/50487 [==============================] - 84s 2ms/step - loss: 0.1063 - acc: 0.9544 - val_loss: 0.3278 - val_acc: 0.8957\n",
      "Epoch 4/5\n",
      "50487/50487 [==============================] - 84s 2ms/step - loss: 0.0721 - acc: 0.9699 - val_loss: 0.3472 - val_acc: 0.8857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2393ec4d2b0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train,y_train,epochs=5,batch_size = 64,validation_data = (X_test,y_test),callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"chatbot-intention.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor36",
   "language": "python",
   "name": "tensorflow36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
