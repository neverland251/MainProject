{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchWindowException\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains as AC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "from pandas import Series,DataFrame\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import csv\n",
    "\n",
    "from time import sleep\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Layer\n",
    "from keras.layers import Input,Dense,Flatten,Embedding,Permute,Dot,Reshape\n",
    "from keras.layers.convolutional import Conv1D,MaxPooling1D,MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM,GRU\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import function\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "\n",
    "import scipy\n",
    "from scipy.sparse import dok_matrix\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import re\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "import copy\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Komoran\n",
    "from konlpy.tag import Kkma\n",
    "\n",
    "Okt = Okt()\n",
    "Kom = Komoran()\n",
    "Kkma = Kkma()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비 및 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 데이터 LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "list_dir = os.listdir(\"C:/Users/23/Desktop/Project/코로나/데이터/\")\n",
    "file_list = np.array(list_dir)[np.where(DataFrame(list(Series(list_dir).apply(lambda x : x.split(\".\"))))[[3]] == \"txt\")[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rawdata = DataFrame()\n",
    "\n",
    "for i in file_list:\n",
    "    texts = Series()\n",
    "    with open(\"C:/Users/23/Desktop/Project/코로나/데이터/\" + str(i) ,encoding = \"utf-8\") as text:\n",
    "        for line in text:\n",
    "            texts = pd.concat([texts, Series(line).str.rsplit(\"\\t\")])\n",
    "            columns = [\"DATE\", \"PRESS\", \"TITLE\", \"TEXT\"]\n",
    "            col_length = DataFrame(list(pd.concat([texts, Series(line).str.rsplit(\"\\t\")]))).shape[1]\n",
    "            columns.extend([i for i in range(0 , (col_length - 4))])\n",
    "        texts = DataFrame(list(texts.reset_index(drop = True)),columns = columns).iloc[:,0:4]\n",
    "        rawdata = pd.concat([rawdata, texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = rawdata[\"TEXT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = rawdata[\"TITLE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_for_vocabulary = pd.concat([text,target])\n",
    "##texts_for_vocuabulary= text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vect_tokenizer(text):\n",
    "    return Kom.nouns(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 색인사전 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = texts_for_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "있는 색인사전을 쓸까요(0), 아님 신규로 만들까요(1)0\n"
     ]
    }
   ],
   "source": [
    "## CountVectorizer로 문자 : 숫자로 이루어진 색인 사전을 만든다.\n",
    "## 이미 만들어진 색인사전을 이용해도 됩니다.\n",
    "\n",
    "zero_or_one = input(\"있는 색인사전을 쓸까요(0), 아님 신규로 만들까요(1)\")\n",
    "\n",
    "if zero_or_one == \"1\":\n",
    "    vect = CountVectorizer(tokenizer = vect_tokenizer ,min_df = 1, analyzer = \"word\")\n",
    "    vect.fit(text)\n",
    "    vocabulary = vect.vocabulary_\n",
    "    vocabulary['CLS'] = len(vocabulary) + 1\n",
    "    vocabulary['EOS'] = len(vocabulary) + 1\n",
    "    DataFrame([vect.vocabulary_]).to_csv(\"색인사전.csv\",encoding=\"utf-8\",index=False)\n",
    "if zero_or_one == \"0\":\n",
    "    vocabulary = pd.read_csv(\"색인사전.csv\",engine=\"python\",encoding=\"utf-8\")\n",
    "    vocabulary = vocabulary.to_dict(orient=\"records\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 문장  토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "있는 벡터화 쓸까요(0), 아님 신규로 만들까요(1)0\n"
     ]
    }
   ],
   "source": [
    "zero_or_one = input(\"있는 벡터화 쓸까요(0), 아님 신규로 만들까요(1)\")\n",
    "\n",
    "morphsVectored = list()\n",
    "\n",
    "if zero_or_one == \"1\":\n",
    "\n",
    "    ## 다시 형태소 분석기를 돌려서, text의 문장을 형태소로 분해하여 morphs에 담는다.\n",
    "    ## 시간이 오래 걸립니다. 5분정도\n",
    "\n",
    "    morphs = list()\n",
    "\n",
    "    for i in text:\n",
    "        temp = Kom.nouns(i)\n",
    "        temp.insert(0,'CLS')\n",
    "        temp.append(\"EOS\")\n",
    "        morphs.append(temp)\n",
    "        \n",
    "    for i in morphs:\n",
    "        temporailyList = list()\n",
    "        for k in i:\n",
    "            #print(k)\n",
    "            try:\n",
    "                temporailyList.append(vocabulary[k])\n",
    "            except KeyError:\n",
    "                temporailyList.append(0)\n",
    "        morphsVectored.append(temporailyList)\n",
    "\n",
    "    DataFrame(morphsVectored).to_csv(\"벡터화.csv\",index=False,encoding=\"utf-8\")\n",
    "\n",
    "if zero_or_one == \"0\" :\n",
    "    morphsVectored = list()\n",
    "    rawdata = pd.read_csv(\"벡터화.csv\",engine=\"python\",encoding =\" utf-8\")\n",
    "\n",
    "    for i in range(0,len(rawdata)):\n",
    "        morphsVectored.append(list(rawdata.loc[i,:].dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "\n",
    "length_1 = DataFrame()\n",
    "\n",
    "for i,j in enumerate(np.array(morphsVectored[1 : (int(len(morphsVectored) / 2))])):\n",
    "    good = DataFrame([len(j)],index=[i])\n",
    "    length_1 = pd.concat([length_1,good],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = length_1.hist()\n",
    "plt.show(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "\n",
    "length_1 = DataFrame()\n",
    "\n",
    "for i,j in enumerate(np.array(morphsVectored[(int(len(morphsVectored) / 2)) + 1 : len(morphsVectored)])):\n",
    "    good = DataFrame([len(j)],index=[i])\n",
    "    length_1 = pd.concat([length_1,good],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = length_1.hist()\n",
    "plt.show(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text classification\n",
    "target = pd.get_dummies(DataFrame(target)).reset_index(drop = True)\n",
    "\n",
    "input_1 = sequence.pad_sequences(morphsVectored ,maxlen = 70)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_1, target ,test_size=0.25)\n",
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text generating\n",
    "\n",
    "input_1 = sequence.pad_sequences(morphsVectored[1 : (int(len(morphsVectored) / 2))],maxlen = 1000,\n",
    "                                padding = 'post',\n",
    "                                truncating = 'post')\n",
    "\n",
    "input_2 = sequence.pad_sequences(morphsVectored[(int(len(morphsVectored) / 2)) + 1 : len(morphsVectored)],maxlen = 20,\n",
    "                                 padding = 'post',\n",
    "                                truncating = 'post')\n",
    "\n",
    "X_train_1,X_val_1,X_train_2,X_val_2 = train_test_split(input_1, input_2 ,test_size=0.25)\n",
    "#y_train = np_utils.to_categorical(y_train)\n",
    "#y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "dummies_temp = DataFrame(columns = [i for i in range(1,len(vocabulary) + 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positioning Encoding 생성 함수\n",
    "\n",
    "def get_timing_signal_1d(length,\n",
    "                         channels,\n",
    "                         min_timescale=1.0,\n",
    "                         max_timescale=1.0e4,\n",
    "                         start_index=0):\n",
    "    position = tf.cast(tf.range(length) + start_index,dtype=tf.float32)\n",
    "    num_timescales = channels // 2\n",
    "    log_timescale_increment = (\n",
    "        math.log(float(max_timescale) / float(min_timescale)) /\n",
    "        (tf.cast(num_timescales, dtype=tf.float32) - 1))\n",
    "    inv_timescales = min_timescale * tf.exp(\n",
    "        tf.cast(tf.range(num_timescales),dtype=tf.float32) * -log_timescale_increment)\n",
    "    scaled_time = tf.expand_dims(position, 1) * tf.expand_dims(inv_timescales, 0)\n",
    "    signal = tf.concat([tf.sin(scaled_time), tf.cos(scaled_time)], axis=1)\n",
    "    signal = tf.pad(signal, [[0, 0], [0, tf.math.floormod(channels, 2)]])\n",
    "    signal = tf.reshape(signal, [1, length, channels])\n",
    "    return signal\n",
    "\n",
    "# 패딩 마스크 생성 함수\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "#미리보기 마스크 생성 함수\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    # 단어 순서에 따라 상삼각행렬을 만들어준다.\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_classification\n",
    "\n",
    "multi_head_num = 8\n",
    "encoder_num = 5\n",
    "decoder_num = 5\n",
    "vocab_size = len(vocabulary) + 1\n",
    "target_size = target.shape[1]\n",
    "embedding_dim = 300\n",
    "dense_dim = 100\n",
    "\n",
    "sen_len_1 = input_1[0].shape[0]\n",
    "sen_len_2 = input_1[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_generating\n",
    "\n",
    "multi_head_num = 8\n",
    "encoder_num = 3\n",
    "decoder_num = 3\n",
    "vocab_size = len(vocabulary) + 1\n",
    "target_size = len(vocabulary) + 1\n",
    "embedding_dim = 300\n",
    "dense_dim = 100\n",
    "\n",
    "sen_len_1 = input_1[0].shape[0]\n",
    "sen_len_2 = input_2[0].shape[0] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)입력 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input_1 ##\n",
    "\n",
    "input_vec_1 = layers.Input([sen_len_1])\n",
    "c_embedding = layers.Embedding(vocab_size, embedding_dim)(input_vec_1)\n",
    "\n",
    "position_encoding = layers.Lambda(lambda x : \n",
    "                                      get_timing_signal_1d(length = int(x.shape[1]), \n",
    "                                                           channels = int(x.shape[2])))(c_embedding)\n",
    "\n",
    "c_embedding = layers.Lambda(lambda x :\n",
    "                           x[0] + x[1])([c_embedding,position_encoding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input_2 ##\n",
    "\n",
    "input_vec_2 = layers.Input([sen_len_2])\n",
    "o_embedding = layers.Embedding(vocab_size, embedding_dim)(input_vec_2)\n",
    "\n",
    "position_encoding = layers.Lambda(lambda x : \n",
    "                                      get_timing_signal_1d(length = int(x.shape[1]), \n",
    "                                                           channels = int(x.shape[2])))(o_embedding)\n",
    "    \n",
    "o_embedding = layers.Lambda(lambda x :\n",
    "                           x[0] + x[1])([o_embedding,position_encoding])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Transformer 모델 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1)encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, encoder_num):\n",
    "    print(i)\n",
    "\n",
    "    if i == 0:\n",
    "        queries = layers.Dense(dense_dim)(c_embedding)\n",
    "        keys = layers.Dense(dense_dim)(c_embedding)\n",
    "        values = layers.Dense(dense_dim)(c_embedding)\n",
    "        \n",
    "        query_key = layers.Dot(axes = 2)([queries,keys])\n",
    "        query_key = layers.Lambda(lambda x: (x / np.sqrt(dense_dim)))(query_key)\n",
    "        query_key = layers.Softmax()(query_key)\n",
    "        \n",
    "        query_key = layers.Lambda(lambda x : x + (create_padding_mask(input_vec_1) * (-1e9)))(query_key)\n",
    "        \n",
    "        attention = layers.Dot(axes=1)([query_key,values])\n",
    "        \n",
    "        for j in range(0 ,(multi_head_num - 1)):\n",
    "            queries_n = layers.Dense(dense_dim)(c_embedding)\n",
    "            keys_n = layers.Dense(dense_dim)(c_embedding)\n",
    "            values_n = layers.Dense(dense_dim)(c_embedding)\n",
    "\n",
    "            query_key_n = layers.Dot(axes = 2)([queries_n,keys_n])\n",
    "            query_key_n = layers.Lambda(lambda x: (x / np.sqrt(dense_dim)))(query_key_n)\n",
    "            query_key_n = layers.Softmax()(query_key_n)\n",
    "            \n",
    "            query_key_n = layers.Lambda(lambda x : x + (create_padding_mask(input_vec_1) * (-1e9)))(query_key_n)\n",
    "\n",
    "            attention_n = layers.Dot(axes=1)([query_key_n,values_n])\n",
    "\n",
    "            attention = layers.Concatenate()([attention,attention_n])\n",
    "            \n",
    "        attention_head = layers.Dense(embedding_dim)(attention)\n",
    "\n",
    "        encoder_resnet = layers.Add()([c_embedding,attention_head])\n",
    "        encoder_resnet = layers.BatchNormalization()(encoder_resnet)\n",
    "\n",
    "        encoder_output_resnet = layers.Dense(embedding_dim)(encoder_resnet)\n",
    "        encoder_output_resnet = layers.Add()([encoder_output_resnet, encoder_resnet])\n",
    "        encoder_output_resnet = layers.BatchNormalization()(encoder_output_resnet)\n",
    "        \n",
    "    else :\n",
    "        \n",
    "        quries = layers.Dense(dense_dim)(encoder_output_resnet)\n",
    "        keys = layers.Dense(dense_dim)(encoder_output_resnet)\n",
    "        values = layers.Dense(dense_dim)(encoder_output_resnet)\n",
    "\n",
    "        query_key = layers.Dot(axes = 2)([queries,keys])\n",
    "        query_key = layers.Lambda(lambda x: (x / np.sqrt(dense_dim)))(query_key)\n",
    "        query_key = layers.Softmax()(query_key)\n",
    "        \n",
    "        query_key = layers.Lambda(lambda x : x + (create_padding_mask(input_vec_1) * (-1e9)))(query_key)\n",
    "\n",
    "        attention = layers.Dot(axes=1)([query_key,values])\n",
    "\n",
    "        for j in range(0 ,(multi_head_num - 1)):\n",
    "            queries_n = layers.Dense(dense_dim)(encoder_output_resnet)\n",
    "            keys_n = layers.Dense(dense_dim)(encoder_output_resnet)\n",
    "            values_n = layers.Dense(dense_dim)(encoder_output_resnet)\n",
    "\n",
    "            query_key_n = layers.Dot(axes = 2)([queries_n,keys_n])\n",
    "            query_key_n = layers.Lambda(lambda x: (x / np.sqrt(dense_dim)))(query_key_n)\n",
    "            query_key_n = layers.Softmax()(query_key_n)\n",
    "            \n",
    "            query_key_n = layers.Lambda(lambda x : x + (create_padding_mask(input_vec_1) * (-1e9)))(query_key_n)\n",
    "\n",
    "            attention_n = layers.Dot(axes=1)([query_key_n,values_n])\n",
    "\n",
    "            attention = layers.Concatenate()([attention,attention_n])\n",
    "\n",
    "        attention_head = layers.Dense(embedding_dim)(attention)\n",
    "\n",
    "        encoder_resnet = layers.Add()([encoder_output_resnet,attention_head])\n",
    "        encoder_resnet = layers.BatchNormalization()(encoder_resnet)\n",
    "\n",
    "        encoder_output_resnet = layers.Dense(embedding_dim)(encoder_resnet)\n",
    "        encoder_output_resnet = layers.Add()([encoder_output_resnet, encoder_resnet])\n",
    "        encoder_output_resnet = layers.BatchNormalization()(encoder_output_resnet)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    " for i in range(0, decoder_num):\n",
    "    \n",
    "    print(i)    \n",
    "    \n",
    "    ## first floor decoder\n",
    "    \n",
    "    if i == 0 :    \n",
    "        queries = layers.Dense(dense_dim)(o_embedding)\n",
    "        keys = layers.Dense(dense_dim)(o_embedding)\n",
    "        values = layers.Dense(dense_dim)(o_embedding)\n",
    "\n",
    "        query_key = layers.Dot(axes = 2)([keys,queries])\n",
    "        query_key = layers.Lambda(lambda x: (x / np.sqrt(dense_dim)))(query_key)\n",
    "        query_key = layers.Softmax()(query_key)\n",
    "        \n",
    "        combined_mask = tf.maximum((create_look_ahead_mask(input_vec_2.shape[1]) * (-1e9)), \n",
    "                   (create_padding_mask(input_vec_2) * (-1e9)))\n",
    "        \n",
    "        query_key = layers.Lambda(lambda x : x + combined_mask)(query_key)\n",
    "        \n",
    "        attention = layers.Dot(axes=1)([query_key,values])\n",
    "        \n",
    "        for j in range(0 ,(multi_head_num - 1)):\n",
    "            \n",
    "            queries_n = layers.Dense(dense_dim)(o_embedding)\n",
    "            keys_n = layers.Dense(dense_dim)(o_embedding)\n",
    "            values_n = layers.Dense(dense_dim)(o_embedding)\n",
    "\n",
    "            query_key_n = layers.Dot(axes = 2)([keys_n,queries_n])\n",
    "            query_key_n = layers.Lambda(lambda x: (x / np.sqrt(dense_dim)))(query_key_n)\n",
    "            query_key_n = layers.Softmax()(query_key_n)\n",
    "            \n",
    "            query_key_n = layers.Lambda(lambda x : x + combined_mask)(query_key_n)\n",
    "\n",
    "            attention_n = layers.Dot(axes=1)([query_key_n,values_n])\n",
    "\n",
    "            attention = layers.Concatenate()([attention,attention_n])\n",
    "\n",
    "        attention_head = layers.Dense(embedding_dim)(attention)\n",
    "\n",
    "        decoder_resnet = layers.Add()([o_embedding,attention_head])\n",
    "        decoder_resnet = layers.BatchNormalization()(decoder_resnet)\n",
    "\n",
    "        decoder_output_resnet = layers.Dense(embedding_dim)(decoder_resnet)\n",
    "        decoder_output_resnet = layers.Add()([decoder_output_resnet, decoder_resnet])\n",
    "        decoder_output_resnet = layers.BatchNormalization()(decoder_output_resnet)\n",
    "        \n",
    "        queries = layers.Dense(dense_dim)(decoder_output_resnet)\n",
    "        keys = layers.Dense(dense_dim)(encoder_output_resnet)\n",
    "        values = layers.Dense(dense_dim)(encoder_output_resnet)\n",
    "        \n",
    "        query_key = layers.Dot(axes = 2)([keys,queries])\n",
    "        query_key = layers.Lambda(lambda x: (x / np.sqrt(dense_dim)))(query_key)\n",
    "        query_key = layers.Softmax()(query_key)\n",
    "        \n",
    "        query_key = layers.Lambda(lambda x : x + (create_padding_mask(input_vec_2) * (-1e9)))(query_key)\n",
    "\n",
    "        attention = layers.Dot(axes=1)([query_key,values])\n",
    "\n",
    "        for j in range(0 ,(multi_head_num - 1)):\n",
    "            queries_n = layers.Dense(dense_dim)(decoder_output_resnet)\n",
    "            keys_n = layers.Dense(dense_dim)(encoder_output_resnet)\n",
    "            values_n = layers.Dense(dense_dim)(encoder_output_resnet)\n",
    "\n",
    "            query_key_n = layers.Dot(axes = 2)([keys_n,queries_n])\n",
    "            query_key_n = layers.Lambda(lambda x: (x / np.sqrt(dense_dim)))(query_key_n)\n",
    "            query_key_n = layers.Softmax()(query_key_n)\n",
    "            \n",
    "            query_key_n = layers.Lambda(lambda x : x + (create_padding_mask(input_vec_2) * (-1e9)))(query_key_n)\n",
    "\n",
    "            attention_n = layers.Dot(axes=1)([query_key_n,values_n])\n",
    "\n",
    "            attention = layers.Concatenate()([attention,attention_n])\n",
    "\n",
    "        attention_head = layers.Dense(embedding_dim)(attention)\n",
    "\n",
    "        decoder_resnet = layers.Add()([decoder_output_resnet,attention_head])\n",
    "        decoder_resnet = layers.BatchNormalization()(decoder_resnet)\n",
    "\n",
    "        decoder_output_resnet = layers.Dense(embedding_dim)(decoder_resnet)\n",
    "        decoder_output_resnet = layers.Add()([decoder_output_resnet, decoder_resnet])\n",
    "        decoder_output_resnet = layers.BatchNormalization()(decoder_output_resnet)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "              ## n-th floor decoder  \n",
    "        \n",
    "        queries = layers.Dense(dense_dim)(decoder_output_resnet)\n",
    "        keys = layers.Dense(dense_dim)(decoder_output_resnet)\n",
    "        values = layers.Dense(dense_dim)(decoder_output_resnet)\n",
    "\n",
    "        query_key = layers.Dot(axes = 2)([keys,queries])\n",
    "        query_key = layers.Lambda(lambda x: (x / np.sqrt(dense_dim)))(query_key)\n",
    "        query_key = layers.Softmax()(query_key)\n",
    "        \n",
    "        combined_mask = tf.maximum((create_look_ahead_mask(input_vec_2.shape[1]) * (-1e9)), \n",
    "           (create_padding_mask(input_vec_2) * (-1e9)))\n",
    "        \n",
    "        query_key = layers.Lambda(lambda x : x + combined_mask)(query_key)\n",
    "        \n",
    "        attention = layers.Dot(axes=1)([query_key,values])\n",
    "        \n",
    "        for j in range(0 ,(multi_head_num - 1)):\n",
    "            \n",
    "            queries_n = layers.Dense(dense_dim)(decoder_output_resnet)\n",
    "            keys_n = layers.Dense(dense_dim)(decoder_output_resnet)\n",
    "            values_n = layers.Dense(dense_dim)(decoder_output_resnet)\n",
    "\n",
    "            query_key_n = layers.Dot(axes = 2)([keys_n,queries_n])\n",
    "            query_key_n = layers.Lambda(lambda x: (x / np.sqrt(dense_dim)))(query_key_n)\n",
    "            query_key_n = layers.Softmax()(query_key_n)\n",
    "            \n",
    "            query_key_n = layers.Lambda(lambda x : x + combined_mask)(query_key_n)\n",
    "\n",
    "            attention_n = layers.Dot(axes=1)([query_key_n,values_n])\n",
    "\n",
    "            attention = layers.Concatenate()([attention,attention_n])\n",
    "\n",
    "        attention_head = layers.Dense(embedding_dim)(attention)\n",
    "\n",
    "        decoder_resnet = layers.Add()([decoder_output_resnet,attention_head])\n",
    "        decoder_resnet = layers.BatchNormalization()(decoder_resnet)\n",
    "\n",
    "        decoder_output_resnet = layers.Dense(embedding_dim)(decoder_resnet)\n",
    "        decoder_output_resnet = layers.Add()([decoder_output_resnet, decoder_resnet])\n",
    "        decoder_output_resnet = layers.BatchNormalization()(decoder_output_resnet)\n",
    "        \n",
    "        queries = layers.Dense(dense_dim)(decoder_output_resnet)\n",
    "        keys = layers.Dense(dense_dim)(encoder_output_resnet)\n",
    "        values = layers.Dense(dense_dim)(encoder_output_resnet)\n",
    "        \n",
    "        query_key = layers.Dot(axes = 2)([keys,queries])\n",
    "        query_key = layers.Lambda(lambda x: (x / np.sqrt(dense_dim)))(query_key)\n",
    "        query_key = layers.Softmax()(query_key)\n",
    "        \n",
    "        query_key = layers.Lambda(lambda x : x + (create_padding_mask(input_vec_2) * (-1e9)))(query_key)\n",
    "\n",
    "        attention = layers.Dot(axes=1)([query_key,values])\n",
    "\n",
    "        for j in range(0 ,(multi_head_num - 1)):\n",
    "            queries_n = layers.Dense(dense_dim)(decoder_output_resnet)\n",
    "            keys_n = layers.Dense(dense_dim)(encoder_output_resnet)\n",
    "            values_n = layers.Dense(dense_dim)(encoder_output_resnet)\n",
    "\n",
    "            query_key_n = layers.Dot(axes = 2)([keys_n,queries_n])\n",
    "            query_key_n = layers.Lambda(lambda x: (x / np.sqrt(dense_dim)))(query_key_n)\n",
    "            query_key_n = layers.Softmax()(query_key_n)\n",
    "            \n",
    "            query_key_n = layers.Lambda(lambda x : x + (create_padding_mask(input_vec_2) * (-1e9)))(query_key_n)\n",
    "\n",
    "            attention_n = layers.Dot(axes=1)([query_key_n,values_n])\n",
    "\n",
    "            attention = layers.Concatenate()([attention,attention_n])\n",
    "\n",
    "        attention_head = layers.Dense(embedding_dim)(attention)\n",
    "\n",
    "        decoder_resnet = layers.Add()([decoder_output_resnet,attention_head])\n",
    "        decoder_resnet = layers.BatchNormalization()(decoder_resnet)\n",
    "\n",
    "        decoder_output_resnet = layers.Dense(embedding_dim)(decoder_resnet)\n",
    "        decoder_output_resnet = layers.Add()([decoder_output_resnet, decoder_resnet])\n",
    "        decoder_output_resnet = layers.BatchNormalization()(decoder_output_resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 출력 및 모델 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_classification\n",
    "\n",
    "output_vec = layers.GlobalAveragePooling1D()(decoder_output_resnet)\n",
    "\n",
    "output_vec = layers.Dense(output_vec.shape[1])(output_vec)\n",
    "\n",
    "output_vec = layers.Dense(target_size, activation=\"softmax\")(output_vec)\n",
    "\n",
    "transformer = Model(inputs = [input_vec_1,input_vec_2], outputs = [output_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text generating\n",
    "\n",
    "output_vec = layers.Dense(target_size,activation=\"softmax\")(decoder_output_resnet)\n",
    "\n",
    "#output_vec = layers.Lambda(lambda x : x[:,0,:])(output_vec)\n",
    "\n",
    "transformer = Model(inputs = [input_vec_1,input_vec_2], outputs = [output_vec])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer.save(\"tranformer_cls.h5\")\n",
    "transformer.save(\"tranformer.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 훈련 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy(\n",
    "    reduction = \"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(tf.argmax(real,axis=-1), 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(tf.argmax(real, axis=-1), tf.argmax(pred, axis=-1))\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(tf.argmax(real,axis=-1), 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "transformer.compile(loss=loss_function, optimizer=\"adam\", metrics = [accuracy_function])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#text_classification\n",
    "\n",
    "    transformer.fit([X_train, X_train] , \n",
    "                    y_train ,\n",
    "                    epochs=50,\n",
    "                    batch_size = 5, \n",
    "                    validation_data = ([X_test, X_test], y_test),\n",
    "                    callbacks = [early_stopping]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_generating\n",
    "\n",
    "temp = [dummies_temp.merge(\n",
    "            pd.get_dummies(j), \n",
    "            how = \"outer\").fillna(0)\n",
    "            for j in X_val_2]\n",
    "\n",
    "y_test = np.array([j[np.sort(j.columns)] \n",
    "            for j in temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 289 samples\n",
      "Epoch 1/50\n",
      " 60/100 [=================>............] - ETA: 12:45 - loss: 2.7374 - accuracy_function: 0.1116"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1020-cca53c746bb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_val_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m                    )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3792\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3794\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m     \"\"\"\n\u001b[1;32m-> 1605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1645\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(0,19) :\n",
    "    temp = [dummies_temp.merge(\n",
    "            pd.get_dummies(j), \n",
    "            how = \"outer\").fillna(0)\n",
    "            for j in X_train_2[(100 * i) : (100 * i) + 100]]\n",
    "\n",
    "    y_train = np.array([j[np.sort(j.columns)] \n",
    "               for j in temp])\n",
    "    \n",
    "    #j = np.random.randint(11,200) - 10\n",
    "    \n",
    "    #X_val_1_reshape = X_val_1[j].reshape((1,X_val_1[j].shape[0]))\n",
    "    #X_val_2_reshape = X_val_2[j].reshape((12.,X_val_2[j].shape[0]))\n",
    "    \n",
    "\n",
    "    transformer.fit([X_train_1[(100 * i) : (100 * i) + 100], X_train_2[(100 * i) : (100 * i) + 100, 0 : 19]] , \n",
    "                    y_train[:, 1:20, :] ,\n",
    "                    epochs=50,\n",
    "                    batch_size = 10, \n",
    "                    validation_data = ([X_val_1, X_val_2[: , 0:19]], y_test[:, 1:20, :]),\n",
    "                    callbacks = [early_stopping]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_list = [vocabulary['CLS']]\n",
    "\n",
    "start_list.extend([0 for i in range(0,sen_len_2 - 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_list = [start_list for i in range(0,5)]\n",
    "start_list = np.array(start_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1007-8f3735e2980d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_train_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mstart_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1462\u001b[1;33m                                             callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3792\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3794\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m     \"\"\"\n\u001b[1;32m-> 1605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1645\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1,19) :\n",
    "    print(i)\n",
    "    pred = transformer.predict([X_train_1[0:5],start_list])\n",
    "    start_list[:, i] = np.argmax(pred[:,i,:], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16848, 14959, 14959, 14959, 14959, 14959, 14959, 14959, 14959,\n",
       "        14959, 14959, 14959, 14959, 14959, 14959, 14959, 14959, 14959,\n",
       "        14959],\n",
       "       [16848, 14959, 14959, 14959, 14959, 14959, 14959, 14959, 14959,\n",
       "        14959, 14959, 14959, 14959, 14959, 14959, 14959, 14959, 14959,\n",
       "        14959],\n",
       "       [16848, 14959, 14959, 14959, 14959, 14959, 14959, 14959, 14959,\n",
       "        14959, 14959, 14959, 14959, 14959, 14959, 14959, 14959, 14959,\n",
       "        14959],\n",
       "       [16848, 14959, 14959, 14959, 14959, 14959, 14959, 14959, 14959,\n",
       "        14959, 14959, 14959, 14959, 14959, 14959, 14959, 14959, 14959,\n",
       "        14959],\n",
       "       [16848, 14959, 14959, 14959, 14959, 14959, 14959, 14959, 14959,\n",
       "        14959, 14959, 14959, 14959, 14959, 14959, 14959, 14959, 14959,\n",
       "        14959]])"
      ]
     },
     "execution_count": 990,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS\n",
      "투입\n",
      "투입\n",
      "투입\n",
      "투입\n",
      "투입\n",
      "투입\n",
      "투입\n",
      "투입\n",
      "투입\n",
      "투입\n",
      "투입\n",
      "투입\n",
      "투입\n",
      "투입\n",
      "투입\n",
      "투입\n",
      "투입\n",
      "투입\n"
     ]
    }
   ],
   "source": [
    "for i in start_list[1]:\n",
    "    if np.any(np.array(list(vocabulary.values()) == i)) == False :\n",
    "        continue\n",
    "    idx = list(vocabulary.keys())[int(np.where(np.array(list(vocabulary.values())) == i)[0])]\n",
    "    print(idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
