{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "    \n",
    "import keras\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.layers import Layer\n",
    "from keras.layers import Input,Dense,Flatten,Embedding,Permute,Dot,Reshape\n",
    "from keras.layers.convolutional import Conv1D,MaxPooling1D,MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM,GRU\n",
    "from keras.callbacks import Callback\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    " \n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import function\n",
    "import math\n",
    " \n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    " \n",
    "import scipy\n",
    "\n",
    "import statsmodels.api\n",
    "import statsmodels as sm\n",
    " \n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "import re\n",
    "import os\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 기본 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dangjin_fcst = pd.read_csv(\"data/dangjin_fcst_data.csv\")\n",
    "dangjin_obs = pd.read_csv(\"data/dangjin_obs_data.csv\")\n",
    "energy = pd.read_csv(\"data/energy.csv\")\n",
    "site_info = pd.read_csv(\"data/site_info.csv\")\n",
    "ulsan_fcst = pd.read_csv(\"data/ulsan_fcst_data.csv\")\n",
    "ulsan_obs = pd.read_csv(\"data/ulsan_obs_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 추가 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 강수확률(당진)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirlist = os.listdir(\"data\")\n",
    "\n",
    "searcher = re.compile(\"석문면_강수확률\")\n",
    "\n",
    "searcher_2 = re.compile(\"[0-9]{8,9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.Series(dirlist).apply(lambda x : len(searcher.findall(x)) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fall_prob = DataFrame()\n",
    "\n",
    "for i in Series(dirlist)[index].reset_index(drop = True):\n",
    "\n",
    "    csv_file = pd.read_csv('data/' + i)\n",
    "\n",
    "    index_list = list(csv_file[csv_file.iloc[:,0].apply(lambda x : len(searcher_2.findall(x)) != 0)].index)\n",
    "\n",
    "    index_list.append(len(csv_file))\n",
    "\n",
    "    csv_file.loc[0 : index_list[1],\"date\"] = searcher_2.findall(csv_file.columns[3])[0]\n",
    "\n",
    "    for j in range(0, len(index_list) - 1):\n",
    "        \n",
    "        csv_file.loc[index_list[j] : index_list[j + 1],\"date\"] = searcher_2.findall(csv_file.iloc[index_list[j],0])[0]\n",
    "\n",
    "    csv_file = csv_file.drop(index_list[:-1], axis = 0).reset_index(drop = True)\n",
    "\n",
    "    csv_file.columns = [\"day\",\"hour\",\"forecast_time\",\"value\",\"date\"]\n",
    "\n",
    "    csv_file[\"day\"] = csv_file[\"day\"].astype(\"int\") - 1\n",
    "\n",
    "    csv_file[\"date\"] = pd.to_datetime(csv_file[\"date\"])\n",
    "\n",
    "    csv_file[\"hour\"] = csv_file[\"hour\"].astype(\"str\").str.split(\".\").apply(lambda x : x[0][:-2])\n",
    "\n",
    "    csv_file[\"time\"] = csv_file.apply(lambda x : x[\"date\"] + pd.Timedelta(x[\"day\"], unit = \"d\"), axis = 1)\n",
    "\n",
    "    csv_file[\"time\"] = csv_file.apply(lambda x : x[\"time\"] + pd.Timedelta(x[\"hour\"] + \":00:00\"), axis = 1)\n",
    "\n",
    "    csv_file = csv_file.drop([\"date\",\"day\",\"hour\"], axis = 1)[[\"time\",\"forecast_time\",\"value\"]]\n",
    "    \n",
    "    fall_prob = pd.concat([fall_prob,csv_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 강수 형태(당진)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirlist = os.listdir(\"data\")\n",
    "\n",
    "searcher = re.compile(\"석문면_강수형태\")\n",
    "\n",
    "searcher_2 = re.compile(\" [0-9]{8,9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.Series(dirlist).apply(lambda x : len(searcher.findall(x)) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fall_type = DataFrame()\n",
    "\n",
    "for i in Series(dirlist)[index].reset_index(drop = True):\n",
    "\n",
    "    csv_file = pd.read_csv('data/' + i)\n",
    "\n",
    "    index_list = list(csv_file[csv_file.iloc[:,0].apply(lambda x : len(searcher_2.findall(x)) != 0)].index)\n",
    "\n",
    "    index_list.append(len(csv_file))\n",
    "\n",
    "    csv_file.loc[0 : index_list[1],\"date\"] = searcher_2.findall(csv_file.columns[3])[0]\n",
    "\n",
    "    for j in range(0, len(index_list) - 1):\n",
    "        \n",
    "        csv_file.loc[index_list[j] : index_list[j + 1],\"date\"] = searcher_2.findall(csv_file.iloc[index_list[j],0])[0]\n",
    "\n",
    "    csv_file = csv_file.drop(index_list[:-1], axis = 0).reset_index(drop = True)\n",
    "\n",
    "    csv_file.columns = [\"day\",\"hour\",\"forecast_time\",\"value\",\"date\"]\n",
    "\n",
    "    csv_file[\"day\"] = csv_file[\"day\"].astype(\"int\") - 1\n",
    "\n",
    "    csv_file[\"date\"] = pd.to_datetime(csv_file[\"date\"])\n",
    "\n",
    "    csv_file[\"hour\"] = csv_file[\"hour\"].astype(\"str\").str.split(\".\").apply(lambda x : x[0][:-2])\n",
    "\n",
    "    csv_file[\"time\"] = csv_file.apply(lambda x : x[\"date\"] + pd.Timedelta(x[\"day\"], unit = \"d\"), axis = 1)\n",
    "\n",
    "    csv_file[\"time\"] = csv_file.apply(lambda x : x[\"time\"] + pd.Timedelta(x[\"hour\"] + \":00:00\"), axis = 1)\n",
    "\n",
    "    csv_file = csv_file.drop([\"date\",\"day\",\"hour\"], axis = 1)[[\"time\",\"forecast_time\",\"value\"]]\n",
    "    \n",
    "    fall_type = pd.concat([fall_type,csv_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain = pd.merge(fall_type, fall_prob, on = [\"time\",\"forecast_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain.columns = [\"Forecast time\",\"forecast\",\"fall_type_dangjin\",\"fall_prob_dangjin\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 강수확률(울산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirlist = os.listdir(\"data\")\n",
    "\n",
    "searcher = re.compile(\"선암동_강수확률\")\n",
    "\n",
    "searcher_2 = re.compile(\"[0-9]{8,9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.Series(dirlist).apply(lambda x : len(searcher.findall(x)) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fall_prob = DataFrame()\n",
    "\n",
    "for i in Series(dirlist)[index].reset_index(drop = True):\n",
    "\n",
    "    csv_file = pd.read_csv('data/' + i)\n",
    "\n",
    "    index_list = list(csv_file[csv_file.iloc[:,0].apply(lambda x : len(searcher_2.findall(x)) != 0)].index)\n",
    "\n",
    "    index_list.append(len(csv_file))\n",
    "\n",
    "    csv_file.loc[0 : index_list[1],\"date\"] = searcher_2.findall(csv_file.columns[3])[0]\n",
    "\n",
    "    for j in range(0, len(index_list) - 1):\n",
    "        \n",
    "        csv_file.loc[index_list[j] : index_list[j + 1],\"date\"] = searcher_2.findall(csv_file.iloc[index_list[j],0])[0]\n",
    "\n",
    "    csv_file = csv_file.drop(index_list[:-1], axis = 0).reset_index(drop = True)\n",
    "\n",
    "    csv_file.columns = [\"day\",\"hour\",\"forecast_time\",\"value\",\"date\"]\n",
    "\n",
    "    csv_file[\"day\"] = csv_file[\"day\"].astype(\"int\") - 1\n",
    "\n",
    "    csv_file[\"date\"] = pd.to_datetime(csv_file[\"date\"])\n",
    "\n",
    "    csv_file[\"hour\"] = csv_file[\"hour\"].astype(\"str\").str.split(\".\").apply(lambda x : x[0][:-2])\n",
    "\n",
    "    csv_file[\"time\"] = csv_file.apply(lambda x : x[\"date\"] + pd.Timedelta(x[\"day\"], unit = \"d\"), axis = 1)\n",
    "\n",
    "    csv_file[\"time\"] = csv_file.apply(lambda x : x[\"time\"] + pd.Timedelta(x[\"hour\"] + \":00:00\"), axis = 1)\n",
    "\n",
    "    csv_file = csv_file.drop([\"date\",\"day\",\"hour\"], axis = 1)[[\"time\",\"forecast_time\",\"value\"]]\n",
    "    \n",
    "    fall_prob = pd.concat([fall_prob,csv_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 강수 형태(울산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirlist = os.listdir(\"data\")\n",
    "\n",
    "searcher = re.compile(\"선암동_강수형태\")\n",
    "\n",
    "searcher_2 = re.compile(\" [0-9]{8,9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.Series(dirlist).apply(lambda x : len(searcher.findall(x)) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fall_type = DataFrame()\n",
    "\n",
    "for i in Series(dirlist)[index].reset_index(drop = True):\n",
    "\n",
    "    csv_file = pd.read_csv('data/' + i)\n",
    "\n",
    "    index_list = list(csv_file[csv_file.iloc[:,0].apply(lambda x : len(searcher_2.findall(x)) != 0)].index)\n",
    "\n",
    "    index_list.append(len(csv_file))\n",
    "\n",
    "    csv_file.loc[0 : index_list[1],\"date\"] = searcher_2.findall(csv_file.columns[3])[0]\n",
    "\n",
    "    for j in range(0, len(index_list) - 1):\n",
    "        \n",
    "        csv_file.loc[index_list[j] : index_list[j + 1],\"date\"] = searcher_2.findall(csv_file.iloc[index_list[j],0])[0]\n",
    "\n",
    "    csv_file = csv_file.drop(index_list[:-1], axis = 0).reset_index(drop = True)\n",
    "\n",
    "    csv_file.columns = [\"day\",\"hour\",\"forecast_time\",\"value\",\"date\"]\n",
    "\n",
    "    csv_file[\"day\"] = csv_file[\"day\"].astype(\"int\") - 1\n",
    "\n",
    "    csv_file[\"date\"] = pd.to_datetime(csv_file[\"date\"])\n",
    "\n",
    "    csv_file[\"hour\"] = csv_file[\"hour\"].astype(\"str\").str.split(\".\").apply(lambda x : x[0][:-2])\n",
    "\n",
    "    csv_file[\"time\"] = csv_file.apply(lambda x : x[\"date\"] + pd.Timedelta(x[\"day\"], unit = \"d\"), axis = 1)\n",
    "\n",
    "    csv_file[\"time\"] = csv_file.apply(lambda x : x[\"time\"] + pd.Timedelta(x[\"hour\"] + \":00:00\"), axis = 1)\n",
    "\n",
    "    csv_file = csv_file.drop([\"date\",\"day\",\"hour\"], axis = 1)[[\"time\",\"forecast_time\",\"value\"]]\n",
    "    \n",
    "    fall_type = pd.concat([fall_type,csv_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_ulsan = pd.merge(fall_type, fall_prob, on = [\"time\",\"forecast_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_ulsan.columns = [\"Forecast time\",\"forecast\",\"fall_type_ulsan\",\"fall_prob_ulsan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain = pd.merge(rain,rain_ulsan, on = [\"Forecast time\",\"forecast\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 과거 발전량"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_past = pd.read_csv('data/한국동서발전 시간대별 태양광 발전량 현황(2015_2017).csv',encoding = \"CP949\")\n",
    "\n",
    "energy_past = energy_past.reset_index()\n",
    "\n",
    "energy_stack = energy_past[[str(i) for i in range(1, 25)]].unstack().reset_index()\n",
    "\n",
    "energy_stack.columns = [\"hour\",\"index\",\"value\"]\n",
    "\n",
    "energy_past = pd.merge(energy_stack,energy_past.iloc[:,0:4])\n",
    "\n",
    "energy_past[\"시간\"] = energy_past[\"시간\"] + ' ' + energy_past[\"hour\"] + \":00:00\"\n",
    "\n",
    "energy_past = energy_past.drop([\"hour\",\"index\",\"용량(MW)\"], axis = 1)\n",
    "\n",
    "energy_past = energy_past.pivot(index = [\"시간\"], columns = [\"태양광명\"], values = [\"value\"])\n",
    "\n",
    "energy_past.columns = DataFrame(list(energy_past.columns))[1]\n",
    "\n",
    "energy_past = energy_past.reset_index()\n",
    "\n",
    "energy_past = energy_past[[\"시간\", \"당진자재창고태양광\",\"당진태양광\",\"울산태양광\",\"당진취수로태양광\"]]\n",
    "\n",
    "energy_past.columns = [\"time\",\"dangjin_warehouse\",\"dangjin\",\"ulsan\",\"dangjin_floating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = pd.concat([energy_past, energy]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 과거 예측(당진)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher_2 = re.compile(\"[0-9]{8,9}\")\n",
    "searcher_3 = re.compile(\"[a-zA-Z]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_type = DataFrame()\n",
    "\n",
    "for i in range(0, len(os.listdir(\"data/weather/dangjin\"))):\n",
    "    file_list = os.listdir(\"data/weather/dangjin/\" + os.listdir(\"data/weather/dangjin/\")[i])\n",
    "    \n",
    "    for n,k in enumerate(file_list):\n",
    "        \n",
    "        csv_file = pd.read_csv(\"data/weather/dangjin/\" + os.listdir(\"data/weather/dangjin\")[i] + \"/\" + k)\n",
    "\n",
    "        index_list = list(csv_file[csv_file.iloc[:,0].apply(lambda x : len(searcher_2.findall(x)) != 0)].index)\n",
    "\n",
    "        index_list.append(len(csv_file))\n",
    "\n",
    "        csv_file.loc[0 : index_list[1],\"date\"] = searcher_2.findall(csv_file.columns[3])[0]\n",
    "\n",
    "        for j in range(0, len(index_list) - 1):\n",
    "\n",
    "            csv_file.loc[index_list[j] : index_list[j + 1],\"date\"] = searcher_2.findall(csv_file.iloc[index_list[j],0])[0]\n",
    "\n",
    "        index_list = list(set(index_list).union(\n",
    "                set(list(csv_file[csv_file.iloc[:,0].apply(lambda x : len(searcher_3.findall(x)) != 0)].index))))\n",
    "\n",
    "        index_list.sort()\n",
    "\n",
    "        csv_file = csv_file.drop(index_list[:-1], axis = 0).reset_index(drop = True)\n",
    "        \n",
    "        csv_file = csv_file.drop_duplicates().reset_index(drop = True)\n",
    "\n",
    "        csv_file.columns = [\"day\",\"hour\",\"forecast_time\",k.split(\"_\")[1] ,\"date\"]\n",
    "\n",
    "        csv_file[\"day\"] = csv_file[\"day\"].astype(\"int\") - 1\n",
    "\n",
    "        csv_file[\"date\"] = pd.to_datetime(csv_file[\"date\"])\n",
    "\n",
    "        csv_file[\"hour\"] = csv_file[\"hour\"].astype(\"str\").str.split(\".\").apply(lambda x : x[0][:-2])\n",
    "\n",
    "        csv_file[\"time\"] = csv_file.apply(lambda x : x[\"date\"] + pd.Timedelta(x[\"day\"], unit = \"d\"), axis = 1)\n",
    "\n",
    "        csv_file[\"time\"] = csv_file.apply(lambda x : x[\"time\"] + pd.Timedelta(x[\"hour\"] + \":00:00\"), axis = 1)\n",
    "        \n",
    "        if n == 0:\n",
    "        \n",
    "            temp_result = csv_file.copy()\n",
    "        \n",
    "        else : \n",
    "            temp_result = pd.merge(temp_result, csv_file, on = [\"day\",\"hour\", \"time\", \"forecast_time\", \"date\"]).drop_duplicates()\n",
    "        \n",
    "    fall_type = pd.concat([fall_type, temp_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_type = fall_type.reset_index(drop = True)\n",
    "\n",
    "dangjin_fcst_past = fall_type.drop([\"date\",\"day\",\"hour\"], axis = 1)[[\"time\",\"forecast_time\",\"3시간기온\",\"강수형태\",\"강수확률\",\"습도\",\"풍속\",\"풍향\",\"하늘상태\"]]\n",
    "\n",
    "dangjin_fcst_past.columns = [\"Forecast time\",\"forecast\",\"Temperature\",\"fall_type_dangjin\",\"fall_prob_dangjin\",\"Humidity\",\"WindSpeed\",\"WindDirection\",\"Cloud\"]\n",
    "\n",
    "rain_dangjin = dangjin_fcst_past[[\"Forecast time\",\"forecast\",\"fall_type_dangjin\",\"fall_prob_dangjin\"]]\n",
    "\n",
    "dangjin_fcst_past = dangjin_fcst_past.drop([\"fall_type_dangjin\",\"fall_prob_dangjin\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dangjin_fcst = pd.concat([dangjin_fcst_past,dangjin_fcst]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dangjin_fcst[\"forecast\"] = dangjin_fcst[\"forecast\"].astype(int)\n",
    "\n",
    "dangjin_fcst[\"Forecast time\"] = dangjin_fcst[\"Forecast time\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_type = fall_type.reset_index(drop = True)\n",
    "\n",
    "dangjin_fcst_past = fall_type.drop([\"date\",\"day\",\"hour\"], axis = 1)[[\"time\",\"forecast_time\",\"3시간기온\",\"강수형태\",\"강수확률\",\"습도\",\"풍속\",\"풍향\",\"하늘상태\"]]\n",
    "\n",
    "dangjin_fcst_past.columns = [\"Forecast time\",\"forecast\",\"Temperature\",\"fall_type_dangjin\",\"fall_prob_dangjin\",\"Humidity\",\"WindSpeed\",\"WindDirection\",\"Cloud\"]\n",
    "\n",
    "rain_dangjin = dangjin_fcst_past[[\"Forecast time\",\"forecast\",\"fall_type_dangjin\",\"fall_prob_dangjin\"]]\n",
    "\n",
    "dangjin_fcst_past = dangjin_fcst_past.drop([\"fall_type_dangjin\",\"fall_prob_dangjin\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dangjin_fcst = pd.concat([dangjin_fcst_past,dangjin_fcst]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dangjin_fcst[\"forecast\"] = dangjin_fcst[\"forecast\"].astype(int)\n",
    "\n",
    "dangjin_fcst[\"Forecast time\"] = dangjin_fcst[\"Forecast time\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 과거 예측(울산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher_2 = re.compile(\"[0-9]{8,9}\")\n",
    "searcher_3 = re.compile(\"[a-zA-Z]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_type = DataFrame()\n",
    "\n",
    "for i in range(0, len(os.listdir(\"data/weather/ulsan\"))):\n",
    "    file_list = os.listdir(\"data/weather/ulsan/\" + os.listdir(\"data/weather/ulsan/\")[i])\n",
    "    \n",
    "    for n,k in enumerate(file_list):\n",
    "        \n",
    "        csv_file = pd.read_csv(\"data/weather/ulsan/\" + os.listdir(\"data/weather/ulsan\")[i] + \"/\" + k)\n",
    "\n",
    "        index_list = list(csv_file[csv_file.iloc[:,0].apply(lambda x : len(searcher_2.findall(x)) != 0)].index)\n",
    "\n",
    "        index_list.append(len(csv_file))\n",
    "\n",
    "        csv_file.loc[0 : index_list[1],\"date\"] = searcher_2.findall(csv_file.columns[3])[0]\n",
    "\n",
    "        for j in range(0, len(index_list) - 1):\n",
    "\n",
    "            csv_file.loc[index_list[j] : index_list[j + 1],\"date\"] = searcher_2.findall(csv_file.iloc[index_list[j],0])[0]\n",
    "\n",
    "        index_list = list(set(index_list).union(\n",
    "                set(list(csv_file[csv_file.iloc[:,0].apply(lambda x : len(searcher_3.findall(x)) != 0)].index))))\n",
    "\n",
    "        index_list.sort()\n",
    "\n",
    "        csv_file = csv_file.drop(index_list[:-1], axis = 0).reset_index(drop = True)\n",
    "        \n",
    "        csv_file = csv_file.drop_duplicates().reset_index(drop = True)\n",
    "\n",
    "        csv_file.columns = [\"day\",\"hour\",\"forecast_time\",k.split(\"_\")[1] ,\"date\"]\n",
    "\n",
    "        csv_file[\"day\"] = csv_file[\"day\"].astype(\"int\") - 1\n",
    "\n",
    "        csv_file[\"date\"] = pd.to_datetime(csv_file[\"date\"])\n",
    "\n",
    "        csv_file[\"hour\"] = csv_file[\"hour\"].astype(\"str\").str.split(\".\").apply(lambda x : x[0][:-2])\n",
    "\n",
    "        csv_file[\"time\"] = csv_file.apply(lambda x : x[\"date\"] + pd.Timedelta(x[\"day\"], unit = \"d\"), axis = 1)\n",
    "\n",
    "        csv_file[\"time\"] = csv_file.apply(lambda x : x[\"time\"] + pd.Timedelta(x[\"hour\"] + \":00:00\"), axis = 1)\n",
    "        \n",
    "        if n == 0:\n",
    "        \n",
    "            temp_result = csv_file.copy()\n",
    "        \n",
    "        else : \n",
    "            temp_result = pd.merge(temp_result, csv_file, on = [\"day\",\"hour\", \"time\", \"forecast_time\", \"date\"]).drop_duplicates()\n",
    "        \n",
    "    fall_type = pd.concat([fall_type, temp_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_type = fall_type.reset_index(drop = True)\n",
    "\n",
    "ulsan_fcst_past = fall_type.drop([\"date\",\"day\",\"hour\"], axis = 1)[[\"time\",\"forecast_time\",\"3시간기온\",\"강수형태\",\"강수확률\",\"습도\",\"풍속\",\"풍향\",\"하늘상태\"]]\n",
    "\n",
    "ulsan_fcst_past.columns = [\"Forecast time\",\"forecast\",\"Temperature\",\"fall_type_ulsan\",\"fall_prob_ulsan\",\"Humidity\",\"WindSpeed\",\"WindDirection\",\"Cloud\"]\n",
    "\n",
    "rain_ulsan = ulsan_fcst_past[[\"Forecast time\",\"forecast\",\"fall_type_ulsan\",\"fall_prob_ulsan\"]]\n",
    "\n",
    "ulsan_fcst_past = ulsan_fcst_past.drop([\"fall_type_ulsan\",\"fall_prob_ulsan\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulsan_fcst = pd.concat([ulsan_fcst_past,ulsan_fcst]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulsan_fcst[\"forecast\"] = ulsan_fcst[\"forecast\"].astype(int)\n",
    "\n",
    "ulsan_fcst[\"Forecast time\"] = ulsan_fcst[\"Forecast time\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain = pd.concat([pd.merge(rain_dangjin,rain_ulsan, on = [\"Forecast time\",\"forecast\"]), rain], axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain[\"forecast\"] = rain[\"forecast\"].astype(int)\n",
    "\n",
    "rain[\"Forecast time\"] = rain[\"Forecast time\"].astype(str)\n",
    "\n",
    "rain[\"fall_type_dangjin\"] = rain[\"fall_type_dangjin\"].astype(float).astype(int)\n",
    "\n",
    "rain[\"fall_prob_dangjin\"] = rain[\"fall_prob_dangjin\"].astype(\"float\")\n",
    "\n",
    "rain[\"fall_type_ulsan\"] = rain[\"fall_type_ulsan\"].astype(float).astype(int)\n",
    "\n",
    "rain[\"fall_prob_ulsan\"] = rain[\"fall_prob_ulsan\"].astype(\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -과거 관측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_type = DataFrame()\n",
    "\n",
    "file_list = os.listdir(\"data/obs/dangjin/\")\n",
    "\n",
    "for n,k in enumerate(file_list):\n",
    "\n",
    "    csv_file = pd.read_csv(\"data/obs/dangjin/\" + k, encoding = \"CP949\")\n",
    "    \n",
    "    csv_file = csv_file[[\"일시\",\"기온(°C)\",\"풍속(m/s)\",\"풍향(16방위)\",\"습도(%)\",\"전운량(10분위)\"]]\n",
    "\n",
    "    if n == 0:\n",
    "\n",
    "        temp_result = csv_file.copy()\n",
    "\n",
    "    else : \n",
    "        temp_result = pd.concat([temp_result, csv_file],axis = 0).drop_duplicates()\n",
    "\n",
    "dangjin_obs = pd.concat([temp_result,dangjin_obs], axis = 0).drop_duplicates(subset = [\"일시\"]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_type = DataFrame()\n",
    "\n",
    "file_list = os.listdir(\"data/obs/ulsan/\")\n",
    "\n",
    "for n,k in enumerate(file_list):\n",
    "\n",
    "    csv_file = pd.read_csv(\"data/obs/ulsan/\" + k, encoding = \"CP949\")\n",
    "    \n",
    "    csv_file = csv_file[[\"일시\",\"기온(°C)\",\"풍속(m/s)\",\"풍향(16방위)\",\"습도(%)\",\"전운량(10분위)\"]]\n",
    "\n",
    "    if n == 0:\n",
    "\n",
    "        temp_result = csv_file.copy()\n",
    "\n",
    "    else : \n",
    "        temp_result = pd.concat([temp_result, csv_file],axis = 0).drop_duplicates()\n",
    "\n",
    "ulsan_obs = pd.concat([temp_result,ulsan_obs], axis = 0).drop_duplicates(subset = [\"일시\"]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일시</th>\n",
       "      <th>기온(°C)</th>\n",
       "      <th>풍속(m/s)</th>\n",
       "      <th>풍향(16방위)</th>\n",
       "      <th>습도(%)</th>\n",
       "      <th>전운량(10분위)</th>\n",
       "      <th>지점</th>\n",
       "      <th>지점명</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01 00:00</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>340.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 01:00</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>340.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01 02:00</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>4.9</td>\n",
       "      <td>340.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01 03:00</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>6.2</td>\n",
       "      <td>320.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01 04:00</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53233</th>\n",
       "      <td>2021-01-31 19:00</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>200.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>서산</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53234</th>\n",
       "      <td>2021-01-31 20:00</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>서산</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53235</th>\n",
       "      <td>2021-01-31 21:00</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>230.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>서산</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53236</th>\n",
       "      <td>2021-01-31 22:00</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>서산</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53237</th>\n",
       "      <td>2021-01-31 23:00</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>230.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>서산</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53238 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     일시  기온(°C)  풍속(m/s)  풍향(16방위)  습도(%)  전운량(10분위)     지점  \\\n",
       "0      2015-01-01 00:00    -4.2      5.3     340.0   48.0        7.0    NaN   \n",
       "1      2015-01-01 01:00    -4.4      5.4     340.0   47.0        6.0    NaN   \n",
       "2      2015-01-01 02:00    -4.6      4.9     340.0   50.0        NaN    NaN   \n",
       "3      2015-01-01 03:00    -4.7      6.2     320.0   50.0        6.0    NaN   \n",
       "4      2015-01-01 04:00    -5.0      5.0     320.0   56.0        6.0    NaN   \n",
       "...                 ...     ...      ...       ...    ...        ...    ...   \n",
       "53233  2021-01-31 19:00     6.7      1.5     200.0   75.0        8.0  129.0   \n",
       "53234  2021-01-31 20:00     6.2      0.8     200.0   77.0        8.0  129.0   \n",
       "53235  2021-01-31 21:00     5.3      0.7     230.0   82.0        8.0  129.0   \n",
       "53236  2021-01-31 22:00     5.8      1.0     200.0   77.0        8.0  129.0   \n",
       "53237  2021-01-31 23:00     5.3      0.6     230.0   80.0        7.0  129.0   \n",
       "\n",
       "       지점명  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3      NaN  \n",
       "4      NaN  \n",
       "...    ...  \n",
       "53233   서산  \n",
       "53234   서산  \n",
       "53235   서산  \n",
       "53236   서산  \n",
       "53237   서산  \n",
       "\n",
       "[53238 rows x 8 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dangjin_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 일사량"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_radio = pd.concat([pd.read_csv(\"data/OBS_ASOS_TIM_20210509142735.csv\",encoding = \"CP949\"),\n",
    "                       pd.read_csv(\"data/OBS_ASOS_TIM_20210509143013.csv\",encoding = \"CP949\"),\n",
    "                       pd.read_csv(\"data/OBS_ASOS_TIM_20210509143059.csv\",encoding = \"CP949\"),\n",
    "                       pd.read_csv(\"data/OBS_ASOS_TIM_20210525163946.csv\",encoding = \"CP949\"),\n",
    "                       pd.read_csv(\"data/OBS_ASOS_TIM_20210525164100.csv\",encoding = \"CP949\"),\n",
    "                       pd.read_csv(\"data/OBS_ASOS_TIM_20210525164127.csv\",encoding = \"CP949\"),\n",
    "                      ]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_radio[\"일시\"] = sun_radio[\"일시\"] + \":00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_radio_ulsan = pd.concat([pd.read_csv(\"data/OBS_ASOS_TIM_20210526161235.csv\",encoding = \"CP949\"),\n",
    "                       pd.read_csv(\"data/OBS_ASOS_TIM_20210526161318.csv\",encoding = \"CP949\"),\n",
    "                       pd.read_csv(\"data/OBS_ASOS_TIM_20210526161340.csv\",encoding = \"CP949\"),\n",
    "                       pd.read_csv(\"data/OBS_ASOS_TIM_20210526161401.csv\",encoding = \"CP949\"),\n",
    "                       pd.read_csv(\"data/OBS_ASOS_TIM_20210526161419.csv\",encoding = \"CP949\"),\n",
    "                       pd.read_csv(\"data/OBS_ASOS_TIM_20210526161438.csv\",encoding = \"CP949\"),\n",
    "                      ]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_radio_ulsan[\"일시\"] = sun_radio_ulsan[\"일시\"] + \":00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(\"data/fine_dust/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'utf-8' codec can't decode byte 0xc1 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xc1 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xc1 in position 0: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xc1 in position 0: invalid start byte\n"
     ]
    }
   ],
   "source": [
    "file_list = Series(file_list).str.split(\".\")\n",
    "\n",
    "for n,k in enumerate(file_list):\n",
    "\n",
    "    if k[1] == \"csv\":\n",
    "        try :\n",
    "            csv_file = pd.read_csv(\"data/fine_dust/\" + k[0] + \".csv\")\n",
    "        except UnicodeDecodeError as e:           \n",
    "            print(e)\n",
    "            csv_file = pd.read_csv(\"data/fine_dust/\" + k[0] + \".csv\", encoding = \"CP949\")\n",
    "        csv_file = csv_file[[\"측정소명\",\"측정일시\",\"PM10\",\"PM25\"]]\n",
    "        \n",
    "    if k[1] == \"xlsx\":\n",
    "        \n",
    "        csv_file = pd.read_excel(\"data/fine_dust/\" + k[0] + \".xlsx\")\n",
    "    \n",
    "        csv_file = csv_file[[\"측정소명\",\"측정일시\",\"PM10\",\"PM25\"]]\n",
    "\n",
    "    if n == 0:\n",
    "\n",
    "        temp_result = csv_file.copy()\n",
    "\n",
    "    else : \n",
    "        temp_result = pd.concat([temp_result, csv_file],axis = 0).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result[\"측정일시\"] = temp_result[\"측정일시\"].astype('str')\n",
    "\n",
    "temp_result[\"Forecast time\"] = temp_result[\"측정일시\"].str.slice(0,4) + \"-\" + temp_result[\"측정일시\"].str.slice(4,6) + \"-\" + temp_result[\"측정일시\"].str.slice(6,8) + \" \" + temp_result[\"측정일시\"].str.slice(8,10) + \":00:00\"\n",
    "\n",
    "temp_result = temp_result.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = DataFrame(list(DataFrame(list(temp_result[\"Forecast time\"].str.split(\" \")))[1].str.split(\":\")))\n",
    "\n",
    "temp[0] = temp[0].astype(int)\n",
    "\n",
    "temp_result.loc[temp[0] == 24, \"Forecast time\"] = pd.to_datetime(temp_result.loc[temp[0] == 24, \"Forecast time\"].str.slice(0,10)).apply(lambda x : x + pd.Timedelta(1,unit = 'd')).astype(\"str\")\n",
    "\n",
    "temp_result.to_csv(\"data/fine_dust.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_dust = temp_result.copy()\n",
    "del temp_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_dust_dangjin = fine_dust[fine_dust[\"측정소명\"] == \"독곶리\"]\n",
    "\n",
    "fine_dust_ulsan = fine_dust[fine_dust[\"측정소명\"] == \"부곡동(울산)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 결측값 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 미세먼지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 당진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>측정소명</th>\n",
       "      <th>측정일시</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>Forecast time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>52608.0</td>\n",
       "      <td>52608.0</td>\n",
       "      <td>49364</td>\n",
       "      <td>30853</td>\n",
       "      <td>52608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3244</td>\n",
       "      <td>21755</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          측정소명     측정일시   PM10   PM25  Forecast time\n",
       "False  52608.0  52608.0  49364  30853        52608.0\n",
       "True       NaN      NaN   3244  21755            NaN"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_dust_dangjin.apply(lambda x : x.isna().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-205-6e4c5335506b>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fine_dust_dangjin[\"group\"] = fine_dust_dangjin[\"Forecast time\"].str.slice(0,10)\n"
     ]
    }
   ],
   "source": [
    "fine_dust_dangjin[\"group\"] = fine_dust_dangjin[\"Forecast time\"].str.slice(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = fine_dust_dangjin.groupby(\"group\")[\"PM10\"].apply(lambda x : len(x[x.isna()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1794"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result == 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result != 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18.203%'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(round(399 / (1799 + 393) * 100, 3)) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result[result != 0].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1794\n",
       "1      101\n",
       "2      100\n",
       "24      75\n",
       "3       22\n",
       "4       13\n",
       "5       12\n",
       "11       9\n",
       "10       8\n",
       "6        7\n",
       "12       7\n",
       "15       6\n",
       "14       6\n",
       "13       6\n",
       "8        5\n",
       "23       4\n",
       "17       3\n",
       "7        3\n",
       "9        3\n",
       "19       3\n",
       "22       2\n",
       "21       2\n",
       "16       1\n",
       "18       1\n",
       "Name: PM10, dtype: int64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     25.313283\n",
       "2     25.062657\n",
       "24    18.796992\n",
       "3      5.513784\n",
       "4      3.258145\n",
       "5      3.007519\n",
       "11     2.255639\n",
       "10     2.005013\n",
       "6      1.754386\n",
       "12     1.754386\n",
       "13     1.503759\n",
       "14     1.503759\n",
       "15     1.503759\n",
       "8      1.253133\n",
       "23     1.002506\n",
       "19     0.751880\n",
       "9      0.751880\n",
       "7      0.751880\n",
       "17     0.751880\n",
       "22     0.501253\n",
       "21     0.501253\n",
       "16     0.250627\n",
       "18     0.250627\n",
       "Name: PM10, dtype: float64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result > 0].value_counts() / len(result[result > 0]) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미세먼지 결측값을 각 일자별로 묶어서 확인해본 결과, 대부분의 일자에서 NAN이 전혀 없는 경우가 많았지만\n",
    "\n",
    "약 18%의 일자에서 적어도 하나의 결측값이 존재하고\n",
    "\n",
    "결측값이 존재하는 경우 한개 ~ 두개인 경우가 약 54%, 20개 이상인 경우가 21% 존재했다.\n",
    "\n",
    "대략 5개 미만인 경우는 살리고, 그 외의 경우는 버리는 것이 현명해보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 울산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>측정소명</th>\n",
       "      <th>측정일시</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM25</th>\n",
       "      <th>Forecast time</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>52608.0</td>\n",
       "      <td>52608.0</td>\n",
       "      <td>48932</td>\n",
       "      <td>24599</td>\n",
       "      <td>52608.0</td>\n",
       "      <td>52608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3676</td>\n",
       "      <td>28009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          측정소명     측정일시   PM10   PM25  Forecast time    group\n",
       "False  52608.0  52608.0  48932  24599        52608.0  52608.0\n",
       "True       NaN      NaN   3676  28009            NaN      NaN"
      ]
     },
     "execution_count": 909,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_dust_ulsan.apply(lambda x : x.isna().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-906-ef6938e7cbb8>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fine_dust_ulsan[\"group\"] = fine_dust_ulsan[\"Forecast time\"].str.slice(0,10)\n"
     ]
    }
   ],
   "source": [
    "fine_dust_ulsan[\"group\"] = fine_dust_ulsan[\"Forecast time\"].str.slice(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = fine_dust_ulsan.groupby(\"group\")[\"PM10\"].apply(lambda x : len(x[x.isna()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 912,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1761"
      ]
     },
     "execution_count": 913,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result == 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result != 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19.699%'"
      ]
     },
     "execution_count": 916,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(round(432 / (1761 + 432) * 100, 3)) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 917,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result[result != 0].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1761\n",
       "1      153\n",
       "24     109\n",
       "2       72\n",
       "3       26\n",
       "4       18\n",
       "9       10\n",
       "5        6\n",
       "16       5\n",
       "15       5\n",
       "6        5\n",
       "14       3\n",
       "12       3\n",
       "23       3\n",
       "11       3\n",
       "10       2\n",
       "8        2\n",
       "17       2\n",
       "7        2\n",
       "13       2\n",
       "18       1\n",
       "Name: PM10, dtype: int64"
      ]
     },
     "execution_count": 918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     35.416667\n",
       "24    25.231481\n",
       "2     16.666667\n",
       "3      6.018519\n",
       "4      4.166667\n",
       "9      2.314815\n",
       "5      1.388889\n",
       "6      1.157407\n",
       "16     1.157407\n",
       "15     1.157407\n",
       "14     0.694444\n",
       "12     0.694444\n",
       "11     0.694444\n",
       "23     0.694444\n",
       "10     0.462963\n",
       "7      0.462963\n",
       "8      0.462963\n",
       "17     0.462963\n",
       "13     0.462963\n",
       "18     0.231481\n",
       "Name: PM10, dtype: float64"
      ]
     },
     "execution_count": 919,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result > 0].value_counts() / len(result[result > 0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.3"
      ]
     },
     "execution_count": 920,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "35.4+16.6+6+4+1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미세먼지 결측값을 각 일자별로 묶어서 확인해본 결과, 대부분의 일자에서 NAN이 전혀 없는 경우가 많았지만\n",
    "\n",
    "약 19%의 일자에서 적어도 하나의 결측값이 존재하고\n",
    "\n",
    "결측값이 존재하는 경우 한개 ~ 두개인 경우가 약 51%, 20개 이상인 경우가 25% 존재했다.\n",
    "\n",
    "대략 5개 미만인 경우는 살리고, 그 외의 경우는 버리는 것이 현명해보인다.(전체의 63%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 결측값 대체"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 데이터 시간형 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dangjin_fcst['Forecast_time'] = pd.to_datetime(dangjin_fcst['Forecast time'])\n",
    "ulsan_fcst['Forecast_time'] = pd.to_datetime(ulsan_fcst['Forecast time'])\n",
    "rain[\"Forecast_time\"] = pd.to_datetime(rain['Forecast time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)데이터 보간"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 20시 예보 데이터 선별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "dangjin_fcst_14 = dangjin_fcst[dangjin_fcst['Forecast_time'].dt.hour==20]\n",
    "ulsan_fcst_14 = ulsan_fcst[ulsan_fcst['Forecast_time'].dt.hour==20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_14 = rain.loc[rain[\"Forecast_time\"].dt.hour == 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 24시(자정) 부터 23시까지 데이터 선별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "dangjin_fcst_14 = dangjin_fcst_14[(dangjin_fcst_14['forecast']>=(24 - 20))&(dangjin_fcst_14['forecast']<=(48 - 1 - 20))]\n",
    "ulsan_fcst_14 = ulsan_fcst_14[(ulsan_fcst_14['forecast']>=(24 - 20))&(ulsan_fcst_14['forecast']<=(48 - 1 - 20))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_14 = rain_14[(rain_14['forecast']>=(24 - 20))&(rain_14['forecast']<=(48 - 1 - 20))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:1342: PerformanceWarning: Adding/subtracting object-dtype array to DatetimeArray not vectorized\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def to_date(x):\n",
    "    return pd.DateOffset(hours=x)\n",
    "\n",
    "dangjin_fcst_14['Forecast_time'] = dangjin_fcst_14['Forecast_time'] + dangjin_fcst_14['forecast'].map(to_date)\n",
    "ulsan_fcst_14['Forecast_time'] = ulsan_fcst_14['Forecast_time'] + ulsan_fcst_14['forecast'].map(to_date)\n",
    "rain_14[\"Forecast_time\"] = rain_14['Forecast_time'] + rain_14['forecast'].map(to_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "dangjin_fcst_14 = dangjin_fcst_14[['Forecast_time', 'Temperature', 'Humidity', 'WindSpeed', 'WindDirection', 'Cloud']]\n",
    "ulsan_fcst_14 = ulsan_fcst_14[['Forecast_time', 'Temperature', 'Humidity', 'WindSpeed', 'WindDirection', 'Cloud']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_14 = rain_14[[\"Forecast_time\",\"fall_type_dangjin\",\"fall_prob_dangjin\",\"fall_type_ulsan\",\"fall_prob_ulsan\"]].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_14_temp_dangjin = pd.get_dummies(rain_14[\"fall_type_dangjin\"], prefix = \"dangjin_type\")\n",
    "\n",
    "else_col = list(set(['dangjin_type_{}'.format(i) for i in range(0, 5)]).difference(set(rain_14_temp_dangjin.columns)))\n",
    "\n",
    "rain_14_temp_dangjin[else_col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_14_temp_ulsan = pd.get_dummies(rain_14[\"fall_type_ulsan\"], prefix = \"ulsan_type\")\n",
    "\n",
    "else_col = list(set(['ulsan_type_{}'.format(i) for i in range(0, 5)]).difference(set(rain_14_temp_ulsan.columns)))\n",
    "\n",
    "rain_14_temp_ulsan[else_col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_14_temp = pd.concat([rain_14_temp_dangjin, rain_14_temp_ulsan], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_14 = pd.concat([rain_14, rain_14_temp], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_14 = rain_14.drop([\"fall_type_dangjin\",\"fall_type_ulsan\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 세 시간 간격 데이터를 한 시간 간격으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "dangjin_fcst_14_ = pd.DataFrame()\n",
    "dangjin_fcst_14_['Forecast_time'] = pd.date_range(start=str(np.min(dangjin_fcst_14[\"Forecast_time\"])), end='2021-03-01 23:00:00', freq='H')\n",
    "\n",
    "ulsan_fcst_14_ = pd.DataFrame()\n",
    "ulsan_fcst_14_['Forecast_time'] = pd.date_range(start=str(np.min(ulsan_fcst_14[\"Forecast_time\"])), end='2021-03-01 23:00:00', freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_14_ = pd.DataFrame()\n",
    "rain_14_['Forecast_time'] = pd.date_range(start = np.min(rain_14[\"Forecast_time\"]), end='2021-03-01 23:00:00', freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "dangjin_fcst_14_ = pd.merge(dangjin_fcst_14_, dangjin_fcst_14, on='Forecast_time', how='outer')\n",
    "ulsan_fcst_14_ = pd.merge(ulsan_fcst_14_, ulsan_fcst_14, on='Forecast_time', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_14_ = pd.merge(rain_14_, rain_14, on='Forecast_time', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "dangjin_fcst_14_[[\"Temperature\",\"Humidity\",\"WindSpeed\",\"WindDirection\",\"Cloud\"]] = dangjin_fcst_14_[[\"Temperature\",\"Humidity\",\"WindSpeed\",\"WindDirection\",\"Cloud\"]].astype(\"double\")\n",
    "\n",
    "ulsan_fcst_14_[[\"Temperature\",\"Humidity\",\"WindSpeed\",\"WindDirection\",\"Cloud\"]] = ulsan_fcst_14_[[\"Temperature\",\"Humidity\",\"WindSpeed\",\"WindDirection\",\"Cloud\"]].astype(\"double\") \n",
    "\n",
    "#rain_14_[[\"fall_prob\",\"fall_type_0\",\"fall_type_1\",\"fall_type_2\",\"fall_type_3\",\"fall_type_4\"]] = rain_14_[[\"fall_prob\",\"fall_type_0\",\"fall_type_1\",\"fall_type_2\",\"fall_type_3\",\"fall_type_4\"]].astype(\"double\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 미세먼지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_dust_dangjin = fine_dust_dangjin.reset_index(drop = True)\n",
    "\n",
    "fine_dust_dangjin[\"group\"] = fine_dust_dangjin[\"Forecast time\"].str.slice(0,10)\n",
    "\n",
    "result = fine_dust_dangjin.groupby(\"group\")[\"PM10\"].apply(lambda x : len(x[x.isna()]))\n",
    "\n",
    "result = result.reset_index()\n",
    "\n",
    "groups = result.loc[result[\"PM10\"] < 6, \"group\"]\n",
    "\n",
    "fine_dust_dangjin = pd.merge(groups, fine_dust_dangjin, how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_dust_ulsan = fine_dust_ulsan.reset_index(drop = True)\n",
    "\n",
    "fine_dust_ulsan[\"group\"] = fine_dust_ulsan[\"Forecast time\"].str.slice(0,10)\n",
    "\n",
    "result = fine_dust_ulsan.groupby(\"group\")[\"PM10\"].apply(lambda x : len(x[x.isna()]))\n",
    "\n",
    "result = result.reset_index()\n",
    "\n",
    "groups = result.loc[result[\"PM10\"] < 6, \"group\"]\n",
    "\n",
    "fine_dust_ulsan = pd.merge(groups, fine_dust_ulsan, how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 보간법 적용(default = 선형 보간)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_recategorized(x):\n",
    "    if x < 0.5:\n",
    "        return 0\n",
    "    else :\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "dangjin_fcst = dangjin_fcst_14_.interpolate()\n",
    "ulsan_fcst = ulsan_fcst_14_.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_14 = rain_14_.interpolate()\n",
    "\n",
    "indexing = list(set(rain_14.columns).difference([\"Forecast_time\",\"fall_prob_dangjin\",\"fall_prob_ulsan\"]))\n",
    "indexing.sort()\n",
    "\n",
    "rain_14.loc[:,indexing] = rain_14.loc[:,indexing].apply(lambda x : x.apply(lambda y : categorical_recategorized(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "dangjin_fcst['Forecast_time'] = dangjin_fcst['Forecast_time'].astype(str)\n",
    "ulsan_fcst['Forecast_time'] = ulsan_fcst['Forecast_time'].astype(str)\n",
    "\n",
    "rain_14[\"Forecast_time\"] = rain_14[\"Forecast_time\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_dust_dangjin[\"PM10\"] = fine_dust_dangjin[\"PM10\"].interpolate()\n",
    "fine_dust_ulsan[\"PM10\"] = fine_dust_ulsan[\"PM10\"].interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3)학습 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바람 방향 더미변수화\n",
    "\n",
    "def direction_label(x):\n",
    "    \n",
    "    if x < 0:\n",
    "        return 0\n",
    "    if x <= 45  and x >= 0:\n",
    "        return 0\n",
    "    if x <= 90  and x > 45 :\n",
    "        return 1\n",
    "    if x <= 135  and x > 90 :\n",
    "        return 2\n",
    "    if x <= 180 and x > 135 :\n",
    "        return 3\n",
    "    if x <= 225 and x > 180 :\n",
    "        return 4\n",
    "    if x <= 270 and x > 225 :\n",
    "        return 5\n",
    "    if x <= 315 and x > 270 :\n",
    "        return 6\n",
    "    if x <= 360 and x > 315 :\n",
    "        return 7   \n",
    "    if x > 360:\n",
    "        return 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_result = pd.merge(pd.read_csv(\"sun_result_dangjin.csv\", names = [\"Forecast_time\", \"sun_dangjin\"], header = 0),\n",
    "         pd.read_csv(\"sun_result_ulsan.csv\", names = [\"Forecast_time\", \"sun_ulsan\"], header = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = DataFrame(list(DataFrame(list(energy[\"time\"].str.split(\" \")))[1].str.split(\":\")))\n",
    "\n",
    "temp[0] = temp[0].astype(int)\n",
    "\n",
    "energy.loc[temp[0] == 24, \"time\"] = pd.to_datetime(energy.loc[temp[0] == 24, \"time\"].str.slice(0,10)).apply(lambda x : x + pd.Timedelta(1,unit = 'd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_datast(energy_df, fcst_df, target, sun_target, rain_target):\n",
    "    # 일기 예보 있는 날짜만 선택\n",
    "    \n",
    "    energy = energy_df.copy()\n",
    "    energy.index = range(energy.shape[0])\n",
    "    energy.columns = [\"Forecast_time\",\"sun_radio_\" + target]\n",
    "    energy[\"Forecast_time\"] = pd.to_datetime(energy[\"Forecast_time\"]).astype(\"str\")\n",
    "    \n",
    "    global concat_df\n",
    "    \n",
    "    # 발전량 데이터가 있는 날짜만 선택\n",
    "    fcst = fcst_df.copy()\n",
    "    fcst.index = range(fcst.shape[0])\n",
    "    \n",
    "    # 발전량과 일기예보 연결\n",
    "    \n",
    "    concat_df = pd.merge(fcst, energy, on = \"Forecast_time\")\n",
    "    \n",
    "    start = '2015-03-02 00:00:00'\n",
    "    end = '2021-01-31 23:00:00'\n",
    "    \n",
    "    start_idx = concat_df[concat_df['Forecast_time']==start].index[0]\n",
    "    end_idx = concat_df[concat_df['Forecast_time']==end].index[0]\n",
    "    \n",
    "    concat_df = concat_df.loc[start_idx:end_idx, :].copy()\n",
    "    \n",
    "    # 예보 시간 및 날짜 정보 feature로 추가\n",
    "    concat_df['date'] = concat_df['Forecast_time'].str.split(' ').str[0]\n",
    "    concat_df['hour'] = concat_df['Forecast_time'].str.split(' ').str[1].str.split(':').str[0].astype(int)\n",
    "    \n",
    "    concat_df['year'] = concat_df['date'].str.split('-').str[0].astype(int)\n",
    "    concat_df['month'] = concat_df['date'].str.split('-').str[1].astype(int)\n",
    "    concat_df['day'] = concat_df['date'].str.split('-').str[2].astype(int)\n",
    "    \n",
    "    concat_df[\"WindDirection\"] = concat_df[\"WindDirection\"].apply(lambda x : direction_label(x)).astype(int)\n",
    "    \n",
    "    concat_df = pd.get_dummies(concat_df, prefix = \"WindDirection\", columns = [\"WindDirection\"])\n",
    "    \n",
    "    concat_df = pd.merge(concat_df, sun_result, how = \"left\")\n",
    "    \n",
    "    concat_df = pd.merge(concat_df, rain_14, how = \"left\")\n",
    "    \n",
    "    # 예보 시간, 날짜, 기상 예보 및 발전량 선택\n",
    "    feature_df = concat_df[['year', \n",
    "                            'month', \n",
    "                            'day', \n",
    "                            'hour', \n",
    "                            'Temperature',\n",
    "                            'Humidity', \n",
    "                            'WindSpeed', \n",
    "                            'Cloud',\n",
    "                            '{}_type_0'.format(rain_target),\n",
    "                            '{}_type_1'.format(rain_target),\n",
    "                            '{}_type_2'.format(rain_target),\n",
    "                            '{}_type_3'.format(rain_target),\n",
    "                            '{}_type_4'.format(rain_target),\n",
    "                            'fall_prob_{}'.format(rain_target),\n",
    "                            sun_target,\n",
    "                            'sun_radio_{}'.format(target)]]\n",
    "    \n",
    "    # 마지막 30일을 검증데이터셋으로 나머지를 학습 데이터셋으로 선택\n",
    "    \n",
    "    train_df = feature_df.iloc[:-24*30].dropna()\n",
    "    val_df = feature_df.iloc[-24*30:].dropna()\n",
    "    \n",
    "    # 발전량이 0인 데이터를 제외\n",
    "    #train_df = train_df[train_df[target]!=0]\n",
    "    \n",
    "    train_x = train_df.loc[:, 'year':str(sun_target)].to_numpy()\n",
    "    train_y = train_df['sun_radio_{}'.format(target)].to_numpy()\n",
    "    \n",
    "    val_x = val_df.loc[:, 'year':str(sun_target)].to_numpy()\n",
    "    val_y = val_df['sun_radio_{}'.format(target)].to_numpy()\n",
    "    \n",
    "    return train_x, train_y, val_x, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_radio.columns = [\"지점\",\"지점명\",\"Forecast_time\",\"sun_radio_dangjin\"]\n",
    "\n",
    "sun_radio = pd.merge(dangjin_fcst[[\"Forecast_time\"]], sun_radio, how = \"left\").drop([\"지점\",\"지점명\"],axis=1).fillna(0)\n",
    "\n",
    "sun_radio_ulsan.columns = [\"지점\",\"지점명\",\"Forecast_time\",\"sun_radio_dangjin\"]\n",
    "\n",
    "sun_radio_ulsan = pd.merge(ulsan_fcst[[\"Forecast_time\"]], sun_radio_ulsan, how = \"left\").drop([\"지점\",\"지점명\"],axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 일사량"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmae_10_lgb(y_pred, dataset):\n",
    "    y_true = dataset.get_label()\n",
    "    \n",
    "    mae = mean_squared_error(y_true, y_pred)\n",
    "    \n",
    "    return 'score', mae, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 당진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, val_x, val_y = train_datast(sun_radio, \n",
    "                                              dangjin_fcst, \n",
    "                                              target='dangjin', \n",
    "                                              sun_target = \"sun_dangjin\",\n",
    "                                             rain_target = \"dangjin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_x[:,0] = np.array(pd.Series(train_x[:,0]).astype(\"str\").apply(lambda x : x[2:4]).astype(\"int\"))\\nval_x[:,0] = np.array(pd.Series(val_x[:,0]).astype(\"str\").apply(lambda x : x[2:4]).astype(\"int\"))\\n\\ntrain_min_dangjin = -9\\ntrain_max_dangjin = 100\\n\\ntrain_x_scaled = (np.array(train_x) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)\\nval_x_scaled = (np.array(val_x) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)\\n\\nae_result = Auto_Encoder_dangjin(train_x_scaled) * (train_max_dangjin - train_min_dangjin) + train_min_dangjin\\n\\ntrain_x = np.hstack([train_x, ae_result])\\n\\nae_result = Auto_Encoder_dangjin(val_x_scaled) * (train_max_dangjin - train_min_dangjin) + train_min_dangjin\\n\\nval_x = np.hstack([val_x, ae_result])\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_x[:,0] = np.array(pd.Series(train_x[:,0]).astype(\"str\").apply(lambda x : x[2:4]).astype(\"int\"))\n",
    "val_x[:,0] = np.array(pd.Series(val_x[:,0]).astype(\"str\").apply(lambda x : x[2:4]).astype(\"int\"))\n",
    "\n",
    "train_min_dangjin = -9\n",
    "train_max_dangjin = 100\n",
    "\n",
    "train_x_scaled = (np.array(train_x) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)\n",
    "val_x_scaled = (np.array(val_x) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)\n",
    "\n",
    "ae_result = Auto_Encoder_dangjin(train_x_scaled) * (train_max_dangjin - train_min_dangjin) + train_min_dangjin\n",
    "\n",
    "train_x = np.hstack([train_x, ae_result])\n",
    "\n",
    "ae_result = Auto_Encoder_dangjin(val_x_scaled) * (train_max_dangjin - train_min_dangjin) + train_min_dangjin\n",
    "\n",
    "val_x = np.hstack([val_x, ae_result])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = lgb.Dataset(train_x, train_y)\n",
    "val_dataset = lgb.Dataset(val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def LGB_cv(learning_rate, \n",
    "           feature_fraction, \n",
    "           bagging_fraction,\n",
    "           lambda_l2,\n",
    "           silent=True, \n",
    "           nthread=-1):\n",
    "\n",
    "    params = {\"learning_rate\": learning_rate,\n",
    "                \"feature_fraction\" : feature_fraction,\n",
    "                \"bagging_fraction\" : bagging_fraction, \n",
    "               \"lambda_l2\" : lambda_l2,\n",
    "               \"objective\" :  \"regression\",\n",
    "              \"nthread\" : nthread\n",
    "                }\n",
    "    \n",
    "    model = lgb.train(params,\n",
    "                      train_dataset,\n",
    "                      feval = mean_squared_error\n",
    "                     )\n",
    "\n",
    "    global y_pred\n",
    "    \n",
    "    y_pred = model.predict(val_x)\n",
    "\n",
    "    mae = mean_squared_error(val_y, y_pred)\n",
    "\n",
    "    return 1/mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | lambda_l2 | learni... |\n",
      "-------------------------------------------------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8828  \u001b[0m | \u001b[0m 0.4077  \u001b[0m | \u001b[0m 0.05546 \u001b[0m | \u001b[0m 0.7885  \u001b[0m | \u001b[0m 0.05753 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.8614  \u001b[0m | \u001b[0m 0.4504  \u001b[0m | \u001b[0m 0.304   \u001b[0m | \u001b[0m 0.5264  \u001b[0m | \u001b[0m 0.1248  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.791   \u001b[0m | \u001b[0m 0.8676  \u001b[0m | \u001b[0m 0.1783  \u001b[0m | \u001b[0m 0.5062  \u001b[0m | \u001b[0m 0.1127  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8573  \u001b[0m | \u001b[0m 0.4039  \u001b[0m | \u001b[0m 0.1389  \u001b[0m | \u001b[0m 0.7068  \u001b[0m | \u001b[0m 0.07922 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8814  \u001b[0m | \u001b[0m 0.398   \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.8963  \u001b[0m | \u001b[0m 0.02957 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.9059  \u001b[0m | \u001b[95m 0.8727  \u001b[0m | \u001b[95m 0.7456  \u001b[0m | \u001b[95m 0.1912  \u001b[0m | \u001b[95m 0.1909  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.9089  \u001b[0m | \u001b[95m 0.5884  \u001b[0m | \u001b[95m 0.2601  \u001b[0m | \u001b[95m 0.6401  \u001b[0m | \u001b[95m 0.05594 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8651  \u001b[0m | \u001b[0m 0.6099  \u001b[0m | \u001b[0m 0.3018  \u001b[0m | \u001b[0m 0.6953  \u001b[0m | \u001b[0m 0.01134 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7391  \u001b[0m | \u001b[0m 0.00209 \u001b[0m | \u001b[0m 0.1902  \u001b[0m | \u001b[0m 0.3289  \u001b[0m | \u001b[0m 0.1744  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.9814  \u001b[0m | \u001b[95m 0.4951  \u001b[0m | \u001b[95m 0.6314  \u001b[0m | \u001b[95m 0.9758  \u001b[0m | \u001b[95m 0.1402  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.9378  \u001b[0m | \u001b[0m 0.4741  \u001b[0m | \u001b[0m 0.6999  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1808  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.9894  \u001b[0m | \u001b[95m 0.4886  \u001b[0m | \u001b[95m 0.5892  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.06932 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.9624  \u001b[0m | \u001b[0m 0.573   \u001b[0m | \u001b[0m 0.5491  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1258  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.9561  \u001b[0m | \u001b[0m 0.4121  \u001b[0m | \u001b[0m 0.5427  \u001b[0m | \u001b[0m 0.958   \u001b[0m | \u001b[0m 0.1247  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9603  \u001b[0m | \u001b[0m 0.5224  \u001b[0m | \u001b[0m 0.6548  \u001b[0m | \u001b[0m 0.9155  \u001b[0m | \u001b[0m 0.03123 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.9738  \u001b[0m | \u001b[0m 0.7174  \u001b[0m | \u001b[0m 0.9895  \u001b[0m | \u001b[0m 0.004671\u001b[0m | \u001b[0m 0.1061  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6403  \u001b[0m | \u001b[0m 0.5641  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m 1.01    \u001b[0m | \u001b[95m 0.5176  \u001b[0m | \u001b[95m 0.5738  \u001b[0m | \u001b[95m 0.7966  \u001b[0m | \u001b[95m 0.05088 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.9516  \u001b[0m | \u001b[0m 0.4859  \u001b[0m | \u001b[0m 0.7182  \u001b[0m | \u001b[0m 0.9898  \u001b[0m | \u001b[0m 0.1664  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[95m 20      \u001b[0m | \u001b[95m 1.018   \u001b[0m | \u001b[95m 0.8067  \u001b[0m | \u001b[95m 0.9867  \u001b[0m | \u001b[95m 0.004853\u001b[0m | \u001b[95m 0.1682  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.9354  \u001b[0m | \u001b[0m 0.8728  \u001b[0m | \u001b[0m 0.7405  \u001b[0m | \u001b[0m 0.209   \u001b[0m | \u001b[0m 0.1807  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.996   \u001b[0m | \u001b[0m 0.9367  \u001b[0m | \u001b[0m 0.8513  \u001b[0m | \u001b[0m 0.4917  \u001b[0m | \u001b[0m 0.1132  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.899   \u001b[0m | \u001b[0m 0.9933  \u001b[0m | \u001b[0m 0.1922  \u001b[0m | \u001b[0m 0.4414  \u001b[0m | \u001b[0m 0.08036 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.9783  \u001b[0m | \u001b[0m 0.8908  \u001b[0m | \u001b[0m 0.7587  \u001b[0m | \u001b[0m 0.3582  \u001b[0m | \u001b[0m 0.1205  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001768 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.9885  \u001b[0m | \u001b[0m 0.8369  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.08879 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7723  \u001b[0m | \u001b[0m 0.5471  \u001b[0m | \u001b[0m 0.4025  \u001b[0m | \u001b[0m 0.8359  \u001b[0m | \u001b[0m 0.007013\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.9686  \u001b[0m | \u001b[0m 0.4994  \u001b[0m | \u001b[0m 0.6337  \u001b[0m | \u001b[0m 0.7745  \u001b[0m | \u001b[0m 0.114   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.6397  \u001b[0m | \u001b[0m 0.4609  \u001b[0m | \u001b[0m 0.6128  \u001b[0m | \u001b[0m 0.7576  \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.977   \u001b[0m | \u001b[0m 0.5378  \u001b[0m | \u001b[0m 0.5757  \u001b[0m | \u001b[0m 0.8213  \u001b[0m | \u001b[0m 0.08706 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.8888  \u001b[0m | \u001b[0m 0.8407  \u001b[0m | \u001b[0m 0.8162  \u001b[0m | \u001b[0m 0.4266  \u001b[0m | \u001b[0m 0.01247 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.9155  \u001b[0m | \u001b[0m 0.783   \u001b[0m | \u001b[0m 0.9557  \u001b[0m | \u001b[0m 0.04462 \u001b[0m | \u001b[0m 0.1667  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.7449  \u001b[0m | \u001b[0m 0.5732  \u001b[0m | \u001b[0m 0.134   \u001b[0m | \u001b[0m 0.2298  \u001b[0m | \u001b[0m 0.143   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.9624  \u001b[0m | \u001b[0m 0.5014  \u001b[0m | \u001b[0m 0.5882  \u001b[0m | \u001b[0m 0.9369  \u001b[0m | \u001b[0m 0.09138 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 1.003   \u001b[0m | \u001b[0m 0.539   \u001b[0m | \u001b[0m 0.64    \u001b[0m | \u001b[0m 0.9999  \u001b[0m | \u001b[0m 0.08489 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.9507  \u001b[0m | \u001b[0m 0.6305  \u001b[0m | \u001b[0m 0.8356  \u001b[0m | \u001b[0m 0.4635  \u001b[0m | \u001b[0m 0.1891  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 1.004   \u001b[0m | \u001b[0m 0.4813  \u001b[0m | \u001b[0m 0.6655  \u001b[0m | \u001b[0m 0.9934  \u001b[0m | \u001b[0m 0.07339 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.924   \u001b[0m | \u001b[0m 0.9426  \u001b[0m | \u001b[0m 0.8351  \u001b[0m | \u001b[0m 0.8672  \u001b[0m | \u001b[0m 0.1928  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 1.006   \u001b[0m | \u001b[0m 0.7928  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.133   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.9182  \u001b[0m | \u001b[0m 0.5484  \u001b[0m | \u001b[0m 0.9981  \u001b[0m | \u001b[0m 0.5161  \u001b[0m | \u001b[0m 0.1764  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.9726  \u001b[0m | \u001b[0m 0.9361  \u001b[0m | \u001b[0m 0.8112  \u001b[0m | \u001b[0m 0.4322  \u001b[0m | \u001b[0m 0.1476  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.9296  \u001b[0m | \u001b[0m 0.8531  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1669  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 1.004   \u001b[0m | \u001b[0m 0.4757  \u001b[0m | \u001b[0m 0.745   \u001b[0m | \u001b[0m 0.0125  \u001b[0m | \u001b[0m 0.1315  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 1.015   \u001b[0m | \u001b[0m 0.1895  \u001b[0m | \u001b[0m 0.8497  \u001b[0m | \u001b[0m 0.5772  \u001b[0m | \u001b[0m 0.06017 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.9998  \u001b[0m | \u001b[0m 0.132   \u001b[0m | \u001b[0m 0.6544  \u001b[0m | \u001b[0m 0.2584  \u001b[0m | \u001b[0m 0.1492  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[95m 45      \u001b[0m | \u001b[95m 1.026   \u001b[0m | \u001b[95m 0.175   \u001b[0m | \u001b[95m 0.8299  \u001b[0m | \u001b[95m 0.5303  \u001b[0m | \u001b[95m 0.07356 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.9283  \u001b[0m | \u001b[0m 0.2802  \u001b[0m | \u001b[0m 0.7922  \u001b[0m | \u001b[0m 0.5893  \u001b[0m | \u001b[0m 0.1279  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.9255  \u001b[0m | \u001b[0m 0.9255  \u001b[0m | \u001b[0m 0.5999  \u001b[0m | \u001b[0m 0.9073  \u001b[0m | \u001b[0m 0.1557  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.747   \u001b[0m | \u001b[0m 0.8578  \u001b[0m | \u001b[0m 0.1327  \u001b[0m | \u001b[0m 0.06475 \u001b[0m | \u001b[0m 0.1419  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.9116  \u001b[0m | \u001b[0m 0.7321  \u001b[0m | \u001b[0m 0.5305  \u001b[0m | \u001b[0m 0.7538  \u001b[0m | \u001b[0m 0.1626  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.9453  \u001b[0m | \u001b[0m 0.1156  \u001b[0m | \u001b[0m 0.9424  \u001b[0m | \u001b[0m 0.5258  \u001b[0m | \u001b[0m 0.02434 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.9893  \u001b[0m | \u001b[0m 0.1451  \u001b[0m | \u001b[0m 0.8232  \u001b[0m | \u001b[0m 0.5562  \u001b[0m | \u001b[0m 0.04269 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.9929  \u001b[0m | \u001b[0m 0.2061  \u001b[0m | \u001b[0m 0.8599  \u001b[0m | \u001b[0m 0.5225  \u001b[0m | \u001b[0m 0.04694 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.9811  \u001b[0m | \u001b[0m 0.1663  \u001b[0m | \u001b[0m 0.8635  \u001b[0m | \u001b[0m 0.55    \u001b[0m | \u001b[0m 0.1073  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.9785  \u001b[0m | \u001b[0m 0.5496  \u001b[0m | \u001b[0m 0.5557  \u001b[0m | \u001b[0m 0.7633  \u001b[0m | \u001b[0m 0.07192 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 1.005   \u001b[0m | \u001b[0m 0.2024  \u001b[0m | \u001b[0m 0.7968  \u001b[0m | \u001b[0m 0.5499  \u001b[0m | \u001b[0m 0.06685 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 1.005   \u001b[0m | \u001b[0m 0.1716  \u001b[0m | \u001b[0m 0.7952  \u001b[0m | \u001b[0m 0.4734  \u001b[0m | \u001b[0m 0.0893  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.9624  \u001b[0m | \u001b[0m 0.4408  \u001b[0m | \u001b[0m 0.684   \u001b[0m | \u001b[0m 0.0252  \u001b[0m | \u001b[0m 0.1611  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.9864  \u001b[0m | \u001b[0m 0.1445  \u001b[0m | \u001b[0m 0.7013  \u001b[0m | \u001b[0m 0.3301  \u001b[0m | \u001b[0m 0.1289  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.984   \u001b[0m | \u001b[0m 0.06807 \u001b[0m | \u001b[0m 0.6671  \u001b[0m | \u001b[0m 0.2867  \u001b[0m | \u001b[0m 0.1058  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[95m 60      \u001b[0m | \u001b[95m 1.044   \u001b[0m | \u001b[95m 0.1556  \u001b[0m | \u001b[95m 0.6362  \u001b[0m | \u001b[95m 0.308   \u001b[0m | \u001b[95m 0.0943  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 1.008   \u001b[0m | \u001b[0m 0.164   \u001b[0m | \u001b[0m 0.6518  \u001b[0m | \u001b[0m 0.2661  \u001b[0m | \u001b[0m 0.06328 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 1.007   \u001b[0m | \u001b[0m 0.1403  \u001b[0m | \u001b[0m 0.5824  \u001b[0m | \u001b[0m 0.298   \u001b[0m | \u001b[0m 0.1025  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.9703  \u001b[0m | \u001b[0m 0.1446  \u001b[0m | \u001b[0m 0.6335  \u001b[0m | \u001b[0m 0.3689  \u001b[0m | \u001b[0m 0.03805 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.9168  \u001b[0m | \u001b[0m 0.7376  \u001b[0m | \u001b[0m 0.4363  \u001b[0m | \u001b[0m 0.3249  \u001b[0m | \u001b[0m 0.1785  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.9874  \u001b[0m | \u001b[0m 0.2065  \u001b[0m | \u001b[0m 0.6279  \u001b[0m | \u001b[0m 0.3062  \u001b[0m | \u001b[0m 0.1184  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.9314  \u001b[0m | \u001b[0m 0.5606  \u001b[0m | \u001b[0m 0.7158  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1336  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.9591  \u001b[0m | \u001b[0m 0.5522  \u001b[0m | \u001b[0m 0.97    \u001b[0m | \u001b[0m 0.02345 \u001b[0m | \u001b[0m 0.1028  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.7151  \u001b[0m | \u001b[0m 0.6523  \u001b[0m | \u001b[0m 0.09528 \u001b[0m | \u001b[0m 0.5087  \u001b[0m | \u001b[0m 0.1692  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.8612  \u001b[0m | \u001b[0m 0.04748 \u001b[0m | \u001b[0m 0.08419 \u001b[0m | \u001b[0m 0.8774  \u001b[0m | \u001b[0m 0.06753 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.9246  \u001b[0m | \u001b[0m 0.5319  \u001b[0m | \u001b[0m 0.9205  \u001b[0m | \u001b[0m 0.03353 \u001b[0m | \u001b[0m 0.1763  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 1.014   \u001b[0m | \u001b[0m 0.1234  \u001b[0m | \u001b[0m 0.6266  \u001b[0m | \u001b[0m 0.3358  \u001b[0m | \u001b[0m 0.1298  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.9981  \u001b[0m | \u001b[0m 0.9096  \u001b[0m | \u001b[0m 0.6604  \u001b[0m | \u001b[0m 0.8735  \u001b[0m | \u001b[0m 0.1342  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.7569  \u001b[0m | \u001b[0m 0.6755  \u001b[0m | \u001b[0m 0.1449  \u001b[0m | \u001b[0m 0.5736  \u001b[0m | \u001b[0m 0.1355  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.9133  \u001b[0m | \u001b[0m 0.8364  \u001b[0m | \u001b[0m 0.511   \u001b[0m | \u001b[0m 0.5621  \u001b[0m | \u001b[0m 0.1655  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.9511  \u001b[0m | \u001b[0m 0.7639  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.9884  \u001b[0m | \u001b[0m 0.4071  \u001b[0m | \u001b[0m 0.7737  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.08985 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.9468  \u001b[0m | \u001b[0m 0.3394  \u001b[0m | \u001b[0m 0.8871  \u001b[0m | \u001b[0m 0.02462 \u001b[0m | \u001b[0m 0.154   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 1.022   \u001b[0m | \u001b[0m 0.884   \u001b[0m | \u001b[0m 0.7026  \u001b[0m | \u001b[0m 0.8306  \u001b[0m | \u001b[0m 0.07433 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.9944  \u001b[0m | \u001b[0m 0.9253  \u001b[0m | \u001b[0m 0.7177  \u001b[0m | \u001b[0m 0.8935  \u001b[0m | \u001b[0m 0.06245 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 1.03    \u001b[0m | \u001b[0m 0.9622  \u001b[0m | \u001b[0m 0.6998  \u001b[0m | \u001b[0m 0.7955  \u001b[0m | \u001b[0m 0.08847 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.9876  \u001b[0m | \u001b[0m 0.3294  \u001b[0m | \u001b[0m 0.6108  \u001b[0m | \u001b[0m 0.02305 \u001b[0m | \u001b[0m 0.1568  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 1.017   \u001b[0m | \u001b[0m 0.9226  \u001b[0m | \u001b[0m 0.6484  \u001b[0m | \u001b[0m 0.8154  \u001b[0m | \u001b[0m 0.08088 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.9734  \u001b[0m | \u001b[0m 0.4375  \u001b[0m | \u001b[0m 0.9431  \u001b[0m | \u001b[0m 0.2214  \u001b[0m | \u001b[0m 0.03808 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 1.008   \u001b[0m | \u001b[0m 0.9165  \u001b[0m | \u001b[0m 0.6426  \u001b[0m | \u001b[0m 0.8183  \u001b[0m | \u001b[0m 0.07601 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.9594  \u001b[0m | \u001b[0m 0.6747  \u001b[0m | \u001b[0m 0.4729  \u001b[0m | \u001b[0m 0.8116  \u001b[0m | \u001b[0m 0.1264  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.9474  \u001b[0m | \u001b[0m 0.9114  \u001b[0m | \u001b[0m 0.7002  \u001b[0m | \u001b[0m 0.7902  \u001b[0m | \u001b[0m 0.1328  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 1.041   \u001b[0m | \u001b[0m 0.9986  \u001b[0m | \u001b[0m 0.6698  \u001b[0m | \u001b[0m 0.8497  \u001b[0m | \u001b[0m 0.07291 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.9797  \u001b[0m | \u001b[0m 0.1683  \u001b[0m | \u001b[0m 0.5244  \u001b[0m | \u001b[0m 0.9133  \u001b[0m | \u001b[0m 0.1067  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.9561  \u001b[0m | \u001b[0m 0.9636  \u001b[0m | \u001b[0m 0.6889  \u001b[0m | \u001b[0m 0.8209  \u001b[0m | \u001b[0m 0.0408  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 1.022   \u001b[0m | \u001b[0m 0.9952  \u001b[0m | \u001b[0m 0.6721  \u001b[0m | \u001b[0m 0.8315  \u001b[0m | \u001b[0m 0.1137  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.8357  \u001b[0m | \u001b[0m 0.7602  \u001b[0m | \u001b[0m 0.2187  \u001b[0m | \u001b[0m 0.009391\u001b[0m | \u001b[0m 0.1016  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[95m 92      \u001b[0m | \u001b[95m 1.047   \u001b[0m | \u001b[95m 0.8532  \u001b[0m | \u001b[95m 0.6484  \u001b[0m | \u001b[95m 0.808   \u001b[0m | \u001b[95m 0.08691 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 1.013   \u001b[0m | \u001b[0m 0.8179  \u001b[0m | \u001b[0m 0.6674  \u001b[0m | \u001b[0m 0.845   \u001b[0m | \u001b[0m 0.08025 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.9988  \u001b[0m | \u001b[0m 0.8291  \u001b[0m | \u001b[0m 0.6647  \u001b[0m | \u001b[0m 0.7718  \u001b[0m | \u001b[0m 0.05624 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.9893  \u001b[0m | \u001b[0m 0.988   \u001b[0m | \u001b[0m 0.7052  \u001b[0m | \u001b[0m 0.909   \u001b[0m | \u001b[0m 0.1018  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.9918  \u001b[0m | \u001b[0m 0.8303  \u001b[0m | \u001b[0m 0.608   \u001b[0m | \u001b[0m 0.8104  \u001b[0m | \u001b[0m 0.1099  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.9906  \u001b[0m | \u001b[0m 0.8217  \u001b[0m | \u001b[0m 0.9917  \u001b[0m | \u001b[0m 0.4861  \u001b[0m | \u001b[0m 0.07958 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 1.029   \u001b[0m | \u001b[0m 0.9961  \u001b[0m | \u001b[0m 0.6265  \u001b[0m | \u001b[0m 0.786   \u001b[0m | \u001b[0m 0.07592 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.98    \u001b[0m | \u001b[0m 0.9873  \u001b[0m | \u001b[0m 0.6711  \u001b[0m | \u001b[0m 0.6864  \u001b[0m | \u001b[0m 0.04365 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.9573  \u001b[0m | \u001b[0m 0.09637 \u001b[0m | \u001b[0m 0.4808  \u001b[0m | \u001b[0m 0.122   \u001b[0m | \u001b[0m 0.04263 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 0.9376  \u001b[0m | \u001b[0m 0.2373  \u001b[0m | \u001b[0m 0.1134  \u001b[0m | \u001b[0m 0.3088  \u001b[0m | \u001b[0m 0.03282 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 0.9337  \u001b[0m | \u001b[0m 0.9096  \u001b[0m | \u001b[0m 0.9508  \u001b[0m | \u001b[0m 0.5054  \u001b[0m | \u001b[0m 0.1472  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m 0.9673  \u001b[0m | \u001b[0m 0.453   \u001b[0m | \u001b[0m 0.7684  \u001b[0m | \u001b[0m 0.0971  \u001b[0m | \u001b[0m 0.09229 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m 0.9771  \u001b[0m | \u001b[0m 0.9534  \u001b[0m | \u001b[0m 0.5872  \u001b[0m | \u001b[0m 0.7359  \u001b[0m | \u001b[0m 0.1197  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m 0.9959  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.7927  \u001b[0m | \u001b[0m 0.5507  \u001b[0m | \u001b[0m 0.1066  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m 0.9148  \u001b[0m | \u001b[0m 0.5309  \u001b[0m | \u001b[0m 0.5853  \u001b[0m | \u001b[0m 0.3231  \u001b[0m | \u001b[0m 0.1647  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 107     \u001b[0m | \u001b[0m 1.011   \u001b[0m | \u001b[0m 0.9969  \u001b[0m | \u001b[0m 0.6675  \u001b[0m | \u001b[0m 0.7208  \u001b[0m | \u001b[0m 0.1231  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 108     \u001b[0m | \u001b[0m 0.9721  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.8673  \u001b[0m | \u001b[0m 0.5333  \u001b[0m | \u001b[0m 0.03587 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 109     \u001b[0m | \u001b[0m 0.8506  \u001b[0m | \u001b[0m 0.03218 \u001b[0m | \u001b[0m 0.1073  \u001b[0m | \u001b[0m 0.07253 \u001b[0m | \u001b[0m 0.08203 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 110     \u001b[0m | \u001b[0m 0.9945  \u001b[0m | \u001b[0m 0.8049  \u001b[0m | \u001b[0m 0.6496  \u001b[0m | \u001b[0m 0.0482  \u001b[0m | \u001b[0m 0.1638  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 111     \u001b[0m | \u001b[0m 0.9893  \u001b[0m | \u001b[0m 0.3777  \u001b[0m | \u001b[0m 0.5503  \u001b[0m | \u001b[0m 0.4411  \u001b[0m | \u001b[0m 0.1932  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 112     \u001b[0m | \u001b[0m 0.9662  \u001b[0m | \u001b[0m 0.8943  \u001b[0m | \u001b[0m 0.6574  \u001b[0m | \u001b[0m 0.2898  \u001b[0m | \u001b[0m 0.1254  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 113     \u001b[0m | \u001b[0m 0.7337  \u001b[0m | \u001b[0m 0.175   \u001b[0m | \u001b[0m 0.1485  \u001b[0m | \u001b[0m 0.8286  \u001b[0m | \u001b[0m 0.1627  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 114     \u001b[0m | \u001b[0m 0.9543  \u001b[0m | \u001b[0m 0.4988  \u001b[0m | \u001b[0m 0.3996  \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 0.08133 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 115     \u001b[0m | \u001b[0m 0.9932  \u001b[0m | \u001b[0m 0.9748  \u001b[0m | \u001b[0m 0.8034  \u001b[0m | \u001b[0m 0.6438  \u001b[0m | \u001b[0m 0.08893 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 116     \u001b[0m | \u001b[0m 0.9869  \u001b[0m | \u001b[0m 0.2073  \u001b[0m | \u001b[0m 0.8649  \u001b[0m | \u001b[0m 0.5145  \u001b[0m | \u001b[0m 0.04317 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 117     \u001b[0m | \u001b[0m 0.9758  \u001b[0m | \u001b[0m 0.9076  \u001b[0m | \u001b[0m 0.6636  \u001b[0m | \u001b[0m 0.8829  \u001b[0m | \u001b[0m 0.128   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 118     \u001b[0m | \u001b[0m 1.022   \u001b[0m | \u001b[0m 0.8675  \u001b[0m | \u001b[0m 0.6559  \u001b[0m | \u001b[0m 0.8283  \u001b[0m | \u001b[0m 0.1151  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 119     \u001b[0m | \u001b[0m 0.9992  \u001b[0m | \u001b[0m 0.3557  \u001b[0m | \u001b[0m 0.9303  \u001b[0m | \u001b[0m 0.1749  \u001b[0m | \u001b[0m 0.09178 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 120     \u001b[0m | \u001b[0m 1.013   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.7344  \u001b[0m | \u001b[0m 0.7501  \u001b[0m | \u001b[0m 0.08906 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 121     \u001b[0m | \u001b[0m 0.9559  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.7237  \u001b[0m | \u001b[0m 0.6215  \u001b[0m | \u001b[0m 0.1604  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 122     \u001b[0m | \u001b[0m 1.008   \u001b[0m | \u001b[0m 0.3113  \u001b[0m | \u001b[0m 0.891   \u001b[0m | \u001b[0m 0.2598  \u001b[0m | \u001b[0m 0.06809 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 123     \u001b[0m | \u001b[0m 1.04    \u001b[0m | \u001b[0m 0.6293  \u001b[0m | \u001b[0m 0.6102  \u001b[0m | \u001b[0m 0.9806  \u001b[0m | \u001b[0m 0.06932 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 124     \u001b[0m | \u001b[0m 0.9705  \u001b[0m | \u001b[0m 0.6498  \u001b[0m | \u001b[0m 0.6571  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.03933 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003024 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 125     \u001b[0m | \u001b[0m 1.002   \u001b[0m | \u001b[0m 0.6483  \u001b[0m | \u001b[0m 0.6004  \u001b[0m | \u001b[0m 0.9313  \u001b[0m | \u001b[0m 0.0612  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 126     \u001b[0m | \u001b[0m 1.025   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.6177  \u001b[0m | \u001b[0m 0.8553  \u001b[0m | \u001b[0m 0.08177 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 127     \u001b[0m | \u001b[0m 0.9967  \u001b[0m | \u001b[0m 0.651   \u001b[0m | \u001b[0m 0.618   \u001b[0m | \u001b[0m 0.9859  \u001b[0m | \u001b[0m 0.1247  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 128     \u001b[0m | \u001b[0m 1.02    \u001b[0m | \u001b[0m 0.6209  \u001b[0m | \u001b[0m 0.5533  \u001b[0m | \u001b[0m 0.9964  \u001b[0m | \u001b[0m 0.05151 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 129     \u001b[0m | \u001b[0m 0.9772  \u001b[0m | \u001b[0m 0.9718  \u001b[0m | \u001b[0m 0.5155  \u001b[0m | \u001b[0m 0.2758  \u001b[0m | \u001b[0m 0.06509 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001323 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 130     \u001b[0m | \u001b[0m 0.9962  \u001b[0m | \u001b[0m 0.3119  \u001b[0m | \u001b[0m 0.9854  \u001b[0m | \u001b[0m 0.2577  \u001b[0m | \u001b[0m 0.09796 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 131     \u001b[0m | \u001b[0m 0.9433  \u001b[0m | \u001b[0m 0.4564  \u001b[0m | \u001b[0m 0.6958  \u001b[0m | \u001b[0m 0.1633  \u001b[0m | \u001b[0m 0.03871 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 132     \u001b[0m | \u001b[0m 0.7799  \u001b[0m | \u001b[0m 0.005215\u001b[0m | \u001b[0m 0.4063  \u001b[0m | \u001b[0m 0.6674  \u001b[0m | \u001b[0m 0.007483\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 133     \u001b[0m | \u001b[0m 0.7313  \u001b[0m | \u001b[0m 0.6371  \u001b[0m | \u001b[0m 0.1634  \u001b[0m | \u001b[0m 0.6574  \u001b[0m | \u001b[0m 0.1645  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 134     \u001b[0m | \u001b[0m 0.9767  \u001b[0m | \u001b[0m 0.1217  \u001b[0m | \u001b[0m 0.6264  \u001b[0m | \u001b[0m 0.3375  \u001b[0m | \u001b[0m 0.1312  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 135     \u001b[0m | \u001b[0m 0.8609  \u001b[0m | \u001b[0m 0.4763  \u001b[0m | \u001b[0m 0.2262  \u001b[0m | \u001b[0m 0.6019  \u001b[0m | \u001b[0m 0.09566 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001768 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 136     \u001b[0m | \u001b[0m 0.974   \u001b[0m | \u001b[0m 0.7141  \u001b[0m | \u001b[0m 0.7602  \u001b[0m | \u001b[0m 0.8233  \u001b[0m | \u001b[0m 0.09587 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 137     \u001b[0m | \u001b[0m 1.017   \u001b[0m | \u001b[0m 0.8592  \u001b[0m | \u001b[0m 0.6705  \u001b[0m | \u001b[0m 0.8233  \u001b[0m | \u001b[0m 0.07857 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 138     \u001b[0m | \u001b[0m 1.042   \u001b[0m | \u001b[0m 0.1242  \u001b[0m | \u001b[0m 0.6136  \u001b[0m | \u001b[0m 0.3159  \u001b[0m | \u001b[0m 0.1305  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 139     \u001b[0m | \u001b[0m 0.9815  \u001b[0m | \u001b[0m 0.1375  \u001b[0m | \u001b[0m 0.6305  \u001b[0m | \u001b[0m 0.3249  \u001b[0m | \u001b[0m 0.1191  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 140     \u001b[0m | \u001b[0m 1.007   \u001b[0m | \u001b[0m 0.8211  \u001b[0m | \u001b[0m 0.6515  \u001b[0m | \u001b[0m 0.8471  \u001b[0m | \u001b[0m 0.09987 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 141     \u001b[0m | \u001b[0m 1.01    \u001b[0m | \u001b[0m 0.6359  \u001b[0m | \u001b[0m 0.6049  \u001b[0m | \u001b[0m 0.9657  \u001b[0m | \u001b[0m 0.06735 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 142     \u001b[0m | \u001b[0m 0.9955  \u001b[0m | \u001b[0m 0.718   \u001b[0m | \u001b[0m 0.3636  \u001b[0m | \u001b[0m 0.5007  \u001b[0m | \u001b[0m 0.06002 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 143     \u001b[0m | \u001b[0m 0.9954  \u001b[0m | \u001b[0m 0.1266  \u001b[0m | \u001b[0m 0.6219  \u001b[0m | \u001b[0m 0.3268  \u001b[0m | \u001b[0m 0.1266  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 144     \u001b[0m | \u001b[0m 1.015   \u001b[0m | \u001b[0m 0.1597  \u001b[0m | \u001b[0m 0.8525  \u001b[0m | \u001b[0m 0.5333  \u001b[0m | \u001b[0m 0.09127 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 145     \u001b[0m | \u001b[0m 0.9515  \u001b[0m | \u001b[0m 0.7983  \u001b[0m | \u001b[0m 0.8137  \u001b[0m | \u001b[0m 0.7879  \u001b[0m | \u001b[0m 0.1931  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 146     \u001b[0m | \u001b[0m 1.014   \u001b[0m | \u001b[0m 0.9909  \u001b[0m | \u001b[0m 0.6321  \u001b[0m | \u001b[0m 0.7957  \u001b[0m | \u001b[0m 0.07635 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 147     \u001b[0m | \u001b[0m 1.037   \u001b[0m | \u001b[0m 0.1233  \u001b[0m | \u001b[0m 0.6206  \u001b[0m | \u001b[0m 0.2996  \u001b[0m | \u001b[0m 0.127   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 148     \u001b[0m | \u001b[0m 1.008   \u001b[0m | \u001b[0m 0.9795  \u001b[0m | \u001b[0m 0.6602  \u001b[0m | \u001b[0m 0.8286  \u001b[0m | \u001b[0m 0.0761  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 149     \u001b[0m | \u001b[0m 0.9463  \u001b[0m | \u001b[0m 0.9959  \u001b[0m | \u001b[0m 0.7223  \u001b[0m | \u001b[0m 0.9249  \u001b[0m | \u001b[0m 0.03703 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 150     \u001b[0m | \u001b[0m 0.9895  \u001b[0m | \u001b[0m 0.155   \u001b[0m | \u001b[0m 0.652   \u001b[0m | \u001b[0m 0.3201  \u001b[0m | \u001b[0m 0.1042  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 151     \u001b[0m | \u001b[0m 0.9358  \u001b[0m | \u001b[0m 0.966   \u001b[0m | \u001b[0m 0.5796  \u001b[0m | \u001b[0m 0.5286  \u001b[0m | \u001b[0m 0.1688  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 152     \u001b[0m | \u001b[0m 1.018   \u001b[0m | \u001b[0m 0.8635  \u001b[0m | \u001b[0m 0.6535  \u001b[0m | \u001b[0m 0.8101  \u001b[0m | \u001b[0m 0.0629  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 153     \u001b[0m | \u001b[0m 1.005   \u001b[0m | \u001b[0m 0.172   \u001b[0m | \u001b[0m 0.8434  \u001b[0m | \u001b[0m 0.5421  \u001b[0m | \u001b[0m 0.07743 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 154     \u001b[0m | \u001b[0m 1.04    \u001b[0m | \u001b[0m 0.9956  \u001b[0m | \u001b[0m 0.6676  \u001b[0m | \u001b[0m 0.8412  \u001b[0m | \u001b[0m 0.0875  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 155     \u001b[0m | \u001b[0m 0.8205  \u001b[0m | \u001b[0m 0.7982  \u001b[0m | \u001b[0m 0.02093 \u001b[0m | \u001b[0m 0.9839  \u001b[0m | \u001b[0m 0.0181  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 156     \u001b[0m | \u001b[0m 1.01    \u001b[0m | \u001b[0m 0.9968  \u001b[0m | \u001b[0m 0.6536  \u001b[0m | \u001b[0m 0.847   \u001b[0m | \u001b[0m 0.07871 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 157     \u001b[0m | \u001b[0m 1.009   \u001b[0m | \u001b[0m 0.1968  \u001b[0m | \u001b[0m 0.8396  \u001b[0m | \u001b[0m 0.5162  \u001b[0m | \u001b[0m 0.06944 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 158     \u001b[0m | \u001b[0m 1.015   \u001b[0m | \u001b[0m 0.9686  \u001b[0m | \u001b[0m 0.6568  \u001b[0m | \u001b[0m 0.8601  \u001b[0m | \u001b[0m 0.08628 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 159     \u001b[0m | \u001b[0m 1.029   \u001b[0m | \u001b[0m 0.5032  \u001b[0m | \u001b[0m 0.6202  \u001b[0m | \u001b[0m 0.000159\u001b[0m | \u001b[0m 0.09484 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 160     \u001b[0m | \u001b[0m 0.7316  \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 0.151   \u001b[0m | \u001b[0m 0.1985  \u001b[0m | \u001b[0m 0.1587  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 161     \u001b[0m | \u001b[0m 0.9897  \u001b[0m | \u001b[0m 0.5426  \u001b[0m | \u001b[0m 0.7799  \u001b[0m | \u001b[0m 0.7906  \u001b[0m | \u001b[0m 0.07285 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 162     \u001b[0m | \u001b[0m 1.02    \u001b[0m | \u001b[0m 0.8576  \u001b[0m | \u001b[0m 0.6701  \u001b[0m | \u001b[0m 0.7887  \u001b[0m | \u001b[0m 0.07748 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 163     \u001b[0m | \u001b[0m 0.9983  \u001b[0m | \u001b[0m 0.8658  \u001b[0m | \u001b[0m 0.6582  \u001b[0m | \u001b[0m 0.8082  \u001b[0m | \u001b[0m 0.08815 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 164     \u001b[0m | \u001b[0m 0.9752  \u001b[0m | \u001b[0m 0.843   \u001b[0m | \u001b[0m 0.6498  \u001b[0m | \u001b[0m 0.7858  \u001b[0m | \u001b[0m 0.1007  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 165     \u001b[0m | \u001b[0m 0.9663  \u001b[0m | \u001b[0m 0.1239  \u001b[0m | \u001b[0m 0.6067  \u001b[0m | \u001b[0m 0.3051  \u001b[0m | \u001b[0m 0.1334  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 166     \u001b[0m | \u001b[0m 1.007   \u001b[0m | \u001b[0m 0.1917  \u001b[0m | \u001b[0m 0.8277  \u001b[0m | \u001b[0m 0.5381  \u001b[0m | \u001b[0m 0.06687 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 167     \u001b[0m | \u001b[0m 0.999   \u001b[0m | \u001b[0m 0.1474  \u001b[0m | \u001b[0m 0.6415  \u001b[0m | \u001b[0m 0.3006  \u001b[0m | \u001b[0m 0.09912 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 168     \u001b[0m | \u001b[0m 0.9865  \u001b[0m | \u001b[0m 0.9819  \u001b[0m | \u001b[0m 0.6855  \u001b[0m | \u001b[0m 0.8339  \u001b[0m | \u001b[0m 0.1055  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 169     \u001b[0m | \u001b[0m 1.03    \u001b[0m | \u001b[0m 0.8405  \u001b[0m | \u001b[0m 0.6514  \u001b[0m | \u001b[0m 0.8119  \u001b[0m | \u001b[0m 0.07306 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 170     \u001b[0m | \u001b[0m 0.879   \u001b[0m | \u001b[0m 0.1126  \u001b[0m | \u001b[0m 0.05589 \u001b[0m | \u001b[0m 0.6575  \u001b[0m | \u001b[0m 0.059   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 171     \u001b[0m | \u001b[0m 0.993   \u001b[0m | \u001b[0m 0.9918  \u001b[0m | \u001b[0m 0.3839  \u001b[0m | \u001b[0m 0.708   \u001b[0m | \u001b[0m 0.04369 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 172     \u001b[0m | \u001b[0m 0.7099  \u001b[0m | \u001b[0m 0.1921  \u001b[0m | \u001b[0m 0.09951 \u001b[0m | \u001b[0m 0.9185  \u001b[0m | \u001b[0m 0.198   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 173     \u001b[0m | \u001b[0m 0.9573  \u001b[0m | \u001b[0m 0.3473  \u001b[0m | \u001b[0m 0.7934  \u001b[0m | \u001b[0m 0.6766  \u001b[0m | \u001b[0m 0.03403 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 174     \u001b[0m | \u001b[0m 0.9039  \u001b[0m | \u001b[0m 0.8032  \u001b[0m | \u001b[0m 0.6111  \u001b[0m | \u001b[0m 0.1108  \u001b[0m | \u001b[0m 0.01533 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 175     \u001b[0m | \u001b[0m 0.828   \u001b[0m | \u001b[0m 0.4336  \u001b[0m | \u001b[0m 0.6812  \u001b[0m | \u001b[0m 0.7448  \u001b[0m | \u001b[0m 0.007285\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 176     \u001b[0m | \u001b[0m 0.991   \u001b[0m | \u001b[0m 0.8534  \u001b[0m | \u001b[0m 0.6933  \u001b[0m | \u001b[0m 0.8095  \u001b[0m | \u001b[0m 0.08709 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 177     \u001b[0m | \u001b[0m 1.003   \u001b[0m | \u001b[0m 0.8825  \u001b[0m | \u001b[0m 0.6513  \u001b[0m | \u001b[0m 0.8374  \u001b[0m | \u001b[0m 0.08834 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 178     \u001b[0m | \u001b[0m 0.9992  \u001b[0m | \u001b[0m 0.172   \u001b[0m | \u001b[0m 0.6342  \u001b[0m | \u001b[0m 0.2927  \u001b[0m | \u001b[0m 0.0991  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 179     \u001b[0m | \u001b[0m 1.008   \u001b[0m | \u001b[0m 0.6336  \u001b[0m | \u001b[0m 0.6233  \u001b[0m | \u001b[0m 0.9702  \u001b[0m | \u001b[0m 0.06332 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 180     \u001b[0m | \u001b[0m 0.6645  \u001b[0m | \u001b[0m 0.3442  \u001b[0m | \u001b[0m 0.05363 \u001b[0m | \u001b[0m 0.8048  \u001b[0m | \u001b[0m 0.00231 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 181     \u001b[0m | \u001b[0m 1.004   \u001b[0m | \u001b[0m 0.9876  \u001b[0m | \u001b[0m 0.6771  \u001b[0m | \u001b[0m 0.8646  \u001b[0m | \u001b[0m 0.08881 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 182     \u001b[0m | \u001b[0m 1.01    \u001b[0m | \u001b[0m 0.8488  \u001b[0m | \u001b[0m 0.6656  \u001b[0m | \u001b[0m 0.8312  \u001b[0m | \u001b[0m 0.08514 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 183     \u001b[0m | \u001b[0m 1.022   \u001b[0m | \u001b[0m 0.8381  \u001b[0m | \u001b[0m 0.6622  \u001b[0m | \u001b[0m 0.7937  \u001b[0m | \u001b[0m 0.07278 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 184     \u001b[0m | \u001b[0m 1.005   \u001b[0m | \u001b[0m 0.9873  \u001b[0m | \u001b[0m 0.7213  \u001b[0m | \u001b[0m 0.78    \u001b[0m | \u001b[0m 0.07919 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 185     \u001b[0m | \u001b[0m 0.9924  \u001b[0m | \u001b[0m 0.6373  \u001b[0m | \u001b[0m 0.5943  \u001b[0m | \u001b[0m 0.9883  \u001b[0m | \u001b[0m 0.04913 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 186     \u001b[0m | \u001b[0m 1.018   \u001b[0m | \u001b[0m 0.9997  \u001b[0m | \u001b[0m 0.6829  \u001b[0m | \u001b[0m 0.8466  \u001b[0m | \u001b[0m 0.07465 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 187     \u001b[0m | \u001b[0m 1.032   \u001b[0m | \u001b[0m 0.1612  \u001b[0m | \u001b[0m 0.6341  \u001b[0m | \u001b[0m 0.3079  \u001b[0m | \u001b[0m 0.07941 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 188     \u001b[0m | \u001b[0m 1.01    \u001b[0m | \u001b[0m 0.1562  \u001b[0m | \u001b[0m 0.6189  \u001b[0m | \u001b[0m 0.3063  \u001b[0m | \u001b[0m 0.09072 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001802 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 189     \u001b[0m | \u001b[0m 1.019   \u001b[0m | \u001b[0m 0.8936  \u001b[0m | \u001b[0m 0.6434  \u001b[0m | \u001b[0m 0.8317  \u001b[0m | \u001b[0m 0.1213  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 190     \u001b[0m | \u001b[0m 0.9951  \u001b[0m | \u001b[0m 0.847   \u001b[0m | \u001b[0m 0.6753  \u001b[0m | \u001b[0m 0.8146  \u001b[0m | \u001b[0m 0.05432 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 191     \u001b[0m | \u001b[0m 0.9912  \u001b[0m | \u001b[0m 0.4962  \u001b[0m | \u001b[0m 0.6177  \u001b[0m | \u001b[0m 0.02478 \u001b[0m | \u001b[0m 0.1082  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 192     \u001b[0m | \u001b[0m 1.017   \u001b[0m | \u001b[0m 0.1787  \u001b[0m | \u001b[0m 0.822   \u001b[0m | \u001b[0m 0.5767  \u001b[0m | \u001b[0m 0.06112 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 193     \u001b[0m | \u001b[0m 1.014   \u001b[0m | \u001b[0m 0.892   \u001b[0m | \u001b[0m 0.6736  \u001b[0m | \u001b[0m 0.8322  \u001b[0m | \u001b[0m 0.09082 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 194     \u001b[0m | \u001b[0m 0.9235  \u001b[0m | \u001b[0m 0.9335  \u001b[0m | \u001b[0m 0.3802  \u001b[0m | \u001b[0m 0.1046  \u001b[0m | \u001b[0m 0.1353  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 195     \u001b[0m | \u001b[0m 1.031   \u001b[0m | \u001b[0m 0.17    \u001b[0m | \u001b[0m 0.6345  \u001b[0m | \u001b[0m 0.3173  \u001b[0m | \u001b[0m 0.0923  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 196     \u001b[0m | \u001b[0m 0.9979  \u001b[0m | \u001b[0m 0.832   \u001b[0m | \u001b[0m 0.6394  \u001b[0m | \u001b[0m 0.8264  \u001b[0m | \u001b[0m 0.1068  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 197     \u001b[0m | \u001b[0m 1.007   \u001b[0m | \u001b[0m 0.1934  \u001b[0m | \u001b[0m 0.8288  \u001b[0m | \u001b[0m 0.5705  \u001b[0m | \u001b[0m 0.05049 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 198     \u001b[0m | \u001b[0m 1.013   \u001b[0m | \u001b[0m 0.9088  \u001b[0m | \u001b[0m 0.6531  \u001b[0m | \u001b[0m 0.8323  \u001b[0m | \u001b[0m 0.09864 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 199     \u001b[0m | \u001b[0m 1.021   \u001b[0m | \u001b[0m 0.9961  \u001b[0m | \u001b[0m 0.6831  \u001b[0m | \u001b[0m 0.8224  \u001b[0m | \u001b[0m 0.09527 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 200     \u001b[0m | \u001b[0m 1.016   \u001b[0m | \u001b[0m 0.8904  \u001b[0m | \u001b[0m 0.7087  \u001b[0m | \u001b[0m 0.8113  \u001b[0m | \u001b[0m 0.08428 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 201     \u001b[0m | \u001b[0m 1.007   \u001b[0m | \u001b[0m 0.1704  \u001b[0m | \u001b[0m 0.8109  \u001b[0m | \u001b[0m 0.5495  \u001b[0m | \u001b[0m 0.06848 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1211\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 2.554473\n",
      "| \u001b[0m 202     \u001b[0m | \u001b[0m 1.009   \u001b[0m | \u001b[0m 0.9617  \u001b[0m | \u001b[0m 0.6866  \u001b[0m | \u001b[0m 0.7811  \u001b[0m | \u001b[0m 0.08772 \u001b[0m |\n",
      "=========================================================================\n",
      "{'target': 1.0467026608312262, 'params': {'bagging_fraction': 0.8532006036285371, 'feature_fraction': 0.64842744223531, 'lambda_l2': 0.8080489929934741, 'learning_rate': 0.08690800978587224}}\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize as optimize\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "params = {\"learning_rate\": (0.0001, 0.2),\n",
    "            \"feature_fraction\" : (0.0001, 1),\n",
    "            \"bagging_fraction\" : (0.0001, 1),\n",
    "            \"lambda_l2\" : (0 , 1)\n",
    "            }\n",
    "\n",
    "capacity = 1000\n",
    "train_max = 1\n",
    "train_min = 0\n",
    "\n",
    "bo=BayesianOptimization(f=LGB_cv, \n",
    "                    pbounds=params, \n",
    "                    verbose=2, \n",
    "                    random_state=40)\n",
    "\n",
    "\n",
    "bo.maximize(init_points=2, n_iter=200, acq='ei', xi=0.01)\n",
    "\n",
    "print(bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ef026d0970>]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'bagging_fraction': 0.8532006036285371,\n",
    " 'feature_fraction': 0.64842744223531,\n",
    " 'lambda_l2': 0.8080489929934741,\n",
    " 'learning_rate': 0.08690800978587224}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 983\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's score: 0.0486761\n"
     ]
    }
   ],
   "source": [
    "capacity = 1000\n",
    "sun_radio_model = lgb.train(params, \n",
    "                           train_dataset, \n",
    "                           10000, \n",
    "                           val_dataset, \n",
    "                           feval= nmae_10_lgb, \n",
    "                           verbose_eval=500, \n",
    "                           early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sun_radio_model.pkl']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(sun_radio_model,\"sun_radio_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sun_radio_model.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ef030595e0>]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAAI/CAYAAADgJsn+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOy9d5wsaV3v/6nqqu7q3JPOnDk57+45G87ZBLukBVZAYFlARDCAermoqNcrxnvVK+pPvV7DVQRBrwkQEUSySHQT7LL5bDq7J+cwuXs6V1f4/VFVPT09HSo8VZ2+79drX7Onp7uqprur6nk+z+f7+XK6roMgCIIgCIIgCIIgCIIYbvheHwBBEARBEARBEARBEAThPyQCEQRBEARBEARBEARBjAAkAhEEQRAEQRAEQRAEQYwAJAIRBEEQBEEQBEEQBEGMACQCEQRBEARBEARBEARBjAAkAhEEQRAEQRAEQRAEQYwAQq92PDk5qe/YsaNXuycIgiAIgiAIgiAIghg6Hn/88QVd16da/a5nItCOHTvw2GOP9Wr3BEEQBEEQBEEQBEEQQwfHcWfb/Y7KwQiCIAiCIAiCIAiCIEYAEoEIgiAIgiAIgiAIgiBGABKBCIIgCIIgCIIgCIIgRgASgQiCIAiCIAiCIAiCIEYAEoEIgiAIgiAIgiAIgiBGABKBCIIgCIIgCIIgCIIgRgASgQiCIAiCIAiCIAiCIEYAEoEIgiAIgiAIgiAIgiBGABKBCIIgCIIgCIIgCIIgRgASgQiCIAiCIAiCIAiCIEYAEoEIgiAIgiAIgiAIgiBGABKBCIIgCIIgCIIgCIIgRgASgQiCIAiCIAiCIAiCIEYAEoEIgiAIgiAIgiAIgiBGABKBCIIgCIIgCIIgCIIgRgASgQiCIAiCIAiCIAiCIEYAEoEIgiAIgiAIgiAIgiBGABKBCIIgCIIgCIIgCIIgRgASgQiCIAiCIAiCIAiCIEYAEoEIgiAIgiAIgiAIgiBGABKBCIIgCIIgCIIgCIIgRgASgQiCIAiCIAiCIAiCIEYAodcHQBAEQRBEsHzn+AK+e3IBl7JlXMqWMR4P46M/ehM4juv1oREEQRAEQRA+QiIQQRAEQYwY//3Th5EtyZjJSAhxHB49s4y5fBXTKanXh0YQBEEQBEH4CJWDEQRBEMQIoagaFotV/Owr9+CBX30V/uAt1wEAjs8WenxkBEEQBEEQhN+QCEQQBEEQI8RSSYauA5OJMABgz3QCAHBiLt/LwyIIgiAIgiACgEQggiAIghghFgsyAGAyEQEATCUiSEkCjs+RE4ggCIIgCGLYIRGIIAiCIEYISwSaMEUgjuOwdzqJEyQCEQRBEARBDD0kAhEEQRDECLFQqAJYLQcDgD1TCRKBCIIgCIIgRgASgQiCIAhihLBEIMsJBAB7pxNYLMpYKsq9OiyCIAiCIAgiAEgEIgiCIIgRYqEgIxzikZKE+mO7N1jh0OQGIgiCIAiCGGZIBCIIgiCIEWKxUMVEIgyO4+qP7TVFoOPUIYwgCIIgCGKoIRGIIAiCIEaIhUK13hnMYlM6ilg4RE4ggiAIgiCIIYdEIIIgCIIYIRaLMiYaQqEBgOc57KZwaIIgCIIgiKGHRCCCIAiCGCEW8uudQIBREkYiEEEQBEEQxHBDIhBBEARBjAi6rmOhhRMIMMKhL+cqyFdqPTgygiAIgiAIIghsi0Acx4U4jnuS47ivtPgdx3HcBzmOO8Fx3NMcx93I9jAJgiAIgvBKvqpAVjRMtXECAcDJ+WLQh0UQBEEQBEEEhBMn0C8AeL7N774fwF7zv/cC+IjH4yIIgiAIgjGLBRkAWjqB9k4nAQDHZ6lDGEEQBEEQxLAi2HkSx3FbALwBwO8DeH+Lp9wN4OO6rusAvsdxXIbjuBld1y+zO9QhI3cRqJV6fRRsiKSA5DS77cklQIgAfIjdNu2g68DyaUBTg92vU9JbAVEKfr8rlwHZRl4IxwPju4CG9tOeUGvGZ9KLv5kg+gVG94zCxSx2cZewVZsEFsprfrdV1XBV6AqWzoaAHRXP+/KMIAGZrb0+isFGMUQ/COtFv4GjWgDywzKs5Iz7JE+pDAQROKUloLTY66MYHaQMkJhit70gPr/0FkCM+ruPHmNLBALw5wB+FUCyze83Azjf8O8L5mPDcrdmy+Wngb9+Wa+Pgh1cCHj/82yEIE0DPngQePmvALf+V+/bc8KTnwC+9PPB7tMNV70eeOengt3n4kngLx1Ueb7hT4Fb3sNm31//n8Dc88CPr6tEJYjR4PJTwF+/nMmmrgPwnxEAX17/OwHA10UAz5j/9QPv/jKwk83fPpJ8/qcAXQPe/rFeH4l3PvFm4MKjvT4KdrzyN4FX/Eqvj4IgRgtNAz54CKhke30kowMvAr98DIiNe9+WIgN/cQNQXfG+rU78l28CW2/1dx89pqsIxHHcGwHM6br+OMdxd7R7WovH9Bbbei+McjFs27bN/lEOG9lzxs9X/zaQGfD34fJTwIMfBFYushGB5AJQmDVEh6BZPmsIWm/9m+D3bZeHPrz6/QmSnKnxvuLXgcm9nZ/7hZ9he4yLJ4z/CGJUsc6nOz9gOAE98MDxefzrYxfwe28+gHR0vTvk7797GueXSvjtuw542o9nSkvAf/xKb653w8TiCcPlOgwsnwV2vgK48V29PhLvfPWXgezZXh8FQYwe1RVDALrhncCeO3t9NMPPxceB7/2VMbdjIQJVssZneOhHgV2v9L69dozv9m/bfYIdJ9BLALyJ47jXA5AApDiO+ydd13+04TkXADSOTLcAuNS8IV3X/wbA3wDAzTffPCSjEhdY6vO1bwXGdvTySLyT2mSIQKwUdWs7vVDoK1lASgPXvS34fdvl5H8Cp+4Lfr/lrPHzmruAjdd2fu7X/sfq81ntm+X2CGLAqBWXIAJ4PPFK3LD/eggh9yUkj88ew5f14/izm74faLGdldlj+MdvH8evXf06SGLAJbmNlLOGCETnvjcq2eEQgXTd+Fs2Hezve7Rd7v9jciIQRC+wzrsdLxuOa0m/Exs3RCBW93JrOzvvoM/PI11Hkrqu/w9d17four4DwDsA/GeTAAQAXwLwLrNL2IsB5CgPqAOVnPFTyvT0MJhg/Q3W3+QVazustud039FM8Pt1gpTp3XsD2Ht/ohm2x1jJAUoZUKrstkkQA8TpC8aayo//y3Hc+gffxq999mmcmLORz9WChUIVY7FwWyFp74YkdB04Oe9u+8yIpABwvbneDROV3HC8h0oFUOXhGDcBvbuXE8So42Q8S3jHr3kifX6ecb2cyHHcT3Mc99PmP78K4BSAEwD+H4D3MTi24aWSA8CZg9wBR0obP4dFBLL+nn5FSgNyHlCVYPdbFy5tvD9Smr0IBAAVn+t/CaJPKeaWoOkcfuutt+Kleybx+cMX8affOOpqW4sFGRPx9iHBe8w28W5FJmbwPCClaKLsBU0zrpvVlf5veNANJ/egQYD1fZIgCHsM27Wk3/Frnkifn2cciUC6rt+r6/obzf//qK7rHzX/X9d1/Wd1Xd+t6/p1uq4/5sfBDg3lrCEADUNXCOskZG3z60UJQDnb/xcV6/j8DkRrppI18pLCie7PldLsbO5WCYB1DAQxgsiFJeQRww/esg0ffOchvHzvlGunzkKhislEpO3vd07GEQ7xeP5yH7SJZ3ktGUWqK6jHMw664GCNCfr9Hm0XKU2ljgTRC4btWtLv1J1AWTbbs7ZDn59nhkCFGEAqOSA6JF/ecBzghSFyAmWC368TLPtj0BMjyyVlp+07S5t7rQRoyuoxEMQIopaWUQolwJnn3+6pOM4slqBqzrNeFgsyJhLtnUBhgcfe6QSOXO4D5x2VzHij8b0b9Pdx2EoAWJdNEwRhj2GK5BgEmDuBsuZ2M2y2N8KQCNQLBqHsyC4cx9bW3HMRqM8/F9YXU7s4eW/8+D4A5AggRhausoKakKz/e9dUHLKi4eJy2fG25rs4gQBg/0wKRy7loPc6UJhKZrwxTNfPYZu4SWmzTE/r9ZEQxGhB5UTBEhKMKgIqB+s7SATqBZXs8AxkALaWfWs7Pcm9yfb/RYV1+Z1dnJTKWTZ3FhPIxr+TrPPECKJpOsLKCrTI6vm3a8ooyzy54KwkrKqoyFcUTHZwAgHA/k0pLBRkzOd7HMZOJTPeaLwvD7qYNmwlAFIa0DVjrEMQRHBUsgDH24s3INjA8l5ezgKhCCBKbLY3wpAI1AsGwXHiBJaW/cbtBJl7U6sY3Uf63WrOOmXfLk46p0UzgK4CcpHNflv9P0GMCLP5ChJ6EXwsU39s12QcAHBq3tk5tliQAQATNpxAAPBcr0vCqGTGG8N0/Rw6J1DG+DnonwtBDBrWHIxhLuunHjmH3/j8My1/t1yUUVUGPJjfK1KGoVlgADo5DwgkAvWCcnZ4BjIAe4W3/v/LbLZph0GxF9bLwbLB7teJS4rlMa5ZyWawPYIYMM4tlpDmigjHx+qPjcfDSEdFnHIYDm2JQN3Kwa7ZZIhARy71WARiOXAcRYbJSTlsYa69cvUSxKjjQxOYf33sPD758Dk8dmZpzeMlWcH3/8UDeOtfPYiyPMJCENOYiOzw3Ad6DIlADDkxl8cffvX57jkKw6Zislyt7dXK5aCsMtaDoXuRCZSx91yWK5zDtJJNEC44u1RCCiVEUxP1xziOw66puGMn0ELBKO/qFAwNAClJxLbxWO/DoaWMEQ6vyL09jkFlmK6flSwgxgCh83d3YOjVvZwgRh3GTWBUTccLV4yyzg/dc2LN7/7hu2dwZaWCI5dX8Cuffar3OXu9Ipph6wTq97nagEAiEEN+7yvP46/vP4W5TjkKag2oFYdLxWQdBMyLq/8fFIMiAokxtt3Y7OI0GNp6DYv9AsZ3ggbLxAhycSGHGFdFIjO55vFdkwmccpgJZIlAU12cQIAVDt1rEci8lgRZGjxMVHIAOIALDf71c+jK6HvU5IEgRh3G15Kzi0WUZBVXTSdx79F5PHPBOKeXizI+eu9J3HnNNH7tdVfjK09fxl/de5LZfgcK1vPEYboX9BASgRhx5NIK7js2DwDIlWvtnzgoZUdOsIKhWSjclSyQ2br6/0ExKKGTVje2IC3kVl6SUxGIxTFa20hvIds8MZLMz88BAEJN7tFdU3HMrlRRqNoP0F+oZwJ1d1Ps35TCmcWio+0zh0pmvFHJAlKKbfOGXlHJQgmnevt9ZEmvSrsJYtRhXE70nLlY8rt3H0BKEvChe44DAD5630kUZAW/8tqr8FMv34U3H9yEP/76UXzjuSvM9j0wSGmgzEgE8qGcb1QhEYgRf33/qrprTwTK+HtAQSJlAFU2hAKvVHJAZvvq/weFta9BKNNjGcRtB6fvDUubeyVndHCITdCKKTGSZJeMxYXm888Khz6zYL8kbLFQRSwcQiwsdH3u/pkUdB04eqWHLhwqmfGGtWLKchW2R9SKWTyzCPzAXz2ISm0IsjUoGJogegPjSI4jl1cghjgc2jaGH3/JTnz9uVncd2we//jgGbzl0GZctTEJjuPwv3/gely/JY33f+Yp5Csd5onDiJQxHL2a5n1bwxap0kNIBGLA+aUSvvzUJdy6cxwAsNJRBMoaP4dJxWRpay5ngbEeiEBWCPUgfC5Br+o6FS6ZZgJlje1RlyBiRMnnFo3/abo21dvEOwiHXizKtlxAgOEEAnocDk1uCW9Y2QnRzMC7qWbnrmBZi+HobB6//+/P9/pwvBNJAeDovkYQQcPYSfLcpRXs2ZBEWODxE7fvQDwcwn/9+GPQdB2/eOe++vMkMYTfvusAClUF33hultn+BwIpDUAHqh6vd7pO5WAMIRGIAf/vgVMI8Vz9ZO/oBBq2DhcAO8u+lZeU2mxkGAQ5aB2kMr2gV3WdCpeR1NrXedp340o2g+0RxACRr9TAtTn/tk/EwHHO2sQvFKpdO4NZzKQljMXEutW9J5AI5A1rsjPgTqAHTyxAK2WxccM03vPSnfjE987i64NeUsHzxr1ywMU5ghgolCqglJmO9Y9cWsEBc9FkLB7Gj962HbKi4UdetB1bx2Nrnnvjtgy2jEXxxacuMdn3fL6K1/7f+/G9U4tMtucbLswCj51ZwvPNzSnkAqCrgzFXGwBIBPLIYqGKzzx2Hm85tBn7po2VWVvlYMNkZWNl2a+YJ3svnB+VHCBEAcHeBKmn9OK9Aew7gUICEE6yKweLZoIvgSOIPuD8UhkplIx/NJ1/khjClrEoTjkoB1soyJiI27vGcRyH/ZtSve0QRiUz3hiC62elpuI3vvAsMnwZ+3Zsxa+87ipcuzmFX/3s07iULff68LwRHWxxjiAGjsZ5BgPm8hUsFKrYP5OqP/bTL9+NH799B37h1XvXPZ/jONx9cBO+e2IB852aCNnko/edxNHZPB482ecikMN5oqbp+Ol/egK/+OnDa38xjJEqPYREII987MEzqCoa3vvy3UhFja5WnUWgrPFzmFTM+kA96207je9N4CVP2cH5TIIOhnbjXmN1jI0r2eUsm/BxghgQzi0VkeZMkafF+bdrMoFTDsrBFgpVTCXtt9jeP5PCC1fyUFQGdfxuoGBob1j3tQF2Uv7VvSdxZiGPJIoQYhlEhBA++I5DqKka3v+Zw4PdcnmAPxeCGEjq84wMk81ZTlnLCQQYbqAPvOkAxuKt77V3H9wMVdPx1Wcue9r33EoF//S9swCcZQP2BIf38heu5LFQqOKFK3k8d6lBOBrGapoeQiKQBzRNxxefuoTvu2YaezYkIIZ4xMMhrJQ7dK8YpLIju7BarV0nAgXsdhmUz6TNe/PClRX862Pn8eF7TuADX3oO/+/+U2z2Z30uTtxrrNxKjeVgugrIfX6jIwiGnFsqNTiBWohAU3GcXijamghrmo6lon0nEGDkAsmK5shtxBQxCoTC5JZwi5UJNKDlYJeyZXzk3hP4oesy4KDXxxq7phL46VfsxvdOLWG5NMABqwPs0CKIgYTxHMzKzLumQQTqxr7pJK7emMQXD1/0tO+P3ncKiqZj11QcZxf7fGzssBzsgeNGQwyB5/C5Jxrep2Gspukh3VuEEG3heQ7//t9etiblPR0Vu5eD8SIgxto/Z9BgFQzdeHL3ogPWoFxUpAygVo3W7aIEAFA1HW/7yEP19rlhgYesaHjtgY3YNuHxu2Z9DhH7Nzlmk47GYFPr35GE9+0SxABwdrGE3WLZEELE6Lrf75pKoCSruLJSwUx6/e8byZZrUDUdkzaDoQFg/4xxbT9yaQX7ppPODp4FHDewAkbPUWSgVjKunzxvdO9suGcMAifnC6ipOt5xfRo4jjUTty1jxvc9V65hvM2Ke98jpYElRos1BEF0x82iZgeOXFrB1vEoUpLo6HV3H9yMP/raCzi/VFqXG2SHuZUKPvnwWbzl0GZExRC+ePgidF0Hx3GOtxUIDs0C9x+fx1XTSeycjOOLhy/i17//aoghfjiNFD2EnEAeSUSENYPvVDcRyCpv6dcT1Q2sLPuNNr9elDwNykWlRVjquaUSClUFv/mGa/D8774O9/7yHeA44PNPeltpqO9HkJxNHljY3DXV6CRgfR+sYyGIEeHcUgmbpGrbe8Zus028nXDoxYKRPzBhMxgaAHZPxREW+LV27KChkhl3NA6WWXbwDJBi1WgFn9TXl0RmYjbK71uQK9X6p8W8lKFSR4IIEsblREcur+DAjPNt3XXDDADgSy4Dov/q3pNQNB0//6o92D4Rw0pF6W9XpIMxfFlW8ejpZbx83yR+4KYtWCjIuP/Y/NrXu/j8Ts0X8OF7Tgx2CTFjSARiTCoqdmkRP0COE7sIYcPZ5DkTqGHQ2ovw40EJGmsRsHb0Sh4AcMuOcUTDIWzKRHHbrgl87skL3i94bt4bFk6uqhXgl6aAWGIkObdUwpRQaXv+WW3i7eQCzZkhlHa7gwGAEOJx9cZk78Oh6bx3zhoRKLP2sQGhJBvO1rhufr8bxk5pM4MxW5IdbfOH/uYh/N5XjjA5Ps8EPc4hiFGHYbBwoarg9EIR+x2UgllsGYvh5u1j+NJh5yLQ7EoF//zIObz10GZsn4hjp7kYdLqfc4EiSYDjbV3vHj69CFnV8LK9U3jFvimMx8OrJWEePr8/++Yx/PHXj+JSruL4tcMKiUCMSUdFrFS6iECD4jhxAgvLfmNgWy/aoA/K59LCeXVs1hCB9k6vlkq95dBmnF0s4YlzWXjCzXeWxedn/X3RzMCuZBOEWxRVw8XlMsZD7dvZTqciiIdDOGnDCfTvz1xGROBxzYyzsq49UwlHbeiZQ+Vg7mgurwYGzlFVlA3HTlQ17m+N50E6apSAOXUCXVgu44HjC2wO0CtSGqgVAbWPV/AJYphg2JznhcvrQ6GdcPfBTTg6m3fstP3ofSehajp+/lVG97EdpgjU1+HQVmm3Defj/ccWEBZ43LpzHGGBx5tu2IRvHplFrlRzF08BY7HgG8/NAgCOmYvmBIlAzOmeCZQdHLHBCSws+/W8pKixPbUK1AJoAavrgyXOtVjVPTqbx7bxGGLh1Ziv779uBpLI43NPXPC2PzelclLacPJoHmz3rcoZyDpPjAiXcxUomo4Uim3PP47jsHMq3jW4OVeq4fNPXMTdBzchE3OWn7JjMo7LuUrvSmiCLg0eFirLxs8BLgcrmRl3UgsRyCoHyzoogVBUDYWqgnNLJcyt9MFq8IB+LgQxsFRyQCjCJBvNcsi6cQIBwOuvm0E8HMK7//7RehByNxYKVXzqkXN488HN9bzPrWMx8BxwJuBw6LKsOruO2lzQeeD4PF60cxySGAIA/MCNWyCrGr789CVjLBBOAiFnkcZfPHwJstnl9OgsiUAWJAIxxlYw9KCUHTmBhWXfKpXjuGDt63IB0LXBKdNr8d4cn81j3/TawORERMDrDmzEV56+jKriUYxx+t60KFlztV/ADIYe8749ghggzi0ZXcFiWqHj+WenTfy/Pn4e5ZqKd9++w/FxbDcHmtbxBA6VzLhjzfUzs/axAaEoq+A4QKxZIlCm/jurHMyJEyhfWe3c+tjZZSbH6IkBLdMjiIGFYSTHcxdXMBYTsTHlTlCaSETwb++7HeNxET/2d4/gD7/6PGRF6/iav/vOaVQVDe975e76Y2GBx5axGM4sBnuP/vNvH8Pr/uIB+/MLG/PEy7kyjs8V8PK9U/XHrt2cwr7phLGg7fLz+8xj53Ht5hQ2piRyAjVAIhBjUpKIkqyiprY5kQfJceIEVuU/1nsT5AoZ46A432kKWJMVDafmiy2797zlxi3IlWu454U59/tzWw5mvdb1frOr27KsnwNWzkAQbrFEl7CS73j+7ZqK42K2XM9PaUbVdHzsoTO4dcc4Dmxyfo3bMdHjvAHLZUphjs5o6aTsA+HDAaWqgqgYAl/JAeDWlACIIR7xcMiRE6hRMHrsTB+8F+RwJYhgYdgE5sjlFRzYlPbUkevqjSl88Wdfih950Tb89f2n8JP/+Cg0rfW9Lleq4RMPncXrr53B7qm1i77bJ2KBl4MdvZLHUlHGgycX7b3ARsXIA8eMUt2X7ZusP8ZxHN5yaAueOJdFpbDU8fN7/OwSXvZ//nM1SBrAsxdzeO7SCt5+81bs25gkJ1ADJAIxJh01LGotV6d0fbC6UDkhmvE+kGkUG6wVsiAGR4PWcrBJBDq9UISi6bhq43oR6CW7J7AhGcG/PeGhS1gl6y4YuuEY3e234XMJCUA4QSumxFBzbDaPbx2ZxbeOzOK7JxYghgC+2lmEvX5LGroOPH2h9blxzwtzOL9UduUCAlZFoLMBW83rSBlAU4x254R9mrttAgN3/SzKqlHiXMkBUspodd9AJhZGtmw/GNrKawzxHB47u8T0WF1BXS8JIlgYLcQrqoajs3nHGXutiIZD+P23XIffu/sAvnNiAZ98+GzL533soTMoVBX87Cv3rPvdzsk4ziwUA+18dc50Hn3juSv2XmDDLHD/8XlMJSO4qmlR+7bdEwCAYm6h7XykLKv4pc88hfNLZfz8p56sj1k++/iFerbQVdMJnJgrQG0jtI0aJAIxJm3WqbfsEFYrA1ptcMqOnMAkGLqhVC5I+zrDbgGBUO/GZhy3pWq3cgIJIR53H9yEe4/OYanorIsKAPd5SUycQA3BpgB1CSKGmmcu5PC6P78f7/n4Y3jPxx/DV56+jP2TIjhN6XhtOrTVKJV84lxrZ8PHHjqDjSkJrzkw7eq40jERYzExcKt5nQEVMHpOJQeEwkbGnhABhOjAvYclWUE8Emp7D0p368bahLU4d/P2MTx3aaWtey4wBrRMjyAGFkaRHOeXy5AVreW42y0/+uLteNneSfzR147iUnZtHmqxquDvv3sar756Q8sMoh0TceSrChbdjPNdoGo6Liwbx/iN52btiSpdSrtVTcd3TizgZXsn17mr9s+kEBF4KMVs2/nIH3/9KM4slvBHP3AdAOCnPvE4siUZXzh8Ea/ZP41MLIx900lUFa135e19BolAjOlYp84wlb7vsEQgrXM9a0caQ7ODXCEbxM+lISz12JU8QjyHXVPxlk994/WbUFN1fPeEi44o1byRl+RWBPLi5CpnjZaS4cTqNsk2Twwhuq7jd778nNEK9X2348s/91J8+edeio+9c5/xhA7n31g8jJ2TcTxxNrvudyfm8njg+AJ+7LbtEEPub/fbJ+K96zxCJTPusO6n1mCaRfOGgCnVnUDZtiKQk3KwlbIh+rz6mg1QNR2HvXbO9Ao5gQgiWBg157Fy+HY1lWV5geM4/MFbroOq6fitLzy7xtXzzw+fQ7ZUw8++ar0LCEC9TXxQ9+krKxXIqobbd09gsSjjcTsZa13G8E+cW0a2VMMr9k2t+11Y4HHd5nRbZ/Qjp5fwDw+exo+9eDt+6JZt+Mt3HsKx2Tze8lcPIluq4e03bwWAesXEUcoFAkAiEHM6i0AD5jhxgpQBoAOyhxOrVTlYkE6gQXJoNbhijs7msXMyjogQavlUK9h1Ll91vh+37w2rYOjGSQwFxBJDypefvozHzi7jV157FW7cNobrtqRx3ZY0Mpy5WtXl/Du0LYPD55fXWcE/8dBZhAUe77hlq6fj2zkZx9leOYHILeGOZvcMC7duwJRkBfFwqO3qfSYmIuvCCXTHVRvAcX0QDk3B0AQRLIyCoa2MvF2TrRdf3bJ1PIZfes0+fPuFOXz56ct45kIO7//0Yfyfr7+A23dP4MZtYy1fV28TH9B92ioFe9dtOxAO8fi6nZIwKQMoZUBpPRf51CPnkIgIePU1rV3LN24fQ1QtQGlqD1+WVfzqZ5/ClrEofv37rwYAvHzfFH7tdVfj9EIRm9ISXrLHyBjasyEBjjNK7wkSgZiTkuyIQAPkOLGLV8u+lZdUL/0JMAh40IKhgTWruq06gzWSjooQQxwWCh5EoF4FQzcO/AdwEkMQ3SjLKv7wq8/j2s0pvO2mJrHG5vl347YxLBRknF9atZBrmo6vPnsFd16zAROJiKdj3D4Rw6VcuTdt4qkczB3NwgmL3L6AKVZVxCJC2yzFTMyZE8gal20di+Gq6SQePdPjXCAxCvAifbcJIggY5rKenC9iLCZiLB72flxN/MRLduKGrRn80mcO464PfQdff+4KfuRF2/Hn7zjY9jVbxqII8VxgTqBzS8Z+9s+k8NK9k/jas1e65xF1uJdnSzK+8vRlvPnQJiQirdu/37QlgQRXxlxtbTe2D99zwiwDux7xhte+9+W78It37sP/uusAQryxmBwLC9g2HqNwaBMSgRhjOYFWKi1qzetiQyaw4wkMr5Z9Ky/J2o6VYRBkMHRkfZ1t32IKImVZxdmlUse6ZI7jMJmIYN6VEyi7uj8nhBMAF/IeDL1uJdvD9giiByiqhjMLxbY18x+97yQu5yr47YaBSh2b59+hbRkAa3OBnrqQxXy+iu/b7y4LqJEdE3HoOnC+F3X0LELmR5Hmyc4AiujdnEApMxPIbhjqSqUGMcRBEnnctH0MT57L9jYglOOozJkggkIuArrKRAQ6vVCol2CxJsRz+JO3XY+bt4/jN99wDR76n6/GB950ABuS7VvRiyEeW8aiOB1QA4eziyUIPIdNGQmvPTCNi9kynru00vlFHZyPn338AmRFww/fur3ty2+cNqodzhbE+mOqpuMzj53HnddM4/bdk2uez3EcfuHOvXjdtRvXPL5vOklt4k1ay22Ea1LRDsHQg1h2ZBevlv1WpXJBlf9UckAkDfCty6n6kmgGWDiKE3MF6DrWJek3M5mIeHQCZZy9zhrcei0HazxXKBia6GOOzeZxJVep//v8cgkPHFvAgycXsFJRMJ2K4I3Xb8KbbtiETZkoLiyXcHaxhI/edxJ33bAJt+wYX79Rm+ffVdNJxMIhPHluGW8+tBkA8K3nZxHiObzyqg2e/7ZGq/lehkGYtqCSGXdUcsD4ztV/Sxlg4XjPDscNxWpDd7AW46ZMNAxZ1VCumc/rQq5cQzoqguM43LJjHJ98+BxeuGK0ee4ZVOZMEMHAMJLj1HwRL9u7PruGFXunk/jUe1/s6DU7AszuO7dUwuaxKIQQjzuvmQbPPYNvPHcF127ucC1tM0/UdR3//PA53Lgt0zL02mJKNMZXx1ZCuM187JHTS5jLV/HmQ5tsH/u+6QTueWEOVUVtG6MxKpAIxBhJDCEi8FQO5pRWK95BrVwyCooLFHP1sN4ZrEV7+EYmE2FvmUBu3h+vn185CyQbFHwpDVRXAE0dLMGOGHqWijLe+MHvQFbXBuPPpCW87tqNuHZzGg8cX8AnHjqLv/vO6TXPGY+H63Xs67A5aBVCPK7fksYTDUG33zwyi1t3jCMT825X32HmivWkTXy9NJgmyo4YAidlSVaQDOtArdi2HAwAsqWaLRFopVyrl+zfvMPI1nj87HJvRaABdGgRxEDCqAlMoapgLl9t24ylV+ycjOOxM0vQdX1ddy3WnFsqYdu4MS6YSERwy45xfO25K3j/a65q/6I2FSMPnVrEqYUi/uztN3TeqXmdfHZx9aEvP30JsXAIr7ra/mLXvukkFE3H6YUirt44QBUgPkAikA+koyJyrerUB7ELlV28WvZbiQ1BDVrdtEDvNaYgcuxKDmGBx3bzYtyOqWQERy53sWq2wrpYu3Gvec2gaDWJsR6PtXBNEESP+NqzVyCrGj74zkPYnDEs22Mxo2uXNRh71207kCvV8M3nZ1GsKtgyFsXmsSi2jcfaT2DrJcTdByo3bhvD39x/CmVZxVy+gmOzBfzWG7ex+POQiYWRjor1MMxACYlGeSmVzNhH19cvblhig66vhu33OUVZxRhv5ly1CoZuaMSxKRPtur1cuVZ3a2/ORLExJeHRM8t41207WB2ycwZQnCOIgYTRQvwZn0KhvbJjIoairGK+UO1YOsaCc0slvOG6mfq/X3tgI373K0fwyYfP4o6rNmBzq+txm26In3z4HDIxEa9v2F5LzDHAmWIYl3NlTCYi+I9nLuPOa6ZtLQJYNHYIIxGIYE4qKmKl0sYJJMaNQe2w4dkJ1KJUTsoABRuJ815h1C0gUKQMoGs4e3kOe6YSELq0f55MRLBYkKFpOvjm3JFOeMlLYlEO1lweaD1OIhDRR3zl6UvYNRnHXdfPdFyBS8dEvO2mLfY3XMkZAoiNe8aN28agaDqeuZjD0xeyAIDXMMgDstjRyw5h5JZwRq0EaMr666euAXIBiARc0ueCmqpBVjSM8eZ3rk2LeAC2w6FXKkr9NRzH4eYdY3is1+HQUgbInuvtMRDEKMAokuOkD+3hWWCVbZ9dLPkqAuXKNWRLtboTCADeeP0M/u47p/Ebn38WgBFU/d6X71orsJv3o6XFeVy5tIIdkzEUqyq+/uwV/PjtOyCJXRz+5ue3ghieOJtFLBLCcqmGu26wXwoGALsmExB4jjqEgUQgX0hHxdblYIxS6fuSSAoA5361tlVotpQG5l/wdlx2992YnTAImN+jubkr2LerTSlJA1PJCBRNR7Zcw7iTbgaVrPHZuim/ktLAyiXnrwOMFpJKuY0TKOtumwThA/P5Kr53ahE/98o97C3YDkpVDzaEQ9/zwhyu3pjE1i4OQSfsmIjh8V611Ca3hDNadbxstOIPgAhUko1OdGnOdJ+1EoFilhNItrXNlfLaics1Myl85enLKMsqouEelRhTMDRBBAOjTsCnF4rgOKNrZj+xY8IQgU4vFFtnDDLCahDR+PdvSEm4/1dfiReurOCR00v46jOX8dtfeg67JhN46V4zsNl83//uW0/iw18zXMrJiABF0/HOF9lwLZtjgEoogSfOLWO5JCMlCXj5vsnOr2siLPDYORnH0SsFR68bRqg7mA+0FYEGMXvGLjxvlCx4DoZueH+CDIYetM/FPN5KfrlrHhBgOIEAOA+HbtOVxRZegpxblgdm1v6OIPqA/3j2MjQdeKPD1ShbOLg2TSYi2D4Rw3++MIfHzi7jzmvYuYAAYPtEHJeyZVSVXrSJz9B574R25dWNv+tzSrLRYTUF0wnUKhjazLuy7QQq15CSVtc+rUyhfCvndlBY4xybHc4IgnAJo2DoU/NFbM5EuztXAmbLWBRCAG3iLUdw8yJTiOdwYFMaP/GSnfjYT96K3VMJ/PdPH653Jj63oqEKEdtiNfzlOw/hl1+zD685sBH//c692G3HVWV+fts2bcJDJxfxjedm8bprN7oKd963MUlOIJAI5AvtRaABLDtyghfLfrtg6OoKoGktX8KMSpZJt4BAMb9Haa7YtTMYsCoCOW4T70Ug8/J9qGcRja3dnnVMBNEnfOWpy9i7IYF9fnTNcijC3rhtDI+cXoKq6UxawzeyczIGTQfOL5WZbtcW5ARyRrvyamBg3sdi1RAbE7q5WtuhHKzleKsJXdfr3cEsrJDoluX7QSGlAa0G1HpwXhHEKGFd+9zEGzRweqHoW3t4LwghHlvHYzjjcwOHc6YTaFsHp3EsLODDP3wj8pUa3v+Zw1ip1PCejz+KFcTx+r1R3HXDJvzcq/biT99+A/77nfvs7biSA7gQ9m+fwZHLKyhUFcelYBZXTSdxbqlUX2wYVUgE8oGUJIyeEwjwNlBvlZckpc0MAx/VWlUxMhIG7XMxjzfDlTq3ZDSZSrp0AnkpYZTSgFIBapXuz22m00o2WeeJPuFKroJHzy7hjdf74AICHJ9/h8ySsOlUBNfZuC44YfuElTfQg3DoaAYok/hrm3aLKsDAiOjW4Dyhty8Hi4dDEHgOWRsiULmmQtH0ejA0gPr/58o9nAhQmTNBBEMlB4STQMh9Eoqu6zg1X7DnXOkB2ydivmf3nVsqYjweRlLqnFV41cYkfvuuA3jg+AK+/88fwMn5IuKpCSR1l2MIczx0aLtR6jYRD+O2XROuNmUt2h2fHe2SMBKBfCAdFVGoKtC0Jnuvl9KaQcBT+U92/SAviPKfqtkxa8AcWs9njVP39XtjmE51D4Cb8uIEcvveNAY5O6VdeaDb7RGED/z7M5eh68Abb+jS1cItDs+/G7cZzrlXXzPtLADeBo15A4FDwdDOaFX2MGDXTysTKKZZTqDMuudwHIdMTLRVDmYtzK11AhmTwd46gTLGzwH5XAhiYGFQjTGfr6Ioq33pBAKAmXQUV3IuFl4d0NgevhvvvHUr3nDdDC5my/jNN1yDWGrCW0xENIMbt2cAAK+/bqZrU5x21DuEjXhJGAVD+0AqKkLXgXxFqQcXAhjM7BknSGlg6ZS715az6y/OQaxclpfX7msA0DQd/9+3LuGTAF6zK2LrNamogHCIx7yrTCC3TqDM6jaSDktT6ivZmdXHwgmA42mwTPQNX3n6Eq6ZSfm3Kujw/LtmJoX3vnwXfuiWrcwPZSwmIiUJvekQ1lgazNPaVVdaiUAD5qS0nEBRNQ/wIiC2bgGfjopYseEEWjHdPilpvRPIzut9Y8AcWgQxsDBoznNy3lgE6V8RSMJiUUalpvqWWXR2sYSbto91fyIMof5P334D3nXbdty6cxw4nQZKC+52bI6HNiQl/MOP34KDWzPutgOjlC0c4uud3kYVGk35QMs6dU0DKiuOL0BfPHwRi04n7r0imnE/wGw12Qli0NrKcdLn/NsTF/DgRRk6OEiqvQsYx3GYTISxkLfXRaWOl7wkLxkUrcoZOI6yQYi+4cJyCU+ey+KN1/vkAtJUoOpMBArxHP7n66/xRZTiOA47JuO+5w20RMoA0I33g+hOvQtOQ/aFlYMxIGKDlQkUUfLG2KJN5710VETWRnew1k4gKxOol+VgGePngIhzBDGwMFiIt5ywu6b6UwTamDYqA+ZW/Jk31lQNl7Jl204gAJDEEF60a8Lonuo1O9a8Xr7y6g0Yc9LpuIkQz2H7RAyn5nswnukjSATygZYiUHUFgO7Iijifr+IX/uUw/sfnnmF7gH7htRtUs9gQhH2dUbeAoFip1PBHX3sBB7eNO+7GNpmMOHMCec1L8rLC2U6coy5BRJ/wof88AY4D7vIrD8gqVe2ja9P2iV6JQOSWcEQlZzgnGzP2+BAQGZyyOssJFFbyHe9BmVjYVjmY5fZJRVcN8EmrHKyXTqABK9MjiIGFQSTH6YUCIgKPTenWzsReYx3X5Zw/QfMXl8vQ9M6h0B3x0vWZcTXNrqk4TpETiGBN3WLcWGfeytnQBSu/5RtHZvGd4y7tcy7RdX19plE3pDRQKwKqiwFVy0ygAAITXXwuveTD95zAYlHG777pWnBS2tHq4VQiggUnmUBeXVJenFzlLCBIgNiUd+TwbyYIP/j3py/jXx49j595xW5sm3A5GOpG3c3RP9emnRMxXFwuQ1Z87tjYzICVMvWcdk0oBshJaTmBBLmzgzoTdZ8JJIkhRAS+993BgIH5XAhiYGHQnOfUvNEZjHXmHissJ9CVFX9ygex0BuuINYbXHc4vASblfI3smkrg3FIJihrweKaPIBHIB1o6gVxMqK1OTmGBx+98+TnUAvyifuzBM3jln97r7EVeAg5bloN52J6T/QJ9NdHqxPdOLeHFOydw3Za0Y1vlZCLirDuYNSj1HAyddf7adoq/l1UEgmDAheUSfv1zT+Pg1gx+8ftstjZ1Qx9em3ZMxqHpwHdOzAe7Y3JLOKPd9XOAArYtJ1BIXum4ep+ymwlkCj2ppo42xuv7oTvYYHwuBDGwMCoH69c8IGBVBLqU9UcEOmuKQFa3UMdIaUBXAdmFo5hBsHcjOyfjqKk6Liz745oaBEgE8oHOIlDG9nasCfsvv2Yfjs8V8E/fO8vqELtybK6As4slVGqq/Re5HcxYeUnNJ3ckBYDzORg6a/wckO5gy0UZG1JmGLSUcSSwTCbDWCzK9h1eXiehXjIo2mURDdAkhhg+FFXDL/zLYeg68MF3HILosjOFLazveR9dm75v/zSumk7iv33qMJ69GOB5SBNlZ7Qre/CS2xcwRVlFOMSD77J6n4mJyFeVrotk1njMKgGzSElCb51AIREQ4/TdJgg/0VSjxNrD/bSmaji3VOrbPCAASEQEJCUBV3wqBzu/VEJY4LEhaa8pzTrcZoXWKoBaZboottv8HE8tjG5JGIlAPtBSBHJh7V8sGGGH77h1G162dxL/95vHAguJto7djs26jlvLvpWX1Pze8LwhJPgdDM0LgOhTSQdjlosyxmJmGJpDQWQqEYGq6Vgu2QyH9loqJ0pGSRdLJ9AAlTMQw8eH7zmJx88u4/ffcq1/ZWAWfViqmpRE/ONP3oKUJODH/+FRnDM7hamajgeOz+Peo3P+7NhLyPwo0s42P0AieqmqIBYJdV29z9js8LVSVpCICOtaCtt1EvkKlTkThL90WNT80H8ex2v/7/146ny24ybOL5WgaDp2TvrUDZQRM2kJl31qE392sYht4zH35XBuF3R8GA/tMj/HUQ6HJhHIB2LhEEI819oJ5ECFXihUERZ4JCMC/tcb96Moq/i/3zrG9mDbYA2KbAsGgPvyn06Ok6jPg1ZrxbRN55F+oqqoyFcVjFuJ+A5LoyZN5d52ODSL0Gy3Qc5tRSCX2yMIBnz9uSt40c5x3H1ws/8769PQ+pl0FB//L7dC0TS86+8fxu995Qhu+8Nv48f+7hH81Cceh+6m1r8b5ARyxhCUgxVlFXEx1LUEIGMuiuS6CDm5cm1NHpBFShJ72x0MMO/l2d4eA0EMM23up4qq4R8fPIujs3n8wEcexN/cf7KtW/5Un7eHt9iYjvqYCeSsM9g63JZ2+zAeGouHMRYTcZJEIIIlHMch3by65KK0Zr5QxVQiAo7jsHc6ibce2owvPHkpkFBOVyKQZ4U3AwA4Npuv5wH4PmhlEBQXFJYrqy4CSRnHwdAA7LeJZ5FJ4vbzK2dbD/ylNKBUDGsoQQRMuaZiQ0rq/kQW9GEmkMWeDUn83btvwZWVCj7+0Bkc3JrB6w5sRFXRUKn5cH8KJwCOHxgBo+e0E04clhD3kpKsYCysAFqt4zlgCTvZbk6gSm1dKRhgOIHy/eAEou82QfhHGyfJ904tYaFQxf9+63W485pp/MFXX8BP/OOjKFbXC8NPnl8GxwF7pvrbCbTJJyeQrus4ZzqBXOO2YsSnRbFdU4mR7hBGIpBPpKNikxMoC4ADwknb21gsyJhIhOv/vnP/NApVBU+cW2Z3oG1wVw6WMX56cALVVA1v+tB38BffPr66TV+7g7FtOegnS0VDvFkVgZx1Y7OcQLbDoVnkJbnNoOgUDG39niACpiyriIoB3TbLWUP4CPfngPOm7WP49i/dgUd/4078zbtuxsv2TQKAP/kqPE8lM3bRVKDawQkkFwC1x84XGxSrKqYEM9eiw8A/HTPL77uMVdo7gXqcCQRQmTNB+E2bRZUvHr6IRETAmw9txkd+9Eb83t0HcN+xeXzsoTNrnqeoGj77+AXcsW+qfs3pVzamJSwUqswNA7MrVRRltZ6l4wq3ZgGf8lt3TcZxaoGcQARjUutEIHNQxtt/yxcKVUwmVsO3bt89AYHncN8x/zuzeMoEcmvzi2ZwJVdBpabhvqPzq9v0uxysj4JXO7FeBMoYPysrtl5vfZfm7baJZ5GX5Obz0/X2waZBdIwjiDaUayqiYiiYnbm4ZwTN5ky0Xo5jdV3yLV+F3BL2qJr3g3bB0MBAvI8lWcGkYK5m28gEypY7O1xXyjWkWolAZncwX8oY7UJlzgThLy0iOaqKiq89dwWvOTANSQyB4zj82G078JI9E/j4g2fXhM3fc3QesytVvOPWbQEfuHNm0hJ0HZhlXBJ20nTM7PbihHI7hvfJGb1zKo75fBX5Xi8E9Ij+HV0OOC3LwRx+eRcLMiYbnEBJScSN28dWBRKf0HW9XiPvqBxMjAK86F7hldJ1C+MLV/KYy1f8Hxy1C9DsQ1o6gQDbK4gpSUBY4O07gazvrJe8JDcTN7lgtJBst5IN0Kop0RPKNRVSOGARaECwJti+uSrILWGPToPlAbp+lmQVE4IRPN65O5iZCdRlwWqlQyaQrGqoBlBm3xYpDZRJBCII32jRnOfeo/PIV5R1GX8/+ZKduLJSwX88e6X+2KceOYcNyQhedfWGII7WExvTUQBgngt0Ys4QgfZs8CAC1bsGZ529zqdGGVY49OkRdQORCOQThsW4wXLtUGzQdR2LxSomEmvb8L1i3xSOXF7BnE+hX4ARyKiawWhZJyIQx7kr/2kYtF5uaGv43RML/re0HaCJliUCrekOBti+mHIch6lExIETKOu9/tZNOV/HSUxm7XMIIiBUTYesaIiJ63NFfGGA8soA454HGF2YfIHcEvbo1Il0gAK2S7KKMd4cD3Rw61rfu+6ZQErdrbbm9VHre9vDlWApbTi4tB4KUQQxzLQYV37p8CVMxMN4ye6JNU995VUbsGMihr//zmkAwKVsGfcencPbb94KMdT/0+aZtJFbyDoX6OR8AcmIgCm37eEBICQYsSh90B0MaGgTP6Lh0P3/bR5Q1mcCOSs7ypVrqKn6mnIwwBCBAOD+4wssDrPtvi2WnZSDAe6cH5WsmX2RxMWsMehLSgIeOL7gOPfGEbrORugIiFURyBzIWt8nByLZZCLsrDuY1wuu9X1wYrXvVPs7QJMYYrgo11QAQDQc0G2zXUlknxKME4jO+6506kTqNrevBxSrCsZ4c2De4TwQQkYH1U6l64qqoVBV2jqBAB+/t3aIZgDoq6V8BEF4ZnalgkVrvFvJAlyonrFXqCr41vOzeP11MxCahB2e5/ATL9mJw+ezeOLcMj7z2HloOvBDt2wN+C9wx0ZTBLrSsKjOgpPzBezakADntZuyW7OAEAUEDwJUC7ZNxMBzGNlwaBKBfMISgep15g5XdRcKxoS/sRwMAPbPpDCZiPiaC9Roq3bkBALcWfYrOcMiyPO4nK0gHRXxin1T+M7xBeh166APg3+lAqjywKy2L5dkpKPi6g3LhSAylYzUv1tdYVEqJ6UBXQOqefuvsVPOUPY/HJ0gGinLpggUVCbQAJWqAgFkAvntCh0WOq2YDpCIXpJVpGAFQ3c+D9IxseP3Lm+6si3XTyOWeJnzy8FmhwEq0yOIQeG/fvwxvPmvvmvMaZriDb555AqqioY3HdzU8rVvu2kLkpKAv33gFD7z6Hm8bO8ktnrpihUgyYiAeDjE3Al0Yq7ApjOamwUdn8ZDESGEreMxnKRyMIIl6agIVdNRNCcOTld1rdyWZicQz3N4+b5JPHB8vl6yxRrLCSTwnAsnUMZd4Jd5cl/OlTGTlvCyvZOYy1dxpSatPoc1nVZM+5DFooyJeIMo6KI0atJRORiD0Gw3QaS2Mi36fxJDDBcV0wkkBRkMPSDXJgD19ttryqBZQk4gewzB9VPXdRRlBUlYTqAuIlBU7FgOZo1p2nUHA3rsBKIyZ4JgSrGq4NmLOZxfKuOX/vUp6OW199MvHr6EzZkobto21vL18YiAd9yyFV995gou5Sr44QEIhLbgOA4zmSiuMBSB8pUaZleq2L3BQ2cwC7fzRJ/GQ7sm41QORrClbo23BiYOS2vaiUCAURKWLdXw9IWs5+NshTUY2joecxYMDbhXeM2T+2K2gk2ZKF661yh7e2bBtB36sULWKTuhD1kuyhhbIwI5Xz2cSkawVKzaExBZlYNZ27JLfSU7s/53ogQIEg2WicApmYJ+LBxUJtDg5JUBhjgWEXh/y8GUMqDYFLFHlboIlFn/OxclxL2gUtOg60BCLwBiHAh1bsmciYkdXcvWd7J1JpDPDjY7DIg4RxCDwjMXc9B04NVXb8C3np/F+UuXACmNSk3F7375CO49Oo+7D24Cz7cvbXrXbTvAc0ZFxquvmQ7w6L0zk5ZwqUkEeujkYj1ywyknTZHEU2cwC7cVIz6Nh3ZOJnBmoQjNJ2NFP0MikE+k6xbjGqDIQK3kyAm02KYcDABetncKHAffSsKsVbNt4zFnLeIB97WeDU6gTRkJmzNR7JqM47ErppPKj0GrTy0H/WKpKK+GQgOuurFNJiLQ9NV8obawyktyk0HR7XNxEzZNEB4JNBNIqRqCx4Bcmyysdtu+QG4Je5SzZsZei8G6GAN4oe/fw6JsfIfiesHW6m8mGrbnBIp1ygTqg3KwPhfnCGJQOHw+CwD4P2+7Hm+4fgYLC3O4Uo3gzR/+Lv7+u6fx7tu247+9em/HbWwdj+FXX3c1fuMN1yAsDNZ0eWNKWpMJVKwqePffP4K/uueEq+2dZNEZzMJtdqxPGYm7puIo11Tm3dQGgcH6Vg8Qa0QgF2VHC4UqeG61/Wkj4/Ewrt+SwX3H5qHrOk7OF/Avj5xj1uLOWhHbMRFDtiQ7U0fdBAGbpXIlWUG2VMOM2d7wpXsn8b3LDeV0rKmLDa3toP3GUnM5mNWNzaEIBKB7m3hWeUmunEDdRCAqCyGCx8oECqQcrJObo48xumL65QTKGD/p3O+MtajCtxjecdxAiOilqim4qkVb96BumUCWMNnKCVQvY+ylE8hN2TRBEG156nwWW8ejmEhE8Ec/cD3GhTIem9OxUKjiH378FvzO3dfaupf/9Ct24y2HtgRwxGyZSUuYy1dRU42Ogw+dXISsaq5zgk7OFyDwHLaxyEVyOG8B4KsTaNcIdwgjEcgnWopADsvBxuMRhNpYFV+xbwqHz2dx+//+T7z6T+/Dr3/uGXzYpcLbTK5cA8cZKrimA/mqgxUyKQ1oNaDmwHJohmZfyhoXp00ZIwfopXsmMSv7mQmUNX4OwGq7rutYLjWVgwHGsTtYPbRaO3YVgVi5pNyIQOWsGRTe5gbt8G8mCBZYmUCBBEMPqggU7TwZ9wS5JezRbbA8ACK65QSS1BV7IlBURLbU0IijiU6ZQL6XMdqBgqEJgimHz2dxcKuxwJuICNgiydi8cSP+4xdejldevaHHR+c/G9NR6DrqGaD3HpsDANc5QSfmCtg+EYMYYiAbSGmjE6Km2n+NjyKQVeJ2amH0OoSRCOQTa0WgrPGgw+5grUrBLN50wybsmozjxm1j+IO3XIc9GxL2A3+7sFKuISWJ9dIjRx3C3Jb/SGlcNq2Lm0wn0It3T6DAJ5xvz8l+gYEQgfJVBTVVX+sEAhwP6K3vVNfvSqc27U5wk0HR7WLvZhWBIDyyWg4WgAg0YHllFilJ9K+shtwS9ujWiXQARKCSKQKFlbwtITQTFaE0NuJoop4J1KI7mPG4j2WMdggnAXB9/7kQxCAwu1LB5VwFB7dm6o8J8goO7d1eXwgddmbMNvGXcxXouo57jxrxIbMuS55OzhfYlIIBzheHNc3XYOgNyQji4dBIOoECSrgcPaywwWxJ7hx024aFQrVlKLTFng0JfPuX7qj/+5tHrthv/d2FXLmGdFRExqyfXy7VsH3C5osbT+5U69aLa7DykqIZXK47gQwRKCWJuHrLBtTmBIh+DI4GaKK1bGb4rHcCZRwJZJNBO4EiqbXbs0O32l8pDSwc93JUBOGYejC0GMBtc8A6F1qkoiLOL5X82Ti5JezRrROpm9y+gCma5WBh2Z4TyBqr5Mo1JCLrz89cuQYxxLV18flaxmgHnh8IcY4gBoEnz2UBYFUEqlWMiIMBu596YSZjiUBlnJwXcWHZ6Lx8OVdBVVEREewvZtVUDWcXS3jtgY1sDq7RLBAb7/58uQDomm9zNY7jsGsqgZPz5AQiGJGSBGwdj+J7p5ZciQ2LXZxAzYzHI93Dfm2SK9eQigr1PCJHHcKcWvYbyh4uZsvgOGA6JdV/fcPWMazoMei+BENnjaBMwf773CsWzc92PN5kZ3c4cExGBEQEvrsTyIVw2RI+ZAhBLpxhbXHTWYAgPGI5gaQggqEHqFS1kWAygbL+bH9YKGeHxgkk1PK2y8GA9q5ly93Mca3L65OSj2WMdqEyZ4JgwuHzWYghDgc2NS1CDtj91AszKWMx/UqugnuPGqVgb7vJyDaaW3FWNXJ2sQRF03vnBApgPHTT9jE8cHwBH7n3ZNuy4mGERCCf4DgOr9m/Ed85sYBKYdl40GEm0EQHJ1AzE4kwFgpVJl9eywk0Fus8sGqJU8t+w8X5cq6MqURkTQr/TFpCVo+jVly2fwx2GaAWzMt1EajpO+FwQM9xHCYTke6uMZaZJFLGeTB0x0lMxnn4OEF4pCIHmQmUNX4OyPXJwphMK/4MoqiNtj2GIROoqoKDBl7O21q9T0eNhZxcm26m1pimHamoj2WMdqEyZ4JgwlPns7hmJrUa/DygGXteSEUFRMUQLucquO/YPHZPxXHTdiMjyWlJmOWQYdIeHnAhAvn/+f2P11+NN92wCX/0tRfwgS89B3VE2sWTCOQjr9k/DVnRcObCJeMBm1bEkqygJKsdy8GamYiHUVW0esmCF1YqiikCmU6gooMVMqcdXBocJ5dzFcyYpWAWG9MS8oj5JAJlB+amYLm8xpu7xVnWfgeTrg2pSPebAMuVE6eTjnK287kipQ1rqDx61k2id5QpGLorqagAWdVQVTT2GxclIBShiXI3umUnWCXEfSyil2oqkiiBg+6oHKxdm/iVioJkJxFIEpDvBycQfbcJwhOqpuPpC1ncsCWz+iArZ/sAwXEcZtISTi8U8fDpJdxx1QZsNHOCnLZCt0Qgq4uWZ5xmhQbg5IoIIfz5Dx3Ee1++Cx976Cx+9pNP1JuBDDMkAvnIzTvGMR4P48Lly0AoDAhS9xfBKAUD4LAcLLzmtV6wVs1SUREc53MwdMOK98VsGZvSa9+jjWkJK3oMasnm9pwwQE6gpXomUItyMIfd2LaPx3B2sUtuB8u8JKcZFHaCoQGyzhOBUq6pCId4CCy6Y3TdWdYQPER794x+wWrB7VtpzQDk2fQUpQoo5e5OIFU2MjL6lFJVQYoz71F2gqFNEehStvV90J4TqB9EoGxvj4EgBpwTcwUUZXVNKPQoloMBxvzp/mPzkBUNd1w1hY1m1IbTDmEn5grYmJKQlNpfQx3h1AnEqlFNF3iew/98/TX4rTfux7een8UT53wwH/QZJAL5SIjncOc1G7C8NA9dygBt6tGbmTdDex05gUzBaLHovUNYzqyfD/Gc0XrVyYBechgEbJ7cupTC5WylHgptsTElIYe4Ty3i/UubZ81SSUY4xK8PvXTqvAKwczKBi9lyZ5WbZV6SkxVOVQHkLjkQVBZC9ICyrEISA7plDtC1qRGrIYJ/uUDkluiIHQfZAIjoRVlFui4CdZ+4TSYi2DkZxx989Xn80ddeQFVZe28zMoHaB7qn/CxjtIvTsmmCINZx+LwxcT+4LbP64IA2WvDKxrQERdMRFUO4Zcc40lERYYF3UQ5WxO4NjFxAgAuzQLAi3n956U7c88t34Pbdk4Hsr5eQCOQzrz2wEVG1gHLIfi3lQt6FCGRmxXgNh67UVMiKVh/Mj8XCWG5TZ9+SkAiIDkQb83k5PY5yTa23NbTYkIpgRY9DkFfsH4NdugVo9hFLBRlj8RbBli465uw0LZ1nFju0Q2TpknIycauan3O37mAArZoSgVKW1WDawwMD5VJsxJpo5/xqt01uic7YEYEGQEQvVRVMC6arx8Z5IIZ4fOFnX4K33bQFH7n3JN74we/gmQurf99KVyeQj2WMdqFgaILwzOHzWaQkATsnGkSLsvNc1mHAmk/dtnsCkhgCx3HYmJIw6yAYWtd1nJwrsMsDAoBwHOBCrrJjg2LreCywffUSEoF85iV7JjHGl7Co2Lf1W52gJpPBl4NZNn5rwJSJic7KwQBnln3z5L5UNUSsZidQRAhBFlMIKyvsMwwGaKK1XJLXh0IDrgb0uyaNm+Pp+U4iUJZd/bSTNvZ2AnFduJ8IwivlmhpMHhBgnn+DcW1qxH8nUIbO+07YKeMdABGoKKuYFM3Vapur9+moiP/zthvwjz9xCwpVBT/8t9/D+aUSdF03O552ygTyuYzRDlLGKOVTvLu5CWJUOXw+hxu2ZsDzDQumI1oONpM25lN3XDVVf2xjSnKUCTSXr6JQVdh1BgOMqhgni8OVLAAOiIzW5xcEJAL5jCSGsFmq4nw5As1m2rjlBLKEHTusloN5E4FyzSJQVHTWIh5wtlpbyQKhCC6ZGb/NTiBre4KuOMq96YqmmSJQht02fWSpKK9vDw+4svbvNEWgUwsBOoHkglHq1Q07tb8DMIkhho9yTV3tNuI3A3RtasT3yTSVg3XGTtmDNGY+N+v30bimJCuYDNkvB2vkjqs24NPvvQ26Dvz3Tx9GvqpA0fSumUCAj+KlHeqdVX1wPRPECFCSFRy9srI2DwgwrnVCFBDsV1cMAzduG8P2iRhes39j/bHptOSoHOzkHOPOYBZOzQKRFMCTZMEaekcDYFIoY0GR8NSFrK3nLxSqSEkCIoL9CUcsbLQDXCx4W0WyRKA15WBOuoMBDhVeQ2y4lDMEns1NTiAACMUyq89lhZwHbHYe6QeWinK9W9saXLhi4hEB06kITgcpAlnb7IadFRvrd2SdJwKkUlMRo3KwjqSiRjmYb+22KRi6M7aclP0voherKsZC9svBmtk2EcPvv+VaPH52Gb//lecBrAqUrfC9jNEOVOZMEJ44fC4LTQcONeYBAQN7P/XK/k0p3Pcrr6x3BQOAjakIruQqtvPPLpph+1vG1s/NPOFknjhA0R2DBolAARDTisgjjq8/N2vr+QtFGZNJ54r1eDzsORNonRMoFnZeDuao/McUgbIViCGuZQ6SmPBh5XLA7KFLRRkTrZxhLgf0OyfjnUWgpjbtuq7jP565jJrqIjOhvsKZ7f5cJyJQH09iiOGjFGQm0IAOegJzAvVxe/OeMiQiUElWMMaXAY4HwklX27j74Ga89cbN+PRj5wGg/51AVOZMEJ546NQiQjyHW3aMr/3FiIpArZhOSagqWn2u141C1RDGO4nornBqFojS5+cHJAL5ja6Dr+aQzEzi28/bFIHyVUy2yn/pwmQi7LkczBoEpetOIBFF2QiLto1ThTeaweVcGdMpaW0dr0k0OQEAqBaW7B+Dnf0CA9EtoKZqWKkoGOsoAmUdbXPnZMKRE+iB4wv4mU8+gW/YFDJbH6MdJ1DWfE2m/XP4kGENpcEyESBlOaBMIF0f2O5gkhhCWOD97Q6mq4Dc4do1yjgJhu5jR5XRHazouQTgd+++FjsmjIBPy6XWiv7IBCInEEF44aGTi7h2c3p9K/OmRc1RxnIF2c0Fypuu3kSH7oqucGwWyLDdPwGARCD/kYuApmBycgOOzxWQs9Fpa6FQdRQKbTEeD3tuEW8dX90JZAoPjtxA0QxQdlgOli2vC4W2iGcMESi3tGD/GOzsFxiI1QErk6mlE8hpNzaTXZNxLBXl1p9ri7yk75403vujV1zkFThpB2n3c3FyAyEIBlSCygSSC4bQMQDXplZY7bZ9wWlr2VGjnAVCEUDs0IhCCANirK/fw1JVQQolzxO3RETAX77zRty4LYOrNrZ3FPlexmiHARDnCKJfKckKnrqQxW27Jtb/kpxAdaZTpgiUsycCFaoKJJGHGGIsFzgNhqbPzxe6fqocx0kcxz3CcdxTHMc9x3Hc77R4zh0cx+U4jjts/ve//DncAcT8km/YMA0AOGwjF2ixKDtqD28xHo9gyWN3MKsmPmmqvmMxQwzKOlkhk9JGq2/NhnvIPLkvZSvY1CoUGkBmzEi2z2f9EIEy7LbpE1YmU0snEGAMlB07gcwOYa3cQC3ykh48sQgAODZbcLQfAM6cQOWs0ToyHO/8PAqIJQKmHFQm0ABdm1qRigr+OoEAOvfbYXey0+cieklWkUSRycD/ui1pfO59L8GGZHthrC+cQPWyafpuE4RTHjuzjJqq47bd7USgTODH1I9sNEUgu+HQ+YqCRIRxKRjgPBiaPj9fsCPtVQG8Stf1GwAcBPA6juNe3OJ5D+i6ftD873dZHuRAY97QN89sBMcBT55b7vj0mqohW6phwkM5mN3Ar1bkyjXEw6G66muFES87KTOT0gB0QwjqRiUHTcpgdqWCmTZOoIkJQwQqrizaP4au+80aPwdAXbbcXeOtgqEB429wuHq4c6qDCNTkxsmVanj2kvHYsbm8o/00bsd2MHQ0Y7SQ7LZNGiwTAVIKqhxsgFyKrTCcQCQC9QS7ZYR9fv0sygoSeiGwc8D3MkZbB0HfbYJwy0OnFiHwHG7ePrb+l+QkqbMhZcwtr+TsVY3kK7W6KYApUhpQq0DNhhhFTi7f6CoC6QbW8r9o/kepjHYxxYZochz7NiRx+Hy249OtYGe35WBVRUNRVh2/1mKlUlsToJgxnUDLNsrY6ti17JvZFyUuDkXT25aDTU1tAABU8wwzgQZoomU5gcYTHUQghwPHrWMxhHiutQjUlJf00KlF6Drwop3jOLtYQlVx+P1y0sbe7sWeugQRAVOuqZCCcAJZ3+sBuDa1IhUV6zkCzHFyLRlF7E52+lwEKskqoloh0NVfX8sY7SBIQCjc1w4tguhXHjy5iINbM4hHmgQLK2NvQO+nrIkIIYzHw5jN2y8H800EArrfh9SaUSJPmU6+YKvIj+O4EMdxhwHMAfimrusPt3jabWbJ2H9wHHeA5UEONA3W/kPbMnjyXLajU2c+b6izbsrBJszXeCkJy5Vr9U4ZwKoTyFEmkN2T28xLysJwpbQrB0vGYyjpESjFzi4qR5SzADgjeLLPWTLf+/ZOoIzjgWNY4LF1LIpTNpxAD51cQFQM4e03b4Wq6Z0DpVshxgBesB8MbWfg3+eTGGK4UDUdsqIF6wQa0EFPSqJysJ5h1zbfxyJ6TdWMc03NBzpx87WM0Q4cZ97L6btNEE7IV2p49mKudSlYNQ/o2sDeT/1gOiVh1m4mUEVBollYY4Fds0DFrCghEc8XbIlAuq6ruq4fBLAFwK0cx13b9JQnAGw3S8b+EsAXWm2H47j3chz3GMdxj83Pz7s/6kGiYUJ9aFsGuXKt4yR6oWCJQM6dQFZw8IKHcOhmEciVE8hubbv5+yXFcADNpFs7gQCgyCegsxwcVXKA5K3zSFBYol7bTCCXgsjOyThOz3cSgTIAjBWWW3aOY/8mQzBznAvkZHBrO9MiTSumRGBUaob7LdhMoMEc9KSiFAzdMxxdP93dTx84Po8bf++bvgkmJdPJLCnBrv76WsZoFxel3QQx6jx6ZgmqprcPhQYG9n7qBxtTEdvdwQpVv0WgbvPE7NrnE0xxNAPWdT0L4F4Ar2t6fMUqGdN1/asARI7jJlu8/m90Xb9Z1/Wbp6amXB/0QFG39mdwcKtRq/rkuWzbpy+aE353wdCGSODFCbRSXlsOFjVr5V05gboNZsyT/3RRgMBz2DEZa//UUBJ8lbUINBg3heWSjKQktE/ndy0CGW3iNa3JmdaQlzS3UsHxuQJesnsCu6biCPEcjs+6zAWy2x3MbrCpXADUHtr3iZGhbIpAwTiBssbPAR30pCTRP0eF5dwkt0RrylnfRaBHTi9hqSjjctbeJMIpJVlBGDUIWiVgJ5DY2+5gADlcCcIFD51cRDjE48aWeUAkAjWzMS05CoZOSj4EQ9t19Q5QfusgYqc72BTHcRnz/6MA7gTwQtNzNnKckeTKcdyt5nYZpvgOMA0XoD0bEkhEhI65QJeyZQBuy8FMEchJiHMTzSIQx3EYi4n1NuW2cHhyPzUPXLs5jVi4vdpcE5MQZRftyTvte0AmWYtFuS7wtSSaMSyTdrqxNbBzKo5yTV1fG9zwnX3olHEa3757EhEhhO0TMRxzLQLZ7A5mN9gUsBc+ThAeKVvuhCDLwQagVLUVSUmArGh19xRTQgIQTtJEuRVW9oWt62fGeK7DewaAeglxzifXTLGqGu3hgYAzgQTke+0Eimbou00QDnno1CIObcu0vj8P+KKKH2xISlgoyJCV7td/34Kh7eb7kYjnK3acQDMA7uE47mkAj8LIBPoKx3E/zXHcT5vPeRuAZzmOewrABwG8Q/fSomqYqGSBcAIICQjxHG7YmsaT59tn29xzdA7XbU6vDzezgdVRzGs5WKMIBBi5QL4EQ5sn9+F5HS/aOd7xqZqUQVTNQ212rbhlkJxA3UQgJ93YGthltYlvLglryEv67okFpKNivRRs74YEjs+5aBNvN4PCSTA0AJQZ5kQRRBvqTqCggqHDSUPwGECscmLf3EB9nGfTU+QCoKv2nUDQAdm5oG/dL/wSgUqyghRn3pOCFIGiPjrY7EJlzgThiFyphucureD23euKTwxIRFjHRjN/da5LOLSu6z6Wg1lmgWzn5zU1qiHYYqc72NO6rh/Sdf16Xdevtdq/67r+UV3XP2r+/4d0XT+g6/oNuq6/WNf1B/0+8IGhaVJ7cGsGz1/O11eWG5lbqeCJc1m8Zv+0q11FwyFExZDrcrCaanQWSzVZ/zIxETknIlA4AXB89xUt8+ReVKO4ZUdnEYiLppFECYsF9wLXGgZIBFoqyu1DoQHXYak7TRFoXTh0Q17SgycX8eJd4wjxRsv2fdNJdx3C7DiBamWjZaTtSQxo1ZQIBOt6HVgw9IBcm1qRMlcN/csFopKZljiZ7LjssqbrOs4sGvcLRyXiDljrBAqwHMzsDtbT9UsKhiaIrpRlFZdzZVzOlfHN52eh62gdCg2QCNSCjSlDBOpWElaSVWg6fO4Olu38PPr8fGUwlxoHiaZuHYe2jkHVdDxzMYdbm9wv3zgyCwB47bUbXe9uIhHGostyMCsUMR1d+7UYi4Vxwon7g+eNUgabwdAriHcVgYTYGFJcEWdXKtiQat1FzBF2y476gKWijAObOpSGrHFebbe93Y0pCZLIrw8qNyeh5xZLuLBcxntfvqv+q73TSaiajlPzRVwz46Bcxc7ErSmQuuv2Gl9DED4SqBPIbklPn+K7E4hEoNYEcP2cy1frwc1+OoHSdSdQsN3BZFVDVdGCKftshfXd1nWjoQJBEGs4cmkFP/y330O2YWE6KoZww9Y21wpykqxj2pxDXcl1XlQvVI2FnIQfIpAQAYSog3kBiUB+QCKQ3zQFNR7clgEAHD6/vE4E+vpzV7BzMo69GxKudzcRdy8CWYO6dKzZCeSwHAywZ9k3T+6ZDdPr9tmMlBxHEmVcyZZw/ZaMs2Npt+8BqBHWdR1LJTvlYHA8oOd5rh4OvQYzL+nBkwsAgNsbVlj2TRvfzWOzeYciUMbYbqfBrZOLPXUJIgIk8GDoAR7wWE5S3zotSRkge9afbQ8y9SYU/jkpTzWUDvv1+RZlFSmY+wm4Oxhg/F2SGIKu69B14z4ZGFIa0BRALgIR9+NAghhGTs0X8K6/fxgxMYRffcvVsE7NPRsSiAht7s0DnrHnB1Y5WLcOYXkzKN+XcjDA5uJwFuBFQGzfOIhwD4lAflPJAZmt9X9OJiLYOh5d1yEsV67hoZOL+C8v2wnOwwrQRCLStc6zHVZnjPWZQCKyJRm6rts/Nhsnt1peRlmP4pZd3TvFxdLj4Dkdi0sLADbZO4a2O64BteJAiEBFWYWsaO3bwwOurf2AkQt05HJTlpDpBHrqQg6ZmIjdU6uD0Z2TVocwh7lAUhpQZUCpAGK09XOcrNiQE4gIkHo5WFBOoIx9R1+/YTlJfeu0RE6g1ljvid1gaMCxiG6VgnEckPXLCVTtlRNo1cGWior4yX98FClJxEd/7KbAjqH+2VVyJAIRRAMXs2X86N8+DF0HPvGeF60Zl3akkgUiaYDvkbuvDxmLiQgLPOa6ikDGNd6XcjDAvllASpMz0icctYgnXNAi3+HQ1rF1ItA9L8xB0XS89oD7UjDAaBO/6DITyHICtcoEUjS9bg20hY3a9uzSAnKI4dadbWp5G4injOfklhbsH0M7BsheeG7RyEbo2C3OgyCyczKOc0sl1NSGLgFmOUquLGMyEVkj/Fkdwo7POQwUbRzctsNJOYMH4YsgnEKZQPbx3QlEwdCtceSkdHfPOL1QRFjgsWUs6l93MLl33cEAYKlYw8/98xN48ORiXfQKDLs5GQQxQiwXZfzY3z6MfEXBx37yVvsCEDDw91M/4DgO06lIVyeQNefzpUU8YD8mgkr5fINEIL9pYe0/tC2DKysVXFgu1R/7+nNXsCEZwUGPpU5WOZibcMN6OVh0fTkYgDU1uF2x0eViZXkBK3oMt+wc67o5Pmo8p5gbLRHoM4+dRzjE446rOrilPIhA28ZjUDUdV3INNwOzhDFfUeoD40b2bUi6cwJZ226Hk89FjAG8QI4AIhAC7w42ANemdgSSCSTnAdUnp9Gg4qQVsp3rcQtOzRexcyKOsVjY2XjAAaWqghRXgh6KACKD/D+bWN/b3/j8M/jW83MYj4fXLo4EATlcCWId//jgGZxeLOLvf+IWXLvZ4b2RRKCWTCelteP+FhT6oRxswMdD/Q6JQH6iqUbb7qZB2cv2TkEMcXjvxx/HfL6KSk3FvUfn8X37pz3Xn08kwpAVzZlrx6SdCDRmikDLTrqB2Di55cIiZCGFDUkbAz3zIlDOL9k/hna4CIqrKipOzOXr/13Olb0fRxcKVQWfffwC3nD9TGcnUDhpdmPLOt5HxsxiWrOqa+YlrZRrLVcA9k0ncGaxiErNQYcwO4NbJ5MYjqOyECIwKkFlAqmKIXAM8MpXROARDvH+dgcDjHsrsYqT7ItICgDn+Pp5ZrGIHZMxpKOif8HQNRVjfBFcwAN/y8F2fK6AX7xzH16xbwo1NeBOYfUyPbqvEQQAaJqOf3viAl66Z7JrA5mWDFATmCCZTktdu4P5nwmUsdcdjEQg3yARyE/aOBv2bEjgb999C04vFPH2v34I//LIOZRrqudSMAAYjxtiwZKLcGjLvp9qkQkEwFk4dBfLvqbp0Cs5CPHuLqD69gDUCsv2j6EddbHB/oXl1//tGdz5Z/fX/7vtD/8Tx2cdlkQ55HNPXEChquBdt3XJB7Hbja0F9VV7a0DfkJe0UlHWfRcAo0OYpq8NCe2KZH7OnS749c/FZoCfnRsIQTDA6ojke9cgS9gY4EEPx3FIRQUfnUAZ4yed+2spZ40FgZCNATvPG9dZB/cMVdNxdrGInZMJpKMis3I/XdfxJ18/ij/86vP48lOXcH6phDG+HPjEbUMqgojA48dv34H/9uo9EENc75xAVO5IEACAh08v4cJyGT9w4xZ3GyARoSUzKQmXcxWoWnuhO2+aCZojQphhNxh6APJbBxUKhvaTDuUtr9g3hX96z634iX94FB/48hEkJQEv3tU9G6cbE2aA8GJRxvaJuKPXrpRrCAv8uonOhOlCOT6bxyv2dQ9xBmD8zUoZUKpGK8Amjs7mkdSLUNM2lX3zPVRLWWcB1a1wWA6m6zoeOL6A23dP4J23bsPFbBn/+z9ewJnFEvZOJ90fR5d9fuzBM7h+SxoHt2a6v8ClK6ae32FN2Brem3yl1roczPybj8/lsb9T6/rm42vcfivKWaNlZIvvS9tt0oopEQDlmgoxxEEM+bxu4kKg7kdSEjuRYB1UMtMap5MdGyXbjVxcLqOm6tg1GUe+UmMWDF2UVXzonhNrHntXrBT4OZCSRDz2m3fW3a9iiA9eBIpaiyX03SYIAPi3Jy4gERHcL5KTCNSSfdNJVBUNZxeL2NUmY8kqB4tHfFr8ssbwmmYsTLSCPj9fISeQn3Tp1nHT9nF8+qduw4ZkBHcf3ISw4P3jmEiYIpCLcOhcubauFAwAdkzE8KKd4/jgt49jPl+1t7H6am1ry/4jp5eQQhHjkxtsbs+4CETUfF2ddo2TsiMAZxdLWChU8YbrZ3DXDZtw90GjO9lCweZ74YIHTy7i5HwR775thz3By2VYasrq5GOVbpjfWV1KYaWstCwH2zEZc94hzFY5mMMAOBKBiIAoy6r/LiDAWTh6H5OMiv52BwPo3G/G8fUz4+g9PG2GJO+YjNfLwdxkDzZTMu/nH7hrP77y8y/FH771OlyT0Xoy8G+834khHrISsAhklfLRd5sgUKwq+Oozl/GG62bc5/GRk6Ql1gLuuu7ADeQrNUTFEAS/Fr+iGUDXALnNXELXSQTyGRKB/MTGqu41Myk8+OuvwgfuOsBkl+OmE2ip6FygaCcCcRyH33/LdSjXVPz+vx+xt7Eulv1HT88jxZWRSNt0P4WT0MEjzRW7hpl1xaET6NEzRg6RVY88YZbcLdgVxFzwsQfPYDwexhuun7H3ApeCSLo5xNUUkmpiGrKq1UWiRiJCCLsm4/X3xfbxNWy/JU4v9tQliAiISk1FLKhQaGDgBz0pSfC3OxhA534zLZpQdMThPeP0vDFQ3zkZRyYmQtV0FGUHuXBtsPILM7Ewrt2cxjtv3YYkij2fuIUFPvhMoJAAhBNU6kgQAL727BWUZBVvu9llKZiqGALDgN9P/WDPhgQEnsORS+1FoEJV8a89PNB9QadWBlSZMp18hEQgP7G5qiuEeGZKa12gcOEEWqm0FoEA44LxM3fswRcOX8IDx+e7b6zLyT03Z2yDszvQ43mo4SRSKHkXgcpZIBQGxKitpz92ZhnpqIg9pmUyLPBIR0XfnEAXlkv41vOzeMctW+27D1zm48TDAniuIRja3EaRN0oJ29UCv+2mLXj49BIeP2szo0kIGx29umUC+TiJIQi3lGtqcO3hgYEf9KSior/dwQA695vxWUQ/vVBEMiJgMhGujxOyTppFtKFYNYSkeGP4aB90hOlJJhDg2KFFEMPKZx+/gO0TMdy83WZ2aDNDcj/1A0kMYc+GRGcnUFVBwlcRKGP8bDcvGKBOzoMKiUB+0oMvcDQcQiwcchUMnSu3zoCxeN8du7FzMo7f+sKz3TtDWRfdNic3V3V+cdalNFJcCYsuXE5rsAbLNnOFHj27hFt2jK3p3DaZCGPeJxHoi4cvQQfwIy/uEgjdiEtBhOc5JBvzO8xtrMAQvNqtAvzoi7djPB7GX/7ncQfHmOleDuZk9dcSvhiUJBBEJ0qBl4MN9qDHyATyqxwsY/wkt8RaHF8/HTqBFkvYMRkHx3F1EYhFh7Ci3JQ7YZUA9HjiJoZ4KJoOrUNwqi9IaXK5ESPPheUSHjq1iB+4cYv7DNAhydjzi/0zqY5OoHxFQdKvzmBA9wWdISmP72dIBPKTHln7x+Nh1yJQOycQYCjHv//ma3FmsYSP3Huy88a6lP+EZOddcPhoBmkUXeUdrcHBiulioYpT80Xc3NSacjIRwULe+ypoK+ZWKkhGBGzO2HMqAfDkijE6+ViZQFkAwApi5u9afx/iEQHvedlO3Ht0HofPZx0cY4fnugk2VWVA8egMI4guVGqq+0wCRzvKGj8HfNDqa3ewcBzgQuSWaMape8ahe/T0QgE7Jw2HaDpqlJ0zEYHMcrB42JxsyEVAV3t+Dlgh8DWtBx3C6LtNjDife+IiAOAthza738iQLKr4xf5NKczlq22zXguVms9OoG4iUHbt8wjmkAjkJ5UcwPFAxJ8OUu2YSEQclyrlSjXMrlQxlezcmen2PZO4dcc47u9WEtbl5BZl5wovH8sgzZWw6ELgWoODoLjHzHKnW3astaNOJp2/x3YpVNWWgcwdiWaAWglQnL83a9r9mp9XVjNFoA7H8a7bdiATE/GX37bpBuo2uC1nnQdDAzRgJnynLAeUCVTJGQJHuHW3jkEhJYmQFa27Y9QNHEcT5WZUBZDzzoOhbd4zqoqKi8vlBhHIdAKVvItAViZQvRysTwb+YUsECjoXKJqh7zYx8tx/bB6HtmWwdTzmfiMOm8CMGvtnjHDo59uUhBWqCpIRn9rDA93z/cgJ5DskAvmJlXHipZ25CyZcOIE+9eg5yIqGtxzqHsA2kQjXWwe2pYNlv6qoiGpF83n2B3qclMFYqIRFr+KLA8fJY2eWEBZ4XLt57fOnEhHfysEK1Zrzloz199tdm/hcowgUCiMrh8zftV8FSEQEvOelO/HtF+bwzAUb++2UQaFpQHXFeaYFQNZ5wncCzQTqwT2DNdZ1wzc3EIXCr6Xq3Flbf261fTmAxfmlEjQdqyJQjF05WMkMl07URaD+GPiLIeMcrAXdIaybY5YgRoC5fBXbvAhAADmButCtQ1ih4ncmUJeFXOseT5lOvkEikJ/0qLXdeDzsqGRKVjT843fP4CV7JuoXhU4kIkJ99a4togSEIi1P7kJFQZpzLgJBSiONoqtStzU4+FweObOMg1syiAhrJ4CTiTDyFcWXle5iVV0dENvFgysmJYlru4NJaayYn2+7cjCLd9++AylJwAftZAN1Wr2X80arSDeTGFo1JXymXAsoE6gPAnFZYF038n62iafzfhU37hk7HRtNTs0b92tLBMqwzAQy7zUxa+GjTyZuomA5gYIWgTL03SZGnoVCFZOJzpUJXemTa0m/komFsTkTbZsLlK8ozuciToiY800Khu4ZJAL5idOgRkZMJMJYLFZtD9C++sxlXFmp4D0v22Xr+QlJ6O4EAtoO1AtVBSmYIpDD8p8kit7LwWyWHZVkBc9dzOHmplIwAPWbk+djaUGhqqztlGIHD2GpqaiwGuJqCmTW5K1TORgAJCUR77ptB755ZLZ7p5hOEzc3q78e3E8E4YSyHKATaAhWvazrhm9t4mmivBY3189684bu7+PpBeN+vcMUgWLhEASeQ5bB51tozgTqUZZiM1YmkBy4CJQ23FmaD6WUBDEAFKsKSrLqXQQiJ0lXrplJtXQCaZqOgqx0rAbwDB8CInbmBSQC+QWJQH7So1Xd7792BgDwC//yJNQunS10XcfffucU9mxI4BV7p2xtPxkRUJCV7l0z2lj28xUFKa4EHbyz7ItoBhG9ily+aP81zVidR2x8LofPZ6FoOm5pCoUGVkWghTaBal4oVJW2XbnaUnfFZB3vL93YztnMS1op1yDwHCSx+yVi+4Rh2e266m9N3FoFbbq52FOXICIgyrWgMoGyQzHgSUWtcjA/nUBZf7Y9iLgRThzcM04vFDERX20Nb3UIY1UOFhVDCFndN/ukrXPPMoHI4UqMOFbe5mQi7G1DlRzAC4DosaxsiNm/KYVT8wWU5bWic6mmQtfhbzkY0GVxOAuIcSDkYy7RiEMikJ/0aFX34NYMPvCmA7j36Dz++OtHOz73e6eW8OzFFfyXl+5c0wK9E0lJhK6vtnZtSwcnUBpFKOGUs+wLc9KvlLL2X9NMrQRoNVsrpo+dWQbHATdub+EEMgO0/QiHLlaV1VVRu3jIx0lJIkqyatjeTYFspVJDKiraas0ZM4+1JHdZuZTSAHSj9KsZT5MYGiwT/lKWVUhBBUMPQQii5QRiIRK0hMrB1uKziH7k8kq9FMwiHWMjAhnO14Zzq0/CXOvdwYJ2AjlwaBHEMFIXgbo0qumK1QRmwDP2/GT/TAqaDhydXTsuz5sLwwk/g6EBIJruEAydHYpFsX6GRCA/6VEmEAD8yIu240detA0fve8kvnj4Ytvn/d13TmE8HnbUhtFShrvmArWx7BcqClJcEZrT98Z8fkhecZ/F42Cw/OiZJVw1nayvfjZirVD4IQIVKm7KwTxkAkUbSjdM4TJfsW8DjYaNy0i522fSaXDrZvXXQaYFQbhF03RUFS3YYOgBx8pP8qU7GEDB0M14uX52uWc8dHIRT1/I4fXXzax5PB0VmXQHKzaXP1vHE+meT+gnVjC03ItgaICcbsTIMp83ogWmWGQCDcH91E8OWOHQTblAVuSH46oEp3Qq7R6S8vh+hkQgr6g1oFpo/bseq5i/fdcB3LJjDL/2b0/jxNz6Yzy9UMS3np/Dj754u6PQUysorHuHsNaWfSMTqGTUgjrBXBn0FA5tUwSqKiqePJdtWQoGNJSDOQjgtoOuG3W47svB3IhADaUbVjB0uWa7TX1UtJxANr4PQOvJm5uVbCFs2HxpsEz4iCVuBiICDUkwdMQsI636NYGW0oBaBWoVf7Y/aPgUDK3rOv7vt45hQzKCH37RtjW/Y1UOVqyqa52vlRwQTgIhnycfXehdMDQ5XInRxlpcnfLsBCIRqBtbxqJIRgQcubz2epM3F/l7Wg42JOOhfoZEIK985CXAF392/eO1CqBUemppDgs8/uQHb0ClpuGhkwvrfv/sRePEe/11Gx1t17oo5Ls6gVqf3Pmq0R2Mc6rwmheDFOdBBLIZFPfBbx9Hoarg+69t/d5IYgjJiIB5xplAJdmow3XsBBKjZje2rON9Wk6nlZLcUA6m1MWhbkTDNlf9Ow1u3ZYAUFkI4TN1EcjvcrBaxRA2hmDly1pUqPrlBKKJ8loqOYALOcvYE6NAKNzxPXzo5CIeOb2E992xe91CUYaZCNRUDtYnA//eZQJljJ/03SZGFEsEGo97zASy2QRmlOE4DtdsSq1zAlkZn0k/u4MBphMo2/p3JOL5DolAXmkXUFldWf19D7EcK63yWqwgMKctAJN2nUDRjHES62sHUflKDSmUEIplHO3XupinUHJfhmXDcfL0hSw+et8pvP3mLbh9z2Tb500mI8zLwax2ua7aMroURKz8jnwhX89LyldqXTuDWViBud0zgTLGz7blYJzzEoBONxCCYIB1nfTdCTREnTAigt9OoIzxk859A2uw7CT7guM63jMsF9DGlIR33Lpt3e/TUbF7R0gbFOUW5WB9MHHrWSYQlTkTI85CoYqxmFg/B11DIoIt9s+k8MKV/JpGQtb8rrfB0MORkdjPkAjklXZf4HrQbSbIo1mHNXFpNUG3yndiDkOI7WcCpQFNAeS13bwKFcMJxLt0AqW9OIG6tNKtKip++V+fwlQigt94w/6Om5pMhJmLQPleiECmE6iSX6xvZ6VsvyTN+o41dxdoeXxA64lbOWsIQLzDSxI5gQifqQTlBOqTQFwWWC4K/0UgOvcBuHfPdOiy9t0Ti3j0zDLe98r1LiDAEIHyVRtdQrvQMhOoDyZu9UwgKgcjiECZz1e9t4cH+uZa0u/s35RCSVZxdnF1rlaoGi5Pu7EQrpHSgFwwolWaoWBo3yERyCvtJqF90uaUN9t8t8prKZqTdqetj62LgpUe35Y2g5lC1QiGdl0OhhIW3WbxdJloffDbx3FstoA/fOt1LQOhG5lMRJhnAnlyArkMS7UcP9X8svGA1R3MbiaQ+f3pGgzdsRwsZ3QJcAqJQITPBJYJ1EWgHiQ4jkNE4FFVfAyGBujct3DrnmkTymm5gGbSEn7olq0tX5qOhaHrq2UDbjEygZq6g/XBwL/uBAo6GDqSBDievtvEyLJQkL2LQLq+2h2M6Mj+GTMc+vJqSZh1XXc1F3FC/V6+thwNmmY81gf3gmGGRCCvtJt4uwlq9IlYWGhbDsZzq9Z9u1gXha6DvzaW/UqpCAk15++NGIUeimCML2LRsxNofdnRsxdz+Oh9p/C2m7bglVdv6LopQwRi6wSy3FWOM4EA14KIJXbViksAADWSRklW6w6hbtguB4ukAHDtg6HdnCvUJYjwmVJQ5WB192jv7xksiAg8qjUfg6EBOvct3Aonbe4ZpxaKePzsMv7ry3YhIrT+3lv3jWzZ20JIaydQxtM2WSD2KhOoXqaXDXa/BNEnLBSq3kOhlQqgykNzP/WT3VNGltzp+VUnUGAiULsKgeoKAL3nRophh0Qgr1iDqKbcm37Kd4iKoZalOiVZRSwsgHOSI4CG7mB2ysGAdYNMtez+veGkNKbECpaKLsWXchYQ40BovcDxlacvg+eA33pj5zIwi8lEBNlSjWlmgKe2jC4HjpLIQwxxUErGa4tcwtExSILNcjCeN8S3dsHQbgb+5AQifCawYOg+umewICKG/HMCURvttTAW0a2snz0b2gdNWyKQl3BoXdeNTKDGkvQ+CYa2ysECzwQCOrdNJoghZ4FFOdiQLar4STQcwkxawumFxnIwBfFwCCHe2fzQMe3u5UM2HupXSATyipQBdNWoaWykj/Id4pFQaydQTXE1sQnxHGLhkL1gaGD9YKbeoWvM8b4hpTERqngoB2tvmz8+m8euyUTXMjCLyaTRucD1sbSgKHtxAmVcDRw5jkNKEqGZn0ueiwOA7XIwq+SwazlYp2N0O4mxtqf1YKBOjAQVOeBMoCFZ+QrECUQikIFb90y7Dp42QkEzMdMJVHIvAlVqGrTGbpiqAsj5vjgHLCdQ4JlAgPG5kMuNGEHKsoqirNbH167pk0iOQWHnZBynFxudQDX/Q6GB9vl+Q1Qe38+QCOSVdjknfaRCR8MCSi0m6IYTyN3EJhER7DuBmgYznJfOadGMx3KwbNv9HpvLY++0/Ra71koFy5IwS1hb0zLXLu1caTZIRUVw5nd4BfH6Y3aJhYXuTqD6MWbXP+5lEgPdmDgQhA8ElwmUNX72wT2DBUYmkE8TaCECCFFyS1h4DYZuumdY9/ZO7YFZOIEK9Qw889zqk66qABAWetQdDCCHKzGyWONpz04gcpI4YsdkfJ0TyPdSMKD9HHrIxkP9ColAXmn7Bc4BggSIUvDH1ERMDKHcIhi6JKuuJzYJSah3smpLG4U3JHtQeKU0UlwJi27LwdqIDSVZwfmlMvZNJ21vyrpJzbMUgarGhDMZcZHIH8207MZmh1RUBF81PpesanxnnZSkRcXWbrN1dOqm5yrYlDqpEP4SaDC0EDUEjiEgIvhYDgbQRNmiVgHUqvtgaE0BaqU1D68uRvgrAq3rUNpHA/+eBUMDxmdJ321iBJnLG+PpKc8iUNb4KbmoOBhBdk7EkS3V6qXA+Yrif2cwYPW+1ex8JBEvEEgE8kqnL3CffHlj4TblYB6cQElJ7B4MHTHDl5sGM4LsYbVPyiChF7HkpTtYi/0enzXK+fY5cAJZN6mFPEsRqAaeM3J6HONBEElJgvG5hBPIydZj9m8A0XAI5ZqNLjGtBrdqDagV3WdaAGSdJ3zDcrhJQWQC9ck9gwUR0UcnEECh8BZeBssdOngCncvBWDqB6mJTH5UArGYCBRwMDVAwNDGykBOoN+ycNCoALDdQoaq4yyZ1SicjBUDlfD5DIpBXOlnZ+uTiE20jAhVlZXUFziHJiIBCtxbxIQEIJ9cNZsKKFxEojZiWR1FWUbGTQdNMufVE69isUU7kyAlk1iyzbBNfrKpIRJyHdQPwlJORiooI11bM9vCK+ZgzJ5DtcjCWij85gQifKQfZHaxP7hks8DUTCCAnkIWX/ME2JdvWAk+8w/hAEkOICLwnEahoOl/rZQd9VEbf80wg+m4TI4glAnnuDtZH15JBYEeTCJSvBFQOJsYAXlg/b6HPLxBIBPJKJxWzD1azAMsJtN6lUZZV12GntjKBgHWDmZqqIaoWVn/nFCmNiFIAoLvLBWoTDH18roCwwGP7RNz2pmJhAbFwiG0mkJc63HYBazZISSIiasEQgcxBvRMraDuhseUxsgyAIxGI8JlyTYUY4uqTQt/oEFo/iPhfDpah8x7wdv1s07yhaLMzTDoqIuchGNpqhBCzMoH6aPV+tUV8j7qDKRWj1I8gRoiFvDGun0gwCobug2vJILBtPAaeA85YTqBKQE4gjuswL+AMIwHhGyQCeaU+8c6ufbyPVnVjYaHlBL0kq4i7FYEkoXt3MGCdZb9YVZDiSlD4iLu8pGgGvK4ghqrzkjBNM4In2ziBdk8lHLdDnExEmAdDu07k9yCIpKMiYmoekDJYqSjguM6hoM1ExZA9Z5aUMUq/1IaJg5cciHbnH0EwolxTIfntAgL6yj3KAl+DoQEqmbHwsmLaoRzMzn0oExORLbt3whbrwdBN5WB9IIaGeA4hnutdMDRAIicxciwUqsjERO+LLpWs4TIRPIpJI0JY4LFlLIZTDeVgCTfZpG5o5Xy0xkM8yRR+Qu+uV9rk3vRTvkMs3LpUpySriLosB0tEbARDA+tO7nxFQRpF1ESX6q75nqZQxILTcOhqDoDeWgS6kneUB2QxmQgzFYGKsuKuPTzQ1tpvh1RUQBJFqJGU0RoyIoB3IIi1y51qe4yN54sPkxiCYEXZQ4C+I/ronsGCiBgKQASi895bOW3G3EZ2zcN5m47UdFT0WA7WnAlkHkefnAdiiOtNJlDUDLOl7zcxYiwUqt7zgIChW1QJgp2TcZxZLELVdNsLAUxoFxNBn5/vkAjklXruTQsRqA9WswBjgq5oOuSmAXlZVjwEQxvlYHq3duRNNr9CVUGKK0INuzy5LRGIKzl3ArWxzecrNVzKVRzlAVlMJiJ1+yoLPNXhehg4piQRKZQgiymslBVHodCAFQxtQwRqVX7gZfU3kgLA0WCZ8I1yzX2AviP6qISYBZLAo+omt80uVsh8t3vQsGMJJ267gwHrnUAVBQkb9wBDBLKxGNQGKxOo7kiu5AAuBISdL8j4gRji142bAoEWN4gRZT5fxaTXUjBg6O6nQbBzMo4zC6V61IeTagBPtGoY00dz6GGGRCAWNHcp0fW+UjEtt0+jG0jXdZQ8TG6SkgBdR3f3R5Nlv1A1nECa5aByinlRT6OIJaeZQG1WTI/PWZ3BXIhASbblYEUvmUDtXGk2SEVFpLkiqqEEVio1x7XAjoKhgbXni5fVX54HpBR1CSJ8oywHUA6maX11z2CB793BpDSga0A1798+BgHr+unmniqZr2m6fhqlAN2/8+loGLmS93KwNd3BpLSRE9EHhEN8j8vBssHvmyB6yEKhiqmki6iIZobsfhoEOyZiKFSVei5QIJlAQOvS7j6KVBlmSARiQbMtXS4Auto3KrQl9JQaWnhXFQ26Dg/B0MYqYdc28U3vTaFiZAK5PrnN142Hys7LwayBbpO6fLzeGcxNOVgESyUZCqOBYqHqoRysTTc2O6SlEBIooxRKIF+pIRV15gRyXg7WcIxeA/yoLITwkXLNfYC+beSCIWgM0cqXEQztswgE0LlfyQGC5C5jLyQarptWTqAAysEKsoKwwK/mf/TZwF/smQiUMX6O+nebGDkWCjIbJ1A5O1T30yDYOWXMgZ6+aFx3gisHy/R1pMowQyIQC5pVzD5Lpa+LQA2TdOv/Yy5XuK2LQ6HaZQAYzRhhzJqxv3xVQQolcFbpklPMi/pMxEUwdJvP5eiVAiSRx9axmOPDmUqEoevAkofV0EY8dQcDXAsiY3wZPKejyCXMcjAXTqCaaq88EFhfDsaLRoifG6QMrZgSvlGpBZAJ1Gf3DBYYwdA+dwcD6Nz3WvbQ4p5hNxQ0HRVRlFXXQkmp2tScos9KAEShR5lAdcfscvD7JogeUampKFQVRplAJCI4ZafZHfmZC1kACKZFPLB6D2qcP1A5XyCQCMSCZhXTS9CtD1gTmFJ1dUBu2bBjLoOhrVpRW04goP7+5Cs1pLkiQrGMq/1aF4WNkYrzFvFtyo6Oz+WxZ0PCURCyhXWzYpELpOu6t3IwoHXAmg3SfAkAkEccK5Wai0wg45grtS6TgVZOIGv1120JADmBCB8pyQFkAvVZIC4LIkIINVWHqvk0iSYnkIFX90wLK36haq89cCZm3CfcuoGKzc7XPgtzFUM8ZOoORhCBMJ833P1TFAzdEzaPRSGGODxzcQUAkHQ4D3CNlAZUGaiVVx+jzy8QSARiQfMktI/anAKrQk9JXhVsrBDfmI26/1asOoGciUCFcg0pFCHEXTqBzNyDKcGNCNQ6GPrYbB77NrjrVjaZNEUgBrlA5ZoKTfdowWwVsGaDlG6IQCt6DPmK4qocDED3cOhWg1uvq78u/2aCsEMgLeLbXJsGmYhoDC98cwO1CpkfRbxeP5sWsXRdt+1ITUe9iUDr9tNnq/fhEI9aL4KhRcko8Rv17zYxUsyb4+jJpMdyME0DKitDdT8NghDPYdt4DMfMiIzAMoGa7+WKDNRK9PkFAIlALGh2X/TZqq4l9JRqLcrBXGcCmSJQVydQxvhpvifV8gpCnA7RrQhk5t5MCGUsOc0EquQAjl/TeSRXrmF2pYp9G12KQAl2IlChOSTTDS5dMXEY4diLagx5l8HQwFqhsSViFAiFm84XjwN/l+4ngrBDJYgW8UNaDgYA1W7uQLe0CpkfRRhfPys1Daqm21qM8CoCrXPZ9VkJgBjiofjlZOtGq7BUghhiFkwnkOdyMDkPQB+q+2lQ7JxM1N27gZaDAavjoD4zUgwzJAKxIJoxLjqqOQHuswF93aWxJhPIONao6LIczBwg5h06gdSiUePOeRy0ZrgSFp1mApWzhpOIX/3aewmFBlAPsGMiAlUYtGV0OXAMy4b982I1DE2HqxbxALp3COO4Fs65rMdJTIZWTAnfCCQYus9KiFkQEYz3zLdwaCqZMfB8/Vx7Pc6bOX+2nEBWOVjJvRNozaJH3wVDc70JhgbovkaMHAvmmH4q6VEEGsL7aVDsnFzN5gy0OxiwOnfpszn0MEMiEAusL2rVmEj3m7U/JlrlYKsT9LJHJ1DSbnewJpufVmag8EpppFBESVbttSW3aGGbP2qKQHtdloMlIgIiAl+/eXmhaGY2eXMCZdwNHM3XnC4YolYq6s4J1LUcDFh/jJ6DTTNArQio7rvUEEQ7ykEGQw/RylfdCeRXOVgkDYCjibLX62dTOW19MSIAJ9CaDLxaBVCrfXUOiCEeci/KwQDKuiNGDmsxdSLuUQQawvtpUOyYjNf/P+4yM9YxklkZ0uwE6pM59DBDIhALmruUWCq0mV/Ta1ZdGquCjddysLhZYta9HKzJss9CoY9mkNDN8iUnJWEtbPPHZwuIhUPYnIm6OhSO4zAeD2PZaT5RC6wV2LjLnCYAxt/X0I3NNuZ39/iKcUlwGgjXqgNdW5rdSiyCTQEaMBPM0TQdlZrmvxPIOh/65J7BgtVMIJ8m0TxvvF+jXDKjaWzKwaq5+j2jXpZsYwLAphzM3E8frv6GhR61iAeozJkYORYKVaSjIsKCx6lpH15LBoWdpgiUiAiumuW4onmeWFle+zjhGyQCsaBVPWM4aeTX9AGtJuiWg8bt5EYI8YiKoe4t4pveG67K4OIspRHVDBFoyYn40sI2f2w2j70uO4PVD0cMMZnoWE6gpI3WvO0PxqUgUslBBY8TWaMW2Gk5mGQ3GBpYu8Kp62wmMQCJQARzKqaLJRAnUCQF8D7vJ0Dq5WB+ZQIB5JaQC4CueS+nBepOZmthx0km0HLJ3SKIEQxtfufrWYoZV9vyAzHE96ZFPEAND4iRY6FQrUcseKLPclkHiUYRKDDaZQLR5+c7JAKxoNUXuI9siNYEptggAhVlby3iAWOQ2LU7WDgBcKH6e8Ob2TNey3/CilHG5ahDWJNtXlY0PHMhh/2bvF1oIgLPpOShwMIJ5LZjTiWHMh+HZexyWg7WKneqLY2D21oZ0Greu4MBtGpKMMerWG6bPgvEZYHv5WAAEB1xtwSLsoem8YuV82dnEiCGeIzFxHprZyfour62RXwflgD0NhOIgqGJ0WI+X/UeCg305bVkUJhOSoiKoeDygAAKhu4hJAKxoHkS6jWokTE8z0ESeablYIARYNw1E6geBJwFAIgyGyeQaIpJjsKhm8qOHjm9hHxVwauu3uD+WGCJQN4HigXTCeSpRXxzwJpdyllUQqu5SI7LwczcKVsiUKPNncWKjdu/mSC6YDnbfG8R32eBuCxYFYH8dAJlRtstwfL6aV6Ti1X7mUAAsDEdxZVcxfFuZVWDoumrIlAfhrmKIR5yT0WgnOGWJYgRYKEgew+FBvryWjIo8DyH7RMxb/MQpwhhQIytj1Shz893+qNeadBppWL2mQIdCwvrysF4bnWg7oakHScQsMayH67lVx9zi5QGL+fBQ6u3ib/36BweOb2E93/fPgihNn9Tk0PrW8/PIiLweOmeSffHAqPsgUXJQ9HBCmxb6vlUzp1AVWFVBEo5vAFIYeM9LzkpB7NKwQDvwdDAaE8GCV+o1LyL5fZ21F/uURZYwpmvTiApDSyd9m/7/Q6L62eTe7Tg8D40k5Zw2YUIVG+EYJ1bfVgCEA71MhMoY5T6yQUg4q5xBUEMEgtMnUDcUGXsBckvveaq4HcqZdZ2BwuFAUEK/jhGDBKBWNCqvV1me88OpxWxcKipRbwRyMhx7rNwEpINJxCwpvxHUvOoCHFIXrIvzEHruFDBybki3v/pw/jckxcBAC/aNYFX7Jta/xqlCijl+mel6zq+/cIsXrJn0nOpR0Tk6wKOFwoVBTznMX/EQyaQEl69YToPhracQHZEwYxRAlYrsxn4kxOI8InnLhmOw5m0u+B421RywPhOf/cRMPVgaF8zgTKjfd77cP3MO8gEAoCNaQlPnc863q11z4zVy8HMbfSRGCqGeNSUHjlxGh1aJAIRQ06lpiJfVdg4gSo5QEoZzQMIx3zf/ungd9qY72cZKTzMTwl70BnCgqbcm3609sfCobVOoJriWfxIRITu3cGAevmPqumIaQXIgscBjfnebo/J+PRj5/Glpy7h5165BylJwOefuND6NU0rpsfnCji/VMarr/FWCgawLAcz8hG8CHPrUvbtUslCNUUgSeQdd2eot4iXbbwPjZOOuu0z42h/rbdHTiCCLV9+6hJm0hIObc34u6M+KyFmQT0Y2tdysBEPhmZhm2+6fhaqCsIhvv75dWNjSsJiUa675uxi5RImmkWgPjoPRKHHmUDAaH+/iZHh/FIJANgFQ/fRdYSwQXNMBH1+gUBOIBbUc2/6MxgaAKJhYU2pjuEE8ioCiTbLwTLAymUUZQUplFATPVo0TcHglo0haJkMfv/N12H/phQWizK+8OTFtWGTFk0i0LeenwUAvPpq74p3RGDTHaxQVZD0msjvIRhazxwA4LwzGACEeA5hgUepZtMZZu6TSQCcGDWsozRYJhiSK9Vw37F5vPu2Hf63Su3DEmKvBBMMnTHKZVSlb7pxBgqTYOjMmm0VKoqj5gQb04Zlf26lim0TMduvs5xAa4KhhSggMHACMKKnmUBu7+UEMWDouo7f/+rziIohvHRvCye/U4bwfjr0RDPAyiXj//twDj2skBOIFZaKqSqAnO87FTMmhtYFQ3tte5yUBOQrXVrEA/Vg6EJFQYor1h0nrjHf21+/YyM+/76XYP8mY3tvvXEzyjUV3zhyZf1rmmzz335+DtduTtUHsF5g1R2spXjllHAC4HjnA8dyFpz53rjtChALh1CxGwxt7pPJ6q8lwo5ylyCCOV8/cgU1VcddN2zyd0dqzRAy+uye4RVLBKr43SIeGN2JsnX99JJ9Yd0zzOtnoao4CgWdMe+hl3NlR7sttMoE6rNzoLeZQFTmTIwGXzx8CfcencevvPYqbM4wKL3uw2sJ0YXGboh9WE0zrJAIxAor96ZqtUDvry9wLByqBzECQElWGDiBjGBovVv3CtMlVagqSKEILeLxvWkz8L9p2xi2jEXxuScurn9Ng21+sVDFE+eWmbiAACP7gkXuRYGFCNTUjc0WZl5SKJYBAKSizp1AgFESVnIiAjU6gbyeL6NeFkIw58tPXcK28Riu3+LztbzSn/cMr0SCCoYGRneiXMkZApCXjD2eX3P9zFcUJCL27wGWCHRlxVk4dKnZCdSHA38xxKOm9ioTKGP8pPsaMcQsFKr4nS8/hxu3ZfDu23ew2WgfXkuILqzLBKLPLwhIBGKF9QWuOxsyvTyadUTDoXq7Y2A1GNoLSUmApmPNdlvvPAMoFRQKBaS4knebXxubNM9zePPBzfjuiQXMNQ9IG0In7zk6D10H7ryGkQjEshyMRVtGp22TzUmoEB8H4K4cDDC+Y/a6g2XM/ZoikBgHQu72uWabozoRJJizWKjiwZOLeOP1M94yuuzQh4G4LKiXg/kdDA2M7rnPquyhYQBedFiWvNEMTXfaJn5dF7I+LAEQQzxUTYeq9UAIcpvvRxADxAe+9ByKVRV/9APXI8Sq7LoPryVEF6SMMRfRNCrnCxASgVhhuS9YBDX6gBEMvVoOVpZV78HQpmDRtUOY+V5U8ktIo1gvO3JNh8HRmw9thqYDX3rq0tpfNJQdffv5WUynIrh2M5v2kUzLwTwKcwCcl0aZ7004kQHgvhwsKtotB8us7pfVig05gQiG/MezV6BqOt54vc+lYEBfBuKyQOA58FwAwdDA6J77TK+fWQDOy8ESEQHJiOC4TXy9O1i9HCzbd+eAKBiT0p6UhI36d5sYeu55YQ5fefoyfv5Ve7B3mmEHvEqWRIRBQ0oD0I1qmj68FwwrJAKxwnJfsAhq9IFYWFhTqlOS1dVafJdYK3jdRaAMAKCWn0eCqyAUH/O033Xd2BrYsyGB67ek8fknm0rCzOdWxSTuPzaPV109zWyF3+oO1rUsrguFirPBd1us0kS7mM+VkqYTyGU5WHMHurZIqdX9VrJszhWnfzNBdODLT13C7qk4rpkJoDVzU2j9sMBxnOmS9DkYGhjdc5/VineDe7RQVVbdOTaZTkuOnUBF816xJhi6zwb+4ZAxRO6JCMSHjFK/Uf1uE0PPfcfmEQuH8FOv2M1uo4oM1EpDdz8deqz7WP4yoCl9dy8YVkgEYkW9HIxRxgljYuEQyk0iUJRBORiA7h3CrItxzmjfLsY8ikDN3diaeMuhzXju0gqev7yy+mAlBz0UwXs++SyKsorXHmBTCgYY2Re6Ds/ZAW4G3y1x6ooxV4CjqQlwHJB2mwkUFrqXBgJG6Vc4sXq+sFrJJts8wYDZlQoeObOEN16/yf9SMKBv7xksiIh8ME6gUT33fbh+5l0sRsykJVx2mAlUrCoQeK5eNtiPJQBiXQTqVS6Qw3w/ghggilUFKUlEWGA4Fe3TXFaiC9bnlT1n/OwzI8WwQiIQK8zcGxSM1uP9dgGKhUNQNB2yOSAvMwmGNsSCgs1yMHHFOLnDCY8ikLXNNoOju27YBEnkcfeHvouf+afH8c0jszh65jwWFQlPnF3G7919AK/Yx6ANpQmLVsi6rjMWgbL2n28O/oXYGP78hw7ih2/d5mq3UZFfIzR2xJp0sLJ9WsKXRzcWQXz1mcvQdeCuG2aC2WGflhCzICKwCc1vy6iXzLC+fgIoVGuO70MbUxKuOOwOVqwaYxCO4xpyIPrrHBB76QQCqMyZGGqKsoJ4xNs8ZB1DfD8daqzPa/ns2n8TvsJgxkkAWK9i9tmKluX6KcsqxBCHUk1l0h0MMAaNnXeeAQBECucBAOHEuKf91rfZZnA0mYjgSz/3UnzqkXP48lOX8B/PXsGHxItIRlL4xs+9gk0LygZWRSANbotHKjUNmg7v3cEAF8HQq+Uodx9075CK2XUCmftCJWvse8MB1/tcsz2tBtTKQDjmfXvEyHJsNo+JeBh7NgRQCgb0bQkxC3wvBxNjAC+O7kSZlXvGvJ/WVA2VmuZYBJpJS5jPV6GoGoSQvbXFoqyu7kcuALrWd+eAGDKcgLKfbrZOOL2XE8QAUaiqbBY+Gxni++lQY93HsmfX/pvwFRKBWGF9YZfPGHk14Xgvj2YdluBTqimIiDx0HZ6DoZMOg6HjJSOnx2pF7okuK2T7ppP47bsO4H++/hp85/gCbrhHwJi4ERxjAQgwJjqAtwDUvCmkJVisikhpw5VWqwCi1P35jMpRJLst4q19VXJAmWE5A2AISyQCER4oySobMdYulRzAC4agMWRYeWm+US8Nzvq3j35FVQzxhNX1UymjWCwCgHMnUDoKTQfmC1XMpO3dY4tVZW0ekHUcfURfOIGWz/Rm3wThM2uuAawY0kYLQ0/dCXRm7b8JX6FyMFY0qphS2hic9hGWCFSsqqtdOUQ2IlD3TCDjZE5WLq35tydsZsCIIR6vvHoDxkMl713J2hARrVbI7le8i1XjtUyCoZ2WSFSyQChiTzDqgJE71eW7YCGlgfKyUb/NVASiVVPCGyXZu0vSEVZJT5/dM1jgeyYQMLolMyyFE3P8UlpZAuD8PjSTNu4dTjqEFaoKYnURKGseR38N/HueCUQND4ghhkQgok69mobKwYKERCBWNJaD9aENMWoKPmVZrbs1Yh6DoeN2u4MJEUCIYky+bPybhc3PTcmTT/bCxnIwt1i5SkxaxEfNzCXbIhCbDjNRMYRyTbXXJS2aAXLnAejsuoMBoxsQSzCjLKueXZKO6MNAXFZIfpeDAca5P4rnvTXZYdUdDEClYIhASafdwVKGCOSkQ1hJVledr33aIc8qB+ttJlC2N/smCJ8pyoxyMBvp02sJ0YVICgDXEAzNIDuW6AqJQKxodCL0oYJpCT4lWanntsQ8lh6JIR6SyHd3AgGAlEZMK9T/3zNuwo99cwJ5Lwez3kO2TqCsveczem+i4RA03eb70Lh6T04goo8oMQjNd4SP16ZeExF9DoYGRtgJlDV+Mrx+VgN0AhWryuqiR5+GuYrmAo/cSxFILhilfwQxZBSrKgVDEwY8D0ip1Xt5JNXb4xkRSARiReNqXB8q0JbgU6o1OoG8X3wTEbG7EwioX5BV8Gzykhpzb7qh68zcLq2oO4E8lYOZIhCrYGjAmROIwQ3T+j5V7LwPjftjWM4wkpNBgiklWUVUDDgTqA/doywwgqH9FoEyo3nesxTRze+fXFwG4Pw+lImJiAi8ow5hhQHIBApb5WC9DIYGVtteE8QQUfClHCwHhMKAyD7/k/AZ63oXTgAhiiwOAhKBWNGoWvbZQAZYnaAb5WCG4MBiopOUBHtOIHOQWeKTbLIvrEmTncGRXAR01T8nEINg6AJTEchpJhCbchSr5NBWOHTj/liVBwJknSc8U2bQOdERfeoeZUFE4O2Jwl4Y1ZIZlmUP5vdPcSkCcRyHmbTkyAlkBLA3lYP1mRja80wg67pQXu7N/gnCJ2qqBlnRkGARgdCIdT8dwoy9oce63vWhkWJYIRGIFaIECGawbh8O6GOiVQ6moszQCZSUBBQqXVrEA/X3pCIkPO/T2F7G+GknC8LnoDgmmUB+iEB2B45WMK1HrBwVeyIQayeQKcKOoiOAYEq5V8HQQ4jv3cGA1XIwO1lkwwTLsgdzG5q5TTdlyRvTEmZXnAVDx5uDofusBKAvMoEAuq8RQ4flfvclGHpI76dDT10Eos8vKEgEYoklTPTZahawOkEvywrjcrC1TqBKu2Bg872RBUaDPCflPz4HxUlWdzAPAaj+ZAIFHwwN2CwHa9wfi/MlJBoWUht/c6Wm4ouHL/ZuYE/0NYEGQ1ulqkO68hUJKhhalY3y4B6iqBp+9p+fwNMXssHskKV7xvz+6ZYI5GJiNpOO2nYCWS6AeiZQJQdE0gAfoPhqA8sJ1LNMIOuzJRGIGDKYLnw2MsT306HHut714Rx6WCERiCV9rGLWW8Q3loMxEoGsTKDFQhUv/aN78BtfeHbd83TzPamJrEQgB0KHz3kDVjlYxUMAarGqgOdWhRRPWK40O+9NfRLKIhNo1W3WFdZOIGs7Npxh33p+Fr/wL4fxZ988xma/xNCg6zpKNZXNeWgHpWIIGH14z2BBYC3igZ53CJvLV/HvT1/GvUfng9lhJQfwAiDGvG9LlIBQBHzVuGe46VI5nTKcQJrW3ZFVqhr3iDWZQH14DoQFqxys106gbG/2TxA+UWy+BrCiT68lhA36eA49rJAIxJI+/gI35rWwahEPGM4VSwT6k28cxUKhin9++BzueWFuzfNqYhIAoLKyezsZHPncLWC1HMz9ine+YnRK4VjVMdvNyZCLgKYwLQcrOwqG5oBw0vO+69u08TefnCsCAD5y70ncfyygCRsxEMiqBlXTgysHG/JOJhEhiO5gGeNnj90S2ZJRFr1YqAazQ6vsgdU9I5oBX11BIiKA551vcyYtoabqWCzKXZ9bMBei4tZ51qcd8lYzgXocDE1OIGLIKNTLwXzoDtaH1xLCBtb1jj6/wCARiCWWha0PrYg8z0ESeeblYEmzHOzZizn8y6Pn8WMv3o590wn8+ueeRq60mhVUNcvAtAijk7tuk852f67PoZP1YGiPTiAmpWAWdjvmMCyVs4TGsmynW5y5PylttIZkgc2/+cxiEVPJCPZNJ/D+zxzGXL63ZSRE/2DlpUVZh1W2o08DcVlhlYO1LBFmRZ/kpuTKxv1uodBdBGEC67IHKQ1BXnFdnrHRbBN/xUZJ2Lo8kD7tkFfPBFJ6HAxNIhAxZDDtiNtIn15LCBvU5wWZXh7FSNF19sVxnMRx3CMcxz3FcdxzHMf9TovncBzHfZDjuBMcxz3NcdyN/hxun9PnyebxsFAPhua5VQeLFxJmd7APfOk5TMTD+JXXXYU/+cEbsFCQ8btfOQLAyGD53iXjgs+xUngtR5GjYOgMm303H4roPRi6KDNulWmzNIplaHbMjROIpeJv0wl0eqGIvRsS+NAP34hCVcH7P/2UrRIGYvhhKZDbwufQ+l4TEXhoOqD4eX71SWfAXNkQf+ZtOIF+7bNP43NPXPC2Q9Yr3lIaYm3F9WLEjCkCXbbRJn7dBLBPw1zDvc4ECscBLtTzUkeCYI0vwdC63rfXEsIGfVxNM6zYUQGqAF6l6/oNAA4CeB3HcS9ues73A9hr/vdeAB9heZADQ59b2aLhkNkiXkWMUelRUhKhajoeO7uMX3ntVUhJIq7fksH77tiNf3viAv7wP57Hq//0PvzbkQIAYNvmGc/7BOAs98Z6jk+dR6yBotdyMKYrIlbHnG4wzEty1B0snAA4nu25Es3YdgLtmIxj33QSv33XAXznxAI+8b2z7I6DGFiCF4H8Da3vNSwE8q70SXiuVQ620EUEevpCFp9+7Lz3UlTW2RdSBhE179kJZKdDmJUHUj/P+jTHo+flYBxn+75GEINEvRyMpeu2VmIWb0D0ABKBAqerCKQbFMx/iuZ/zct6dwP4uPnc7wHIcBzHaLY/QFhf3D61IsbCIcMJVFOYdb+xBozXb0njB2/aWn/851+1F1dvTOKv7zuFTEzEz73+JgBAOD7OZL8AnJU8hZNAyJ8SD57nEA55C0AtVhmLQHYHjgzLUVY70NkQgXhTAGJ5rkhpoNz5b86WZGRLNeyciAMA3nHLVuyYiOHh04vsjoMYWOrlYEEFQw+7CFQvlfWxQ1ifBENny1YmUOdysH8yBWdbYnknWJc9SGlEPYhAk/EIBJ6z1SGs0KocrA/PAbHXwdCA/Xw/ghggin5kAg35/XTooe5ggWPrbs9xXAjA4wD2APiwrusPNz1lM4DzDf++YD52mcVBDgwxU+CIjvX2ONoQDQso1VREZJ7ZSvfmsSgEnsNv33VgTZhkWODx9z9+C45cWsGrrt4Afu5Z4Ftg+95Ex4AnPgY8+YnOz9M1IL2183M84jUAtVBVsCEpsTug6BiwfBr4nS7vt5XVwTQTyObkJjrO9vsgpYFqDtC0tjlDpxeMUOgdk4YIxHEctk/EcX6pewkDMcT89cuBK8/gWgAnIzr4z3LAZwPYr25eM4Z00LMamu/jJLpPclMsJ1CuXIOsaPXOUo3kSjV86alLANqUzcpF4C9vBgpXuu9Q14AdL/V0zGuQ0ohpBdciEM9zmE5Jq5lAK5eAv7oNqK6se+5rdfM8+1tzzKBrfXkO1DOB1B6WC9t19RLEAFGUVfxg6F6M/9m7Vu+DXrHGs314LSFsEO3vOfQwYutur+u6CuAgx3EZAJ/nOO5aXdcb+4C3qitad9fkOO69MMrFsG3bNudH2+/c8E4gMQ3EJ3t9JC2JiSGUqgrCIZ7ZSvcd+6bw2G/eiUwsvO53mzJRbMpEjX9MXwu86UPAVd/PZL8AgNf9AXD2QXvP3XILu/22wGiF7H5lt1hV2dZGv+inTWHHxuA1vgEY2+F5l2KIhxjiULK76n/XXwCxCc/7XT0As1WyUgHCrdsmn1k0RKCdk6u/3zoexVMXsuyOgxgsdB24/BSw7XacTR7El566hB88uLWeceI76S19e8/wimTeZ3wVgUIiwItGKUAPsTKBAGCxWMVMOrruOf/2xAVUahqmkpHWYnlxHshfAq56PTB9oMseOeD6t3s86gbCMUT0qqcGBRvT0qoTKHvOcLBc94Nr7i+qpuMbR2ZxfC6P99y2y1iQ4kLAwR/xdvw+IJqLCbKf39+uBxEHarRIQQwXhaqCA/w549x/6S+y27AgAXvuZLc9Ijg23wTc9UFg96t7fSQjg6O7va7rWY7j7gXwOgCNItAFAI1Wiy0ALrV4/d8A+BsAuPnmm4cviTU2Dlz3tl4fRVti4RAu52qIiAozJxDHcS0FoBZPBG78MSb7rLP7VcZ/fYDRBcf9QDFXriHJsjvYxG7gVb/Bbns2iYoh+06gnS9ju3PBnLR3EIFOL5TAc8DW8dXfbxmLIVuqIV+pISmJbI+J6H8UM8Nl7514PvPD+LPHn8D3vfhlmJnxJ0NslFh1AvlYDgYY574SUGv2NljdwQBgIS+vE4F0XccnHz6Lg1szmEyEcSnbomzK+huu/YHgxxKChDBqSHgYG2xMS3jwxAI+/eg5vCa6gjEAuOkngB0vAQAsFWX89D89jkcuLeEXXr0Xse/bx+bYfYLnOQg819tyMCFC5WDE0FGsKkiEFKNZzKt+s9eHQ/QDPA/c9O5eH8VIYac72JTpAALHcVEAdwJ4oelpXwLwLrNL2IsB5HRdH61SsAEgGg6hXFsNhibYERHcZwKVZMUoB0tFGB9V8Fjh4z1BMN+/DpPBMwtFbMpE61klALB1zBCELizTautIopiTcSEafDD0kFMPhvZQKmsLIbL6OfaIbKlWbxKwUFx/DXro1CJOzhfxoy/ejmhYaF0OZv0N4noXkd/oggQeOtIebkN3Xb8JESGEX/u3Z/D+f34EAPAX95/Hh+85gc89cQF3f/g7OHw+i794x0H8Yp8LQBZiiO+tCCRGey5wEgRrilUVcV4xmrwQBNET7CgBMwA+ZuYC8QA+o+v6VziO+2kA0HX9owC+CuD1AE4AKAH4CZ+Ol/CAEQytICLwmEoMvuDQT4QF3nX46dyKMcCbZpkJ1CNiZu5UT7AmTh0mg6cXithp5gFZbB03Xnd+qYRryP0xelgTLCFS/+6yCs4fdSyxteL3NaEPJsrZUg07JmM4NlvAQn79sXzy4XNIR0W88foZPHJ6ESVZWb+Rhu9i0NS4MMIA0qL7z+p1127Eaw9M4/nLeZz9zgXgCPC9c0U8dOQoAGAqGcGn3/tiHNo2OJkPYojrbSZQHwicBMGaYlVBNKSsOrgJggicriKQrutPAzjU4vGPNvy/DuBn2R4awZpYWEBJVhERVFrpZkxEdF8OZrXUnU4N/s1QclIOxpq6E6j1gFnXdZxZKOLNhzavedxyAp0nJ9BoopifuyChXDYm5uSUZEMgwdCAOVHu7fmbK9dww9a0IQI1dQiby1fw9Wev4N2374Akhur34nXUVr+LQVPVRc8iEGCUiO/flML+qzLAEeBTP3MHContOLNQxNbxGNLRwSq5DQs85J6Wg0lAjUQgYrgoygpiXK0ngjdBEAY00h0hYmapTkRQEaVJDlOMcjB3g+dZc9V4GMrBYuEQyrUWK9xB0JgJ1ILFoox8VVnnBMrERMTDIZxf6m2wLNEjGp1AQbeIH3LqLeJ9F4F6nwmULcnYmIoiKoawUFh7LI+eXoai6XjzQUOAbls2W/8uBi8ClXURSQBJgdH1u15mGUEiIuDazWk22w0YMcRD6XUmEDmBiCGjUFUQ5WrkBCKIHtI1E4gYHmLhEBRNx0q5Rk4gxnjJBJqznEBDUQ7WD06g1pPBMwtWZ7C1IhDHcdg6HsOFZRKBRpL6ZFVCWVYRFniE+FYNLwmn1DOBfA+G7u1EuaZqKMoqMjERk8kwFptEoHOmwLxzyrj2xETjXrwua6ZBOAmasm4sDCVDjD6rHgpaLDEygXpZDtZ7gZMgWFOsKpBIBCKInkIi0AhhuX9kVSMRiDERIeQ6/HQuX0VE4JGKDr47SxJDrcscgqCLE+i0KQLtaBKBAKNDGAVDjyjWBEuUzNB8ujayol4O5nswdG8nylZnsExMxGQisq4c7PxyCePxMBIR4xpvZU6tu1bWhZPgg6HLmlGmlWAmAq2Kq4OMGOJ6XA5GTiBi+ChWVURAIhBB9BISgUaIxskNBZ+yJSJ6KAdbqWBDKgKOG3z3QSwc8j8Eth11EaiNE2ixiBDPYcvY+gnW1vEozi+VYMSbESNFw2S1JKuIUSkYM4ItB+vdRDlbMkSgdFTERDyyrhzs/FIJWxuuO1bm1DrXZA+dQEXNOKY4s3KwIXIC+f397YQQBbQaoPXovkoQPlCoKgiDMoEIopeQCDRCNIpANNFhi7dysOpQlIIBRpZKz51AtdaOnjMLxkRMDK2/7G0Zi6Eoq1g2J3PECFFrKAerKSSQM2Q1GNrvcrDehufmyobzJxMLYyoZbi0Cjcfq/46GjfdlXYewHrpniqopAnGsRKAywIWA0GA7XMNCj1vEd2l4QBCDhq7rKFYVRFAdeJGYIAYZEoFGiMawU+p+w5aI4KE7WL4yFJ3BgA6Bp0HQJRPo9EKxZSkYgPoqPYVDjyAN7gujHIyujaxYzQQKojtY751AmahRDrZUlKFqhqtQ1XRczJbXikCi8R1bXw7WOydQwRSBYiFGQrgyHBO8vsgEAigXiBgaqooGRdMh6FQORhC9hESgESIeWZ3cxCK02s2SiMCj6rIMam6liqnkcFhije5gvS4HWz8Z1HUdZxaL2DHRRgQyJ2iUCzSCNJStlGWVnEAMCYdGIxOosRxsMhGBpgPLJcMddGWlgpqqY1uDCGS5ctddK3voBMorxjFJHCsRqDIUpR59kQkEkBOIGBqKVcNtKGryUFwjCGJQIRFohGic3FD4KVuMTCDnA8ViVUGhqgyPE8jseiP3IkOhw4rpXL6Kkqyu6wxmYYlA56lD2OjR2B2sRsHQLBFCPASeG/ruYI3B0BOJMADUS8LOLRrXlK1j60WglsHQHA+ERL8PeR05xRgOiprc5Zk2USqAGHzANWsMJ1AvRaDODQ8IYtAoVo3rXkirDsU1giAGFRKBRog1wdAilTywxCoHcxosPJc3JgrTqeFYDbE60PXEDSS2Hyx36gwGAImIgLGYSOVgo0hzMDSJQEyRRPelsrYRo711ApVr4DggKRlOIABYyBtiiiUsb1uTCWQ6gVqVgwkSEHCTgKWijH8/kjWPgdH7qFSHYpU/3GsRSKRyMGK4KJhOoBA5gQiip5AINELEGoQfmuiwxQpAdWobn10xJqAbhigYGmgxuQmCUHvb/BlTBNrZphwMMMKhz1M52OhRLweLGOVgJJAzxQjND8IJ1LtzN1eSkZJEhHiuLgItFo3v1fmlEngOmMmsXuPr3cFqzcHQwQsnuq7jVz/7FObLpvDE6n20BK0Bx+gO1geZQG0aHhDEoFGUFYSggteVobhGEMSgQiLQCEHlYP6x2gXHmQg0bE6g1TIHRh1mnBASAF5o7QRaLEIMcdjcoj28xdbxKC6QE2j0sCa9goSSrNC1kTFGXloAmUCqDGi9cWxkyzVkYkYJ15QpAs3nV0WgmfTaroRty8Fq5cAnRZ/43ll86/k5vO/O/cYDrBwntSHJBOqb7mDkBCKGg0JVQQRm9tgQXCMIYlAhEWiEWFMORhMdpkRMB4zTyc6c5QQakkwgSWwTeBoUbQJiT84VsW08hhDfvsxi61gMF7JlaFoPV32J4FGqADggJKJEwdDMiYghVILoDgYAam8mytlSDZmoIQKlogLEEIeFglEOdm6ptKYUDGi4TrbKBApwUvTClRX8f//+PO64ago/8tJ95jEwyp4ZGidQr4OhKROIGC6M9vBm9tgQXCMIYlAhEWiEoBbx/rHqBHImfsyuVBAReKSk4fg8Yu2yLoKiRUCspul47OwSDm4d6/jSLeMxyIqG+QKtuI4U5mRV1Q0nX+N1kvCOl86JtunxRDlXriFlikAcx2EiHqkHQ59fLmPr+FoHYvtg6OCEk8u5Mt73ySeQkkT8yQ/eAI51K3LKBGIDOYGIIaNITiCC6AtIBBoheJ6rT3Co5IEtXsrBplMSuICDQP2ibevjoBCkdRPBF67kkS3VcPvuiY4v3WKWilE49IihVAFRqn9n6drIFiMTKCAnUI8myrlyDZlYuP7vyWQYi4UqyrKK+Xx1nRNIDPEQQ1zr7mABiEDPXszhzR/+LuZWqvjQDx8ycow4zshVY+oEGvzOP0Z3sD7IBCInEDEkFKoqIpwlAg3+NYIgBhUSgUaMWDgEnlsVLQg2RAR35WCzK5WhyQMCVssc1k1ugqJFOdhDpxYBALd1EYGsFs7UJn7EMN0XVo4ViUBsMTon+u0EMicSPZooZ0tyvRwMACYTESwUZFwwryVbm0QgwHDmVprF8gCcQN9+fhZv/+uHEOI4fPZnbsOLdzVcF8XW5bSuGBInkBEM3Q/lYOQEIoaDEjmBCKIvGI4aFMI20XAIVUUYGudJvxAR3ZWDza1Ucc1Myo9D6gnWBHrd5CYoBGldF5WHTi5i+0QMmzKdV5wsJ9CFJerCMlKYAbZWCWOUSmWZEhH5ektg37AmErXgRSBN000n0KoINBGP4OiVPM4ttReBYmFhfYC+DyLQ7375CP7l0XP1f5dkFddtTuPv3n3z+iy6FtdP1yjBh1z7Qf9kAtF9iRgOCrKCZMi89g3BNYIgBhUa7Y4YsXDIf2v+COKlHOwVVw3PSki0XdZFUAiRNSumqqbj4dOLeMN1M11fKokhbEhGyAk0apgTbyoH84eIwGOxEEB3MKAnTqB8VYGmA+lGJ1AyjMWCvCoCjbUSgUKtM4GkDNPj++6JBWxMSXj1NRsAAJlYGD/xkh2tcwGbrp+eGCYnUF+IQOQEIoaDYlVBJqwCGobiGkEQgwqJQCNGNCyQCOQD9XIwB+9toaqgUFUwPSSdwQAgJhqXlN6Wg61OBJ+7lEO+onQtBbPYMhbFeXICjRbmZLVUdwKRCMSSYMrBepcJlCsZZQ2NmUBTiQhkVcNzl1YQFUOYTITXvS4aDgXSHezKSgVvumETfuMN+7s/uUWmmmuGpjsYD003FhQ6dZf0jfp3mzKBiOGgWFWRElWgiqG4RhDEoELBMCNGTAxR9xsfqDuBHJRB1dvDJ4dnJcSaQBf9Lv9oR9NK9kMnzTygXfZEoK3jMXICjRpmgK01IY/R9ZEpwQRD984JlCsbIlC6KRMIAJ48t4yt49GW5ddRsY0TSGQXlFqpqciVa/Zz51g7gcTBn+CJgvHZ9cwNRE4gYsgoVBWkBPN8GoJrBEEMKiQCjRivv34Gdx/c3OvDGDok0Xk52FzeGNQNkxMoLPBISgKWinJvDkCMrpkIPnRqEbun4uuzL9qwYyKOS9my/xkmRP/Q5ARqWSZDuCYiBiACib2bKGfLxrVuTSaQ6fw5OV9c1xnMIhoOobQuGJqtE2jWXGiwfY8RomyENF0fGidQOGTc23uWCxQSAF4gJxAxNBSrClKCee0bgmsEQQwqJAKNGD/24u34mTt29/owhg435WCrA/ThcQIBRinEfKFHq5bCaovjmqrh0dNLtkvBAODWnePQdODR00t+HSHRbzR1B6NyMLZEhJAjh6Qrehiem7XKwVo4gQBgS4s8IMDIBKq0cgIxnBRd+f/bu+9wSe7yTvTfX3d1PN0n54maqBmlUUCAJLCEyAYLY4xhWQyGNY5r8Hp9792967B77b279q7t67C2sYm2l2QwYIxJRoCEJFAaZc1oos6cHLtP51T3j6rq0+eczl3d9auq7+d5eNDMSTUzdep0vfW+3zemXQsnB5otApm0Ir6Y2/p8NufTi0CWbwizIPScqBuS2QIiihEMbf9rBJFdsQhEZIKtYOjmb3aW9U6gsaiznoSMRgLlP1vPVWRaPDUbQzJXxMsPjTb94TcfGIJf8eD+cyvdOkKSTWH7djAGQ5urt+NgVnQC6eNg4epFoFqdQGG/glR+R8ehvqnOLAv6g4bJpjuBTMoEMjaMOeApf7kIVFStOwizinNEEkhkuR2MSAYsAhGZoNwJlG+tEyjo86A/6Kzxk7FoACuWdgJpX9vIA3rZoeGmPzzo8+KWA0P4PotA7lHuBNKDoZkJZKqAT9tIqapdvIm2MDw3ltK6XiozgYbCPhgxQNXWwwNVgqG7MEK1FNeuhc2Ow5qWCWR8Dgc85fd5Lc4EAvTiHDOByBmS2SL6WAQishyLQEQmCLSRCbQYz2KiP1g1NNTORiN+rEjQCfTg+VVcPRnFSKS1G5Hbj4zi+YVN6wpZ1Ft6gK2xIp7jYOYyuiS7mqliYSdQLJ1H2O8tPwgAAMXrwbC+LaxmJ9DOYOhiHoBq7jhYPIOQz9v8gwazOoGMz6GYF3JtFX8vzt9G2AlEDpLMFhD2sAhEZDUWgYhMYIRHtjIOtrSZcdRmMMNoJIB4ptD9tdDV6E+yc4USHrm8hpc1uRWs0m16hpDRSUQOV5EJ5BFbRQsyh/H3mWmhS7JlFnYCbaTy27qADMZI2N6h6oWQsN+LdL641SFVLpyYWwSaHGjhQYPPpI4TR3UCGeNgVhaBTArsJrKYqqpI5iqLQPa/RhDZFV/tEpnA4xHwe1vLvliKZ5tv07eRMb2wtZKwYEOY/mL5xdUkMvkSbtg30PKnuG7PAKIBBQ+c50iYK1RsBwv7Fcd15lkt4DNC87tYFDY6TiwIz91I1ygCRf0Y6fOjL1C9Cyfo90JVK4pjXSicLMYyrS0eUIJbeT6d6EJByypbwdDMBCLqVDpfREkFQiIPeHyAh523RFZhEYjIJAHF03Im0ITDQqGBrSfgloyE6TdQ82sxAMCeweqjGHU/hdeDlx4awffPsRPI8VRVu+lVgsjkixwF64JyaH43O4G8CiC8FmUC5bethze84dopvP0l+2p+XFgvjhlb6cqbzUwsnCxuZppfD298bVM6gZxUBNKKwtaOgzETiJwhkdW3cIq8I64PRHbmrERaIgsFfJ6mn3YnsgUkc0WMO2w9PACMljuBrCgCaS8qltY2AADTg+29yLj9yAi+9dwiZtZSNYNdyQHKOSxGJxCLQGbb2pzYgw1hVoyDpXM4NBrZ9fv/+mUH6n5c2K+9/DKyqLY6gcy5MVJVFYvxbPObwQDzOk7KRSD7/3zzSzEOFgByCeu+PpFJklntehcQeUdcH4jsjJ1ARCYJKN6mb3SW9NW9LbXq28RoRAtEtaYIpP19Lq/H4BFo7Sl4hduPaGvlORLmcBUdC6lckZvBuqC8ObHbGWFmbbZq0UaNTqBGjK6z8oYwkwsn66k8coVS651AahEoFhq/bz0mF7Ss5FNkKAJZU+AkMltS7wQKgJ1ARFZjEYjIJAGl+UygRX11r5PHwZYtGQfT/j5XNjYx0R8s5zm06uh4BGPRAEfCnK7iZjXNTqCuaGdzYlssulGOpfMYaKMIZJxr5Q1hxrnoM2ej1kJM+7uYHGixEwjo/O/R+Hif/X++yREMbU2Bk8hsxjiYX8054vpAZGcsAhGZxK94kM0397R7aVN7kezEcbCgz4toULEmGFp/UbEei2N6sP2bKSEEbjs8ggfOr25t7yHn2dYJVCiP6JB5epIJBJi32aoFmXwR2UIJgyF/yx8b2lUEMrcTaHGzjW5TI2C7079HJ3UCGZlAVgZD+7gdjJzByEDzsxOIyHIsAhGZJOBrZRxMe5HsxO1gADAWCWDZwkyg2OZmR0UgALj98ChWElmcXWQWg2PtHAdjJ5DpejcOFtwKV+6RjVQeAKpuB2vEGD1M5/XRq/zWuWiGxZhRBGqnE6jDv0djw5gDMj+kyQSyYPMdkdkSeiaQUso64vpAZGcsAhGZRBsHa+5GZzGeQcjnRbTG+mC7G40ELN0OFk8k2g6FNtx61TAA4PTMeseHRZKq6L5I5zkO1g29C4bu/cjMRlrrdmwnE8joOutWJ9CCnjs33srIsVGA6rgTyEnbwWQoAnE7GDmDkQnkU3OOuD4Q2RmLQEQmaSUTaGkzi/H+AIQQXT4qa4xFre0E8pay2NNhJ5CRpWFJthH1RsXYCreDdUfQwZlARifQYBudQOGawdAmdQLFMxiN+OFXWniZZ1omkPF9Zf8n/XIEQ5u0tY3IYkYRyMtOICLLsQhEZJKA4m0692IxnnFkKLRhNOK3qBNI+zsNII/pgc6KQEGfF/1BhUUgJ6sIsE3nighyO5jpyuNgTealtc2CTqBYWh8H62Q7WJdWxC/Gs611AVV+bbOCoRVzQq6tVM4EKlqYCaQEgWIWYD4d2ZwRDO0pZh1xfSCyMxaBiEwS8DU/DmZ0AjnVaCSAeKbQ/RyQnfQnSwHkO84EAizsaKLe0G9WVW9AD4ZmEchsTt4OFjM6gcKtB0Pv3g5mbifQQizT2mYwYGtbjynB0ALwtl4ck005E6jb5289Zo3pEVksmS0g5PNCFNgJRGQ1FoGITNLSOFg80/pTWhsZjWo/3Hu+IUx/shRAruNxMEAvArETyLn0m6qc8KOkgtvBumArGLoHRaAeh+eup7TrWzvB0EGlxop4s7aDxTOthUIDW8WGfIfB0IWM9rkcMO4sTSYQ0PPgcyKzJbJF9AUU7XrHTCAiS7EIRGSSgNLcdrBEtoBkrtja6l6bGYvoRaBeF1D0G6h+pYj+UOc39GPRIItATqbf7Gah3cSHOA5mOiMYOtP1cbDedwItxrPo83vR10YHmccjEPJ5kdZXJpdv8E24McoWilhN5lr/GVPOBDIhGNohT/nlKAKZ9O9CZLFktoBIwKtd7xxyjSCyKxaBiEwSUDxN5V4sxttY3WszW51AvS4CaX+n42GYEro9FmEnkKPpN1XpklYw5DiY+Zy8HWwhnsbkQLDta03I7+1KJ5BxzZpstxPIjEwghzzllyYTCGA4NNleMltgJxCRJFgEIjKJlgnU+EZnKa69QB+POvcpyGhEy8jofRFI+zsdDZrzgn0sGkAyVyxvtCCH0W+qUqp2voZYBDKdEAJ+pfm8tLZZ0Ak0H8t0lD0W8nkrgqHNG6EqP2hoNRPItE6g7Fa+kM0JIeDzCtM7gQrFEkqlJn9OsROIHCJRLgJlHHONILIrFoGITGKMg6kNNngsbWov0Med3Amkj4P1vItGf7I0YmIRCLCgmEW9od9UpYpGJxAzgbpB65J0YCdQLNN6t02FsN9bsSLevKDUhVi7nUB6QYudQNv4vB4UTC4CveYPv4e/vv9Ckwdg0r8LkcWSuQKifg9QzDnqGkFkRywCEZnEGHvINXixuDUO5txOoKDPi2hQ6XkwdKbkQVEVGPKb84LdKAJxJMyh9JuqJMfBuqrZvLSO+ELav2eP1mgXiiUsxjOYarXbpkJ42ziYeYWThXZHjs3sBHJQ3ofP60HexHGwTL6IiytJPD0bb+4D2AlEDpHMFjHg17+XHHSNILIjFoGITNJs9sVSPIuQz4tIwNldB2OR3q9Xn4tlkIUfgz5zRk/GrOpoot4wikBFrfjDcbDuCPRkHCwAQNWeMPfAciKLkgpMDnQwDlbZCZQ3L0x5KZ6BX/FgKNzi1jKztlDl0456yu/zeho+3GmF0Vm6EGuys8esrW1EFktkCxj06eP1DrpGENkRi0BEJgnom4UajT0sbmYx0R8wJbhYZqORQM+3g81tZJCFD/2KSUUgoxOI42DOVMgA3gDS+vcsO4G6o9m8tI70ODx3Xr+B76wTSEEqb2wHM7cTqK2fMewEqsrvFcibeP4aHbLz8SaLOuVzmz+HyL5KJRWxVB7DAXYCEcmARSAik2x1AtUvQCzGM47OAzKMRv297wTaSCMLHyKKOUHOw31+eAQ7gRxL31BijOSEfc7uzrNKQPH2JhMI6NmNstHFMdlBEWjXdjDTMoHazCryeAGPj5lAO/gUj6nB0MbDkcVYtrlw6PK5zUwgsq+VRBa5Ygl7ovqtp4OuEUR2xCIQkUmaHQdb3sw6ejOYYcyCTqBZvQgUEuYUgbwegRGuiXcufUNJOqedL0E/fyR2Q2/GwezXCRTyVQZDZ7aCmTvU0YMGJWhSJ5BzbvDMzgQyxsFyxRLWUk2ML7ITiBxgZl3rfJvu03/DQdcIIjviK14ikwSUxuNgqqpiMZ5pPbDThkYjAcQzhe7f/FWY20ij4AnAWzLvxfIYi0DOpXdflDuBuB2sK8J+L5JZcwqzNfX4RnkhlkbQ58FAqMXcnQphf+WKeHM6gbSfMdn2t5b5guwE2qFbmUBAk7lAPS5wEnXD7IZWBJrs08dUHXSNILIjFoGITBLwNR4HS2QLSOWKjt4MZhjVu51We7ghbC6WhuoNaCGrJhmL9j7gmnpED7A1bsRDPmYCdUNPvod6HJ47H8tgaiDUUbbb9nEwc8KU45kC0vli+0UgJdj59bNgXsi1DPxeYe44WMXPxHkWgcglZvVOoPEQM4GIZMAiEJFJmhkHW9I7Ssajzn8CMmrBZq25jQyEYsKT7ApjUXYCOZbefZHOFRFQPPB6nB3WbpXxaACL8SzUbq5v73knUJu5OxXCPgW5QgnFkmpaJ5DRWTLR7piaEmAn0A7aOJi5nUBRfTvoQqyJoiUzgcgBZjdSGAz7EBJ57TccdI0gsiMWgYhMUh4Hq1MEWoxrL+LGXdAJZGzWWulRF42qqpjdSMPjNyHTosJYNICVRJMBnmQv+s1qKlfkZrAumugPIlcoIZ7u4khYj2+UtU6gDotA+jmXyhVMK5zM6UWFPYNWZwI552ecz+tBvmBuJtCxySgUj8AcO4HIJa6sp7F3KLR1fWERiMhSLAIRmaTcCZSvPQ62FNd++LkjE8gPoHdFoNVkDrlCCYo/ZG4nUCSAfFFFLJ037XOSJCq2gzEPqHuMgvDSZhdvYnvYCVQqadlunWwGA7RxMABaOHQhq+XxdGh+wwisbjNkutNOIFXVA9fNCbmWgU8xOxMoh/FoABP9weYygbw+AILB0GRrs+tp7BmseH1mwvWOiNrHIhCRSYK+ZsbB9E4gF2wHM8bBVnqUCTSnhw76A2HTO4EAMBfIifTui3S+UL4hJ/MZ469L3Ryr7GEn0Eoyi0JJ7bgTyMigSuWK5nUCbaThER38jFFCnV0/SwVALTmrE8hjdiZQFqORAKYGgphvZhxMCK2oxk4gsimjU3vPYJidQESSYBGIyCTNjYNlEfZ7EQk4v+sg6PMiGlR6lqdjFIECobAWsmqSchGIuUDOU7EdjONg3WOMv3a1E8joPOnBjbLRvTHZbreNzjjn0vmiaWvV52JpTPYHoXjbfHmnBDq7fhp//w66wTMzEyhfLGEjlcdoJIDJgSY7gQDt38XEhQdEvbSRyiOVK2LPUEUx00GFYiI7YhGIyCRbwdB1xsE2sxiPBjraKGMnY5Hebdaa1ccgQuG+7nQCsQhkK7FUHu/+yA/wnTNLtd9J38iUyhW5GayLjK6UxbgzOoGMjU4ddwL5KzqB8mlTbormNtKYGuygONVpJlDegUUgxYN80ZxMIGNb5mjUr3cCZZoLTDd54QFRL11ZN7LKQo68RhDZEYtARCYpdwLl6wdDj7sgD8gwGglgpYedQCGfF/6AyZlALALZ0nfOLuG+F1bwC3/7GE7PbFR/J737Is1OoK6KBBSE/d5yJlpX9DA8d17vOuw0E8jIoUpnsoBaNOWmaD6WwXRHRaAOM4Ec+JTf5xXI1enwbYWRkad1AoWQLWidQQ0pAWYCkW3NbqQAQA+Gdt41gsiOWAQiMkmgmUygeMYVodCG0ai/Z51AcxtpTA8GIXzmbgeLBhQEFA8zgWzm++dW0B9UMBYN4H0ffxgXlhO736mQ0cfBCgyG7iIhBMajgS4HQxudQN3/Pp2PZ+D3ejDS5+/o8xiFx2wmqf1GhzdFpZKqFYE6KU512gnkwLwPv4njYMsVRSCjk2y+2Q1h7AQimzI6gbgdjEgeLAIRmcTvrT8OpqpqeRzMLcajwe4+/a+gFYFCWy+Wm2mxb4IQAmPRADuBbERVVdz/wgpuPzKKT7zvVggA7/nYD/H0bAyPvbiObz27iK8/swBV32KUzhUR5DhYV41Hg10Ohu5dJ9BCTNsM1ulYrzEOlsvoGTxKZxlDxobEjjqBfB0WG5gJVFd5HCziL3eSLcSbyGDqtDhHZKHZjTT6/F4MhHzaNUJ49a13RGQVPvokMonHI+D3emp2AiWyBaRyRUz0u6cINDUQRCJbwGYmj2iwuz/wZzcyODHVr71YVkvalhqTXmSwCGQvl1ZTmItl8It3jeKq0T589L0vwTs+/BDe9Cf3b3u/FwIZ3H8+hlg6z3GwLhvrD+CZ2Vj3voDXj16t0Z6Pdb4eHqjsBNJGJTrtBDI2TXWUVcROoF20IpA5DxUqx8H8eo4gO4HI6a6sp7FnKKQVzk3ahEhEnWERiMhEAcVTMxPICEV10ziYcaO0GM90tQiUyRexkshudQIBWtCqWUWgSACXV1OmfC7qvvvPrQAAXnF0FABww75BfOmXb8eTV2IY6fNjuM+PZCYD398V8eRCBslcEdEgfxx200Q0iHs364R0d0oI7Xs/b95mwFoWYhncuH+w489jhJEXskYRqLOfDcaGxI4zgTr5OzQ2izko78OnCORM6gRa2cwi5POiTx8z9gg0tyGs06wmIgvNrqe1UGigPIZNRNbiq14iEwV8nprjYEYexpiLxsGm9BXK87EMjoxHu/Z1jBfR04MhoGh+NshYNIBHLq+b9vmou+5/YRl7h0LYPxwu/96xiSiOTVScg1ktI+gDrzqJg4On8LJDI70+TFcZ7w8glSsikS0gEujSS48ehOeqqloeB+uUMQ6Wz5pTOJnbqLgOtksJAqU8UCoCnja64xw4DmZkAqmqCiEE/uHxK7h6sl/rPG3RSiKL0aiWJaV4PRiPBpvvBMpstPz1iGQwu5HGzQeGtF+wE4hICswEIjJRQPHWHAdbcmMnUH8LwZcd2HoCHuxKNshYNIC1ZM60XAjqnmJJxQPnV3HHkdH6mS16sSAU6sM9p/a46vvSCkYW2lK8m+HQ3R+ZWUvmkCuWMGXC+eL3euD1CBRyRhGo806ggOLBULiDDshOA7bL42DOedjh83qgqtq15cXVFP7dZ5/AR++/2NbnWknkMBrZ+ruZHAi20AnEkWSyn81MHrF0HnuGjE6grKOuD0R2xSIQkYkCSu1MoEX95sdNN5vjev5RUy9yOzCrF4H2VI6DmdwJBGyFepK8npqNYTNTwO1HRuu/owM7FmQ2HjVGQ7sZDt39G2WjoD050FmIM6CFzod9XhSMTiBfZ+fifCyDPYOhzgKrOy2iGx/n6/zvRxY+felDvqjikw9egqpuZfu0aiWR3VYEmh4MlrOc6mImENnUttdngHYeO+j6QGRXLAIRmciveJDN1xoHyyLs93ZvFEJCQZ8XI31+LHTz6T+2xiAmB4IVT7JN7ATSX7QzHFp+39fzgG473GC8i0WgnjIKwt1dE9/9G2WjoN1R+HKFkN+LYs6cc3EulsbUYIfH1WkR3ZGdQFpRbSOdw2cemQGwteq9VTuLQJP9IczHMlAbbbP0cTsY2dOsvh6enUBEcmERiMhEAV/tcbDFeMZVXUCGptvdOzC3kcZYNICA4t16wmTyOBgALCf4JFZ297+wgpNT/RiJNHiRWS4C8cVoL0zonUBdLaR2ut68CfNxc4tAYb8XpbxZmUBpTHfaoVQuArUZDu3A4qqxxevTP5zBZqaAYxMRrGy23hVaLKlYS+YwGvGXf29qIIhUrojNbKH+B/co9JzIbEYn0F6jEyifdtT1gciuWAQiMpE2Dla9E2h2I23ajYOdTPY3GXzZgblYeisMtRudQFF2AtlBOlfEo5fXccfRBqNggCNvVmXWH1LgVzxY6ub3UE86gdJQPKJxkbFJIb8CNd/5uZgvlrC0mcVUJ6HQQOeZQHnnFVeNcbC/eegybtg7gLtPTGA1mUWp1Nra+LVkDiUVuzKBgCZGppkJRDY1u56GX/FsnffsBCKSAotARCaqlwl0eTWFAyN9PT4i62mdQN19gjm7kcYeYwyiC8HQoxwHs4UfXlpDrljCHY3ygABHjq3ITAiB8Wigy8HQvckEmugPwuvpIHenQsjnqSgCtX8uLsQyUFVgutMHDWZlAjmouGoUgdaSObz39oMYjQSQL6qIpfMtfZ7VpHZuVhaBjAdDDR+UGAXORmNjRJK5oq+H9xjXTG4HI5ICi0BEJgooXmTzu4tAm5k81pI5HBgJV/koZ5saCGI9lUemRlZSp1RV3T4G0emT7CqCPi/6gwpWGAwtrUy+iL/87nn4FQ9ecnC48Qc4MMBWduPRQJeDoXswDrZhznp4Q9ivQC0XTto/F40iQkfr4QETt4M55ybPyAQajQTwxuumyp2hrYZDGyNkleNgW51ADR6UKAEAKlBsrfBEZLUrG+mtUGhA7wRyzvWByK5YBCIyUcDnQabKONjl1RQA4MCw+4pAxhadxS51AGgFplLFOJj5nUCANhLGTiA5pXIFvO/jD+PBC6v43bdci5Df2/iD2AnUcxP9wS4HQ3e3E6hUUnFxJWnqWG/I7zUln8rYMDXdaTB0p5lqhQzgDQCdbCiTjF/vBHrXS/cjoHjLRZxWw6GNotFodOvfeTwahBBbyw1qUjr8dyGyyOz6ziIQO4GIZMAiEJGJAoqnaidQuQjkxnGw/ibb3ds0t2Hc/OwoAuXNLwJ1e8sZtS6ZLeC9H3sYD11Yxf/8yRvwk7fsa+4DHTi2IrvxaKDLmUChrobnPnRxFQvxDF59YsK0zxn2eyFM6J4xwlenOg6GNqETyGHfU9fvG8SrT0zg3S8/AKD9bZHlIlDFOJiRldJUJhDAIhDZSiZfxEoiu7UZDGAmEJEkWAQiMlFAqb4d7PJaEgCw34XjYE0HX7bJuPnZ0+VOoKtGIzi/nGi8ypd66uf/9lE8enkdf/hTp/DWm/Y2/4EODLCV3Xh/EJuZAtK57oyGdrsT6HOPXEE0qOD1106a9jnDfi9EsfOutPmNDAZCPvQFlM4OqFxEb3c7WNpx31N7BkP46/fcUi7ebI2DtTYevJzIwu/1oD+4/d9oaiBY3jpXU5d+rhF1U3kz2LYiELeDEcmgYRFICLFPCHGvEOI5IcQzQogPVnmfO4UQMSHEaf1/v9mdwyWSW63tYC+upjAaCSDS6Qt0GyoXgbrURbPVCWQEQ5ufCQQAR8cj2EjlsZpkLpAsrqyncN8LK/jVVx/FPaf2tPbB7ATqOePmuWsjYV3MBIql8/jqU/O459Q0gr4mxg2bFPIp8BazgMcHeNr/vHMb6c7zgICKYgM7gWoZCPng84q2MoFGI36IHaNyk/1NLE/o9N+FyAJX1nc8pAPYCUQkiWbuSAsAfk1V1ceEEFEAjwohvqmq6rM73u8+VVXfZP4hEtlHwFd9O9il1aQrQ6EBIBJQEA0qXesEmttII6B4MNynh2126YnpkfEIAOCFxcS2dn6yzgPnVgEArznZRmeGAwNsZTehj4YubWa7MxrbxU6gf3xiDtlCCW9vdtywSWG/F55iFmogiE5SdOZimc43gwGdjx0VMo6/wRNCYKSv9Yy4lUQWI1V+dkwNBPHghdX6H8xxMLKhrzwxh6DPg6sn+7XfUFVmAhFJomEnkKqq86qqPqb/9yaA5wC0+MiVyB0Cihe5QgnF0vaRoRdXU64MhTZM9gfLwaVmm9vIYM9gaOvparc6gSa0ItC55YSpn5fad/+5FYxGAjim/9u0hJ1APTdudAJ1a0NYFzuBPvfIDK6ejOK6PQOmft7+kAI/clA7PA/nNtKY6jQUGqgIIO6gE8jn/O+psWig9U6gRHbbZjCDMSZZd4Omr8N/F6IeW4pn8MXTs3j7LfswEPZpv1nUO6ldcI0gkl1LmUBCiIMAbgTwgypvfrkQ4gkhxD8LIa4x4+CI7MYo9Jxb2ioUZPJFzMczrgyFNkwOBLuaCbRtDEIIbTuNyTeDk/1BRAIKzi1umvp5qT2qquKB8yu448jIrvGKpnA7WM+N92IcTC0CxYKpn/b5hTieuBLDT96yr71zrY7hvgACyKPk3V0caFYqV0AsnTdpHMyMTiDn3+CNRvxtFoF2X2/GmimOshOIbOZjD1xCsaTi/XdctfWbfPhCJI2mi0BCiAiAzwP4kKqq8R1vfgzAAVVVbwDwJwC+WONzfEAI8YgQ4pHl5eU2D5lIXqf2DwIATs+sl3/vynoKqgrXjoMBWrt7NzOBdq1F9pnfESCEwJHxCF5YYieQDM4sbmIlkcPtR0bb+wSFdMc5LNSaobAfikdgsVudQMbT5YK5XYefe+QKfF6BH7/R/CbokT4/giKHgmi/GGmsF5/udDMY0Pk4bd4tRaDWxsFUVcVqIrdtPbyhqeJol7ZeEnVDIlvA3z10Ga+/dnL7A1AuZCCSRlNFICGED1oB6O9UVf3CzrerqhpXVTWh//dXAfiEELtemauq+mFVVW9RVfWWsbGxDg+dSD5XjfShP6jg9MxG+feM9fBu3AxmmBwIYWkzi3xxd15SJ7KFIpY2s7ufgHdpLIRFIHnc/8IKAHRQBHJ+gK1sPB6BsWigu51AgKkjM7lCCf/w+Cxec3JiK3fMRCMRPwLIIy98bX+OrXB8E4pAXgUQXmYCNTAWDWA1kUOp1Ny2yFg6j0JJrdoJNB7Vztu6RSV2ApGNfPbhGcQzBfzsKw5tfwM7gYik0cx2MAHgIwCeU1X1D2q8z6T+fhBC3Kp/3gYpd0TO4/EI3LBvEI+/uFH+vUt6Eeigm8fB+oNQ1QYvctuwGNM+3+4iUHcCYo+OR7C8mUUslTf9c1Nrvn9uBYfG+tq/8XXJzapsxvuDpl8Hyrpwo/zYi+tYS+bwlla3zzVpuE8rAuVE+wUmI29tyoxgaEAvonM7WD2jkQAKJRWxdHM/C4zRsWqZQFtb8+oVgbginuyhUCzhI/dfxK0Hh3Hj/qEdb+RCBiJZNNMJdDuAdwN4VcUK+DcKIX5eCPHz+vu8DcDTQognAPwxgHeoqtrc4xEih7lx/xDOLm4imdVyKV5cTSIaUDAUbv9Jr90ZNyfzJucCzW5UWT8KdK0TaCscmrlAVsoVSvjBxTXcfrjNLiBAD7A1oXOCWjIeDXQ3GBowtQBsZJkdGmsjfLwJI30BBEQeGbX9ItDsehpCaNlrplA6yFRzSyaQXrhZbjIXaHlTC8Qdq9IJNNLnh9cjGoyDdWfhAZHZvvr0AmY30vjZVx7a/UZ2AhFJo+GKeFVV7wfqby5VVfVPAfypWQdFZGc37htESQWemo3hZYdGcHkthQOjYdMDRe3EuDlZNDkXqOYYRNc6gaIAtDXxNx8YNv3zU3NOz2wglSu2PwoGsBPIIuPRAB65tNadT96FTiCja2msSpaLGUJ+L0Iij4za8OVYTWcWN3FwpA8+b0u7PmrzhTooArmjE8go5qxsZnFsItrw/VeT2nlUbUW8xyMwGvE3CIY2toOxE4jk9oXHrmD/cBh3Xz2++43sBCKShkmvGIjIcMO+QQAoj4RdXk3hwLB7R8EAbRwMML8TyCgC7RqDUEJA3vyV9HsGQwj6PMwFstj3z63AI4CXHxpp/5O45GZVNuPRINZTeWQLddZht8u4UTYxPHdpM4OA4kF/sP0iTSNhTwGpUvudos/Ox3Fyut+8A1IC7f8duqS4OhbVOrea7QTa0EeIB2t0BI9Hg/U/FzOBqMeeno3hut/+Oi6uJFv6uBfXUrh2Tz88nioPPsudQM6/RhDJjkUgIpMN9/lxYCSM0zPrKBRLuLKecnUoNKC98A0oHizEzC3MzMXSGI34EfTt2PDUpU4gj0fg8FgE51gEstT3z63gur2DGOhkxDKf5gtRC0z0a3/nCyYXhAF0rRNovD/Q1U7OsCePZKm9IlMsncfMWhonp8wsAnUwTuuWcTCjEyiRa+r94xmtCDQQqlUEajAmyUwg6rFHL69jM1PAN59daPpjVFXF/EYGU7U2FXIcjEgaLAIRdcGpfYM4PbOB+VgG+aKKgy4vAgkhMDUQ7EImUKZ6MHCXMoEALRyaRSDrbGbyeHxmA3cc6aALCGAnkEVuOqAFhd6nb3czVRdulJc2s1VzXMwUQB6JorfxO1bx3HwcAMzvBGo7GNodnUADIR98XtF0yHksnYff60FAqf6yW9ua10wnEDOBqDcuLGuvc1q5Vm+k8kjni7UXNrATiEgaLAIRdcGpfYNYjGfxg4ta9sV+l4+DAVoukNmZQLPrKUxXe+LUpU4gADg6EcXsRhoJPfibeuuRS+soltTOQqEB13QsyOboeAQHRsL45rOL5n/yLtwoL29myyu8uyWAPOL59jqBnp3TikDXmFoEarOIXiwApYIrAteFEBiNBMpbvxqJpwvoD/lqdpSNRwNYTWZRKJZqfUHA20FgN1GLLuhjYD+4uIZMvrnx3Tm923u6Vki9cW12wTWCSHYsAhF1wSk9F+hLp2cBAAdH3d0JBGi5QGZ2AhWKJcyspXGgWpdVFzuBjoxrW4LOsxvIEs/qnQ/X699jbWMnkCWEEHjNiQk8eH7V/EJqtzqBuhQKbfAhh1jBg3aWqj47H8doJGBuoardFfFFI/TVHU/5WysC5dEfql3oG+sPQlWB1WSd8TJf7X+Xzz4ygw9++vGmjoWoGRdXkhiNBJArlPDDi82F+c9taNdedgIRyY9FIKIuODndD7/Xg++fW4Ff8WCiy0+S7WByIITFeAalUus3OtXMrKeRK5ZweLzK6uZ2b2KaYBSBOBJmjTMLm9g7FEIk0GFQr0vGVmT0mpMTyBVL+O6ZZXM/scmdQJl8EbF0HuPdLgKVckiXfEjmWg/LfmYubm4XENB+Ed1lm3/GooGmx8HimXzNPCAA5XOs7uer8+/y0IVV/MtzS00dC1EjmXwRsxtp/MRNe+BXPLjvheau1fN6J9DUYK1OIGYCEcmCRSCiLggoXpyY7kdJBfYPh6tvSXCZqYEg8kW1/pPOFhhFmCPVikC+IFAwfzsYABwYDsPnFdwQZpEzC5s43sRK5oY4DmaZmw8MYSjsaylwtCnGiIFJ3/tGl8d4fxeLQKUivGoeWdWH1Sa7Sgy5QgnnljbNzQMC9HHaNopAxkZGlxRXRyP+pjuBYunmikBLm3X+3utsbUtli0hkC6Y9ZCF3e3EtBVXVHmjeenAY3zvbXC7Q7EYafq8Ho301rgF5dgIRyYJFIKIuuVEfV3F7KLRhUp8RNysXqG4RqIudQIrXg0OjEZxb2uzK56facoUSzi8ncGzSrCIQX4haQfF6cPeJCXz7+SXka2WgtPWJze0EMoJ6uzoOph9rFr6WC+RnFzeRL6rmbgYDOugEctdT/tFIAKuJXFOFl3g6j/5g7SKQcY413BBW498lmdNGK1NNZrcQ1XNhWcsDumq0D684Ooozi5tNvXab38hgciBY+8Gny64RRDJjEYioS4xcIIZCa/boM+IvrqVM+XznlhIYjwaqv7Bu90l2k45McEOYFS6tJlEoqbjalCIQM4Gs9JqTE4hnCk1nTTTF5EwgYzSnq8HQ+rFm4cNak+vGDUY+lvnjYG0G6xfclQk0Fg2gUFKxkc43fN9GnUDlIlCjDWE1/l2Ser5WkgsLyAQXVyqLQGMAmtsSNreRxnStUTBAP38F4PWbcZhE1AEWgYi65OYDQxACODpRpVPFhQ6NacUwY+1op84tJ6p3AQHazWCpoG2r6YIjYxG8uJZqemMGmeP5Ba376phZ42A+FoGs8oqjowgoHnO3hHnt2wmUgR+rydaO+9m5OMJ+Lw6MmPygwRfqsBPIHZt/RiPaedFoJExVVcQzhbrB0AHFi8Gwr8E4WO1/l5SeJ8WtlWSGC8sJjEUDiAZ9uHoyitFIoKlcoPlYpvrGVoMxhl1jSx4R9Q6LQERdsm84jC//0h146017rD4UKYT9CvYMhnBebzPuhKqqOL9Urwik37QVuzMSdmisDyUVmDGpq4mac3ZhE16PKBcU21YqAcUcO4EsFPYreMXRUXzz2cW2tmJV5fFoT5hN7AQSAhjp6+JTa6MTSG19HOzZuTiunozCa3bmHDuBmlIuAjUIh07miiiW1LqdQICWC1Q/GLr2v0uCnUBkoosrSVw1qv2c9XgEXnF0FPe/sFJ39LFYUrEQz9TeDAboHbjuuD4QyY5FIKIuum7vAAKK1+rDkMahsT6cN6ETaDGeRSJbwOGxWkUg/UVIjRDNTo3ooYfrqcZjAGSeM4ubODTa1/n3FNfUSuE1Jycwu5EujzWZQgm19X3/2Ivru26glzczGOnzQ/F28aVSRUZGK+NgpZKKZ+fjuGZ6wPxjMrJnWi3OGYHcLimuGh1iyw06gWL6uFi9TCBAGzusPw5We+EBO4HITBdXkjg0uvWw5RVHR7GazNW9Vi9tZlAsqbU3gwHa+euS6wOR7FgEIqKeOTwWwfmlRMdP/uuGQgMVAbHdKQINhrUX8xspczadUXPOLGyaFwoN8MWoxe4+MQEhgG+budq6jTywdK6It//Fg/jY9y9u+/3lzSzGupkHBJSP1RcMtdQJdGU9jUS2YP5mMKD9gG2XdQKNRZpY6w4tFBpAw06gsWigQTB040ygRIZFIOpMLJXHajJX7gQCgDuOjAIAvldnJGxuQytQ1h8HYycQkSxYBCKinjk8HkEyV8RivRe6TTA2c9XNBAK6XwRqIhCUzJHKFfDiWsqk9fDuulmV1WgkgAPDYTy/aOKmvTY2A8bSeRRKKp6b334cS5vZ8ururtGPNRgMt1QEemYuBgDmbwYD2r9+uqy42h9S4Pd6sNKggyvWZBHIGAer+ZCkxnawQrGEbEHbsmdsCSNq18VVbWT/UEWn9Xh/EIfG+vDEzEbNj5vb0M7N+uNgGddcH4hkxyIQEfXMYT3LpdORsHPLCUQDSu0bNJNXRe80GNYyQmIcB+uZs4vaOXPc1E4gdwTYyuyQ3h1omjY6gTYz2vfxC0s7ikDxbHdDoYHysQbDEay1EAz97HwcXo8w5/thp047gVwSuC6EwGjE33QnUH8TnUC5YgnxdI1CTo0CZzK3taAgkeWyAurMxRXtelzZCQQAxyei5Z/D1RidQPXHwbKuuT4QyY5FICLqmSP6k6VOi0Dnl5I4PB6BqLVhosudQH1+LxSPwDrHwXrmrL4ZjJ1AznJ4rA8XV5J1A0db0kYnUFwvAl1cSSJf1DoqSiUVK4nedQKFw2GstpAJ9OxcHIfH+hD0dSFzziiOshOoodFooOF2sKY7gfq1v7eaG8J81TuBUhXdPwyGpk5dXE7CI4D9w+Ftv39sIopLq8maW1HnYxlEA0r97Ct2AhFJg0UgIuqZsWgA0YDS8ZP/uuvhga0nTV0qAgkhMBj2cRysh84sbiLo82DfjhembXHhzaqsDo1FkC2UMLtRPfC2Zb7a4bm1GJ0X+aKKy/ooxHoqh0JJ7VknUF+4D6vJXNN5ac/MxbszCga0n6lWLq665/tqNNK4CBTXc3oaBUMbGUM1w6GVYNXQ88rCD4tA1KnzK0nsGw7Dr2y/RTw+GYWqbmUy7jS7ka7fBQQwE4hIIiwCEVHPCCFwaDzS0Zr4WDqP5c1s/SJQlzuBAO2pLsfBeufMwiaOTZi0DpvbwaRhbPi7sNL+NWGbDjqBgK2xQ2Pj03i3g6H1m/pIJIJcobRttKeW5c0sFuIZXLunC5vBgPavn3ljO5h7vq/GIg3WukP7mSUEEA0qdd9vvN8oAtX4e68x6pisGAHbZDA0dejicnLXKBigdQIB2s/iauZj6fp5QIB2jXBRkZhIZiwCEVFPHe5wTXx5M1it9fBA1zOBAC0XaCPNcbBeObO4WX4R2jF2AknjkJETZlYuUBuZQPGKG+cX9CKQsaWpV51A0Yh2PVtt0FUCAE/PaqHQ13W9CNTudjD3fF+N9wewmsyVxwiriafziAQUeBoUsI3Rw5obwpQgoBaB4vZCDzuByCyqquLiSvUi0MGRMPxeD87WCPKf28hgqt5mMICdQEQSYRGIiHrq8FgE87EMEm2+WD3faD080JNOoMGQDxvsBOqJtWQOy5tZc/KAANcF2MpspM+PgZAPF1bMKgK13glkBEOPRwM4q4dDG90dvcoEGohq53YzG8KevBKDEMA1XSsCtTsOlgE8PsDThZwiSe0fDqNYUjG7XnsEMZ7ON8wDAoBIQEHI563dWVTj36Wye4zbwagTi/Es0vnits1gBsXrweHxCM5UKQJl8kWsJXPY03AcLMOFDESSYBGIiHrKGP+42OZI2LnlBPxKg2yYHnQCDYRZBOoVo/3ctE1I7ASShhACh8b6cH7JrHGwNjqB0gX4vR5ct2cA54xOoM3edgIN9mvn9loT4dBPzcZw1WgfIoH640Vt8xnB0G10Arnse8romDDWalcTS+cb5gEB2vfCeH+gTiZQ9X8XIxg6GlS4HYw6YhTjD1XpBAKA4xORcrdkpfmYdh1jJxCRfbAIREQ9dWS8szXx55YSODTaVz8bpgedQENhf3nrC3WX0X5uXhHIfWMrMjs8FrG8EygaVHB0IooLKwkUiiUsbWbQ5/eir1uFFoN+rEYRaLWJNfFPz8Zwfbe6gIDOOoFcdoN3YET7eXapTqZVPNNcJxCgZQzVzQQCdv27GF21E/1BjoNRRy7q53G1cTAAODYZxexGutw9aTDWwzfMBOJ2MCJpsAhERD21f1gr4HRSBDpcbxQM2HqRUWWTilkGQz4ksoW6WRCtiKXyKJj0uZzmzOImBkI+80ZzXBhgK7NDY31YjGd33Vi0RQlu/fs2KZ4poD/kw9HxCPJFFZdWU1jezJZXdndVIQ0IL0ai2k1Xo3Gwpc1Md0Ohgfavny68wRuN+BEJKLi8mqr5PrEmx8EANOgEqv5wI6V3/4xHAywCUUcuLicR9HkwWePad2xcK1af3dENtFUEamYcjD93iWTAIhAR9ZRf8eDAcLitIlAmX8TMeqp+KDTQm0ygsPai3oyRsFJJxd1/8B38r++c7/hzOdG5pQSOjkcghAmbwQB2AkmmPCJqxoawDjqBjODxc0ubWNrMlld2d5U+QhXyexH2e7HaYBys66HQADuBWiCEwMHRcN1zN54uoD/UXEfZeDSI5ZrB0PU7gcajAW4Ho448ORvD4bFIzRBzoxt3Zzj03IZ2Tk4O1PmZqqquLBQTyYpFICLquUNjkbYyQC4sJ6GqaKITqBeZQH4AQMyEDWHLiSxWEjl867nFjj+XE81tpLF3yMQwSa6Il8rhsc5GRLdpKxNIy2w5rI+qnl1MYGUzi7H+XhSBtgonw31+rDXoBHrqSry7odBA+0V0F2YCAdpI2KUGmUBNj4NFA9jMFpDOVcn2qdUJlCsg5PMiGvQxGJraNh9L4+FLa3jtycma77NnMISw37trTfx8LI3RSAABpU4ofKkAqCVXXiOIZMQiEBH13OHxPlxcSaJYUlv6uCvrWsv9gXqh0IC2ncbj6/p2MMCcTiDjz/XUbAwxhk1vUyypWIhlsMfUIpDRCcQtJTIwRkQvtBkWv40SBEp5oNR8QO5mpoBoUEHYr2DfcAgvLCV62AmUKQcxj/T5G46DPTUbw6FuhkIDHayIz7hy495VI324sp6uOhqcK5SQzhebCoYGtrbRVd0Q5qv+75LMFdEX0PKrOA5G7frHJ+agqsA9p6Zrvo/HI3B0IrqrE2h2I93cZjDAldcIIhmxCEREPXd4LIJcsVQufjTLeEo+EvE3fuc2xkJaYeY42BV9vbCqAg9eWOn48znJYjyDQkltHDjZikIGEF7A2+XQX2qKX/Fgf5sjoru00QUYz2xtbzo6HsWTVzaQyBYw3pNOoK1tOSORAFYT9Y/7qdmN7o6CAewEatHB0T4US2r5Ol4prudcDYSb7wQCUD0cusa/SzJbQF9AQTSoIF9UkS1wQxi17kun53DDvkEcrBEKbTg+EdlVBJqPZZrbDAa48hpBJCMWgYio54wMkFZv+oyn5CN9Tdyc+YJa6GqXDIa0QtSGCRvCjJuHkM+L+8+xCFTJCJzcY3YRiC9EpXJ4rM+cTqDyevPmCxhGJxAAHJ2IlEN+x6M9OEfy6fK52GgcbGkzg8V4truh0ADg9QEQzARq0sERrTO12oawuP7zoflOIO1cqNoJZPzd5ncWgYoI+xX0+b3lXxO14tzSJp6Zi+OeG2p3ARmOTUSxksiVC9aqqmJuI934QQ0XMhBJhUUgIuq5cgZIi7lAa8kcQj4vQv46c+eGLncCDZQ7gTrPBLqynsJoxI+XHRrGA+dWO/58TjLbtSIQX4jK5NBYBBfaGBHdpcVQ43yxhFSuiP7QVieQYcysbXT1VHYC6eNgqlr978AIhb5+72B3j0kI/frZYhEo787iqtE5US0cOqYXgZrNBDKKkZvVxrrqZAL1+bVxMAAcCaOWfen0HDwCeNMNUw3fdyscWnuINx/LIJUrNrEZjJ1ARDJhEYiIem4w7MdoxI/nFuItfdxaMofhviZGwYC2AmJbEQ0o8IitF/mduLKexp6hMG4/MooLK8ly9wttFYFMHwfjC1GpHBrtQ65Q6vzcb3GUKaFvUzJuvo9NbIXOj/ekCLR1Lo5E/MgVSuVtTzs9eSWmhUJP93f/uJRAe5lALiyujvT5EQ0ouFwlHNr4+dDfZBHIyHpKVS0CVR91NMbBjI/lhjBqhaqq+NLpOdx+ZLSp7sfjE1sbwtK5In7h7x5D0OfBjxwbq/+BXMhAJBUWgYjIEj9ybBz//NRCwwyMSqvJXHN5QEDXO4E8HoHBsN+UTKDZdW371R1HRwEA3+dIWNnsehqDYV/5KbcpClmGU0rG2Ph3rtNcoBYzgYzMFmNcxxhVBXrZCWSMg2lfr9ZI2NN6KLSp3wu1tNMJVMi6MmxdWxPfh4uruzPu4npBZqDJFfHhgD7S1cJ2sMpgaO3XLAJR8x6f2cCLayncc2pPU+8/Fg1gIOTDc/NxfOgzj+PJKxv443fciKMT0fofyIUMRFJhEYiILPELdx5CplDExx+41PTHrCWz0nQCAdqGsPUOx8FKJRVXNtLYOxjC8YkoRiN+FoEqzG2kzR0FA9gJJKFD+khNx7lALXYCbe7oBOoLKNg7FILiERgON3mt6URlJ5B+bau1Ieyp2Vj3R8EMvjaK6C7tBAKAAyPhqplArXYC+b0eKB5RfaSrxta2ZLaAPr+CiH4O1+okI6rmS4/PIqB48LprJpp6fyEEjk9E8blHr+DrzyziN370JF57Te218mXsBCKSCotARGSJI+NRvP6aSXz8gUvYzDTXTbOWaGUcLLgrQNNsA2Ffx+NgK4kscoUS9g6FIITAbYdH8f3zqzVzQdxmtpnAyVZV5LCQHIb7/BgM+zrfEFYjPLeWeJWb9KPjEYxGAvB4RGfH0oxt28G0a9vMWgqxVH7b/84vJ3oTCm1ouxPIncXVq0b7cGU9hVxh+5r4VoOhhRDoCyhI1e0E2j4yuXMcjJlA1KxCsYSvPDmPV5+YQLTJcxQAjk1GUCypeO9tB/G+O65q8osZRSB3XiOIZMP9uERkmV+88wj++ekF/M1Dl/GLdx6p+76qqmrjYK0UgTIxE46ytsGQDyuJzjqBZvTNYHuHtA0zdxwZxZefmMMLSwkca9Re7XCqqmJ2PY3bDo+a+4krNjKRHIQQODTahwsdF4Fa2w4W39EJBAC/+ppjWIh1t4BcVtg6F43xsw9++nTNd79+b6+KQIHWi+iFtGuLqwdH+lBStZD/QxUjhfF0HgHFg6CviWUGuj6/t3o3T5VRR1VVkcoVEWYwNLVhbiOD1WQOrzzW2s/Yd730ACaiQfziXfVft23DTiAiqbAIRESWuW7vAF55bAwfue8ifua2q+pu/UrlisgWSuXcjIaUIFBYMulIqxsM+zvOMLmyruVI7B3Sbl5vOzICALj/hRVHFIE+8cAlrCay+HevPd7yx8bTBSRzxfLfjWkKWcAfNvdzUscOj0XwnbPLnX2SDjOBAG371vV7OzuMplV0Ak0NhPAn77yx+npwaIWqm/cP9ea4Wu0EKpWAYs61xdWDo/qa+NXk9iJQJt/0KJghHFCQqpbr4/ECHt+2f5dsoYRCSdU6gfwMhqbWLMS1c6nVbtsTU/04MdViQD07gYikwiIQEVnql+86grf/5YP47CMzeM9tB2u+nxGW2nwwdPczgQZCvo6Docsr0PVCx96hMA6OhPH9cyvNt1lL7DMPzyCVK7RVBLqyoRXIzB8HywDhYXM/J3XswEgYy5tZZPLFljontmkxE6jVcR3T7cinevMN09Ycx06tbgcrGqGv7nzKf3DEWBO/PRw6ls43vR7e0BdQkMxWGQcDdi08MMbGtBXxeqh0rY8l2mE+pr3+mOzvQWGm4O5rBJFsmAlERJa69aphvOTgEP7yu+dRLNXOwTHCUlsaB+vidjAAGAz7sJkpoFAsNX7nGq6spzHS50fYv1WTv/P4OO57YQXPzHV3nK3bCsUSzi0nsN5moWxuQ7uRNz8Y2r3ZJTIzRiKN7ri2tNgJZHRNRIIWPROTdVOdEmqtiG68r8+dm3+G+/yIBpVd4dDxdKH1IpDfW3uky7e9Q8t4v76AAsXrQUDxcDsYNW1R7wSaHOhFEcjd1wgi2bAIRESW+7EbpjEXy2Clzrr4taT2Ntm2gwFbuSLtuLKeLncBGX7l7qMY6vPh337q8W1jAZl8Eb/22Sfwf/z9E1it83cli0urWlBqPJOvWuB7/MX1utkrs+td7ARiEUg6+4a1f+eZtXSD96yj1U6gTB6RgAJvL0Kgd1JVec/FVjuBXP6UXwiBgyN9uLS6vQgUS+fR32KBMexXqq+IB3Y93DAKPkYeUDSocDsYNW0+lkGf39tSKHTbXH6NIJINi0BEZLlxvRW5VhYGAKwmjE6gJl9A+Fp8kt2GIb0gtdHBmvgr66ldmTfDfX784U+dwsWVJH7rS88AADYzebz3Yz/E5x+7gi88Nou7/+C7+PtHr0i9Rezs4iYA7V632ha1D/zNo/i9rz1f8+PnYhn4FQ9Gmx0BbJaLV1nLbJ8ZnUDGU+YWVsS3epNuGplvipTgri1UdeXTWx/nUgdHdxeB4pnWx8EiAW/1TCBAD+ze+ncxRr/Cep6eNkrGIhA1ZzGe6U0XEMBrBJFkWAQiIssZW3HqFoH0cbBhyTKBALQ97mRsvzLGYCrddngUv3TnEXzu0Sv4xAOX8K6//gEevrSOP/qpU/jqB1+Bw2MR/PvPPYH3fOzhXWuJZfH8wmb5v9d3FMqKJRUriSyeuLJR8+Nn19PYMxiCECZ3acjafeFyo5EA/IqnvDGvLeVxsOYzgXryFLwamYNS2QnUsqtGwphdT2+7HsfS7QVD1yzk7OwE0t/PWA/f52cRiJo3H+thEcg4b73uvUYQyYRFICKy3HgTRaC1ZA5+xYO+OhvEtlGC2raaUvcKJINhrSAVS7fXCbScyCJbKNXcfvWhVx/FTfsH8VtffgZnFjbx4XffjLfcuAfHJqL43M+9HP/xjVfje2eX8eUn5tr+M3TT2Yoi0M5uqY1UDqoKXFhJ1rxpmd1Im58HBGzbyETy8HgE9g6FOusE8raeCdQfYifQLq1uB5O5oNUjB0e1NfEz+vlbKqmItxMM7ffWCYbe/nDD6BgyMuUiAYXbwahpi7EMJvt7lNFTyABeP+DhrSeRDPidSESWG43oRaA6OTeriRxG+vzNd4UYN1bF7mXnGJlA7W4Im9U7HmoVgRSvB3/8zhtx99Xj+MT7bsXdJybKb/N4BH72FYdw9WQUH/7eeSnHws4ubmJaf8q48+/I6AxSVeC5+XjVj5/dSGN60OSbSiOHheGUUto3FO4sE8irAB6lpUwg6zuBJDwX2+4Ecm8R6ICxIWxZGwlL5gooqa1vnusLKEjni9UXJezoBEroxaJyJ1DAy2BoakqxpGJxM4vJgR4VoQtZOa91RC7FIhARWS7o86I/qGApXvvGbS2ZbT4UGmg5ILYdg+HOikBX9CLQnsHd42CGvUNhfOS9L8HLDo3sepsQAh945SGcXUzgO2eW2zqGbsnki7i0msRL9ePeOTJnZDwBwNOzu7egZfJFLG9m6/7dtKWof10Zuy8Ie4dC5U6KtrWwGZCZQDUYmWrNFpfZCYTjk1H4vR48cH4VwFYOWuudQNr5WDUXaEeHVrkTSF8PHwn6uCKemrKayKJYUjE50MNOIBmvdUQuxSIQEUlhLBqo2wm0lsy1WATSX2zku1cEigZ9EALYqBJ63IxyEahGJ1Az3nzDNKYHgviL755v+3MY8sUSnroSw6WVZEdr7wHg3FICJRV42aFhALvHwSozgp6e290JZGwNM70TiDerUts3HMZGKo/NTHvfUwB2hefWI0cnkITnohIA1BJQbPLfgZ1AiAQUvPLYGL761Lw+CqYVaFrPBNIKOqlqG8J2FIGMgk9feRzMy+1g1JR5/WfsZH8PM4FcfH0gko1Fj7+IiLYbiwYaBkNfNdrX/Cc02o672Ank9Qj0B32Itbkd7Mp6CkNhX7mVvx0+rwfvu+Mq/M4/PYfTMxs4tW+wpY/PFUr4zMMv4rtnV/DQhdXyDYTPq608Hu8PQKD6CN6/eul+vPG6qapvO6PnAd18YBhej9gVDL2W1G4ur56MVu0Emt3ovEBWlVEU5BNJKRmjkVfW0zgx1WZxRgk11QmkqqrFmUAyF4EqOimVJorvxiYxl39fvfmGKXzruUU8cnm9PM7V6vll/DxIZAuY2PnGHZlAyWwBHgEEfdozXQZDU7MW9M7rqZ4FQ6ddf30gkgk7gYhICmPRYMNg6OFm18MDFVuCupcJBGgjYZ10AlXbDNaqd9y6H9Gggg9/r/VuoL/87nn8xpeewZnFON58wzT++J034vfedj3ef8chHBztQyZfQjpf3PW/5xfi+L2vPV8zi+jM4ib8igcHR8IYCPl2jYOtJbV/l1ccHcULSwlk8tufepeLQGYHQ8t8400Va+I73BDWRPE3ldNyV6zvBJLwxqhcBGry+slOIADA3ScmEFA8+MqTc4hn2hsHM0KeU9XGunZuB8sV0OdXyll5fQGlfF4T1WN0206wE4jIldgJRERSGK/TCZTJF5HKFTHS7Hp4oCeZQIAWDt1+JlAKxyaiHR9DJKDgX7/sAP7yu+dxaSWJgy10TH3zuUXctH8QX/jF21v6mp97ZAa//vdP4tHL67jl4PCut59Z2MSRsQgUr0crlFXpBOrze3HzgSH81X0X8fzC5rYuptn1NISA+etrebMqtX3DWhFoZq2DXKAmN1sZW5RaDe41jXEuyhhSXi6iN3n9NN7P5+7vq0hAwauuHsdXn1rAyal+AG0EQ+sbMKsGPO/cDpYtlsfHjK9vfKxl5zXZwkI8A59XYKSVMftOFDKuvz4QyYSdQEQkhbFoAMlcsWor+2pSKyC0lQnU9U4g/64CRzNUVcXsRrrmZrBW/cxtB6EC+NLp5tfFL21m8OSVGF519XjLX+8N100h5PPi849dqfr2MwubuHpSK3ANhf1Vt4MNR/y4ZnoAwO5w6LmNNMYiAQQUL0zFTiCpDYV9CPu9nYVD19hsdXElWX76DaDcqRG1LBha5k4gY5yWnUCtetP101hJZPHNZxcBAAPh1reDAag+1uXbPuqYyBXK79/wY4kqLMYyGI8G4fE0uXG1U+wEIpIKi0BEJIUxfU38SpVw6LVEO0WgHnUCtTkOtprMIZMvmTbuNN4fxFR/EJdXk01/jLFR7K42ikCRgII3XDuJrzwxv2uUK5bKYyGewbFyEWj3ONhqMofhsB97h0IYCPnwzNz2ItDsRtr8PCCAN6uSE0Jg31C4w3Gw6p1Av/y/H8N/+uJT5V8b4dOtBveaRuZzsd1OIBkLWj32qqvHEfZ7ce+ZJQgBRPytFRn7AkYnULVxsJ2dQIVyKDQARIIsAlFz5mMZ8ztt6+F2MCKpsAhERFIYi2ovDpaqjISt6vkxLbUt++QeBzNucs3IBDLsGw7jxRbGaO59fgmT/cHy2EKrfuLmvdjMFvAN/Ym34eySFgp9XB91q9YttZ7MYajPDyEErtszgKeqdAKZngcEMMDWBvYOhTobB/NVLwItxjN4tmITnbG9ybJOoLzE52KrRfQ8O+wMIb8Xd5+YQEnVRsFa7bQwunlS1Qo5ShAo5oCSViBKZovlohGgbQcDgATXxFMDi/EeF4HyGV4fiCTCIhARScEoAlXLBVrTx8FGIq0EQ/emCDQQ9iOeybccxGkUa8zsdtnfQhEoXyzhvhdWcNfVY+VQ0Va9/NAIpgeC+Pyj20fCntc3gx3f1gm0MxMoV+7sumZPP84sbCJX0NbSl0oq5jYyXSoCSdx9QQC0Yubserpm6HhDVTqBVFXFeiqPuVim3AFkjINZlwkkceGknU4g4QE8jJoEgDddr21NbGfznBEMXXXV+44xZyMY2mD8NzuBqB5VVbVOoF6FQgPsBCKSDItARCSFZopA7Y2DdTkTKOSDqm6NljTrwfOr6PN7cXgsYtqxHBgJY2kzi3S1MYIdHr60hkS2gLuOtz4KZvB4BH78pj2474VlLMa3bhbPLmwiGlDKq2cHw35k8qVtY2PrKW0cDACunR5Avqji7KJWPHriygZyxVKXxsE4tiK7vUMhbGYLiLW5da9aJlA8UygXas8uJsq/BwD9lmUCGQVJCc/FVovoBf0pf5sFZaf5kWNjiAaUljeDAVvB0Kmq42Db/11SuSLCVTKBjNBzomrimQLS+WLv1sMDzAQikgyLQEQkheGwH16PqFoEWk3m4POK1m7WWn2S3aZBPfSzlZEwVVVx7/NLeMXRMfgV8y7DxmalK02E6t77/BL8Xg9uPzLa0dd86017UVKBLz4+W/69M4ubODYZLXcYGX9HRjeQse1tSC/qXbtHC4d+Zi6G2Y00fu5vHsX0QBBvuHaqo2OrSuaNTARga0RyZq3NXKAqnUDrya1OtBf0YmM8bXUmkFGQlPBc9LVYROcN3jZBnxcffPVRvOXUnpY/VvF6EFA8NbaDbf93SWQL5REwoGI7GDuBqI6er4cHtgrFRCQF9u0SkRQ8HoHRiL96J1Aih6Gwv7WxpV51AhlFoBa6Fp6dj2MhnsGrTrTfhVPNfr0I9OJaCkcbrJ7/9vNLeOmh4W2bZdpxeCyCG/cP4pMPXka+WMJIJIDn5+N40w3T5fcZ0jt+NlJ5TA2Etsb79CLQgeEwIgEFD55fxUfvv4R0roi//4Xbyt1hpmInkPT2DWtFkSvrKVy3d6D1T1ClE6hyHPGMXgTazBTg8woETCzEtqSQBSAAr4SrvNvtBKKyf/OKQ21/bF9AqV7I2dkJlC2Ux8eAimDoagUkIt2C3rnLTiAi92IRiIikMRYNYLnKdrDVZLa1UTBg6yY/38GWoSYMhIwCR/Nr4r/93BIAdDSKVU1lEaieF1dTOL+cxLteesCUr/uzrziE/+vzT+J/fONs+fduqLh539kJZBSBjE4gj0fg5HQ/vnh6DopH4BPvu7WcJ2S6chgvX4zKqtwJ1O6aeCW4FVSsM849v9eDF8rjYHn0B31tZ2J1rJCWd4SqfP1spQjEwqpZwn4vUtXCnSs6XEslFclccVsh3+gEqponRKRbiGk/B3vbCZTmNYJIIiwCEZE0xiKBmuNgI5FWi0D6iEWPOoFayS/59pkl3LB3wPROl+E+P/r83oZFoG8/r23zelUbq+GreeN1U3jjdVPI5ItYS+awmSngyPhW1lFlJxBQPePphr0D+OHFNfy3n7i+4xG1umTOYSEAwEDIh/6g0v6a+CrjYGtJ7dw7tW+wnD21mSlYtxkM0J+MS3oeshPIUpGA0mAcLIO0nrFmZAgBQEDxwOsRHAejuhZi2s/BnhWBigWgVOA1gkgiLAIRkTTGogE8Ox/f9ftryRz2Dg229sm8CiC8Xc8EMgoclZkj9awksjg9s4EP3X3M9GMRQmDfcLjheu1vn1nGodE+HBztM/XrB31eTFfZ6FX+O9K7MYz/rywC/cKdR3DX1eO47XAXC0CA3BuZqKyZ87gmJQgUs4CqlrtsjE69lx4axg8vrWEjlUM8nbcuDwiQu3CyYwtVQzIXtGwo7PciWbcTKFsuElUGQwsh0FfrY4l0C/E0RiN+UzMJ6yry4QuRbBgMTUTSGIsGsJLIobRj3fpaIlfOj2lJlY4Asxlh1c1mAn3nzDJUFbjb5DwgQ6M18clsAQ+dX8VdJnUBNWNneHa5Eyi89W863OfvfgEIqMhhaeN8op7ZOxTCTNudQLsLGGvJHBSPwE37hwBoG8I2M3nrO4F8shaB2ugEYti6afqa6AQyCj2VwdDarxVuB6O6FmIZTPY6DwjgNYJIIiwCEZE0xqNBFEvqthDXbKGIzWyh9UwgoGpArNkUrwdj0QDOLGw29f73Pr+E8WgA10z3d+V4jCKQqqpV337fC8vIFUt4zcmJrnz9aoI+L4I+T7lbai2Zg0egrfXJHeMqa1vYNxTGlfXa53FdVQoY66kchvr85aypM4ubiGcK6A+yE6iqVoP12Qlkqj5/jWDoiq1txtsrg6GBOqHSRLr5WAaTvd4MBvAaQSQRFoGISBpGRk5lOPS6nuXRXhEoqIURdtmbr5/Gt55bxGqVUOtKuUIJ3zu7jFddPd61MNr9I2Fk8qWq2UoA8M1nlzAQ8uGWA0Nd+fq1DIX95W6ptaS27c3jsaAQw5tVW9g7FEImX8JKovnA9bKK8FzDejKPobAPUwNBRAMKXljclKMTSNZzUQjAG2j++ilzQcuGwoFa42D633E+jVTO6ATafg5HgjW6iIh0i/FedwJxDJtINiwCEZE0ykWgigLGalL777bGwXzBrncCAcA7b92HfFHF5x+7Uvf9Hrm0hs1swbRA5mr21dkQViyp+Pbzi7jr+BgUb28v/4NhfzmXxejKsISxkYmkZpzHV9rZEGaMHFQUgdZSWuFRCIGjExGcWdhEPG1xJ1Be8nNRaeH6med2MDP1+RWk6o6DVXYC7R4H43YwqiWTL2I9le9tJ1CenUBEsmERiIikMRbZXQSqtkmqaT3IBAKAoxNR3HxgCJ9+eKbu+Mo3n1uE3+vp6varA3WKQI+9uI71VB6v7uEomGEo7MO6ngm0mshtywPqKZm7L6jswIh2Hl9cSbb+wVUygdaTufI15PhkFM8vbCKdLyJq6TiY5OeiEuB2MItoI131V8Qb3T59OzqBao6SEUHrAgJ6vR6enUBEsmERiIikYXQCLVUpArW8Ih7oSSaQ4Z237seF5SR+eHFt19sy+SL+yz8+i499/xLuunps14t2M+0ZCkGI6kWgbz27CJ9X4JXHxrr29WsZCvu3bQdrq6hnBgbY2sLBkT4EFA+endu9LbChqplAeQzqhcej41HE9NHE/pCV42AZQJH4XGylE6iQ5Q2eifr8XuSKJeQKpe1vqNIJtKsIFFCQYDA01bAQ066LUwM9vPYY1xFeI4ikwSIQEUmjL6Ag7PduHwdLGJ1AbTwx71EnEAD86HVTiAYVfPrhmW2///iL63jjH9+Hj37/In765Qfwhz91qqvHEVC8mOoPVi0CffO5Rbzs0IglIzCDYV/FdrC8heNgkndfEAAtcP3qqX4801YRaHsnkKqq2EjlMNynnfdGODQAdgLV42vh+slOIFMZa9/TuR3dQFW2g/XtGgfzchyMalrQO4EmB3p47WEnEJF0WAQiIqmMRwO7xsE8AhhsZ5NUDzuBQn4v3nJqD/7pqXlspHLIFor4/a8/j5/48weQyRXxt+9/Kf7LPdfu2uTSDfuGw5jZUQQ6v5zAheUkXn2i96NggFEEypW3vxk35D3Hm1XbODnVj2fmYq1vCNvRCbSZLaBQUjFkdAJNRMrv2m9pMLTk52Ir10/ZC1o2Y6x9T+zMBaroBDIyg3b+TNGCoYvtbdYjxzM6gXo7DmZ0AvEaQSQLFoGISCpjO4pAq3qWR1ubpJSQFr7aI++4dR9yhRL+4Jtncc+ffh9/du95/MRNe/G1X30l7jjavRygnYw18ZX+5blFAMDdJ7oXSl3PUNiPkgrMbaRRrLgh7zkG2NrGNdP9iGcKuLLe4vewMWKlh5Gu6yOlxjk3FglgKKwVIa3tBJL8XFSCzV0/VZWB6yYzCjupnR09XgUQXqCQRiJbhN/rgV/Z/lK+L6CgWFKR3TlKRgTtNVVA8ezaKtdVxpZBXiOIpMEiEBFJZSwaKK+IL5VUPHp5DXuGwu19sh52AgHANdMDuH7vAD754GWsJnP4yHtuwe//5A09H7/aPxzGYjyLTH5rlOBbzy3hxFQ/9rb7d9khI4/l/HICQJsZT2aQvfuCyq6Z7gcAPDvf4kjYjhXxO8PltQ1h2kiY9ZlAEp+LzWYCFXP6+0tc0LKZPr0TKLlzHAwo/7ukcgWEA95dbzZu7jkSRtWsJLIYjQQgRBsP1trFTiAi6bAIRERSGYtsdQJ95al5nF1M4P13XNXeJ+thJpDh/37jCbz/jqvwjQ+9EndbNHq1f2T7eu3VRBaPXFrDayzqAgJQ7ry4sJzUf81MIKrv6sl+eARazwWqGJkBUM6iGgxvFWOPG0UgZgLV1ux2MOZ9mK5P7wSquuVL/3dJZAvl92v6Y8n11pIWLGbgNYJIOiwCEZFUxqIBxNJ5pHIF/NE3z+L4RBRvum6q8/degAAAPc9JREFUvU/W404gAHjpoRH8xptOWhd8DC0TCNjaEPY7//QcAOBHr5+27JiMTqALK1onkKXbwWTeyERlIb8Xh8cieHYu1toHNugEAoCXHx7BQMiH0YhFRRhVlX9TXbOdQMb7+HiDZxZj41fVQo4vBBQySGWL5Y6hah+7yQ1hVIU1RSDjGiHx9Y7IZSzsgyYi2s1YE//h713AhZUk/vLdN7eXBwRY0gkkg/1GEWg1hS+dnsU/PD6LD7366LatSL1mdAKdX9I6gawrAknefUHbXDPdjx9cXGvtg3YEQ6+n9EyginPuDddO4vXXTLZ/belUqQCoJbnPxWavn3zKb7qwvvErVXUcTHu4kcwVqi4aiNQrIJHrrSZyODIWafyOZipfIyS+3hG5DDuBiEgq41HtRuJ/fec8rtszgNee7GCkqtlxBocZ6fMj7PfigfOr+E//8DRuOTCEX77riKXHJE8nEANs7eTkdD/mY5lyN09TdnQCradyUDwC0YogVCGEdQUgYCtwWeZzsdkiUJ5FILPVzfXRA7uT2ULVcN+ovvHOKH4SVbKkE8i4RnhZBCKSRcMikBBinxDiXiHEc0KIZ4QQH6zyPkII8cdCiHNCiCeFEDd153CJyOmMTqBcoYRfe+2xzsIL9bZ5uGxVrhAC+4fD+Maz2kawP/ypU1C81tb8B0I+CAEsxrMIKB6EfLvHGHqCnUC2cs30AADgmVZGwoyRg/I4WB6DYX9vg1AbKQelSlw4aTkTiN9XZgnrxZ3UzhXxQLkTKJUrljuGKh2fjCIaUPCt55a6fZhkM+lcEel8EcO9XsxQyAAeRdtuR0RSaOauoADg11RVPQHgZQB+SQhxcsf7vAHAUf1/HwDw56YeJRG5hlEEuuXAEH7k2Fhnn8y4KSm674moMRL2Oz9+bTkjyEpejyiH8I70WXRDbuSwyHzjTduUN4S1Eg7tUQDhKRda1pM5DPdZGABdjR0KJ61mAvH7yjRhvUiezNbaDqYFQ1frBAr6vHj9tZP42tML2zZEEq0mte/VESsygXh9IJJKwyKQqqrzqqo+pv/3JoDnAOzZ8W73APikqnkIwKAQos0kVyJys/FoAB945SH8P2+5tvNCwY5sEDd5z20H8R/ecDXuObXzcm0dIxfIstBsI4eFAba2MRj2Y89gqLUNYUJsG2VaT+XK44jSKBdOJA5K5XYwy3g8AmG/t852ML0TqEowNADcc2oPEtkCvv08u4Foy1ZIfo+Lz3z4QiSdluYDhBAHAdwI4Ac73rQHwEzFr69gd6GIiKghIQT+4xtP4MRUf+efrJwN0tsNYTK4/cgofu5HDlt9GNsYN+KWbgYD+GLUZk5O97c2DgZs2wy4nsphWLoikA06gXwhrXBabBAwzE6grgj7FSSrBkOHoNZZEQ9o2+/GogF86fRsl4+S7GS1yqbEnmAnEJF0mi4CCSEiAD4P4EOqqu58JFftcf2uEA4hxAeEEI8IIR5ZXl5u7UiJiFplvOgwQljJUkYnkKWbwQC+GLWZa6b7cWElWT0fpRY9PBfQMoEs6z6rxQ7nYnmctkER3Q4FLRuKBGp3AhVzaeQKJUz0Vz9/vB6BN18/jXufX0Ysne/ykZJdrCW0IlDvx8EyvD4QSaapIpAQwgetAPR3qqp+ocq7XAGwr+LXewHM7XwnVVU/rKrqLaqq3jI21mHWBxFRI+VxMPd1AsloSO/GGLKqK6O8kYkvRu3k5FQ/VBV4bn6z+Q/S82xUVcVGKlcuQEqjYINzsVxEbzASxg67rgj7lRrB0EEUstr5c3wyWvPj7zk1jVyxhK89Pd+tQySbMcbBRqwIhub1gUgqzWwHEwA+AuA5VVX/oMa7fRnAT+tbwl4GIKaqKn/qEJG1XJwJJKMBdgJRG67Zo20Ie7aVkTA9E2gzW0ChpFp3ztVih8JJeZy22SKQxAUtG+oLeGsEQwdQ0gtzxyZqF4Gu3zuAgyNhfOn0rmey5FIrySz8Xk/VQPGuYicQkXSauQrcDuDdAJ4SQpzWf+8/AtgPAKqq/gWArwJ4I4BzAFIAfsb0IyUiahU7gaQyxEwgasP0QBCDYR/+7gcv4rkFrRtoMOTDB155qHbgs54JtK4/+ZY2GFrmkPJmi+jG230Sh1zbUF9AKXdubKMEIQoZDPf5MVqno0MIgXtO7cEff/sFLMYzNUfHyD3WEjkMW7Gds5Dl9YFIMg2LQKqq3o/qmT+V76MC+CWzDoqIyBTNPsmmnmAmELVDCIG3nNqDrzw5j288swhAC3v++0ev4Pfedj3uPD6++4P0TqD1lJaHIu+KeInPxWaL6OXvKz7pN1OfX8HMWmr3G3xBeEo5HJ2KNLyZ/7FT0/j//uUF/OMTc/g3rzjUpSMlu1hL5qz5+VvIAIHaXWtE1Hs97gckIuohdgJJZdDqTCCOrdjWb//YNfjtH7um/OunZ2P41c+cxns/9jD+9cv24/9+40mE/BXrsnd0All2ztVih8JJq51AMhe0bCjs9yJVZTuY6g0ggByOT0Qafo7DYxHcuH8Qf/HdC7jn1B6MRSU+36jrVpO53ucBAdo1oo9ZsEQyaWlFPBGRrZQ7gbgdTAYvvWoYP3rdFK7d02/NAZTDeHmzanfX7hnAP/7bO/Bv7rgKf/vQi/jTe1/Y/g5KECiksZ6StAiUt8G52GwnpREc7ZXs79jm+gIKElW2g8UL2vPbq8eaK+j8v2+9DpuZPH7tc0+gVNq1uJdcxLJOoDwzgYhkwyIQETmXMYPOTiApjPcH8WfvugnRoEWjOXbovqCmBX1e/Kc3ncQdR0bxtacXtr/Rp20HMzJV5F0RL/G52EonkBIEep0z4nB9Aa0TSEtc2LKk1w+PjzZ3Tl892Y/feNNJfO/sMv7qvgtmHybZiHXjYFm5C95ELsQiEBE5FzOBqBLHVhzp1SfGcX45iQvLia3fLGcC5eD1CPQHJZt+t8O5WL5+NpEJJHMxy6bCfgXFkopsobTt9xeSWlHoyJC32odV9a6X7scbrp3E73/9DB5/cd3U4yR7yBaKSGQLGLEqE4jXCCKpsAhERM7FFfFUyQ4bmahlrz45AQD41nOLW79pZAKl8hgK+3q/DacRO4SUlzspm+kE4uYfsxlrvJM7RsKuJLQi0ICvtOtjahFC4L+99XpM9AfxK59+HJl8ldXz5GhGV+RwnwXFmEKW1wgiybAIRETO1eyTbHIHO3RfUMv2DoVxYqof33p2aes3jU6gZE6+PCBAOxe9AblHqNgJZKmwHnS+Mxx6Jq7/usWfawNhH373x6/FzFoa33h2sfEHkKOsJowiEDuBiIhFICJyMuNmP89gaMJWgC1fjDrOa06M45HLa+Wn3VACQD6DtWROvjwgYCtHR2bNXj/t8GexoT6jEyi31QlULKm4HNM7gNpYePDKo2PYMxjC5x6ZMeUYyT6Ma+Nor7eDlUpAkZlARLJhEYiInMvrByDYCUQadgI51qtPTqCkAt9+Xu8GUkJAIYONZA5DYYuCyOuxw5Px8jhto04gG/xZbKivyjjYzFoKiaKeb9XGzzWPR+BtN+/F/edWMLvBhyNusprUzpeedwIVbRCCT+RCLAIRkXMJUR4LISrfNHn5YtRprtszgIn+AL5ljLkoAQAq4qmUNeMPjdhhW06zwfrsBOqKPn0cLJndGgc7s7iJLPSiZps/1952816oKvD5R690fIxkH8Y42EivM4H48IVISiwCEZGz6QGxROUcFg9/9DmNEAKvPjGB772wrIXe6jcc6VRS3kwg2QPKm+4Eysr/Z7GhsF/r+ElVjIOdXdhEVjWKQO39XNs3HMbtR0bwuUdnUCqpjT+AHGEtmYPiEegP9XhTIhcyEEmJr4SJyNnYCUQGO3RfUNtefXICqVwRD55fLXexeEuyBkPbIEzZ4wU8PnYCWcTYDpao6AQ6u5TAQH9U+0UHP9fefss+zKyl8dDF1Y6OkezDyEfr+aZEdgIRSYlFICJyNnYCkYHZJY522+ER9Pm9+NLpWSzqcScB5BkM3QklyO1gFgkHjO1g2zuBpkeHtF908HPtdddMIhpU8LlHOBLmFqvJHEYs2QzGTCAiGbEIRETOpgTb2qJCDmSXG29qS0Dx4s7j4/ji6Tn87tcvAgCCIofxqIQ3H3mbnItKoPH1M5+2x5/FZvr8RieQVgTKF0u4sJLA3jG9CNTB1sugz4sfu2EaX31qHvFMvuNjJfmtJXPW5KMZ5ymvEURSYRGIiJzN18STbHIHdgI53n++5xr8yTtvxLtfcRwA8F/ffBS3Hxm1+KiqsMu5yE4gywR9HngEkNLHwS6tJJEvqjg4YXQCdTbm/PZb9iFbKOGrT853eqhkA5YVgdgJRCQlFoGIyNmYCUQGZgI53mgkgDffMI2XHJkGALxsfwReT48zMJphl3NRCTATyCJCCPT5FST1cbBv6JvvDk6OaO/Q4cON6/cOYCjsw+mZjY4+D9nDaiJr0TgYM4GIZMQiEBE5GzOByGCHjUxkjmbXm1vFLoUTX6jJTiAb/FlsqC+gIJkt4M/uPYff//oZ3H31OK7eO669scNzWwiB45NRnFncNOFISWb5YgnxTAHDvV4PD1R0AoV6/7WJqKYe7wkkIuoxJQhk+SKXwJtVNymvN5e1CGSTc5GdQJYKB7z46lMLSGQLuOfUNP7HT94Aj0cAEKY83Dg+EcXfP3oFqqr2fmsU9cx6MgcAGIlY2QnEcTAimbATiIicTQloIaxE+TRfiLqF8e8s6/d+wSbnohKs/3dYzANqkUWgLunzK0hkC3jPyw/gD99+Cj6vBxDCtIUHxyajSOaKuLLO5QlOtpLQi0AcByMiHTuBiMjZlJC83QDUW3bpvqDOGaMHsn7v2+VcVAJAJl777XzK31Xveul+JHNFvO/2g9s7dUwacz4+EQUAnF3cxL7hcMefj+S0pncCWRMMzWsEkYxYBCIiZ2MmEBnsspGJOlfOBJL0e98u56ISBArLtd9ezvuwQUHLht5x6/7qbzBp4cGxSa0IdGZxE3efmOj485GcVpPa96k142C8RhDJiONgRORs3A5GhkKW4ZRuIXMmULEAlApa6LLsGl0/jbcxcL23fEFTCpz9QR+mB4I4u8DcPCfb6gSyIhia1wgiGbEIRETOxk4gMtil+4I6J3MnUNF4Mm6Dc1FpUGzgU35rmPhw49hkFGcWE6Z8rl7KF0vYSOWsPgxbWEvm4BHAYMjX+y/OTCAiKbEIRETOZgRoqqrVR0JWs0sOC3Wu3AkkYeCtnQonjbaDMe/DGiYuPDg+EcX5pQQKxZIpn69XPv79S7j7f34XpRJ/tjeymsxhKOzXN8v1WCELCA/gYQIJkUxYBCIiZ1OCgFrSxi/I3eyykYk6J3MnUF4vTNnhXGzUcZLnU35LmNkJNBFFrljCpdWkKZ+vV84sbmI1mcMau4EaWkvkrAmFBvStnEFtqx0RSYNFICJyNp/E2SDUO0YOC29W3aG8RlvC73s7jUewE0hOJo45HzfCoRfsNRK2GNfOvaW4hIVeyawlLSwCFbK8PhBJiEUgInK28lgIXyi6mpHDwnBK95A1D8xW42BBoJgDSjVGhcpFIBuEXDuJiQXOI+MReITWWWMn8zG9CLQpYaFXMiuJrDWbwQA9i4/XByLZsAhERM5WHgvhC0VXs9ONN5mDnUCdM4qmxRrFtIKNQq6dpFFgdwuCPi8OjvTZbkPYYrkIJGGhVyIbqRwuriZxbCJqzQGwE4hISiwCEZGzsROIAI6tuJH0nUA2OBeVBuO0dipoOYnJBc5jE1GctVEnUDJbwGZWy/lbZhGorh9cXIOqArcfGbXmAAoZXh+IJMQiEBE5m3GjlZdwSxD1TjmMly9GXUMJyvl9X7DRuVi+fjYqAtmgoOUkjbKaWnR8MopLq0lk8kXTPmc3LcS3/uxLcQm7/STy4PlVhHxe3LB30JoDKGR4fSCSEItARORsxiy6jB0B1Dt26r4gc5g4MmMqO52L7ASSk8mdQMcnoyipwLkle4RDL8S2/uyLDIau64HzK7jl4BD8ikW3fOwEIpISi0BE5GzMBCKAN6tuxEygzpWvn8wEkorJo45GXswZm+QCGUWgPYMhBkPXsbyZxdnFBF5+eMS6g2AmEJGUWAQiImdr9CSb3IHB0O4jeyaQHTbVlTspG3QC+bj9p6d8Ie3vXlVN+XQHR8Lwez22yQUyxsGu2zPAYOg6HrqwCgC47bBFeUCAdp7y+kAkHRaBiMjZGj3JJnewU/cFmYOdQJ1rthPIyyf9PaUEALUElArmfDqvB4fHI02tid9I5fCNZxZM+brtWohlMBDyYf9IGEubWagmFcOc5sELq4gEFFw73W/dQbATiEhKLAIRkbOVO4EkDIil3mGArfuYHJ5rmrydikANrp/5NOD1Ax6+nOwp49/FxODzk1P9OD2z0TAc+r9/7Xl84G8exVNXYqZ97VYtxDOY7A9iPBpArlBCPG1OMcxpHjy/ipdeNQzFa+H3Zz5tj2sdkcvwpzYROZsxcsFOIHezU/cFmcMYmZGNnQqSSoPrZyHL7ykrNPp3acPbbt6LjVQe//D4bM33WUvm8IXHtLf/zUOXTPvarVqMZzAxEMR4v/b3wFyg3eZjaVxcSVqbBwSwE4hIUiwCEZGzMROIAAbYupHsmUB2KJ40Ctbn+mdrdGHhwcsODePaPf346/suoFSqPl71qR++iGyhhNsOj+BLp+ewkcqZ9vVbMR/LYErvBALAXKAqHjyv5QFZXwTidjAiGbEIRETOxkwgAhhg60YyZwJ5fIDHa/WRNGZ8v9TtBOL3VM8pDf5d2iCEwM++4hDOLyfxnbNLu96eK5TwyQcv4RVHR/EbbzqJbKGEzz1yxbSv36x8sYSVRFbrBNKLQItxCb/PLfbg+VUMhn04MWlhHhDAbkEiSbEIRETOxk4gAuzVfUHmUIJyFn/tdFPETiA5daETCADeeN0UpgaC+PD3Lux621efmsdiPIv33XEVTkz14yUHh/C3P7hcs2uoW5Y3s1BVaJlA5XEwCb/PLfbA+VW87KoReDzCuoNQVXYCEUmKRSAicjZja02eRSBXs1MOC5lDCZganGsaOxVOmAkkpy493PB5PfiZ2w/ioQtreHp2K/hZVVV89PsXcWisDz9ydAwA8O6XH8Tl1RS++8KyqcfQyHxM+zNPDQQRCSgI+71YirMI9MOLa/jNLz2N//CFJ/HBTz+O2Y00bjti8ShYMQ9Atc/1jshFWAQiImfzeLTtNewEcjejCMhV1u6hBAG1CBQl2xxkpyfjxs1brWJaIc0bPCt0qRMIAN5x635EAgr+6r6tbqBHL6/jySsxvO/2q8qdJa+/ZhKjkQD+9sHLph9DPcbo14TeBTQeDTg6GPryahKrifpFrnyxhF/9zGl85uEZ/MtzS3jk0jpOTPXj1ScmenSUNRhbBe1yvSNyEcXqAyAi6jolJOdYCPVOIQN4FMDLH3uuUdkt4Y1YeyyV2AlEnerimHN/0Iefesk+fPyBS9jMFCAAnF9OYCDkw1tv2lN+P7/iwTtv3Yc/vfccZtZS2DccNv1YqlnQO4EmB/QiUH/QseNgiWwB9/zZ9zEaCeCfP/gK+Gqsev/i47OY3Ujjo++9Ba+62uLCTyUuZCCSFjuBiMj5lAA7gdyOAbbu04U12qYoZO0TUO5RAOGpnwnkYxGo57q88OBnX3EIN+8fwtJmBoubGUSCCn79dccR9m8vor/z1v1QVeBrTy905TiqWYxn4Fc8GAr7AGidQMsOLQJ94oFL2EjlcW4pgU/W6LgqllT8r++cx8mpftx1fLzHR9gAFzIQSYuPRInI+WQNiKXesVP3BZmjiyMzHbHTuSiE3klZqwjETiBLlLe2defcnhwI4rM///KG7zc9GEI0oGB2o3fZW/OxDCb7gxBCG0sbjwZxb3z3NjO7S2QL+Kv7LuDO42MoqcAffess7jk1jdHI9mvHPz01j4srSfz5u24q/51IgwsZiKTFTiAicj52AhFvVt1H1s2AdjsXlUCdcTAbFbScpMudQK2YGgxirodFoIW4VgQyjPcHkMwVkchKlv3VoU8+qHUBfejVx/CbbzqJdK6I//H1M9vep1RS8WffPocj4xG87ppJi460Di5kIJIWi0BE5HxKUL4bQeotBti6j6ydQHmbnYtKcCvgdae8jUKuncT4O5dg+93UQKi8sasXFuMZTAxUFIGi2vfSUlyy7/MOJLMF/NX3tC6gU/sGcWQ8gp+5/SA+88gMnryyUX6/bz63iDOLm/jlu45Yuwq+FmMhA68RRNLhOBgROZ+PRSDXs1v3BXWuyyMzbbPbuchOIPlI1Ak0PRjatk6+m1RVxXwsg9ddU1kE0v57aTOLQ2MSBcB34JMPXsZ6Ko8P3n20/Hu/cvdR/MPjc/i1zz6BO46OAgC+c2YZB0bCeNP1U1Ydan3sBCKSFotAROR8zAQi3qy6j0Q3ytvY7Vys10lpt4KWU0g06jg9EMRqModMvoigz9vVr7WRyiNXKJXXwwPARL/eCWTzcOhiScWF5QSemo3hr+67gB85NoYb9w+V3x4N+vA7b7kG/+mLT+PvH70CAPB6BH7nLddCqbE1zHLMBCKSFotAROR8SgBIr1t9FGQlO21kInNIdKO8jd021fnqFNELHAezhESb76YGtXN5IZbBwdG+rn6tBX3ka1smkNEJZONxsL/7wWX8zleeQzpfBAD069vYdnr9tVN4/bWSdv1UU+A4GJGsWAQiIudjJxAVMkAgavVRUC+xE8gctTqBSkWglOcNnhWEALxyLDyY1vN55mLp7heB9OyhyYGt75/+kAK/4rH1mvivP7OIobAPv/Paa3HtngEcHuuTt7unFSwCEUmLRSAicj4lIEWAJlkonwH6xqw+CuolicJzt7Fb94wSAHKp3b9fHvWwUUHLSSRZeGB0As1vdP9Yyp1AA1uddEIIjEcDth4Hu7SSxE0HhvATN++1+lDMxUwgImk5oMxMRNQAO4HIbt0X1Dl2ApmjVrGBT/mtpcjRCTSldwLNx7pfbF2IZSDE1kYww3g0gEWbjoPlCiVcWU/hqi53UVmC1wgiabEIRETOJ8kTU7IQA2zdR5FwO1ipBBRz9joXa20H41N+a0nycCPo82K4z4+5HqyJX4xnMNIXgG/HqNR4NGjbTqCZ9RRKKnBwxIlFIHYLEsmKRSAicj5JXiyThew2gkOdk7ETqKgfi89G56ISqt8JxMB1a/jkebgxNRDE/Eb3O4HmY5ly51Glif6AbYOhL60kAaDreUqW4DWCSFrMBCIi55OkbZ4sxE4g95FxO5gdxyNqdgLxKb+lav27WGBqIIQr61VyozqUL5bwjWcWkS1oW7POLSVwYqp/1/uN9wcRzxR6sqbebBf1IpAzx8H089Prt/Y4iGgXFoGIyPmUoLbFplQEPPZ6gUgmsVsOC3VOxk4gOxZOmAkkJ4nGnKcHg/jhxVXTP+9XnpzDr37miW2/92Onpne935ieEbS8mcW+4bDpx9FNl1aT6A8qGAr7rD4U8xkduEJYfSREtAOLQETkfOWbwQzgd+DTNqqvVNLGcHiz6i4eL+DxAQWJtoMZm8rsdC7W6qTMMxPIUkpw69/AYlMDIcQzBSSyBUQC5t1afPv5ZYxGAvj7n385hAAEBPYO7R4tMoKilzYz9isCrWih0MKJhZI8H74QyYqZQETkfMY8ukwdAdQ7RRt2X5A5fCG5vu/t3Amkqtt/n51A1pJozHl6UN8QZmIuUKFYwvfOLuPO42M4ONqHAyN92D8Shsezu1gyHtW+/g8vrkPdeZ42KZMv4tc++wSeno11dNyturiSdGYeEMAsPiKJsQhERM5X2QlE7sObVfeS6EYZgD3PReP6Wcxt/307FrScRKKFB9OD2oMWMzeEnZ7ZQCydx13Hxxu+7+HxPly7px///WvP46f+8iE8MbPR8td7/MUNfP6xK3j3R36AMwubbRxx6zL5IuZiaWduBgP0LD5eH4hkxCIQETmfjAGx1DsFG25kInNIdKMMoKJwYqNzsdxJueP6WS5ocfOPJSTKBDI2dpnZCXTvmSV4PQJ3HB1t+L4BxYsv/uLt+N0fvxYXVhK458++jz/4xpmWvt7ZRa3wI4TAu/76B+XA5m6aWUtBVR0aCg3onUC8PhDJiEUgInI+GQNiqXfs2H1B5mAnUOdqXT/ZCWQtiQqcE/1BCGFuJ9C9zy/j5gNDGAg1F5iseD1410sP4N5/fydee3ICf/G9C4il801/vbOLm+gPKvjsz70MqqriXX/1UFc2nlW66OT18AA7gYgkxiIQETmfccOVlygglnqHAbbuJVF4LgCbFoFqXD8LNgy5dhIlIE3ouc/rwXg0YFon0GI8g2fn402Ngu0UDfrwS3cdQa5Qwj89Od/0x72wmMCxiSiOjEfxN+9/KRLZAn7zS8+0/PVbcWlVXw/v2HGwNK8PRJJiEYiInI+dQO5mxxtvMoe0nUA2KkiWx2lrdQLx+8oSEnUCAdqGsHmTOoG+e2YZAHDX1WNtffz1ewdwdDyCzz92pan3V1UVZxY3cWwyCgA4Od2P15ycxDNz3Q2JvriSwlDYhwEnrocH2AlEJDEWgYjI+ZQamRbkDhxbcS9F1u1gNiqc1ArWt2NBy0kkK3BODwYxFzOnE+jeM0uYGgji+ES0rY8XQuAnbt6LRy+vN5Xts7yZRSydx7HxSPn3Do/3YTGeRTzT/EhZqy6tJJ2bBwRwOxiRxFgEIiLnYyeQuzHA1r0ku1EuH4udQsrLRXR2AknFFwJKBaBYsPpIAOidQBuZtle0G/LFEu57YQV3Hh+HELvXwTfrx2/cA48AvtBEN9AZPRTa6AQCgCNjWkHownL3AqIvrTp4PTygXSPsdK0jchEWgYjI+bgdzN14s+peko3M2PJcrNcJ5FEAr9L7Y6Ktf5eiHOf31EAQ6XyxpTDmah65tI5EtoC7jrc3CmaY6A/ijqNj+MJjsyiV6hemzi4mAADHKjqPDutdQeeWEh0dRy3pXBHzsYxz84AAdgIRSYxFICJyvlo3MeQO5QBbjq24jkThuQC2wpXtdC7WywTiDZ51yoHdcvxcmx7UOsbmNjo7nm89twifV+D2I41Xwzfytpv3YnYjjYcurtZ9v7MLmxju82M0svV9uX84DJ9X4Pxyd4pAl9ccvhkM0M5NO13riFyERSAicj52ArmbHbsvyBzsBOpcuYi+o5iWT/MGz0qSPdwwikDzHeQC3ffCMj7xwCW89ppJ9AU67zB77ckJRIMKPv/obN33O7u0iWMTkW2/5/N6cGCkr2udQJf0rCJmAhGRFVgEIiLn89XItCB3YICte/mC0twkA9CORXi0MSq7YCeQnCR7uDE9oB3PXJtr4p9fiOMX//YxHBmP4P9963WmHFPQ58Wbrp/CPz89j2S2enaSqqrl9fA7HRmLdK0T6OJKCoDDO4F4jSCSFotAROR8kj0xpR4zbl59DIZ2Hek6gTJa0HIHgbc9Vy8TiDd41pFs4cFoJACfV2CujTXxi/EM3vexhxEOePHR974E/UHzVqa/8boppHJFPHp5verb52IZJLKFqkWgw+N9uLyaQq5QMu14DJdWkhiNBBAxoeNJWrxGEEmLRSAicj6vXC+WqcfYCeRe0m0Hy9rvPCx3UrIIJBWlxr+LRTwegYn+IOZb7ASKZ/J438cfRiydx0ff+5LyWJlZbtg3CCGA0zMbVd9+dkHfDFatE2g8gmJJxYtr7W0I+8j9F/HpH75Y9W0XV5O4ajTc1ue1hWIBUIu8RhBJikUgInI+r6KNX0jyYpl6rFwE4otR11GCQDEHlMx/kt8WOxZOanWc2LGg5SSSdQIBwPRAqKVOoGS2gJ/52MM4s7CJP33XTbhmesD0Y+oP+nB4LFK7CGSsh9+RCQQAh8eMDWGtF4FUVcWffPsF/JevPIv1ZG7X2y+tJHHQ6ZvBAF4jiCTVsAgkhPioEGJJCPF0jbffKYSICSFO6//7TfMPk4ioQ0pQmi0q1GN5G+awkDlkGwUt2HBbTnkL1Y4ODzsWtJyknAkkz/a7E1NRPHp5Hf/y3GLD903ninj/Jx7G6ZkN/Mk7b8Rdx8e7dlyn9g3i9MwGVHX3qvgzi5sYjwYwGPbveptRBGonF+jCShIbqTxSuSI+8eClbW979PIaljazODHV3/LntQ0+fCGSWjOdQB8H8PoG73Ofqqqn9P/9l84Pi4jIZIpkAbHUO8bNqp1yWMgcko3M2LJw4tVvjnd1AtmwoOUkEnYC/frrr8Y10/34xb97DA9fWtv2tqXNDJ6ejeHp2RieuhLDB/7mEfzg4hr+4O034A3XTXX1uE7tG8RaMoeZtd0FsxcWEzg+uXsUDAD6AgqmBoI438aGsMf0DKKj4xF8/IFLSOW0YOpSScVvf/lZTPYH8Y5b97X8eW2DnUBEUmv4WFRV1e8JIQ724FiIiLpHtoBY6h2OrbiXbDfKdjwXhaheRC9kgPCoNcdE0m0HA4BIQMHH3vsS/ORfPIj3ffxhfPbnXo54Oo+PP3AJX39mAaUdjTi//7brcc+pPV0/rlP7BgEAj8+sY//IVg5PqaTihaVN/KtbD9T82CPjEZxroxPo8ZkNRIMK/utbr8NP/sWD+NQPZ/D+O67C5x6dwVOzMfx/7ziFsN/B3anGNdduRW8ilzDr6vNyIcQTAOYA/HtVVZ8x6fMSEZlDtoBY6h1jIxO5j2w3yoWMPbfUVSuiF7KAjzd4ljH+7mUpcOpGIgF88v234m1//iDe/Cf3o1BSMRDy4QOvPIyb9g9C6B2ZUwNBXLvH/Aygaq6ejCLo8+D0zMa2otPMegqZfAnHJ3fnARkOj0XwuUdmoKpq+dib8djldZzaN4iXHBzGrVcN46/vu4C3nJrG73/9DG45MIQfu2G6oz+T9IxrLq8RRFIyowj0GIADqqomhBBvBPBFAEervaMQ4gMAPgAA+/fvN+FLExE1ieNg7mXH7gsyh4ydQLYtAnE7mFRkK3BW2DsUxt+8/1b896+dwd0nxvGWU3sQ8nstOx7F68F1ewZ2hUOfXdQ6fI5W2QxmODweQTJXxEI8g6mB5r53E9kCzi5u4nXXTAIAfvHOw3jvxx7GOz78EFaTOXzsvbe2VFCyJWYCEUmt4+1gqqrGVVVN6P/9VQA+IUTV/mBVVT+squotqqreMjY21umXJiJqHjuB3KuQ5gtRt5ItPDdv03Ox2vUzz0wgS5UDu+X8uXZ0Ioq/fs8teOet+y0tABlO7RvEM3Nx5ApbmwKfn48D0HJ7ajk8pm3wOq9vCCsUS/jtLz+D+15YrvkxT8xsoKQCNx0YAgD8yLExXDPdjxeWEnj7zftw3d7edEBZyjgveY0gklLHRSAhxKTQy9lCiFv1z7na6eclIjIVM4Hci51A7iVjJ5Adz8WqnUBZexa0nEK2zXeSO7VvCLlCCc/phZ98sYTPPjqDG/YNIhr01fy4I+PGmnhtlfxffu8CPv7AJfzy/34ci/Hqf/dGKLSRRSSEwK+/7jiunozi37/uuFl/JLmxE4hIas2siP8UgAcBHBdCXBFCvF8I8fNCiJ/X3+VtAJ7WM4H+GMA71Go7GImIrOTjOJhrcWzFvXzcDmYKJcDtYLIpd7lJUuCU3Kn9gwBQHgn74uOzmFlL49/edaTux41FAogGFZxfTuL5hTj+6FtncdvhEWQLRfyfn3+y6tr5x15cx9HxCAZCW8WlO4+P42sfeiXGoi75nikHQ7vkz0tkM81sB3tng7f/KYA/Ne2IiIi6QQkCydrt2+Rgds1hoc5J2QlkwyKQL7S9kKaqQDHLwHUrebyAxydPgVNy0wNBjEUDOD2zgXcVS/ize8/hmul+3H1ivO7HCSFwZDyC5xfi+HefeQIDIR/+9F/dhC+fnsVv/+Oz+NQPZ/CvXrqVc6qqKh6f2cBrT050+48kt3InEK8RRDLqeByMiMgWqj3JJnewa/cFdU628Fy7nos7r598yi8Hjjk3TQiBU/sGcXpmA19+Yg6XVlP4lbuPNhXQfHgsgocvrePZ+Th+98evw3CfHz/98oO4/cgIfuefnsWLq6ny+15cSWIjlcdN+4e6+ceRH68RRFJjEYiI3EEJShugSV1m1xwW6pxs4bl2PRd3ZgIx70MOSkCe0HMbOLVvEBdXkvif3ziLE1P9TXfrGLlAb71xT3njl8cj8PtvuwFej8AHP/M4UrkCAOCxFzcAbIVCuxavEURSYxGIiNyB28Hcy64bmahzMoXnqqp9N9Upge2FtPINng0LWk7CTqCW3KgHNc9upPErrzrS9Jr215ycwFtOTeO33nzNtt+fHgzh937iejwxs4H3fuxhJLIFPPbiOqJBBUfGam8ccwVeI4ikxiIQEbmDEuKLZbeya/cFdc7Io5Dhe7+Y0/7fjuciO4HkxIcbLblu7wCEAI5PRMsdPc04PBbBH73jRgyEd28Re8N1U/ijd9yIRy+v4z0f/SEeurCKU/sG4fE0V2ByLF4jiKTWMBiaiMgR+GLZvQoZhlO6lUydQMYx2DGkvFYmkI83eJZiJ1BLokEf/vOPXYPr95pbpPmxG6aheAR+5VOPo1BS8ebrp0373LZVzgTiNYJIRiwCEZE7KEFtm42qAk22gJNDsBPIvWRao23noFQlxE4gGfmCchQ4beSnX36wK5/3jddNwesR+M0vPY1Xn3D5ZjBAOy+9fsDDoRMiGbEIRETuULkqmk+v3UNV7buRiTrnVQDhleNG2c6FE24HkxM7gaTyumsmWxozc7RC1p7XOiKXYHmWiNyh3BHATSquUswBUHmz6mY782yskrdzESioXTtVVft1Pr31+2QdJbD1b0Ekk3yaP3eJJMYiEBG5Q2UnELmHnbsvyByy5IHZeVuOEgTUElDS1mAz70MS7AQiWbETiEhqLAIRkTsYYawy3AxS73BshXwhOb7v7Vw42RmwbeeClpPIUuAk2qmQ4fWBSGIsAhGRO7ATyJ3svJGJzLEzz8Yqdu5KKxfRs9v/n1v3rKWE5Di3iXYqZHl9IJIYi0BE5A7lTCA+NXUVO3dfkDlkyQSy87nITiA5sROIZMVOICKpsQhERO5gvBjJ8wWzq5QDbPli1LWUgBzf9wUbn4tG4Sq/swhkw4KWk8hS4CTaiVs5iaTGIhARuQM7gdzJzt0XZA5ZbpTtfC6yE0hO7AQiWbETiEhqLAIRkTsoOzItyB14s0qybFCy87lYLqIbmUDsBJKCEgSKOaBUsvpIiLbjdjAiqbEIRETusPNJNrkDA2xJmk4gG4eU7+ykLGQB4QG8PuuOiQCf/u9SlKDISVSpkNk6P4lIOiwCEZE77HySTe5g5+4LMoc028GMgqQNz8VdRSA970MI646JOOZM8mInEJHUWAQiIndgJ5A7cWyFZOsEsuO5WL5+VqyIt2Mxy2l2/rsQyYKZQERSYxGIiNyBT0zdiZ1AJEt4rrFZy+u39jjaUb5+6hvO8ml7FrOcpry1LW3tcRDtlOd2MCKZsQhERO7ATiB3snP3BZlDpk4gu45QsRNITuwEIlmxE4hIaiwCEZE7GGGsMtwMUu8YN0cMqHQvnyzbwWyckVE1E8iGAddOww5XklGpCJTyvEYQSYxFICJyB4+ibbOR4WaQeoedQGR0AqmqtcdRsPF4hFFEZSeQXLjwgGRk5xB8IpdgEYiI3EEIecZCqHeMF6N2zGEhcxg3IsWctcdh58JJre1gZC12ApGM+PCFSHosAhGReyiBrXBWcgcjwNaOOSxkDlnCcws2DlP26sWrfGURyKYFLSdhEYhkxIUMRNJjEYiI3IOdQO5j5+4LMocs4bl2Phc9Hq2bjp1AcuHCA5IRO4GIpMciEBG5hyJJQCz1Dm9WSZEkFN7u52Ll9dPOBS0nYSYQyYiZQETSYxGIiNyDnUDuY+eNTGQOmTqB7LylrvL6WchsbVwk6/g4DkYSMs5HXiOIpMUiEBG5hxKw/kaQesvu3RfUOVlyU+x+LrITSD7sBCIZsROISHosAhGReyhBLZyV3IMBtiRLEShv83NRCTATSDbG+WR16DlRJeN85DWCSFosAhGRe7ATyH14s0qyhOfa/VysHAeze0HLKdgJRDJiJxCR9FgEIiL3YCaQ+3BshWS5Ubb7uWh0Aqmq/QtaTuFRAOHhzzWSC7eDEUmPRSAicg8ft4O5DgNsSZbw3EJma1OZHflC2vWzmAeg8gZPBkJo55TV5zZRpXInEK8RRLJiEYiI3IOdQO5j9+4L6hw7gcxhdALxKb9cOOZMsuE1gkh6LAIRkXvwxbL7cGyFmAlkDmM7GPM+5MKHGyQbdgIRSY9FICJyDyXILSpuwwBbMm5ErPzeL+YBtWjvmyIloP0dFrj5RyqVW9uIZFC+RvBnL5GsWAQiIvdgJ5D72L37gjpX7gSy8Hu/PB5h45uiXZ1A/L6SAjuBSDa8RhBJj0UgInIPI0BTVa0+EuqVQpYvRN3OCGO28kbZCTdFuzKBbFzQchI+3CDZFDKA8AJexeojIaIaWAQiIvdQAgBUfbsNuQI7gcjrAyDk6ATy2fhcVELbO4G4dU8OPm4HI8kUsrw+EEmORSAico/yliC+YHaFYsH+OSzUOSGsH5lhJxB1CzuBSDYFZvERyY5FICJyD1m2BFFvMJySDFaH5+YdcC4qQaCUB3LJrV+T9bjwgGSTZwcukexYBCIi92AnkLs4ofuCzMFOoM4ZBaxMbPuvyVrsBCLZsBOISHosAhGRexgz6nzB7A4cWyGDLyhHJpCdz0WjgFUuAtm4oOUkVhc4iXZiFh+R9FgEIiL34DiYuzDAlgxW3yiXi0A2PheNUOvMhvb/vMmTg2JxgZNoJ27lJJIei0BE5B7lcTC+YHYFJ3RfkDmsHpkpj4PZ+FxkJ5CcrC5wEu3ETiAi6bEIRETuYdyAMUTTHcpFIL4YdT2rw3OdcC4yE0hOVoeeE+1UyPL6QCQ5FoGIyD3YCeQueXYCkc7yTiAHnIvG9TO9sf3XZC2jE0hVrT4SIk0hzesDkeRYBCIi92AmkLs4ofuCzGH1yIwTzsVyJ9DG9l+TtYx/h2LO2uMgMrATiEh6LAIRkXsYoawsArmDE9ZykzmsDs8th5Tb+Fw0rp+ZmPb3KYS1x0MaH3+ukWQKGS5kIJIci0BE5B7lTiCOg7mCE7ovyBzsBOpcZSYQn/LLgz/XSDbsBCKSHotAROQe5UwgPjF1BSdsZCJzWJ4JpH9tr43PxcrtYHYuZjkNf66RbLgdjEh6LAIRkXswE8hdCvo2KL4YJSW4dT5YIZ8GvH7AY+OXXewEkpNxfcvz5xpJIp/hNYJIcjZ+NUJE1CI+MXUXdgKRQYZOILsXI43jV0v2/7M4CR9ukExUFSg64HpH5HAsAhGRezA7wV2ckMNC5vCFrF2jXXDAk/HK7yO7/1mcpPxwgz/XSAJ8+EJkCywCEZF7CGF9QCz1DreDkUEJaB0spYI1X7+Q3dquZVeVm83s/mdxEna4kkzKD194jSCSGYtAROQuVo+FUO8UMvbPYSFzWH2j7IROoMpQa7v/WZyEnUAkE3YCEdkCXxkTkbsoQS2klZwvzw0lpLM6PNcJ23K8CuBRtP+2+5/FScpjzvy5RhLgQgYiW2ARiIjchZ1A7uGE7gsyh9XhuU45F40bOyf8WZyCnUAkE3YCEdkCi0BE5C7MBHIPJ2xkInNYfaPslHPRuLFzwp/FKawucBJV4kIGIltgEYiI3EUJ8ompWzhhBIfMIUMmkM8B56IR9uqEP4tT+PR/ExaBSAbG6yteI4ikxiIQEbkLO4HcwyndF9Q5dgKZg51A8il3AvHhBkmAnUBEtsAiEBG5CzOB3MMpOSzUOatHZpxyLpYzgXiDJw2ru9yIKpUzgXiNIJIZi0BE5C5KkFtU3ILjYGQo3yhb9L3vlE115U4gBxS0nMLr1/7fqs13RJWM7au8RhBJjUUgInIXdgK5h1O6L6hzVo/MOOVcZCeQfITgmDPJg51ARLbAIhARuYsvxBfLblHIboWmkrtZHZ5byG6FKtuZj0UgKXHhAcmCmUBEtsAiEBG5CzuB3MMp3RfUOXYCmYOdQHJiJxDJgkUgIltgEYiI3IUvlt3DKRuZqHNWhueWikAp74xzkZlAcuLDDZJFeRyM1wgimbEIRETuogQZoOkW+TRfiJLGOA+s+N4vPxl3wLnITiA5ceEBycI4D3mNIJIai0BE5C5KgJ1AbsFOIDJY2QnkpKBUdgLJiZ1AJItCFoAAvD6rj4SI6mARiIjcRQkCahEoFqw+Euo2p+SwUOe8FmYCsROIuo1jziSLQkY7H4Ww+kiIqA4WgYjIXazsCKDeKeewOGAjE3XO49EKQZZ0Aulf0wmb6ozrp49FIKn4uB2MJFHI8vpAZAMNi0BCiI8KIZaEEE/XeLsQQvyxEOKcEOJJIcRN5h8mEZFJykUgvmB2NIZT0k5WrdF20rnITiA5sROIZGF0AhGR1JrpBPo4gNfXefsbABzV//cBAH/e+WEREXVJeVU0QzQdjWtqaSclYM33fd5BQanMBJKTEuDCA5JDnmPYRHbQsAikqur3AKzVeZd7AHxS1TwEYFAIMWXWARIRmYqdQO7gpBwWMgc7gTrHTiA5sROIZMFOICJbUEz4HHsAzFT8+or+e/MmfG4iInMZN2Jf/XUg2G/tsVD35FLa//PFKBmUAHDxPuBz7+3t100s61/fAeciO4HkpASAzYXen9tEO838EIhOWH0URNSAGUWgavHvatV3FOID0EbGsH//fhO+NBFRi6auB6ZuAGIzQMzqg6GumrwOmL7R6qMgWZx4E/D8PwGLz/T+a++5GRg91vuva7YDtwHHfxTo32P1kVClw68CZh625twmqhTsB46/0eqjIKIGhKpWrddsfychDgL4iqqq11Z5218C+I6qqp/Sf30GwJ2qqtbtBLrlllvURx55pK2DJiIiIiIiIiKi3YQQj6qqeku1t5mxIv7LAH5a3xL2MgCxRgUgIiIiIiIiIiLqrYbjYEKITwG4E8CoEOIKgN8C4AMAVVX/AsBXAbwRwDkAKQA/062DJSIiIiIiIiKi9jQsAqmq+s4Gb1cB/JJpR0RERERERERERKYzYxyMiIiIiIiIiIgkxyIQEREREREREZELsAhEREREREREROQCLAIREREREREREbkAi0BERERERERERC7AIhARERERERERkQuwCERERERERERE5AIsAhERERERERERuQCLQERERERERERELsAiEBERERERERGRC7AIRERERERERETkAiwCERERERERERG5AItAREREREREREQuwCIQEREREREREZELsAhEREREREREROQCLAIREREREREREbkAi0BERERERERERC7AIhARERERERERkQuwCERERERERERE5AIsAhERERERERERuYBQVdWaLyzEMoDLlnxx840CWLH6IIga4HlKsuM5SnbA85TsgOcpyY7nKNmBnc/TA6qqjlV7g2VFICcRQjyiquotVh8HUT08T0l2PEfJDniekh3wPCXZ8RwlO3DqecpxMCIiIiIiIiIiF2ARiIiIiIiIiIjIBVgEMseHrT4AoibwPCXZ8RwlO+B5SnbA85Rkx3OU7MCR5ykzgYiIiIiIiIiIXICdQERERERERERELsAiUAeEEK8XQpwRQpwTQvxfVh8PkUEIcUkI8ZQQ4rQQ4hH994aFEN8UQryg//+Q1cdJ7iKE+KgQYkkI8XTF79U8L4UQ/0G/vp4RQrzOmqMmN6lxjv62EGJWv56eFkK8seJtPEep54QQ+4QQ9wohnhNCPCOE+KD++7yekhTqnKO8npI0hBBBIcQPhRBP6Ofpf9Z/3/HXUo6DtUkI4QVwFsBrAFwB8DCAd6qq+qylB0YErQgE4BZVVVcqfu/3AKypqvrf9KLlkKqq/6dVx0juI4R4JYAEgE+qqnqt/ntVz0shxEkAnwJwK4BpAN8CcExV1aJFh08uUOMc/W0ACVVV/8eO9+U5SpYQQkwBmFJV9TEhRBTAowDeAuC94PWUJFDnHH07eD0lSQghBIA+VVUTQggfgPsBfBDAW+Hwayk7gdp3K4BzqqpeUFU1B+DTAO6x+JiI6rkHwCf0//4EtB/GRD2jqur3AKzt+O1a5+U9AD6tqmpWVdWLAM5Bu+4SdU2Nc7QWnqNkCVVV51VVfUz/700AzwHYA15PSRJ1ztFaeI5Sz6mahP5Ln/4/FS64lrII1L49AGYqfn0F9S9uRL2kAviGEOJRIcQH9N+bUFV1HtB+OAMYt+zoiLbUOi95jSWZ/LIQ4kl9XMxoC+c5SpYTQhwEcCOAH4DXU5LQjnMU4PWUJCKE8AohTgNYAvBNVVVdcS1lEah9osrvcbaOZHG7qqo3AXgDgF/SRxyI7ITXWJLFnwM4DOAUgHkA/1P/fZ6jZCkhRATA5wF8SFXVeL13rfJ7PFep66qco7yeklRUVS2qqnoKwF4Atwohrq3z7o45T1kEat8VAPsqfr0XwJxFx0K0jaqqc/r/LwH4B2itiov6jLYxq71k3RESldU6L3mNJSmoqrqov0gsAfgrbLV+8xwly+j5FZ8H8Heqqn5B/21eT0ka1c5RXk9JVqqqbgD4DoDXwwXXUhaB2vcwgKNCiKuEEH4A7wDwZYuPiQhCiD49hA9CiD4ArwXwNLTz8z36u70HwJesOUKibWqdl18G8A4hREAIcRWAowB+aMHxkcsZLwR1Pw7tegrwHCWL6GGmHwHwnKqqf1DxJl5PSQq1zlFeT0kmQogxIcSg/t8hAK8G8DxccC1VrD4Au1JVtSCE+GUAXwfgBfBRVVWfsfiwiABgAsA/aD9/oQD436qqfk0I8TCAzwoh3g/gRQA/aeExkgsJIT4F4E4Ao0KIKwB+C8B/Q5XzUlXVZ4QQnwXwLIACgF+y4/YFspca5+idQohT0Fq+LwH4OYDnKFnqdgDvBvCUnmUBAP8RvJ6SPGqdo+/k9ZQkMgXgE/rWbw+Az6qq+hUhxINw+LWUK+KJiIiIiIiIiFyA42BERERERERERC7AIhARERERERERkQuwCERERERERERE5AIsAhERERERERERuQCLQERERERERERELsAiEBERERERERGRC7AIRERERERERETkAiwCERERERERERG5wP8PErvdMz4d5GwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(y_pred[200:500])\n",
    "plt.plot(val_y[200:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 울산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, val_x, val_y = train_datast(ccc, \n",
    "                                              dangjin_fcst, \n",
    "                                              target='ulsan', \n",
    "                                              sun_target = \"sun_ulsan\",\n",
    "                                             rain_target = \"ulsan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_x[:,0] = np.array(pd.Series(train_x[:,0]).astype(\"str\").apply(lambda x : x[2:4]).astype(\"int\"))\\nval_x[:,0] = np.array(pd.Series(val_x[:,0]).astype(\"str\").apply(lambda x : x[2:4]).astype(\"int\"))\\n\\ntrain_min_dangjin = -9\\ntrain_max_dangjin = 100\\n\\ntrain_x_scaled = (np.array(train_x) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)\\nval_x_scaled = (np.array(val_x) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)\\n\\nae_result = Auto_Encoder_dangjin(train_x_scaled) * (train_max_dangjin - train_min_dangjin) + train_min_dangjin\\n\\ntrain_x = np.hstack([train_x, ae_result])\\n\\nae_result = Auto_Encoder_dangjin(val_x_scaled) * (train_max_dangjin - train_min_dangjin) + train_min_dangjin\\n\\nval_x = np.hstack([val_x, ae_result])\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_x[:,0] = np.array(pd.Series(train_x[:,0]).astype(\"str\").apply(lambda x : x[2:4]).astype(\"int\"))\n",
    "val_x[:,0] = np.array(pd.Series(val_x[:,0]).astype(\"str\").apply(lambda x : x[2:4]).astype(\"int\"))\n",
    "\n",
    "train_min_dangjin = -9\n",
    "train_max_dangjin = 100\n",
    "\n",
    "train_x_scaled = (np.array(train_x) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)\n",
    "val_x_scaled = (np.array(val_x) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)\n",
    "\n",
    "ae_result = Auto_Encoder_dangjin(train_x_scaled) * (train_max_dangjin - train_min_dangjin) + train_min_dangjin\n",
    "\n",
    "train_x = np.hstack([train_x, ae_result])\n",
    "\n",
    "ae_result = Auto_Encoder_dangjin(val_x_scaled) * (train_max_dangjin - train_min_dangjin) + train_min_dangjin\n",
    "\n",
    "val_x = np.hstack([val_x, ae_result])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = lgb.Dataset(train_x, train_y)\n",
    "val_dataset = lgb.Dataset(val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def LGB_cv(learning_rate, \n",
    "           feature_fraction, \n",
    "           bagging_fraction,\n",
    "           lambda_l2,\n",
    "           silent=True, \n",
    "           nthread=-1):\n",
    "\n",
    "    params = {\"learning_rate\": learning_rate,\n",
    "                \"feature_fraction\" : feature_fraction,\n",
    "                \"bagging_fraction\" : bagging_fraction, \n",
    "               \"lambda_l2\" : lambda_l2,\n",
    "               \"objective\" :  \"regression\",\n",
    "              \"nthread\" : nthread\n",
    "                }\n",
    "    \n",
    "    model = lgb.train(params,\n",
    "                      train_dataset,\n",
    "                      feval = mean_squared_error\n",
    "                     )\n",
    "\n",
    "    global y_pred\n",
    "    \n",
    "    y_pred = model.predict(val_x)\n",
    "\n",
    "    mae = mean_squared_error(val_y, y_pred)\n",
    "\n",
    "    return 1/mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | lambda_l2 | learni... |\n",
      "-------------------------------------------------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 17.97   \u001b[0m | \u001b[0m 0.2149  \u001b[0m | \u001b[0m 0.2727  \u001b[0m | \u001b[0m 0.3573  \u001b[0m | \u001b[0m 0.1238  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 21.37   \u001b[0m | \u001b[95m 0.6414  \u001b[0m | \u001b[95m 0.714   \u001b[0m | \u001b[95m 0.5803  \u001b[0m | \u001b[95m 0.06685 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 21.43   \u001b[0m | \u001b[95m 0.6505  \u001b[0m | \u001b[95m 0.7305  \u001b[0m | \u001b[95m 0.5972  \u001b[0m | \u001b[95m 0.05825 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 19.27   \u001b[0m | \u001b[0m 0.9517  \u001b[0m | \u001b[0m 0.9084  \u001b[0m | \u001b[0m 0.5233  \u001b[0m | \u001b[0m 0.1585  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 2.842   \u001b[0m | \u001b[0m 0.5451  \u001b[0m | \u001b[0m 0.7372  \u001b[0m | \u001b[0m 0.7422  \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 20.65   \u001b[0m | \u001b[0m 0.7125  \u001b[0m | \u001b[0m 0.7498  \u001b[0m | \u001b[0m 0.5521  \u001b[0m | \u001b[0m 0.07708 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 18.7    \u001b[0m | \u001b[0m 0.007636\u001b[0m | \u001b[0m 0.5952  \u001b[0m | \u001b[0m 0.2435  \u001b[0m | \u001b[0m 0.1715  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 20.22   \u001b[0m | \u001b[0m 0.2285  \u001b[0m | \u001b[0m 0.4304  \u001b[0m | \u001b[0m 0.2965  \u001b[0m | \u001b[0m 0.1535  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m 21.87   \u001b[0m | \u001b[95m 0.6561  \u001b[0m | \u001b[95m 0.7123  \u001b[0m | \u001b[95m 0.5916  \u001b[0m | \u001b[95m 0.06648 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 7.761   \u001b[0m | \u001b[0m 0.7322  \u001b[0m | \u001b[0m 0.6489  \u001b[0m | \u001b[0m 0.5767  \u001b[0m | \u001b[0m 0.008754\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 20.16   \u001b[0m | \u001b[0m 0.6694  \u001b[0m | \u001b[0m 0.7347  \u001b[0m | \u001b[0m 0.5958  \u001b[0m | \u001b[0m 0.1197  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 20.99   \u001b[0m | \u001b[0m 0.1358  \u001b[0m | \u001b[0m 0.4885  \u001b[0m | \u001b[0m 0.2785  \u001b[0m | \u001b[0m 0.159   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 17.83   \u001b[0m | \u001b[0m 0.2144  \u001b[0m | \u001b[0m 0.536   \u001b[0m | \u001b[0m 0.2554  \u001b[0m | \u001b[0m 0.1728  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 19.14   \u001b[0m | \u001b[0m 0.1214  \u001b[0m | \u001b[0m 0.4188  \u001b[0m | \u001b[0m 0.3253  \u001b[0m | \u001b[0m 0.1362  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 7.419   \u001b[0m | \u001b[0m 0.7693  \u001b[0m | \u001b[0m 0.9923  \u001b[0m | \u001b[0m 0.8307  \u001b[0m | \u001b[0m 0.007608\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 19.58   \u001b[0m | \u001b[0m 0.1419  \u001b[0m | \u001b[0m 0.4199  \u001b[0m | \u001b[0m 0.2154  \u001b[0m | \u001b[0m 0.1885  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 20.88   \u001b[0m | \u001b[0m 0.137   \u001b[0m | \u001b[0m 0.4718  \u001b[0m | \u001b[0m 0.2325  \u001b[0m | \u001b[0m 0.07099 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 20.83   \u001b[0m | \u001b[0m 0.634   \u001b[0m | \u001b[0m 0.7314  \u001b[0m | \u001b[0m 0.5875  \u001b[0m | \u001b[0m 0.06496 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000948 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 9.438   \u001b[0m | \u001b[0m 0.4353  \u001b[0m | \u001b[0m 0.2291  \u001b[0m | \u001b[0m 0.359   \u001b[0m | \u001b[0m 0.01676 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 11.02   \u001b[0m | \u001b[0m 0.238   \u001b[0m | \u001b[0m 0.1117  \u001b[0m | \u001b[0m 0.9839  \u001b[0m | \u001b[0m 0.1164  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 21.16   \u001b[0m | \u001b[0m 0.09364 \u001b[0m | \u001b[0m 0.5461  \u001b[0m | \u001b[0m 0.3062  \u001b[0m | \u001b[0m 0.06115 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 12.35   \u001b[0m | \u001b[0m 0.5153  \u001b[0m | \u001b[0m 0.1693  \u001b[0m | \u001b[0m 0.9707  \u001b[0m | \u001b[0m 0.1005  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 20.33   \u001b[0m | \u001b[0m 0.03818 \u001b[0m | \u001b[0m 0.4938  \u001b[0m | \u001b[0m 0.2441  \u001b[0m | \u001b[0m 0.08459 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000945 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 2.84    \u001b[0m | \u001b[0m 0.09612 \u001b[0m | \u001b[0m 0.5797  \u001b[0m | \u001b[0m 0.2122  \u001b[0m | \u001b[0m 0.0001  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 9.676   \u001b[0m | \u001b[0m 0.5356  \u001b[0m | \u001b[0m 0.06423 \u001b[0m | \u001b[0m 0.4331  \u001b[0m | \u001b[0m 0.1407  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 21.17   \u001b[0m | \u001b[0m 0.08359 \u001b[0m | \u001b[0m 0.5084  \u001b[0m | \u001b[0m 0.3198  \u001b[0m | \u001b[0m 0.09757 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 20.63   \u001b[0m | \u001b[0m 0.1649  \u001b[0m | \u001b[0m 0.4911  \u001b[0m | \u001b[0m 0.3175  \u001b[0m | \u001b[0m 0.07274 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 20.99   \u001b[0m | \u001b[0m 0.1004  \u001b[0m | \u001b[0m 0.5841  \u001b[0m | \u001b[0m 0.3772  \u001b[0m | \u001b[0m 0.08816 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 17.38   \u001b[0m | \u001b[0m 0.8101  \u001b[0m | \u001b[0m 0.2133  \u001b[0m | \u001b[0m 0.1007  \u001b[0m | \u001b[0m 0.1222  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 19.77   \u001b[0m | \u001b[0m 0.09856 \u001b[0m | \u001b[0m 0.4061  \u001b[0m | \u001b[0m 0.2662  \u001b[0m | \u001b[0m 0.06635 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 17.88   \u001b[0m | \u001b[0m 0.06214 \u001b[0m | \u001b[0m 0.53    \u001b[0m | \u001b[0m 0.3869  \u001b[0m | \u001b[0m 0.0268  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 16.39   \u001b[0m | \u001b[0m 0.639   \u001b[0m | \u001b[0m 0.3388  \u001b[0m | \u001b[0m 0.3938  \u001b[0m | \u001b[0m 0.06952 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 19.78   \u001b[0m | \u001b[0m 0.1095  \u001b[0m | \u001b[0m 0.5652  \u001b[0m | \u001b[0m 0.3156  \u001b[0m | \u001b[0m 0.12    \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 18.64   \u001b[0m | \u001b[0m 0.2044  \u001b[0m | \u001b[0m 0.3939  \u001b[0m | \u001b[0m 0.2248  \u001b[0m | \u001b[0m 0.05009 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 21.08   \u001b[0m | \u001b[0m 0.1054  \u001b[0m | \u001b[0m 0.4674  \u001b[0m | \u001b[0m 0.2496  \u001b[0m | \u001b[0m 0.1165  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 12.98   \u001b[0m | \u001b[0m 0.714   \u001b[0m | \u001b[0m 0.1658  \u001b[0m | \u001b[0m 0.4909  \u001b[0m | \u001b[0m 0.05861 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 19.84   \u001b[0m | \u001b[0m 0.4284  \u001b[0m | \u001b[0m 0.9272  \u001b[0m | \u001b[0m 0.8528  \u001b[0m | \u001b[0m 0.1892  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 12.38   \u001b[0m | \u001b[0m 0.5806  \u001b[0m | \u001b[0m 0.5017  \u001b[0m | \u001b[0m 0.9216  \u001b[0m | \u001b[0m 0.01578 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 17.73   \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.4669  \u001b[0m | \u001b[0m 0.2486  \u001b[0m | \u001b[0m 0.1914  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 18.5    \u001b[0m | \u001b[0m 0.2457  \u001b[0m | \u001b[0m 0.8261  \u001b[0m | \u001b[0m 0.9682  \u001b[0m | \u001b[0m 0.1611  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 13.33   \u001b[0m | \u001b[0m 0.6482  \u001b[0m | \u001b[0m 0.1696  \u001b[0m | \u001b[0m 0.4731  \u001b[0m | \u001b[0m 0.07307 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 19.63   \u001b[0m | \u001b[0m 0.6712  \u001b[0m | \u001b[0m 0.7352  \u001b[0m | \u001b[0m 0.5985  \u001b[0m | \u001b[0m 0.1058  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 18.46   \u001b[0m | \u001b[0m 0.1411  \u001b[0m | \u001b[0m 0.4799  \u001b[0m | \u001b[0m 0.269   \u001b[0m | \u001b[0m 0.1662  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 20.16   \u001b[0m | \u001b[0m 0.1284  \u001b[0m | \u001b[0m 0.5016  \u001b[0m | \u001b[0m 0.297   \u001b[0m | \u001b[0m 0.1303  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 20.49   \u001b[0m | \u001b[0m 0.09303 \u001b[0m | \u001b[0m 0.4758  \u001b[0m | \u001b[0m 0.2898  \u001b[0m | \u001b[0m 0.06057 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 20.09   \u001b[0m | \u001b[0m 0.09576 \u001b[0m | \u001b[0m 0.5073  \u001b[0m | \u001b[0m 0.2917  \u001b[0m | \u001b[0m 0.1724  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 18.71   \u001b[0m | \u001b[0m 0.7216  \u001b[0m | \u001b[0m 0.4086  \u001b[0m | \u001b[0m 0.3946  \u001b[0m | \u001b[0m 0.1563  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 20.9    \u001b[0m | \u001b[0m 0.4611  \u001b[0m | \u001b[0m 0.5763  \u001b[0m | \u001b[0m 0.8088  \u001b[0m | \u001b[0m 0.14    \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 7.728   \u001b[0m | \u001b[0m 0.9964  \u001b[0m | \u001b[0m 0.3042  \u001b[0m | \u001b[0m 0.002419\u001b[0m | \u001b[0m 0.01403 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 21.39   \u001b[0m | \u001b[0m 0.05061 \u001b[0m | \u001b[0m 0.5546  \u001b[0m | \u001b[0m 0.3302  \u001b[0m | \u001b[0m 0.08841 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 20.15   \u001b[0m | \u001b[0m 0.6762  \u001b[0m | \u001b[0m 0.7281  \u001b[0m | \u001b[0m 0.5325  \u001b[0m | \u001b[0m 0.1435  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 18.95   \u001b[0m | \u001b[0m 0.111   \u001b[0m | \u001b[0m 0.4098  \u001b[0m | \u001b[0m 0.186   \u001b[0m | \u001b[0m 0.1142  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 21.11   \u001b[0m | \u001b[0m 0.2039  \u001b[0m | \u001b[0m 0.4727  \u001b[0m | \u001b[0m 0.3379  \u001b[0m | \u001b[0m 0.1342  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 19.82   \u001b[0m | \u001b[0m 0.2614  \u001b[0m | \u001b[0m 0.4857  \u001b[0m | \u001b[0m 0.3377  \u001b[0m | \u001b[0m 0.09748 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 19.78   \u001b[0m | \u001b[0m 0.1593  \u001b[0m | \u001b[0m 0.3514  \u001b[0m | \u001b[0m 0.1932  \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 19.84   \u001b[0m | \u001b[0m 0.6389  \u001b[0m | \u001b[0m 0.6817  \u001b[0m | \u001b[0m 0.5931  \u001b[0m | \u001b[0m 0.1566  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 10.83   \u001b[0m | \u001b[0m 0.09679 \u001b[0m | \u001b[0m 0.1847  \u001b[0m | \u001b[0m 0.4956  \u001b[0m | \u001b[0m 0.1485  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 13.02   \u001b[0m | \u001b[0m 0.5988  \u001b[0m | \u001b[0m 0.1239  \u001b[0m | \u001b[0m 0.6463  \u001b[0m | \u001b[0m 0.08235 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 19.11   \u001b[0m | \u001b[0m 0.5549  \u001b[0m | \u001b[0m 0.6872  \u001b[0m | \u001b[0m 0.7479  \u001b[0m | \u001b[0m 0.1313  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 18.39   \u001b[0m | \u001b[0m 0.0131  \u001b[0m | \u001b[0m 0.5944  \u001b[0m | \u001b[0m 0.2546  \u001b[0m | \u001b[0m 0.1662  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000977 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 19.75   \u001b[0m | \u001b[0m 0.5046  \u001b[0m | \u001b[0m 0.6166  \u001b[0m | \u001b[0m 0.7759  \u001b[0m | \u001b[0m 0.1765  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 20.68   \u001b[0m | \u001b[0m 0.2059  \u001b[0m | \u001b[0m 0.4279  \u001b[0m | \u001b[0m 0.3226  \u001b[0m | \u001b[0m 0.083   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 18.37   \u001b[0m | \u001b[0m 0.6759  \u001b[0m | \u001b[0m 0.7558  \u001b[0m | \u001b[0m 0.5929  \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 21.11   \u001b[0m | \u001b[0m 0.1753  \u001b[0m | \u001b[0m 0.5333  \u001b[0m | \u001b[0m 0.3906  \u001b[0m | \u001b[0m 0.08239 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 17.88   \u001b[0m | \u001b[0m 0.1615  \u001b[0m | \u001b[0m 0.513   \u001b[0m | \u001b[0m 0.3491  \u001b[0m | \u001b[0m 0.1825  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 3.562   \u001b[0m | \u001b[0m 0.6259  \u001b[0m | \u001b[0m 0.5642  \u001b[0m | \u001b[0m 0.3174  \u001b[0m | \u001b[0m 0.001888\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 17.44   \u001b[0m | \u001b[0m 0.4065  \u001b[0m | \u001b[0m 0.6012  \u001b[0m | \u001b[0m 0.809   \u001b[0m | \u001b[0m 0.1833  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 20.16   \u001b[0m | \u001b[0m 0.1967  \u001b[0m | \u001b[0m 0.4621  \u001b[0m | \u001b[0m 0.3958  \u001b[0m | \u001b[0m 0.08132 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000999 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 19.04   \u001b[0m | \u001b[0m 0.1414  \u001b[0m | \u001b[0m 0.4239  \u001b[0m | \u001b[0m 0.2124  \u001b[0m | \u001b[0m 0.1932  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001006 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 18.15   \u001b[0m | \u001b[0m 0.1658  \u001b[0m | \u001b[0m 0.3623  \u001b[0m | \u001b[0m 0.2495  \u001b[0m | \u001b[0m 0.1455  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 21.27   \u001b[0m | \u001b[0m 0.1074  \u001b[0m | \u001b[0m 0.5435  \u001b[0m | \u001b[0m 0.3488  \u001b[0m | \u001b[0m 0.06887 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 19.66   \u001b[0m | \u001b[0m 0.4916  \u001b[0m | \u001b[0m 0.5322  \u001b[0m | \u001b[0m 0.7602  \u001b[0m | \u001b[0m 0.1334  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 21.64   \u001b[0m | \u001b[0m 0.1788  \u001b[0m | \u001b[0m 0.6034  \u001b[0m | \u001b[0m 0.3893  \u001b[0m | \u001b[0m 0.05785 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[95m 74      \u001b[0m | \u001b[95m 22.56   \u001b[0m | \u001b[95m 0.2202  \u001b[0m | \u001b[95m 0.5904  \u001b[0m | \u001b[95m 0.4423  \u001b[0m | \u001b[95m 0.07296 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 21.71   \u001b[0m | \u001b[0m 0.1697  \u001b[0m | \u001b[0m 0.5988  \u001b[0m | \u001b[0m 0.454   \u001b[0m | \u001b[0m 0.08028 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 21.48   \u001b[0m | \u001b[0m 0.2136  \u001b[0m | \u001b[0m 0.6122  \u001b[0m | \u001b[0m 0.4161  \u001b[0m | \u001b[0m 0.1119  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 18.83   \u001b[0m | \u001b[0m 0.2644  \u001b[0m | \u001b[0m 0.5891  \u001b[0m | \u001b[0m 0.3968  \u001b[0m | \u001b[0m 0.02872 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 3.787   \u001b[0m | \u001b[0m 0.526   \u001b[0m | \u001b[0m 0.1706  \u001b[0m | \u001b[0m 0.9676  \u001b[0m | \u001b[0m 0.007241\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 21.81   \u001b[0m | \u001b[0m 0.209   \u001b[0m | \u001b[0m 0.5281  \u001b[0m | \u001b[0m 0.4541  \u001b[0m | \u001b[0m 0.08847 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 22.27   \u001b[0m | \u001b[0m 0.2365  \u001b[0m | \u001b[0m 0.5838  \u001b[0m | \u001b[0m 0.4959  \u001b[0m | \u001b[0m 0.1063  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 20.62   \u001b[0m | \u001b[0m 0.22    \u001b[0m | \u001b[0m 0.5687  \u001b[0m | \u001b[0m 0.504   \u001b[0m | \u001b[0m 0.04714 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 20.6    \u001b[0m | \u001b[0m 0.2628  \u001b[0m | \u001b[0m 0.5577  \u001b[0m | \u001b[0m 0.452   \u001b[0m | \u001b[0m 0.1197  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 18.57   \u001b[0m | \u001b[0m 0.0166  \u001b[0m | \u001b[0m 0.7353  \u001b[0m | \u001b[0m 0.3398  \u001b[0m | \u001b[0m 0.1378  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 20.13   \u001b[0m | \u001b[0m 0.08105 \u001b[0m | \u001b[0m 0.9559  \u001b[0m | \u001b[0m 0.6556  \u001b[0m | \u001b[0m 0.1114  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 6.606   \u001b[0m | \u001b[0m 0.7103  \u001b[0m | \u001b[0m 0.9636  \u001b[0m | \u001b[0m 0.7645  \u001b[0m | \u001b[0m 0.006558\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 20.67   \u001b[0m | \u001b[0m 0.23    \u001b[0m | \u001b[0m 0.6527  \u001b[0m | \u001b[0m 0.4832  \u001b[0m | \u001b[0m 0.08886 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 8.953   \u001b[0m | \u001b[0m 0.6045  \u001b[0m | \u001b[0m 0.1882  \u001b[0m | \u001b[0m 0.09672 \u001b[0m | \u001b[0m 0.0325  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 20.32   \u001b[0m | \u001b[0m 0.1999  \u001b[0m | \u001b[0m 0.609   \u001b[0m | \u001b[0m 0.5279  \u001b[0m | \u001b[0m 0.1511  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 19.71   \u001b[0m | \u001b[0m 0.2202  \u001b[0m | \u001b[0m 0.511   \u001b[0m | \u001b[0m 0.5388  \u001b[0m | \u001b[0m 0.1315  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 13.65   \u001b[0m | \u001b[0m 0.4848  \u001b[0m | \u001b[0m 0.8168  \u001b[0m | \u001b[0m 0.5355  \u001b[0m | \u001b[0m 0.01677 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 19.34   \u001b[0m | \u001b[0m 0.2727  \u001b[0m | \u001b[0m 0.7108  \u001b[0m | \u001b[0m 0.003525\u001b[0m | \u001b[0m 0.1155  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 11.5    \u001b[0m | \u001b[0m 0.4914  \u001b[0m | \u001b[0m 0.01502 \u001b[0m | \u001b[0m 0.4718  \u001b[0m | \u001b[0m 0.1042  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 21.38   \u001b[0m | \u001b[0m 0.1384  \u001b[0m | \u001b[0m 0.6885  \u001b[0m | \u001b[0m 0.4061  \u001b[0m | \u001b[0m 0.08862 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 17.38   \u001b[0m | \u001b[0m 0.3277  \u001b[0m | \u001b[0m 0.4216  \u001b[0m | \u001b[0m 0.8064  \u001b[0m | \u001b[0m 0.04216 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001006 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 9.149   \u001b[0m | \u001b[0m 0.1534  \u001b[0m | \u001b[0m 0.6801  \u001b[0m | \u001b[0m 0.4353  \u001b[0m | \u001b[0m 0.01029 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 19.61   \u001b[0m | \u001b[0m 0.137   \u001b[0m | \u001b[0m 0.6729  \u001b[0m | \u001b[0m 0.3947  \u001b[0m | \u001b[0m 0.1369  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 21.56   \u001b[0m | \u001b[0m 0.2957  \u001b[0m | \u001b[0m 0.6138  \u001b[0m | \u001b[0m 0.548   \u001b[0m | \u001b[0m 0.1116  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 18.42   \u001b[0m | \u001b[0m 0.3022  \u001b[0m | \u001b[0m 0.6593  \u001b[0m | \u001b[0m 0.5038  \u001b[0m | \u001b[0m 0.1677  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001128 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 21.15   \u001b[0m | \u001b[0m 0.2504  \u001b[0m | \u001b[0m 0.6348  \u001b[0m | \u001b[0m 0.624   \u001b[0m | \u001b[0m 0.1052  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 11.23   \u001b[0m | \u001b[0m 0.4622  \u001b[0m | \u001b[0m 0.1272  \u001b[0m | \u001b[0m 0.05099 \u001b[0m | \u001b[0m 0.1249  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 19.54   \u001b[0m | \u001b[0m 0.2937  \u001b[0m | \u001b[0m 0.5797  \u001b[0m | \u001b[0m 0.6261  \u001b[0m | \u001b[0m 0.1211  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 21.54   \u001b[0m | \u001b[0m 0.2417  \u001b[0m | \u001b[0m 0.6105  \u001b[0m | \u001b[0m 0.5605  \u001b[0m | \u001b[0m 0.08928 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m 20.74   \u001b[0m | \u001b[0m 0.3068  \u001b[0m | \u001b[0m 0.6933  \u001b[0m | \u001b[0m 0.592   \u001b[0m | \u001b[0m 0.06962 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m 18.86   \u001b[0m | \u001b[0m 0.3063  \u001b[0m | \u001b[0m 0.6211  \u001b[0m | \u001b[0m 0.5969  \u001b[0m | \u001b[0m 0.02863 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m 21.24   \u001b[0m | \u001b[0m 0.2358  \u001b[0m | \u001b[0m 0.7383  \u001b[0m | \u001b[0m 0.6664  \u001b[0m | \u001b[0m 0.1141  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m 10.07   \u001b[0m | \u001b[0m 0.5043  \u001b[0m | \u001b[0m 0.0276  \u001b[0m | \u001b[0m 0.1813  \u001b[0m | \u001b[0m 0.1325  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 107     \u001b[0m | \u001b[0m 11.74   \u001b[0m | \u001b[0m 0.7923  \u001b[0m | \u001b[0m 0.1407  \u001b[0m | \u001b[0m 0.3045  \u001b[0m | \u001b[0m 0.1118  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 108     \u001b[0m | \u001b[0m 16.95   \u001b[0m | \u001b[0m 0.2399  \u001b[0m | \u001b[0m 0.7241  \u001b[0m | \u001b[0m 0.5983  \u001b[0m | \u001b[0m 0.1816  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 109     \u001b[0m | \u001b[0m 20.89   \u001b[0m | \u001b[0m 0.2385  \u001b[0m | \u001b[0m 0.7023  \u001b[0m | \u001b[0m 0.6804  \u001b[0m | \u001b[0m 0.0498  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 110     \u001b[0m | \u001b[0m 21.09   \u001b[0m | \u001b[0m 0.2401  \u001b[0m | \u001b[0m 0.7105  \u001b[0m | \u001b[0m 0.6894  \u001b[0m | \u001b[0m 0.06229 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 111     \u001b[0m | \u001b[0m 17.89   \u001b[0m | \u001b[0m 0.2938  \u001b[0m | \u001b[0m 0.202   \u001b[0m | \u001b[0m 0.9912  \u001b[0m | \u001b[0m 0.1356  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 112     \u001b[0m | \u001b[0m 20.27   \u001b[0m | \u001b[0m 0.2107  \u001b[0m | \u001b[0m 0.8372  \u001b[0m | \u001b[0m 0.7168  \u001b[0m | \u001b[0m 0.071   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 113     \u001b[0m | \u001b[0m 19.01   \u001b[0m | \u001b[0m 0.1609  \u001b[0m | \u001b[0m 0.3553  \u001b[0m | \u001b[0m 0.1909  \u001b[0m | \u001b[0m 0.1941  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 114     \u001b[0m | \u001b[0m 18.29   \u001b[0m | \u001b[0m 0.09424 \u001b[0m | \u001b[0m 0.3651  \u001b[0m | \u001b[0m 0.2628  \u001b[0m | \u001b[0m 0.188   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 115     \u001b[0m | \u001b[0m 20.24   \u001b[0m | \u001b[0m 0.1563  \u001b[0m | \u001b[0m 0.7459  \u001b[0m | \u001b[0m 0.6948  \u001b[0m | \u001b[0m 0.08578 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 116     \u001b[0m | \u001b[0m 11.0    \u001b[0m | \u001b[0m 0.03096 \u001b[0m | \u001b[0m 0.2231  \u001b[0m | \u001b[0m 0.9176  \u001b[0m | \u001b[0m 0.02063 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 117     \u001b[0m | \u001b[0m 10.94   \u001b[0m | \u001b[0m 0.9646  \u001b[0m | \u001b[0m 0.1797  \u001b[0m | \u001b[0m 0.528   \u001b[0m | \u001b[0m 0.1421  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 118     \u001b[0m | \u001b[0m 19.96   \u001b[0m | \u001b[0m 0.2301  \u001b[0m | \u001b[0m 0.7658  \u001b[0m | \u001b[0m 0.7588  \u001b[0m | \u001b[0m 0.1349  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 119     \u001b[0m | \u001b[0m 18.84   \u001b[0m | \u001b[0m 0.1336  \u001b[0m | \u001b[0m 0.8651  \u001b[0m | \u001b[0m 0.6985  \u001b[0m | \u001b[0m 0.1471  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 120     \u001b[0m | \u001b[0m 19.14   \u001b[0m | \u001b[0m 0.7352  \u001b[0m | \u001b[0m 0.8204  \u001b[0m | \u001b[0m 0.49    \u001b[0m | \u001b[0m 0.09351 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 121     \u001b[0m | \u001b[0m 21.72   \u001b[0m | \u001b[0m 0.2675  \u001b[0m | \u001b[0m 0.8071  \u001b[0m | \u001b[0m 0.6419  \u001b[0m | \u001b[0m 0.04789 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 122     \u001b[0m | \u001b[0m 19.46   \u001b[0m | \u001b[0m 0.2958  \u001b[0m | \u001b[0m 0.779   \u001b[0m | \u001b[0m 0.6852  \u001b[0m | \u001b[0m 0.0839  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 123     \u001b[0m | \u001b[0m 11.39   \u001b[0m | \u001b[0m 0.5256  \u001b[0m | \u001b[0m 0.02072 \u001b[0m | \u001b[0m 0.9678  \u001b[0m | \u001b[0m 0.1078  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 124     \u001b[0m | \u001b[0m 21.07   \u001b[0m | \u001b[0m 0.871   \u001b[0m | \u001b[0m 0.8704  \u001b[0m | \u001b[0m 0.633   \u001b[0m | \u001b[0m 0.0574  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 125     \u001b[0m | \u001b[0m 20.41   \u001b[0m | \u001b[0m 0.2138  \u001b[0m | \u001b[0m 0.7759  \u001b[0m | \u001b[0m 0.634   \u001b[0m | \u001b[0m 0.05182 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 126     \u001b[0m | \u001b[0m 20.45   \u001b[0m | \u001b[0m 0.2453  \u001b[0m | \u001b[0m 0.8886  \u001b[0m | \u001b[0m 0.625   \u001b[0m | \u001b[0m 0.04822 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 127     \u001b[0m | \u001b[0m 19.11   \u001b[0m | \u001b[0m 0.8716  \u001b[0m | \u001b[0m 0.8428  \u001b[0m | \u001b[0m 0.5592  \u001b[0m | \u001b[0m 0.08996 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 128     \u001b[0m | \u001b[0m 20.5    \u001b[0m | \u001b[0m 0.9573  \u001b[0m | \u001b[0m 0.8916  \u001b[0m | \u001b[0m 0.6351  \u001b[0m | \u001b[0m 0.06626 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 129     \u001b[0m | \u001b[0m 19.59   \u001b[0m | \u001b[0m 0.193   \u001b[0m | \u001b[0m 0.654   \u001b[0m | \u001b[0m 0.7132  \u001b[0m | \u001b[0m 0.1205  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 130     \u001b[0m | \u001b[0m 19.39   \u001b[0m | \u001b[0m 0.6127  \u001b[0m | \u001b[0m 0.3954  \u001b[0m | \u001b[0m 0.5536  \u001b[0m | \u001b[0m 0.1306  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 131     \u001b[0m | \u001b[0m 6.786   \u001b[0m | \u001b[0m 0.905   \u001b[0m | \u001b[0m 0.9213  \u001b[0m | \u001b[0m 0.5847  \u001b[0m | \u001b[0m 0.006871\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 132     \u001b[0m | \u001b[0m 4.949   \u001b[0m | \u001b[0m 0.5706  \u001b[0m | \u001b[0m 0.1286  \u001b[0m | \u001b[0m 0.1579  \u001b[0m | \u001b[0m 0.01405 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 133     \u001b[0m | \u001b[0m 19.37   \u001b[0m | \u001b[0m 0.9057  \u001b[0m | \u001b[0m 0.848   \u001b[0m | \u001b[0m 0.6591  \u001b[0m | \u001b[0m 0.1038  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 134     \u001b[0m | \u001b[0m 19.39   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.9102  \u001b[0m | \u001b[0m 0.6485  \u001b[0m | \u001b[0m 0.1304  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 135     \u001b[0m | \u001b[0m 21.01   \u001b[0m | \u001b[0m 0.1973  \u001b[0m | \u001b[0m 0.5647  \u001b[0m | \u001b[0m 0.4499  \u001b[0m | \u001b[0m 0.09684 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 136     \u001b[0m | \u001b[0m 20.4    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.8451  \u001b[0m | \u001b[0m 0.6878  \u001b[0m | \u001b[0m 0.0456  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 137     \u001b[0m | \u001b[0m 20.09   \u001b[0m | \u001b[0m 0.139   \u001b[0m | \u001b[0m 0.4684  \u001b[0m | \u001b[0m 0.2378  \u001b[0m | \u001b[0m 0.06556 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 138     \u001b[0m | \u001b[0m 11.84   \u001b[0m | \u001b[0m 0.1378  \u001b[0m | \u001b[0m 0.92    \u001b[0m | \u001b[0m 0.6703  \u001b[0m | \u001b[0m 0.01351 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 139     \u001b[0m | \u001b[0m 20.09   \u001b[0m | \u001b[0m 0.2557  \u001b[0m | \u001b[0m 0.846   \u001b[0m | \u001b[0m 0.6321  \u001b[0m | \u001b[0m 0.109   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 140     \u001b[0m | \u001b[0m 6.346   \u001b[0m | \u001b[0m 0.8839  \u001b[0m | \u001b[0m 0.1774  \u001b[0m | \u001b[0m 0.3773  \u001b[0m | \u001b[0m 0.02094 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 141     \u001b[0m | \u001b[0m 8.411   \u001b[0m | \u001b[0m 0.4295  \u001b[0m | \u001b[0m 0.01137 \u001b[0m | \u001b[0m 0.8921  \u001b[0m | \u001b[0m 0.1735  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 142     \u001b[0m | \u001b[0m 18.44   \u001b[0m | \u001b[0m 0.08172 \u001b[0m | \u001b[0m 0.9801  \u001b[0m | \u001b[0m 0.6327  \u001b[0m | \u001b[0m 0.1978  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 143     \u001b[0m | \u001b[0m 20.85   \u001b[0m | \u001b[0m 0.268   \u001b[0m | \u001b[0m 0.4858  \u001b[0m | \u001b[0m 0.4573  \u001b[0m | \u001b[0m 0.06622 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 144     \u001b[0m | \u001b[0m 19.58   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.8216  \u001b[0m | \u001b[0m 0.6029  \u001b[0m | \u001b[0m 0.09038 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 145     \u001b[0m | \u001b[0m 20.47   \u001b[0m | \u001b[0m 0.01584 \u001b[0m | \u001b[0m 0.4495  \u001b[0m | \u001b[0m 0.3013  \u001b[0m | \u001b[0m 0.07685 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 146     \u001b[0m | \u001b[0m 8.764   \u001b[0m | \u001b[0m 0.9467  \u001b[0m | \u001b[0m 0.06606 \u001b[0m | \u001b[0m 0.8298  \u001b[0m | \u001b[0m 0.04749 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 147     \u001b[0m | \u001b[0m 20.74   \u001b[0m | \u001b[0m 0.8324  \u001b[0m | \u001b[0m 0.8348  \u001b[0m | \u001b[0m 0.6382  \u001b[0m | \u001b[0m 0.07438 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 148     \u001b[0m | \u001b[0m 21.75   \u001b[0m | \u001b[0m 0.5959  \u001b[0m | \u001b[0m 0.662   \u001b[0m | \u001b[0m 0.3318  \u001b[0m | \u001b[0m 0.07827 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 149     \u001b[0m | \u001b[0m 19.46   \u001b[0m | \u001b[0m 0.5851  \u001b[0m | \u001b[0m 0.7041  \u001b[0m | \u001b[0m 0.3354  \u001b[0m | \u001b[0m 0.1135  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 150     \u001b[0m | \u001b[0m 16.42   \u001b[0m | \u001b[0m 0.2948  \u001b[0m | \u001b[0m 0.8376  \u001b[0m | \u001b[0m 0.5712  \u001b[0m | \u001b[0m 0.02148 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 151     \u001b[0m | \u001b[0m 9.502   \u001b[0m | \u001b[0m 0.3691  \u001b[0m | \u001b[0m 0.2728  \u001b[0m | \u001b[0m 0.9466  \u001b[0m | \u001b[0m 0.01835 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 152     \u001b[0m | \u001b[0m 13.26   \u001b[0m | \u001b[0m 0.9558  \u001b[0m | \u001b[0m 0.1733  \u001b[0m | \u001b[0m 0.4658  \u001b[0m | \u001b[0m 0.06365 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 153     \u001b[0m | \u001b[0m 18.69   \u001b[0m | \u001b[0m 0.08039 \u001b[0m | \u001b[0m 0.6923  \u001b[0m | \u001b[0m 0.8273  \u001b[0m | \u001b[0m 0.1149  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 154     \u001b[0m | \u001b[0m 21.03   \u001b[0m | \u001b[0m 0.5311  \u001b[0m | \u001b[0m 0.6559  \u001b[0m | \u001b[0m 0.3557  \u001b[0m | \u001b[0m 0.08556 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 155     \u001b[0m | \u001b[0m 19.89   \u001b[0m | \u001b[0m 0.5891  \u001b[0m | \u001b[0m 0.6368  \u001b[0m | \u001b[0m 0.3792  \u001b[0m | \u001b[0m 0.1278  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[95m 156     \u001b[0m | \u001b[95m 23.35   \u001b[0m | \u001b[95m 0.279   \u001b[0m | \u001b[95m 0.59    \u001b[0m | \u001b[95m 0.4913  \u001b[0m | \u001b[95m 0.07728 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 157     \u001b[0m | \u001b[0m 21.76   \u001b[0m | \u001b[0m 0.3607  \u001b[0m | \u001b[0m 0.6075  \u001b[0m | \u001b[0m 0.4449  \u001b[0m | \u001b[0m 0.07069 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 158     \u001b[0m | \u001b[0m 19.81   \u001b[0m | \u001b[0m 0.1705  \u001b[0m | \u001b[0m 0.8167  \u001b[0m | \u001b[0m 0.484   \u001b[0m | \u001b[0m 0.0336  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 159     \u001b[0m | \u001b[0m 4.04    \u001b[0m | \u001b[0m 0.02083 \u001b[0m | \u001b[0m 0.04295 \u001b[0m | \u001b[0m 0.8309  \u001b[0m | \u001b[0m 0.0134  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 160     \u001b[0m | \u001b[0m 21.47   \u001b[0m | \u001b[0m 0.3356  \u001b[0m | \u001b[0m 0.5608  \u001b[0m | \u001b[0m 0.4997  \u001b[0m | \u001b[0m 0.07289 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 161     \u001b[0m | \u001b[0m 18.13   \u001b[0m | \u001b[0m 0.1087  \u001b[0m | \u001b[0m 0.7856  \u001b[0m | \u001b[0m 0.4172  \u001b[0m | \u001b[0m 0.1256  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 162     \u001b[0m | \u001b[0m 20.38   \u001b[0m | \u001b[0m 0.4347  \u001b[0m | \u001b[0m 0.6172  \u001b[0m | \u001b[0m 0.4058  \u001b[0m | \u001b[0m 0.1135  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 163     \u001b[0m | \u001b[0m 19.35   \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.9575  \u001b[0m | \u001b[0m 0.7178  \u001b[0m | \u001b[0m 0.1433  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 164     \u001b[0m | \u001b[0m 21.11   \u001b[0m | \u001b[0m 0.326   \u001b[0m | \u001b[0m 0.624   \u001b[0m | \u001b[0m 0.4804  \u001b[0m | \u001b[0m 0.09709 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 165     \u001b[0m | \u001b[0m 19.19   \u001b[0m | \u001b[0m 0.1633  \u001b[0m | \u001b[0m 0.8963  \u001b[0m | \u001b[0m 0.5088  \u001b[0m | \u001b[0m 0.1054  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 166     \u001b[0m | \u001b[0m 11.56   \u001b[0m | \u001b[0m 0.2872  \u001b[0m | \u001b[0m 0.1142  \u001b[0m | \u001b[0m 0.8925  \u001b[0m | \u001b[0m 0.104   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 167     \u001b[0m | \u001b[0m 19.16   \u001b[0m | \u001b[0m 0.626   \u001b[0m | \u001b[0m 0.6428  \u001b[0m | \u001b[0m 0.7452  \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 168     \u001b[0m | \u001b[0m 21.85   \u001b[0m | \u001b[0m 0.1753  \u001b[0m | \u001b[0m 0.5994  \u001b[0m | \u001b[0m 0.3893  \u001b[0m | \u001b[0m 0.05392 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 169     \u001b[0m | \u001b[0m 18.91   \u001b[0m | \u001b[0m 0.2957  \u001b[0m | \u001b[0m 0.9233  \u001b[0m | \u001b[0m 0.8038  \u001b[0m | \u001b[0m 0.1608  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 170     \u001b[0m | \u001b[0m 19.37   \u001b[0m | \u001b[0m 0.4355  \u001b[0m | \u001b[0m 0.5901  \u001b[0m | \u001b[0m 0.4401  \u001b[0m | \u001b[0m 0.03376 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 171     \u001b[0m | \u001b[0m 19.0    \u001b[0m | \u001b[0m 0.1367  \u001b[0m | \u001b[0m 0.2365  \u001b[0m | \u001b[0m 0.2012  \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 172     \u001b[0m | \u001b[0m 18.11   \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.9113  \u001b[0m | \u001b[0m 0.5904  \u001b[0m | \u001b[0m 0.1265  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 173     \u001b[0m | \u001b[0m 19.27   \u001b[0m | \u001b[0m 0.4951  \u001b[0m | \u001b[0m 0.6457  \u001b[0m | \u001b[0m 0.257   \u001b[0m | \u001b[0m 0.1325  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 174     \u001b[0m | \u001b[0m 18.07   \u001b[0m | \u001b[0m 0.5305  \u001b[0m | \u001b[0m 0.7207  \u001b[0m | \u001b[0m 0.2931  \u001b[0m | \u001b[0m 0.02837 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 175     \u001b[0m | \u001b[0m 14.3    \u001b[0m | \u001b[0m 0.2007  \u001b[0m | \u001b[0m 0.7383  \u001b[0m | \u001b[0m 0.8077  \u001b[0m | \u001b[0m 0.01875 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 176     \u001b[0m | \u001b[0m 18.19   \u001b[0m | \u001b[0m 0.1957  \u001b[0m | \u001b[0m 0.5287  \u001b[0m | \u001b[0m 0.4235  \u001b[0m | \u001b[0m 0.02792 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 177     \u001b[0m | \u001b[0m 19.69   \u001b[0m | \u001b[0m 0.2635  \u001b[0m | \u001b[0m 0.404   \u001b[0m | \u001b[0m 0.3976  \u001b[0m | \u001b[0m 0.1615  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 178     \u001b[0m | \u001b[0m 20.94   \u001b[0m | \u001b[0m 0.3962  \u001b[0m | \u001b[0m 0.5117  \u001b[0m | \u001b[0m 0.3972  \u001b[0m | \u001b[0m 0.1128  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 179     \u001b[0m | \u001b[0m 18.23   \u001b[0m | \u001b[0m 0.4384  \u001b[0m | \u001b[0m 0.5193  \u001b[0m | \u001b[0m 0.4824  \u001b[0m | \u001b[0m 0.1574  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 180     \u001b[0m | \u001b[0m 20.99   \u001b[0m | \u001b[0m 0.3749  \u001b[0m | \u001b[0m 0.5903  \u001b[0m | \u001b[0m 0.3395  \u001b[0m | \u001b[0m 0.09808 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 181     \u001b[0m | \u001b[0m 17.62   \u001b[0m | \u001b[0m 0.4055  \u001b[0m | \u001b[0m 0.5721  \u001b[0m | \u001b[0m 0.361   \u001b[0m | \u001b[0m 0.1895  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 182     \u001b[0m | \u001b[0m 19.58   \u001b[0m | \u001b[0m 0.3726  \u001b[0m | \u001b[0m 0.5373  \u001b[0m | \u001b[0m 0.3646  \u001b[0m | \u001b[0m 0.03468 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 183     \u001b[0m | \u001b[0m 20.66   \u001b[0m | \u001b[0m 0.3822  \u001b[0m | \u001b[0m 0.7001  \u001b[0m | \u001b[0m 0.3596  \u001b[0m | \u001b[0m 0.04405 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 184     \u001b[0m | \u001b[0m 19.8    \u001b[0m | \u001b[0m 0.4681  \u001b[0m | \u001b[0m 0.6729  \u001b[0m | \u001b[0m 0.2602  \u001b[0m | \u001b[0m 0.09921 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 185     \u001b[0m | \u001b[0m 13.15   \u001b[0m | \u001b[0m 0.5257  \u001b[0m | \u001b[0m 0.1725  \u001b[0m | \u001b[0m 0.3433  \u001b[0m | \u001b[0m 0.07632 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 186     \u001b[0m | \u001b[0m 19.27   \u001b[0m | \u001b[0m 0.3447  \u001b[0m | \u001b[0m 0.6972  \u001b[0m | \u001b[0m 0.3178  \u001b[0m | \u001b[0m 0.1262  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 187     \u001b[0m | \u001b[0m 17.55   \u001b[0m | \u001b[0m 0.3581  \u001b[0m | \u001b[0m 0.9676  \u001b[0m | \u001b[0m 0.9519  \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 188     \u001b[0m | \u001b[0m 15.28   \u001b[0m | \u001b[0m 0.3949  \u001b[0m | \u001b[0m 0.2215  \u001b[0m | \u001b[0m 0.2879  \u001b[0m | \u001b[0m 0.07044 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 189     \u001b[0m | \u001b[0m 20.67   \u001b[0m | \u001b[0m 0.5538  \u001b[0m | \u001b[0m 0.665   \u001b[0m | \u001b[0m 0.08742 \u001b[0m | \u001b[0m 0.1633  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 190     \u001b[0m | \u001b[0m 19.54   \u001b[0m | \u001b[0m 0.4437  \u001b[0m | \u001b[0m 0.687   \u001b[0m | \u001b[0m 0.08068 \u001b[0m | \u001b[0m 0.1403  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 191     \u001b[0m | \u001b[0m 16.84   \u001b[0m | \u001b[0m 0.5376  \u001b[0m | \u001b[0m 0.7161  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 192     \u001b[0m | \u001b[0m 20.42   \u001b[0m | \u001b[0m 0.5516  \u001b[0m | \u001b[0m 0.7185  \u001b[0m | \u001b[0m 0.1376  \u001b[0m | \u001b[0m 0.09831 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 193     \u001b[0m | \u001b[0m 22.26   \u001b[0m | \u001b[0m 0.5263  \u001b[0m | \u001b[0m 0.6252  \u001b[0m | \u001b[0m 0.08482 \u001b[0m | \u001b[0m 0.07447 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 194     \u001b[0m | \u001b[0m 19.53   \u001b[0m | \u001b[0m 0.2606  \u001b[0m | \u001b[0m 0.9588  \u001b[0m | \u001b[0m 0.9343  \u001b[0m | \u001b[0m 0.142   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 195     \u001b[0m | \u001b[0m 21.72   \u001b[0m | \u001b[0m 0.5908  \u001b[0m | \u001b[0m 0.6528  \u001b[0m | \u001b[0m 0.05861 \u001b[0m | \u001b[0m 0.06838 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 196     \u001b[0m | \u001b[0m 9.052   \u001b[0m | \u001b[0m 0.7399  \u001b[0m | \u001b[0m 0.0377  \u001b[0m | \u001b[0m 0.1521  \u001b[0m | \u001b[0m 0.04953 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 197     \u001b[0m | \u001b[0m 19.39   \u001b[0m | \u001b[0m 0.5157  \u001b[0m | \u001b[0m 0.6815  \u001b[0m | \u001b[0m 0.05185 \u001b[0m | \u001b[0m 0.0345  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 198     \u001b[0m | \u001b[0m 21.4    \u001b[0m | \u001b[0m 0.5757  \u001b[0m | \u001b[0m 0.5815  \u001b[0m | \u001b[0m 0.07392 \u001b[0m | \u001b[0m 0.1108  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 199     \u001b[0m | \u001b[0m 19.38   \u001b[0m | \u001b[0m 0.5756  \u001b[0m | \u001b[0m 0.6333  \u001b[0m | \u001b[0m 0.1274  \u001b[0m | \u001b[0m 0.09413 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 200     \u001b[0m | \u001b[0m 21.34   \u001b[0m | \u001b[0m 0.5318  \u001b[0m | \u001b[0m 0.6008  \u001b[0m | \u001b[0m 0.01967 \u001b[0m | \u001b[0m 0.09275 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 201     \u001b[0m | \u001b[0m 19.07   \u001b[0m | \u001b[0m 0.3246  \u001b[0m | \u001b[0m 0.7933  \u001b[0m | \u001b[0m 0.06502 \u001b[0m | \u001b[0m 0.143   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "| \u001b[0m 202     \u001b[0m | \u001b[0m 19.94   \u001b[0m | \u001b[0m 0.4765  \u001b[0m | \u001b[0m 0.5687  \u001b[0m | \u001b[0m 0.08778 \u001b[0m | \u001b[0m 0.1153  \u001b[0m |\n",
      "=========================================================================\n",
      "{'target': 23.349635078003743, 'params': {'bagging_fraction': 0.27899374566613044, 'feature_fraction': 0.5899890925573251, 'lambda_l2': 0.49129300614732957, 'learning_rate': 0.07728432511779665}}\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize as optimize\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "params = {\"learning_rate\": (0.0001, 0.2),\n",
    "            \"feature_fraction\" : (0.0001, 1),\n",
    "            \"bagging_fraction\" : (0.0001, 1),\n",
    "            \"lambda_l2\" : (0 , 1)\n",
    "            }\n",
    "\n",
    "capacity = 1000\n",
    "train_max = 1\n",
    "train_min = 0\n",
    "\n",
    "bo=BayesianOptimization(f=LGB_cv, \n",
    "                    pbounds=params, \n",
    "                    verbose=2, \n",
    "                    random_state=250)\n",
    "\n",
    "\n",
    "bo.maximize(init_points=2, n_iter=200, acq='ei', xi=0.01)\n",
    "\n",
    "print(bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ef042e6be0>]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.349635078003743"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'bagging_fraction': 0.27899374566613044,\n",
    " 'feature_fraction': 0.5899890925573251,\n",
    " 'lambda_l2': 0.49129300614732957,\n",
    " 'learning_rate': 0.07728432511779665}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 988\n",
      "[LightGBM] [Info] Number of data points in the train set: 76336, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.517483\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's score: 0.0427425\n"
     ]
    }
   ],
   "source": [
    "capacity = 1000\n",
    "sun_radio_ulsan_model = lgb.train(params, \n",
    "                           train_dataset, \n",
    "                           10000, \n",
    "                           val_dataset, \n",
    "                           feval= nmae_10_lgb, \n",
    "                           verbose_eval=500, \n",
    "                           early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sun_radio_ulsan_model.pkl']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(sun_radio_model,\"sun_radio_ulsan_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sun_radio_model.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ef0d264cd0>]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(y_pred)\n",
    "plt.plot(val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 미세먼지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) train-test 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Forecast_time', 'Temperature', 'Humidity', 'WindSpeed', 'Cloud',\n",
       "       'Forecast time', 'PM10', 'date', 'hour', 'year', 'month', 'day',\n",
       "       'WindDirection_0', 'WindDirection_1', 'WindDirection_2',\n",
       "       'WindDirection_3', 'WindDirection_4', 'WindDirection_5',\n",
       "       'WindDirection_6', 'WindDirection_7', 'sun_dangjin', 'sun_ulsan',\n",
       "       'fall_prob_dangjin', 'fall_prob_ulsan', 'dangjin_type_0',\n",
       "       'dangjin_type_1', 'dangjin_type_2', 'dangjin_type_3', 'dangjin_type_4',\n",
       "       'ulsan_type_0', 'ulsan_type_1', 'ulsan_type_2', 'ulsan_type_3',\n",
       "       'ulsan_type_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_datast_dust(dust_df, fcst_df, target, sun_target, rain_target):\n",
    "    # 일기 예보 있는 날짜만 선택\n",
    "    \n",
    "    dust = dust_df.copy()\n",
    "    dust.index = range(dust.shape[0])\n",
    "    dust.columns = [\"Forecast time\",\"PM10\"]\n",
    "    dust[\"Forecast_time\"] = pd.to_datetime(dust[\"Forecast time\"]).astype(\"str\")\n",
    "\n",
    "    # 발전량 데이터가 있는 날짜만 선택\n",
    "    fcst = fcst_df.copy()\n",
    "    fcst.index = range(fcst.shape[0])\n",
    "    \n",
    "    # 발전량과 일기예보 연결\n",
    "    \n",
    "    concat_df = pd.merge(fcst, dust, on = \"Forecast_time\")\n",
    "    \n",
    "    start = '2015-03-02 00:00:00'\n",
    "    end = '2021-01-01 00:00:00'\n",
    "    \n",
    "    start_idx = concat_df[concat_df['Forecast_time']==start].index[0]\n",
    "    end_idx = concat_df[concat_df['Forecast_time']==end].index[0]\n",
    "    \n",
    "    concat_df = concat_df.loc[start_idx:end_idx, :].copy()\n",
    "    \n",
    "    # 예보 시간 및 날짜 정보 feature로 추가\n",
    "    concat_df['date'] = concat_df['Forecast_time'].str.split(' ').str[0]\n",
    "    concat_df['hour'] = concat_df['Forecast_time'].str.split(' ').str[1].str.split(':').str[0].astype(int)\n",
    "    \n",
    "    concat_df['year'] = concat_df['date'].str.split('-').str[0].astype(int)\n",
    "    concat_df['month'] = concat_df['date'].str.split('-').str[1].astype(int)\n",
    "    concat_df['day'] = concat_df['date'].str.split('-').str[2].astype(int)\n",
    "    \n",
    "    concat_df[\"WindDirection\"] = concat_df[\"WindDirection\"].apply(lambda x : direction_label(x)).astype(int)\n",
    "    \n",
    "    concat_df = pd.get_dummies(concat_df, prefix = \"WindDirection\", columns = [\"WindDirection\"])\n",
    "    \n",
    "    concat_df = pd.merge(concat_df, sun_result, how = \"left\")\n",
    "    \n",
    "    concat_df = pd.merge(concat_df, rain_14, how = \"left\")\n",
    "    \n",
    "    global feature_df\n",
    "    \n",
    "    # 예보 시간, 날짜, 기상 예보 및 발전량 선택\n",
    "    feature_df = concat_df[['year', \n",
    "                            'month', \n",
    "                            'day', \n",
    "                            'hour', \n",
    "                            'Temperature',\n",
    "                            'Humidity', \n",
    "                            'WindSpeed', \n",
    "                            'Cloud',\n",
    "                            '{}_type_0'.format(rain_target),\n",
    "                            '{}_type_1'.format(rain_target),\n",
    "                            '{}_type_2'.format(rain_target),\n",
    "                            '{}_type_3'.format(rain_target),\n",
    "                            '{}_type_4'.format(rain_target),\n",
    "                            'fall_prob_{}'.format(rain_target),\n",
    "                            sun_target,\n",
    "                            'PM10']].drop_duplicates()\n",
    "    \n",
    "    # 마지막 30일을 검증데이터셋으로 나머지를 학습 데이터셋으로 선택\n",
    "    \n",
    "    train_df = feature_df.iloc[:-24*30].dropna()\n",
    "    val_df = feature_df.iloc[-24*30 - 1 :].dropna()\n",
    "    \n",
    "    train_x = train_df.loc[:, 'year':str(sun_target)].to_numpy()\n",
    "    train_y = train_df[[\"year\",\"month\",\"day\",'PM10']].to_numpy()\n",
    "    \n",
    "    val_x = val_df.loc[:, 'year':str(sun_target)].to_numpy()\n",
    "    val_y = val_df[[\"year\",\"month\",\"day\",'PM10']].to_numpy()\n",
    "    \n",
    "    return train_x, train_y, val_x, val_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 당진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmae_10_lgb(y_pred, dataset):\n",
    "    y_true = dataset.get_label()\n",
    "    \n",
    "    mae = sklearn.metrics.mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    return 'score', mae, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, val_x, val_y = train_datast_dust(fine_dust_dangjin[[\"Forecast time\",\"PM10\"]], \n",
    "                                              dangjin_fcst, \n",
    "                                              target='dangjin', \n",
    "                                              sun_target = \"sun_dangjin\",\n",
    "                                             rain_target = \"dangjin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y[:,-1]\n",
    "val_y = val_y[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_x[:,0] = np.array(pd.Series(train_x[:,0]).astype(\"str\").apply(lambda x : x[2:4]).astype(\"int\"))\\nval_x[:,0] = np.array(pd.Series(val_x[:,0]).astype(\"str\").apply(lambda x : x[2:4]).astype(\"int\"))\\n\\ntrain_min_dangjin = -9\\ntrain_max_dangjin = 100\\n\\ntrain_x_scaled = (np.array(train_x) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)\\nval_x_scaled = (np.array(val_x) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)\\n\\nae_result = Auto_Encoder_dangjin(train_x_scaled) * (train_max_dangjin - train_min_dangjin) + train_min_dangjin\\n\\ntrain_x = np.hstack([train_x, ae_result])\\n\\nae_result = Auto_Encoder_dangjin(val_x_scaled) * (train_max_dangjin - train_min_dangjin) + train_min_dangjin\\n\\nval_x = np.hstack([val_x, ae_result])\\n'"
      ]
     },
     "execution_count": 1212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_x[:,0] = np.array(pd.Series(train_x[:,0]).astype(\"str\").apply(lambda x : x[2:4]).astype(\"int\"))\n",
    "val_x[:,0] = np.array(pd.Series(val_x[:,0]).astype(\"str\").apply(lambda x : x[2:4]).astype(\"int\"))\n",
    "\n",
    "train_min_dangjin = -9\n",
    "train_max_dangjin = 100\n",
    "\n",
    "train_x_scaled = (np.array(train_x) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)\n",
    "val_x_scaled = (np.array(val_x) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)\n",
    "\n",
    "ae_result = Auto_Encoder_dangjin(train_x_scaled) * (train_max_dangjin - train_min_dangjin) + train_min_dangjin\n",
    "\n",
    "train_x = np.hstack([train_x, ae_result])\n",
    "\n",
    "ae_result = Auto_Encoder_dangjin(val_x_scaled) * (train_max_dangjin - train_min_dangjin) + train_min_dangjin\n",
    "\n",
    "val_x = np.hstack([val_x, ae_result])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = lgb.Dataset(train_x, train_y)\n",
    "val_dataset = lgb.Dataset(val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def LGB_cv(learning_rate, \n",
    "           feature_fraction, \n",
    "           bagging_fraction,\n",
    "           lambda_l2,\n",
    "           silent=True, \n",
    "           nthread=-1):\n",
    "\n",
    "    params = {\"learning_rate\": learning_rate,\n",
    "                \"feature_fraction\" : feature_fraction,\n",
    "                \"bagging_fraction\" : bagging_fraction, \n",
    "               \"lambda_l2\" : lambda_l2,\n",
    "               \"objective\" :  \"regression\",\n",
    "              \"nthread\" : nthread\n",
    "                }\n",
    "    \n",
    "    model = lgb.train(params,\n",
    "                      train_dataset,\n",
    "                      feval = sklearn.metrics.mean_absolute_error\n",
    "                     )\n",
    "\n",
    "    global y_pred\n",
    "    \n",
    "    y_pred = model.predict(val_x)\n",
    "\n",
    "    mae = mean_squared_error(val_y, y_pred)\n",
    "\n",
    "    return 1/mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | lambda_l2 | learni... |\n",
      "-------------------------------------------------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.002679\u001b[0m | \u001b[0m 0.522   \u001b[0m | \u001b[0m 0.6994  \u001b[0m | \u001b[0m 0.2699  \u001b[0m | \u001b[0m 0.1349  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.002805\u001b[0m | \u001b[95m 0.9081  \u001b[0m | \u001b[95m 0.6852  \u001b[0m | \u001b[95m 0.2117  \u001b[0m | \u001b[95m 0.06352 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.002674\u001b[0m | \u001b[0m 0.435   \u001b[0m | \u001b[0m 0.7801  \u001b[0m | \u001b[0m 0.4364  \u001b[0m | \u001b[0m 0.1333  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.002648\u001b[0m | \u001b[0m 0.4912  \u001b[0m | \u001b[0m 0.28    \u001b[0m | \u001b[0m 0.5366  \u001b[0m | \u001b[0m 0.1884  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.002411\u001b[0m | \u001b[0m 0.4445  \u001b[0m | \u001b[0m 0.9592  \u001b[0m | \u001b[0m 0.5674  \u001b[0m | \u001b[0m 0.1235  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.002797\u001b[0m | \u001b[0m 0.9684  \u001b[0m | \u001b[0m 0.702   \u001b[0m | \u001b[0m 0.464   \u001b[0m | \u001b[0m 0.07075 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.002523\u001b[0m | \u001b[0m 0.6692  \u001b[0m | \u001b[0m 0.4567  \u001b[0m | \u001b[0m 0.6331  \u001b[0m | \u001b[0m 0.1103  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.002673\u001b[0m | \u001b[0m 0.5009  \u001b[0m | \u001b[0m 0.3496  \u001b[0m | \u001b[0m 0.1886  \u001b[0m | \u001b[0m 0.01085 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.002428\u001b[0m | \u001b[0m 0.3024  \u001b[0m | \u001b[0m 0.1419  \u001b[0m | \u001b[0m 0.1612  \u001b[0m | \u001b[0m 0.1408  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.002694\u001b[0m | \u001b[0m 0.054   \u001b[0m | \u001b[0m 0.3549  \u001b[0m | \u001b[0m 0.8703  \u001b[0m | \u001b[0m 0.01291 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.002469\u001b[0m | \u001b[0m 0.05706 \u001b[0m | \u001b[0m 0.8806  \u001b[0m | \u001b[0m 0.8852  \u001b[0m | \u001b[0m 0.164   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.002416\u001b[0m | \u001b[0m 0.7327  \u001b[0m | \u001b[0m 0.1318  \u001b[0m | \u001b[0m 0.9982  \u001b[0m | \u001b[0m 0.000880\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.002485\u001b[0m | \u001b[0m 0.2478  \u001b[0m | \u001b[0m 0.1319  \u001b[0m | \u001b[0m 0.001929\u001b[0m | \u001b[0m 0.08342 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.002349\u001b[0m | \u001b[0m 0.004703\u001b[0m | \u001b[0m 0.9485  \u001b[0m | \u001b[0m 0.7221  \u001b[0m | \u001b[0m 0.164   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.002704\u001b[0m | \u001b[0m 0.4834  \u001b[0m | \u001b[0m 0.7931  \u001b[0m | \u001b[0m 0.4857  \u001b[0m | \u001b[0m 0.05496 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.002674\u001b[0m | \u001b[0m 0.6042  \u001b[0m | \u001b[0m 0.3301  \u001b[0m | \u001b[0m 0.8461  \u001b[0m | \u001b[0m 0.04334 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.002216\u001b[0m | \u001b[0m 0.7757  \u001b[0m | \u001b[0m 0.06438 \u001b[0m | \u001b[0m 0.5378  \u001b[0m | \u001b[0m 0.1715  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.002391\u001b[0m | \u001b[0m 0.7544  \u001b[0m | \u001b[0m 0.8937  \u001b[0m | \u001b[0m 0.8064  \u001b[0m | \u001b[0m 0.1347  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.002531\u001b[0m | \u001b[0m 0.03494 \u001b[0m | \u001b[0m 0.7592  \u001b[0m | \u001b[0m 0.2076  \u001b[0m | \u001b[0m 0.104   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.002405\u001b[0m | \u001b[0m 0.6249  \u001b[0m | \u001b[0m 0.8087  \u001b[0m | \u001b[0m 0.09914 \u001b[0m | \u001b[0m 0.1217  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m 0.002863\u001b[0m | \u001b[95m 0.4556  \u001b[0m | \u001b[95m 0.2899  \u001b[0m | \u001b[95m 0.8854  \u001b[0m | \u001b[95m 0.05525 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.002641\u001b[0m | \u001b[0m 0.08473 \u001b[0m | \u001b[0m 0.6992  \u001b[0m | \u001b[0m 0.3435  \u001b[0m | \u001b[0m 0.1401  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.002812\u001b[0m | \u001b[0m 0.452   \u001b[0m | \u001b[0m 0.5712  \u001b[0m | \u001b[0m 0.04221 \u001b[0m | \u001b[0m 0.1161  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.002541\u001b[0m | \u001b[0m 0.4079  \u001b[0m | \u001b[0m 0.6027  \u001b[0m | \u001b[0m 0.3408  \u001b[0m | \u001b[0m 0.1104  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.002631\u001b[0m | \u001b[0m 0.7268  \u001b[0m | \u001b[0m 0.2279  \u001b[0m | \u001b[0m 0.05022 \u001b[0m | \u001b[0m 0.05625 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.002574\u001b[0m | \u001b[0m 0.2665  \u001b[0m | \u001b[0m 0.9124  \u001b[0m | \u001b[0m 0.2731  \u001b[0m | \u001b[0m 0.09083 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.002526\u001b[0m | \u001b[0m 0.2056  \u001b[0m | \u001b[0m 0.2112  \u001b[0m | \u001b[0m 0.1495  \u001b[0m | \u001b[0m 0.09306 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[95m 28      \u001b[0m | \u001b[95m 0.003057\u001b[0m | \u001b[95m 0.0362  \u001b[0m | \u001b[95m 0.6045  \u001b[0m | \u001b[95m 0.4966  \u001b[0m | \u001b[95m 0.1719  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.002381\u001b[0m | \u001b[0m 0.3977  \u001b[0m | \u001b[0m 0.8703  \u001b[0m | \u001b[0m 0.9652  \u001b[0m | \u001b[0m 0.1735  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.002726\u001b[0m | \u001b[0m 0.4227  \u001b[0m | \u001b[0m 0.2684  \u001b[0m | \u001b[0m 0.6008  \u001b[0m | \u001b[0m 0.1717  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.002488\u001b[0m | \u001b[0m 0.8214  \u001b[0m | \u001b[0m 0.5892  \u001b[0m | \u001b[0m 0.4182  \u001b[0m | \u001b[0m 0.1322  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.002176\u001b[0m | \u001b[0m 0.2253  \u001b[0m | \u001b[0m 0.03211 \u001b[0m | \u001b[0m 0.7064  \u001b[0m | \u001b[0m 0.194   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.002648\u001b[0m | \u001b[0m 0.6111  \u001b[0m | \u001b[0m 0.8841  \u001b[0m | \u001b[0m 0.1676  \u001b[0m | \u001b[0m 0.1258  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.00281 \u001b[0m | \u001b[0m 0.1702  \u001b[0m | \u001b[0m 0.7181  \u001b[0m | \u001b[0m 0.6363  \u001b[0m | \u001b[0m 0.02724 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.002098\u001b[0m | \u001b[0m 0.6656  \u001b[0m | \u001b[0m 0.8817  \u001b[0m | \u001b[0m 0.2191  \u001b[0m | \u001b[0m 0.1973  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.002451\u001b[0m | \u001b[0m 0.7253  \u001b[0m | \u001b[0m 0.09322 \u001b[0m | \u001b[0m 0.005571\u001b[0m | \u001b[0m 0.01508 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.002302\u001b[0m | \u001b[0m 0.1701  \u001b[0m | \u001b[0m 0.2109  \u001b[0m | \u001b[0m 0.2881  \u001b[0m | \u001b[0m 0.1602  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.002419\u001b[0m | \u001b[0m 0.1601  \u001b[0m | \u001b[0m 0.04758 \u001b[0m | \u001b[0m 0.2054  \u001b[0m | \u001b[0m 0.07144 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.002657\u001b[0m | \u001b[0m 0.08584 \u001b[0m | \u001b[0m 0.5825  \u001b[0m | \u001b[0m 0.1257  \u001b[0m | \u001b[0m 0.1427  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.002479\u001b[0m | \u001b[0m 0.9143  \u001b[0m | \u001b[0m 0.1628  \u001b[0m | \u001b[0m 0.4385  \u001b[0m | \u001b[0m 0.08985 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.002781\u001b[0m | \u001b[0m 0.7055  \u001b[0m | \u001b[0m 0.3672  \u001b[0m | \u001b[0m 0.45    \u001b[0m | \u001b[0m 0.02126 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000550 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.002247\u001b[0m | \u001b[0m 0.9359  \u001b[0m | \u001b[0m 0.01595 \u001b[0m | \u001b[0m 0.07464 \u001b[0m | \u001b[0m 0.1567  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.002455\u001b[0m | \u001b[0m 0.1947  \u001b[0m | \u001b[0m 0.1615  \u001b[0m | \u001b[0m 0.3201  \u001b[0m | \u001b[0m 0.1079  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.002447\u001b[0m | \u001b[0m 0.5789  \u001b[0m | \u001b[0m 0.05609 \u001b[0m | \u001b[0m 0.7281  \u001b[0m | \u001b[0m 0.01238 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.002455\u001b[0m | \u001b[0m 0.2602  \u001b[0m | \u001b[0m 0.1348  \u001b[0m | \u001b[0m 0.7779  \u001b[0m | \u001b[0m 0.1084  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.002227\u001b[0m | \u001b[0m 0.855   \u001b[0m | \u001b[0m 0.08624 \u001b[0m | \u001b[0m 0.02007 \u001b[0m | \u001b[0m 0.1643  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.002761\u001b[0m | \u001b[0m 0.154   \u001b[0m | \u001b[0m 0.5408  \u001b[0m | \u001b[0m 0.2784  \u001b[0m | \u001b[0m 0.04505 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.002532\u001b[0m | \u001b[0m 0.5382  \u001b[0m | \u001b[0m 0.6382  \u001b[0m | \u001b[0m 0.8143  \u001b[0m | \u001b[0m 0.1052  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.002505\u001b[0m | \u001b[0m 0.8733  \u001b[0m | \u001b[0m 0.7129  \u001b[0m | \u001b[0m 0.5559  \u001b[0m | \u001b[0m 0.1988  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.002609\u001b[0m | \u001b[0m 0.5241  \u001b[0m | \u001b[0m 0.2579  \u001b[0m | \u001b[0m 0.4611  \u001b[0m | \u001b[0m 0.01488 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.002744\u001b[0m | \u001b[0m 0.4252  \u001b[0m | \u001b[0m 0.7436  \u001b[0m | \u001b[0m 0.03573 \u001b[0m | \u001b[0m 0.04043 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.002475\u001b[0m | \u001b[0m 0.01622 \u001b[0m | \u001b[0m 0.1339  \u001b[0m | \u001b[0m 0.787   \u001b[0m | \u001b[0m 0.01864 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.002674\u001b[0m | \u001b[0m 0.3591  \u001b[0m | \u001b[0m 0.8318  \u001b[0m | \u001b[0m 0.3094  \u001b[0m | \u001b[0m 0.06189 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.002256\u001b[0m | \u001b[0m 0.7109  \u001b[0m | \u001b[0m 0.05513 \u001b[0m | \u001b[0m 0.8083  \u001b[0m | \u001b[0m 0.1519  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.002744\u001b[0m | \u001b[0m 0.3256  \u001b[0m | \u001b[0m 0.9976  \u001b[0m | \u001b[0m 0.5151  \u001b[0m | \u001b[0m 0.007625\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.002744\u001b[0m | \u001b[0m 0.3775  \u001b[0m | \u001b[0m 0.2031  \u001b[0m | \u001b[0m 0.8282  \u001b[0m | \u001b[0m 0.0387  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.002489\u001b[0m | \u001b[0m 0.7648  \u001b[0m | \u001b[0m 0.3363  \u001b[0m | \u001b[0m 0.9246  \u001b[0m | \u001b[0m 0.09168 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.002326\u001b[0m | \u001b[0m 0.6719  \u001b[0m | \u001b[0m 0.01079 \u001b[0m | \u001b[0m 0.02399 \u001b[0m | \u001b[0m 0.1195  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.002274\u001b[0m | \u001b[0m 0.1187  \u001b[0m | \u001b[0m 0.000670\u001b[0m | \u001b[0m 0.9322  \u001b[0m | \u001b[0m 0.1424  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.002479\u001b[0m | \u001b[0m 0.5385  \u001b[0m | \u001b[0m 0.8668  \u001b[0m | \u001b[0m 0.4528  \u001b[0m | \u001b[0m 0.1959  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.002679\u001b[0m | \u001b[0m 0.7841  \u001b[0m | \u001b[0m 0.8401  \u001b[0m | \u001b[0m 0.005316\u001b[0m | \u001b[0m 0.005962\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.002362\u001b[0m | \u001b[0m 0.5492  \u001b[0m | \u001b[0m 0.2295  \u001b[0m | \u001b[0m 0.3296  \u001b[0m | \u001b[0m 0.1741  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.002762\u001b[0m | \u001b[0m 0.4751  \u001b[0m | \u001b[0m 0.5174  \u001b[0m | \u001b[0m 0.4076  \u001b[0m | \u001b[0m 0.03475 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.002692\u001b[0m | \u001b[0m 0.1425  \u001b[0m | \u001b[0m 0.2602  \u001b[0m | \u001b[0m 0.3675  \u001b[0m | \u001b[0m 0.09369 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.002452\u001b[0m | \u001b[0m 0.1148  \u001b[0m | \u001b[0m 0.1285  \u001b[0m | \u001b[0m 0.4265  \u001b[0m | \u001b[0m 0.1094  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.002764\u001b[0m | \u001b[0m 0.6596  \u001b[0m | \u001b[0m 0.4022  \u001b[0m | \u001b[0m 0.3778  \u001b[0m | \u001b[0m 0.1447  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.002853\u001b[0m | \u001b[0m 0.7417  \u001b[0m | \u001b[0m 0.3836  \u001b[0m | \u001b[0m 0.9512  \u001b[0m | \u001b[0m 0.1922  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.002627\u001b[0m | \u001b[0m 0.5265  \u001b[0m | \u001b[0m 0.9725  \u001b[0m | \u001b[0m 0.9081  \u001b[0m | \u001b[0m 0.08965 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.00274 \u001b[0m | \u001b[0m 0.1233  \u001b[0m | \u001b[0m 0.4165  \u001b[0m | \u001b[0m 0.1751  \u001b[0m | \u001b[0m 0.01629 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.002714\u001b[0m | \u001b[0m 0.2755  \u001b[0m | \u001b[0m 0.4532  \u001b[0m | \u001b[0m 0.1805  \u001b[0m | \u001b[0m 0.1994  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.002763\u001b[0m | \u001b[0m 0.5599  \u001b[0m | \u001b[0m 0.4577  \u001b[0m | \u001b[0m 0.8871  \u001b[0m | \u001b[0m 0.04219 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.002728\u001b[0m | \u001b[0m 0.07437 \u001b[0m | \u001b[0m 0.6354  \u001b[0m | \u001b[0m 0.8805  \u001b[0m | \u001b[0m 0.1595  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.002395\u001b[0m | \u001b[0m 0.3875  \u001b[0m | \u001b[0m 0.3775  \u001b[0m | \u001b[0m 0.3271  \u001b[0m | \u001b[0m 0.1683  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000734 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.002648\u001b[0m | \u001b[0m 0.7977  \u001b[0m | \u001b[0m 0.3614  \u001b[0m | \u001b[0m 0.459   \u001b[0m | \u001b[0m 0.09562 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.002372\u001b[0m | \u001b[0m 0.672   \u001b[0m | \u001b[0m 0.9197  \u001b[0m | \u001b[0m 0.1111  \u001b[0m | \u001b[0m 0.1964  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.002576\u001b[0m | \u001b[0m 0.2569  \u001b[0m | \u001b[0m 0.4657  \u001b[0m | \u001b[0m 0.6397  \u001b[0m | \u001b[0m 0.1694  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.00263 \u001b[0m | \u001b[0m 0.9874  \u001b[0m | \u001b[0m 0.496   \u001b[0m | \u001b[0m 0.2268  \u001b[0m | \u001b[0m 0.1139  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.002184\u001b[0m | \u001b[0m 0.6658  \u001b[0m | \u001b[0m 0.0576  \u001b[0m | \u001b[0m 0.3628  \u001b[0m | \u001b[0m 0.1881  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.00244 \u001b[0m | \u001b[0m 0.5862  \u001b[0m | \u001b[0m 0.8448  \u001b[0m | \u001b[0m 0.3864  \u001b[0m | \u001b[0m 0.191   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.002439\u001b[0m | \u001b[0m 0.8509  \u001b[0m | \u001b[0m 0.8058  \u001b[0m | \u001b[0m 0.4363  \u001b[0m | \u001b[0m 0.1162  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.00254 \u001b[0m | \u001b[0m 0.5138  \u001b[0m | \u001b[0m 0.5938  \u001b[0m | \u001b[0m 0.00461 \u001b[0m | \u001b[0m 0.1902  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.002698\u001b[0m | \u001b[0m 0.0921  \u001b[0m | \u001b[0m 0.7082  \u001b[0m | \u001b[0m 0.07647 \u001b[0m | \u001b[0m 0.1513  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.002197\u001b[0m | \u001b[0m 0.2737  \u001b[0m | \u001b[0m 0.02765 \u001b[0m | \u001b[0m 0.9359  \u001b[0m | \u001b[0m 0.1832  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.002653\u001b[0m | \u001b[0m 0.2102  \u001b[0m | \u001b[0m 0.3741  \u001b[0m | \u001b[0m 0.1751  \u001b[0m | \u001b[0m 0.04037 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.002059\u001b[0m | \u001b[0m 0.3631  \u001b[0m | \u001b[0m 0.9288  \u001b[0m | \u001b[0m 0.6648  \u001b[0m | \u001b[0m 0.1879  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.002508\u001b[0m | \u001b[0m 0.1805  \u001b[0m | \u001b[0m 0.3798  \u001b[0m | \u001b[0m 0.5938  \u001b[0m | \u001b[0m 0.1566  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.00241 \u001b[0m | \u001b[0m 0.2351  \u001b[0m | \u001b[0m 0.3534  \u001b[0m | \u001b[0m 0.5964  \u001b[0m | \u001b[0m 0.1255  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.002635\u001b[0m | \u001b[0m 0.6261  \u001b[0m | \u001b[0m 0.4756  \u001b[0m | \u001b[0m 0.4559  \u001b[0m | \u001b[0m 0.09241 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.002795\u001b[0m | \u001b[0m 0.4656  \u001b[0m | \u001b[0m 0.6294  \u001b[0m | \u001b[0m 0.6555  \u001b[0m | \u001b[0m 0.1572  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.002867\u001b[0m | \u001b[0m 0.09194 \u001b[0m | \u001b[0m 0.6746  \u001b[0m | \u001b[0m 0.6275  \u001b[0m | \u001b[0m 0.08042 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.002732\u001b[0m | \u001b[0m 0.3652  \u001b[0m | \u001b[0m 0.2552  \u001b[0m | \u001b[0m 0.1605  \u001b[0m | \u001b[0m 0.1057  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.002762\u001b[0m | \u001b[0m 0.6087  \u001b[0m | \u001b[0m 0.7275  \u001b[0m | \u001b[0m 0.8918  \u001b[0m | \u001b[0m 0.1872  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.002818\u001b[0m | \u001b[0m 0.1902  \u001b[0m | \u001b[0m 0.563   \u001b[0m | \u001b[0m 0.972   \u001b[0m | \u001b[0m 0.03309 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.002419\u001b[0m | \u001b[0m 0.3304  \u001b[0m | \u001b[0m 0.3742  \u001b[0m | \u001b[0m 0.7865  \u001b[0m | \u001b[0m 0.1632  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.002738\u001b[0m | \u001b[0m 0.1169  \u001b[0m | \u001b[0m 0.2363  \u001b[0m | \u001b[0m 0.01343 \u001b[0m | \u001b[0m 0.04365 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.002709\u001b[0m | \u001b[0m 0.767   \u001b[0m | \u001b[0m 0.4138  \u001b[0m | \u001b[0m 0.124   \u001b[0m | \u001b[0m 0.01384 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.002753\u001b[0m | \u001b[0m 0.9607  \u001b[0m | \u001b[0m 0.2828  \u001b[0m | \u001b[0m 0.1522  \u001b[0m | \u001b[0m 0.1374  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.00266 \u001b[0m | \u001b[0m 0.9931  \u001b[0m | \u001b[0m 0.5148  \u001b[0m | \u001b[0m 0.9013  \u001b[0m | \u001b[0m 0.1666  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.002538\u001b[0m | \u001b[0m 0.6087  \u001b[0m | \u001b[0m 0.6183  \u001b[0m | \u001b[0m 0.6766  \u001b[0m | \u001b[0m 0.1066  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.002557\u001b[0m | \u001b[0m 0.18    \u001b[0m | \u001b[0m 0.211   \u001b[0m | \u001b[0m 0.9897  \u001b[0m | \u001b[0m 0.09751 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 0.002618\u001b[0m | \u001b[0m 0.1702  \u001b[0m | \u001b[0m 0.6592  \u001b[0m | \u001b[0m 0.6622  \u001b[0m | \u001b[0m 0.1615  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 0.002766\u001b[0m | \u001b[0m 0.743   \u001b[0m | \u001b[0m 0.4431  \u001b[0m | \u001b[0m 0.4221  \u001b[0m | \u001b[0m 0.04502 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m 0.002756\u001b[0m | \u001b[0m 0.3308  \u001b[0m | \u001b[0m 0.4333  \u001b[0m | \u001b[0m 0.1419  \u001b[0m | \u001b[0m 0.02232 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m 0.002638\u001b[0m | \u001b[0m 0.02017 \u001b[0m | \u001b[0m 0.2048  \u001b[0m | \u001b[0m 0.1738  \u001b[0m | \u001b[0m 0.05528 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m 0.00224 \u001b[0m | \u001b[0m 0.4818  \u001b[0m | \u001b[0m 0.9637  \u001b[0m | \u001b[0m 0.1213  \u001b[0m | \u001b[0m 0.1592  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m 0.002715\u001b[0m | \u001b[0m 0.0657  \u001b[0m | \u001b[0m 0.5507  \u001b[0m | \u001b[0m 0.09114 \u001b[0m | \u001b[0m 0.1959  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 107     \u001b[0m | \u001b[0m 0.002654\u001b[0m | \u001b[0m 0.04593 \u001b[0m | \u001b[0m 0.6869  \u001b[0m | \u001b[0m 0.3273  \u001b[0m | \u001b[0m 0.09484 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 108     \u001b[0m | \u001b[0m 0.002671\u001b[0m | \u001b[0m 0.3876  \u001b[0m | \u001b[0m 0.9647  \u001b[0m | \u001b[0m 0.5199  \u001b[0m | \u001b[0m 0.04065 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 109     \u001b[0m | \u001b[0m 0.002535\u001b[0m | \u001b[0m 0.1019  \u001b[0m | \u001b[0m 0.4697  \u001b[0m | \u001b[0m 0.5555  \u001b[0m | \u001b[0m 0.1921  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 110     \u001b[0m | \u001b[0m 0.002597\u001b[0m | \u001b[0m 0.7214  \u001b[0m | \u001b[0m 0.3887  \u001b[0m | \u001b[0m 0.1271  \u001b[0m | \u001b[0m 0.07431 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 111     \u001b[0m | \u001b[0m 0.002582\u001b[0m | \u001b[0m 0.3484  \u001b[0m | \u001b[0m 0.7821  \u001b[0m | \u001b[0m 0.602   \u001b[0m | \u001b[0m 0.1248  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 112     \u001b[0m | \u001b[0m 0.002441\u001b[0m | \u001b[0m 0.9342  \u001b[0m | \u001b[0m 0.3893  \u001b[0m | \u001b[0m 0.6301  \u001b[0m | \u001b[0m 0.1479  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 113     \u001b[0m | \u001b[0m 0.002688\u001b[0m | \u001b[0m 0.9966  \u001b[0m | \u001b[0m 0.2532  \u001b[0m | \u001b[0m 0.2358  \u001b[0m | \u001b[0m 0.1716  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 114     \u001b[0m | \u001b[0m 0.002576\u001b[0m | \u001b[0m 0.8979  \u001b[0m | \u001b[0m 0.5203  \u001b[0m | \u001b[0m 0.7886  \u001b[0m | \u001b[0m 0.0779  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 115     \u001b[0m | \u001b[0m 0.002311\u001b[0m | \u001b[0m 0.6743  \u001b[0m | \u001b[0m 0.0174  \u001b[0m | \u001b[0m 0.4554  \u001b[0m | \u001b[0m 0.1267  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 116     \u001b[0m | \u001b[0m 0.00275 \u001b[0m | \u001b[0m 0.4908  \u001b[0m | \u001b[0m 0.6848  \u001b[0m | \u001b[0m 0.2216  \u001b[0m | \u001b[0m 0.02939 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 117     \u001b[0m | \u001b[0m 0.002469\u001b[0m | \u001b[0m 0.287   \u001b[0m | \u001b[0m 0.2603  \u001b[0m | \u001b[0m 0.5233  \u001b[0m | \u001b[0m 0.004005\u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 118     \u001b[0m | \u001b[0m 0.002672\u001b[0m | \u001b[0m 0.4822  \u001b[0m | \u001b[0m 0.5766  \u001b[0m | \u001b[0m 0.5473  \u001b[0m | \u001b[0m 0.1516  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 119     \u001b[0m | \u001b[0m 0.002452\u001b[0m | \u001b[0m 0.1614  \u001b[0m | \u001b[0m 0.01586 \u001b[0m | \u001b[0m 0.5332  \u001b[0m | \u001b[0m 0.04955 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 120     \u001b[0m | \u001b[0m 0.002347\u001b[0m | \u001b[0m 0.2287  \u001b[0m | \u001b[0m 0.08729 \u001b[0m | \u001b[0m 0.4067  \u001b[0m | \u001b[0m 0.1107  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 121     \u001b[0m | \u001b[0m 0.002429\u001b[0m | \u001b[0m 0.7525  \u001b[0m | \u001b[0m 0.9486  \u001b[0m | \u001b[0m 0.4509  \u001b[0m | \u001b[0m 0.000241\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 122     \u001b[0m | \u001b[0m 0.002428\u001b[0m | \u001b[0m 0.49    \u001b[0m | \u001b[0m 0.2167  \u001b[0m | \u001b[0m 0.3899  \u001b[0m | \u001b[0m 0.1457  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 123     \u001b[0m | \u001b[0m 0.002585\u001b[0m | \u001b[0m 0.5958  \u001b[0m | \u001b[0m 0.3606  \u001b[0m | \u001b[0m 0.03781 \u001b[0m | \u001b[0m 0.09488 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 124     \u001b[0m | \u001b[0m 0.002619\u001b[0m | \u001b[0m 0.4556  \u001b[0m | \u001b[0m 0.8843  \u001b[0m | \u001b[0m 0.5187  \u001b[0m | \u001b[0m 0.1249  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 125     \u001b[0m | \u001b[0m 0.00277 \u001b[0m | \u001b[0m 0.8791  \u001b[0m | \u001b[0m 0.5688  \u001b[0m | \u001b[0m 0.4735  \u001b[0m | \u001b[0m 0.06317 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 126     \u001b[0m | \u001b[0m 0.002185\u001b[0m | \u001b[0m 0.1527  \u001b[0m | \u001b[0m 0.01998 \u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.1896  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 127     \u001b[0m | \u001b[0m 0.002507\u001b[0m | \u001b[0m 0.2366  \u001b[0m | \u001b[0m 0.6052  \u001b[0m | \u001b[0m 0.3799  \u001b[0m | \u001b[0m 0.1686  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 128     \u001b[0m | \u001b[0m 0.002838\u001b[0m | \u001b[0m 0.4102  \u001b[0m | \u001b[0m 0.4395  \u001b[0m | \u001b[0m 0.5456  \u001b[0m | \u001b[0m 0.1745  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 129     \u001b[0m | \u001b[0m 0.002782\u001b[0m | \u001b[0m 0.5158  \u001b[0m | \u001b[0m 0.5389  \u001b[0m | \u001b[0m 0.5564  \u001b[0m | \u001b[0m 0.06959 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 130     \u001b[0m | \u001b[0m 0.002414\u001b[0m | \u001b[0m 0.9121  \u001b[0m | \u001b[0m 0.3821  \u001b[0m | \u001b[0m 0.4594  \u001b[0m | \u001b[0m 0.1033  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 131     \u001b[0m | \u001b[0m 0.00281 \u001b[0m | \u001b[0m 0.5565  \u001b[0m | \u001b[0m 0.3016  \u001b[0m | \u001b[0m 0.508   \u001b[0m | \u001b[0m 0.03188 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 132     \u001b[0m | \u001b[0m 0.002688\u001b[0m | \u001b[0m 0.1264  \u001b[0m | \u001b[0m 0.5257  \u001b[0m | \u001b[0m 0.9817  \u001b[0m | \u001b[0m 0.05462 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 133     \u001b[0m | \u001b[0m 0.002462\u001b[0m | \u001b[0m 0.9793  \u001b[0m | \u001b[0m 0.7741  \u001b[0m | \u001b[0m 0.8962  \u001b[0m | \u001b[0m 0.1701  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 134     \u001b[0m | \u001b[0m 0.002578\u001b[0m | \u001b[0m 0.4202  \u001b[0m | \u001b[0m 0.7176  \u001b[0m | \u001b[0m 0.02231 \u001b[0m | \u001b[0m 0.1161  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 135     \u001b[0m | \u001b[0m 0.002711\u001b[0m | \u001b[0m 0.843   \u001b[0m | \u001b[0m 0.2873  \u001b[0m | \u001b[0m 0.5551  \u001b[0m | \u001b[0m 0.1683  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 136     \u001b[0m | \u001b[0m 0.002256\u001b[0m | \u001b[0m 0.8815  \u001b[0m | \u001b[0m 0.03103 \u001b[0m | \u001b[0m 0.2952  \u001b[0m | \u001b[0m 0.1525  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 137     \u001b[0m | \u001b[0m 0.002671\u001b[0m | \u001b[0m 0.6013  \u001b[0m | \u001b[0m 0.2932  \u001b[0m | \u001b[0m 0.198   \u001b[0m | \u001b[0m 0.07849 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 138     \u001b[0m | \u001b[0m 0.002208\u001b[0m | \u001b[0m 0.1183  \u001b[0m | \u001b[0m 0.07976 \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.1739  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 139     \u001b[0m | \u001b[0m 0.002471\u001b[0m | \u001b[0m 0.5638  \u001b[0m | \u001b[0m 0.8856  \u001b[0m | \u001b[0m 0.7523  \u001b[0m | \u001b[0m 0.1497  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 140     \u001b[0m | \u001b[0m 0.002658\u001b[0m | \u001b[0m 0.05093 \u001b[0m | \u001b[0m 0.2964  \u001b[0m | \u001b[0m 0.7919  \u001b[0m | \u001b[0m 0.02115 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 141     \u001b[0m | \u001b[0m 0.0025  \u001b[0m | \u001b[0m 0.7748  \u001b[0m | \u001b[0m 0.9128  \u001b[0m | \u001b[0m 0.8547  \u001b[0m | \u001b[0m 0.1491  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 142     \u001b[0m | \u001b[0m 0.002732\u001b[0m | \u001b[0m 0.7339  \u001b[0m | \u001b[0m 0.7535  \u001b[0m | \u001b[0m 0.5977  \u001b[0m | \u001b[0m 0.02024 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 143     \u001b[0m | \u001b[0m 0.002616\u001b[0m | \u001b[0m 0.9045  \u001b[0m | \u001b[0m 0.5511  \u001b[0m | \u001b[0m 0.929   \u001b[0m | \u001b[0m 0.07902 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 144     \u001b[0m | \u001b[0m 0.002621\u001b[0m | \u001b[0m 0.922   \u001b[0m | \u001b[0m 0.4807  \u001b[0m | \u001b[0m 0.7899  \u001b[0m | \u001b[0m 0.1795  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 145     \u001b[0m | \u001b[0m 0.002492\u001b[0m | \u001b[0m 0.1747  \u001b[0m | \u001b[0m 0.1718  \u001b[0m | \u001b[0m 0.2032  \u001b[0m | \u001b[0m 0.0803  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 146     \u001b[0m | \u001b[0m 0.002453\u001b[0m | \u001b[0m 0.06214 \u001b[0m | \u001b[0m 0.8288  \u001b[0m | \u001b[0m 0.9922  \u001b[0m | \u001b[0m 0.1626  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 147     \u001b[0m | \u001b[0m 0.002706\u001b[0m | \u001b[0m 0.2055  \u001b[0m | \u001b[0m 0.4257  \u001b[0m | \u001b[0m 0.7789  \u001b[0m | \u001b[0m 0.1227  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 148     \u001b[0m | \u001b[0m 0.002584\u001b[0m | \u001b[0m 0.8899  \u001b[0m | \u001b[0m 0.3413  \u001b[0m | \u001b[0m 0.9004  \u001b[0m | \u001b[0m 0.06153 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 149     \u001b[0m | \u001b[0m 0.002715\u001b[0m | \u001b[0m 0.3152  \u001b[0m | \u001b[0m 0.2718  \u001b[0m | \u001b[0m 0.265   \u001b[0m | \u001b[0m 0.1086  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 150     \u001b[0m | \u001b[0m 0.002433\u001b[0m | \u001b[0m 0.6755  \u001b[0m | \u001b[0m 0.3266  \u001b[0m | \u001b[0m 0.4204  \u001b[0m | \u001b[0m 0.133   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 151     \u001b[0m | \u001b[0m 0.002556\u001b[0m | \u001b[0m 0.2593  \u001b[0m | \u001b[0m 0.5227  \u001b[0m | \u001b[0m 0.4843  \u001b[0m | \u001b[0m 0.00412 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 152     \u001b[0m | \u001b[0m 0.002623\u001b[0m | \u001b[0m 0.8767  \u001b[0m | \u001b[0m 0.4576  \u001b[0m | \u001b[0m 0.2026  \u001b[0m | \u001b[0m 0.06508 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 153     \u001b[0m | \u001b[0m 0.002616\u001b[0m | \u001b[0m 0.7975  \u001b[0m | \u001b[0m 0.3677  \u001b[0m | \u001b[0m 0.4246  \u001b[0m | \u001b[0m 0.1242  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 154     \u001b[0m | \u001b[0m 0.002559\u001b[0m | \u001b[0m 0.8874  \u001b[0m | \u001b[0m 0.3502  \u001b[0m | \u001b[0m 0.7328  \u001b[0m | \u001b[0m 0.1063  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 155     \u001b[0m | \u001b[0m 0.002622\u001b[0m | \u001b[0m 0.8724  \u001b[0m | \u001b[0m 0.205   \u001b[0m | \u001b[0m 0.9074  \u001b[0m | \u001b[0m 0.01322 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 156     \u001b[0m | \u001b[0m 0.002436\u001b[0m | \u001b[0m 0.5194  \u001b[0m | \u001b[0m 0.1998  \u001b[0m | \u001b[0m 0.2371  \u001b[0m | \u001b[0m 0.1702  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 157     \u001b[0m | \u001b[0m 0.002432\u001b[0m | \u001b[0m 0.7961  \u001b[0m | \u001b[0m 0.2493  \u001b[0m | \u001b[0m 0.9068  \u001b[0m | \u001b[0m 0.001044\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 158     \u001b[0m | \u001b[0m 0.002558\u001b[0m | \u001b[0m 0.4734  \u001b[0m | \u001b[0m 0.6065  \u001b[0m | \u001b[0m 0.1838  \u001b[0m | \u001b[0m 0.1063  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000734 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 159     \u001b[0m | \u001b[0m 0.002332\u001b[0m | \u001b[0m 0.5599  \u001b[0m | \u001b[0m 0.9129  \u001b[0m | \u001b[0m 0.6739  \u001b[0m | \u001b[0m 0.1706  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 160     \u001b[0m | \u001b[0m 0.002413\u001b[0m | \u001b[0m 0.3599  \u001b[0m | \u001b[0m 0.1302  \u001b[0m | \u001b[0m 0.62    \u001b[0m | \u001b[0m 0.143   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 161     \u001b[0m | \u001b[0m 0.002581\u001b[0m | \u001b[0m 0.5642  \u001b[0m | \u001b[0m 0.646   \u001b[0m | \u001b[0m 0.9389  \u001b[0m | \u001b[0m 0.1254  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 162     \u001b[0m | \u001b[0m 0.002419\u001b[0m | \u001b[0m 0.6555  \u001b[0m | \u001b[0m 0.5957  \u001b[0m | \u001b[0m 0.3338  \u001b[0m | \u001b[0m 0.09892 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 163     \u001b[0m | \u001b[0m 0.002381\u001b[0m | \u001b[0m 0.7613  \u001b[0m | \u001b[0m 0.02128 \u001b[0m | \u001b[0m 0.3892  \u001b[0m | \u001b[0m 0.09408 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 164     \u001b[0m | \u001b[0m 0.002535\u001b[0m | \u001b[0m 0.3279  \u001b[0m | \u001b[0m 0.241   \u001b[0m | \u001b[0m 0.9799  \u001b[0m | \u001b[0m 0.09909 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 165     \u001b[0m | \u001b[0m 0.002738\u001b[0m | \u001b[0m 0.4722  \u001b[0m | \u001b[0m 0.2178  \u001b[0m | \u001b[0m 0.6624  \u001b[0m | \u001b[0m 0.04024 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 166     \u001b[0m | \u001b[0m 0.002645\u001b[0m | \u001b[0m 0.391   \u001b[0m | \u001b[0m 0.6263  \u001b[0m | \u001b[0m 0.7978  \u001b[0m | \u001b[0m 0.008246\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 167     \u001b[0m | \u001b[0m 0.002782\u001b[0m | \u001b[0m 0.7065  \u001b[0m | \u001b[0m 0.6264  \u001b[0m | \u001b[0m 0.4133  \u001b[0m | \u001b[0m 0.03776 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 168     \u001b[0m | \u001b[0m 0.002622\u001b[0m | \u001b[0m 0.3314  \u001b[0m | \u001b[0m 0.1958  \u001b[0m | \u001b[0m 0.1183  \u001b[0m | \u001b[0m 0.07543 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 169     \u001b[0m | \u001b[0m 0.002342\u001b[0m | \u001b[0m 0.2029  \u001b[0m | \u001b[0m 0.02996 \u001b[0m | \u001b[0m 0.3977  \u001b[0m | \u001b[0m 0.1118  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 170     \u001b[0m | \u001b[0m 0.002713\u001b[0m | \u001b[0m 0.4458  \u001b[0m | \u001b[0m 0.8371  \u001b[0m | \u001b[0m 0.5559  \u001b[0m | \u001b[0m 0.02276 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 171     \u001b[0m | \u001b[0m 0.002766\u001b[0m | \u001b[0m 0.8116  \u001b[0m | \u001b[0m 0.5938  \u001b[0m | \u001b[0m 0.7498  \u001b[0m | \u001b[0m 0.01644 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 172     \u001b[0m | \u001b[0m 0.002613\u001b[0m | \u001b[0m 0.81    \u001b[0m | \u001b[0m 0.3787  \u001b[0m | \u001b[0m 0.07004 \u001b[0m | \u001b[0m 0.08142 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 173     \u001b[0m | \u001b[0m 0.002524\u001b[0m | \u001b[0m 0.2295  \u001b[0m | \u001b[0m 0.4715  \u001b[0m | \u001b[0m 0.7036  \u001b[0m | \u001b[0m 0.1136  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 174     \u001b[0m | \u001b[0m 0.002477\u001b[0m | \u001b[0m 0.5472  \u001b[0m | \u001b[0m 0.9011  \u001b[0m | \u001b[0m 0.9633  \u001b[0m | \u001b[0m 0.1927  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 175     \u001b[0m | \u001b[0m 0.002451\u001b[0m | \u001b[0m 0.305   \u001b[0m | \u001b[0m 0.1441  \u001b[0m | \u001b[0m 0.2332  \u001b[0m | \u001b[0m 0.1122  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 176     \u001b[0m | \u001b[0m 0.00262 \u001b[0m | \u001b[0m 0.8286  \u001b[0m | \u001b[0m 0.4925  \u001b[0m | \u001b[0m 0.8351  \u001b[0m | \u001b[0m 0.1196  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 177     \u001b[0m | \u001b[0m 0.002273\u001b[0m | \u001b[0m 0.09491 \u001b[0m | \u001b[0m 0.04477 \u001b[0m | \u001b[0m 0.02448 \u001b[0m | \u001b[0m 0.1434  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 178     \u001b[0m | \u001b[0m 0.00265 \u001b[0m | \u001b[0m 0.849   \u001b[0m | \u001b[0m 0.7967  \u001b[0m | \u001b[0m 0.8445  \u001b[0m | \u001b[0m 0.1148  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 179     \u001b[0m | \u001b[0m 0.002566\u001b[0m | \u001b[0m 0.2052  \u001b[0m | \u001b[0m 0.2665  \u001b[0m | \u001b[0m 0.7667  \u001b[0m | \u001b[0m 0.01102 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 180     \u001b[0m | \u001b[0m 0.002719\u001b[0m | \u001b[0m 0.3447  \u001b[0m | \u001b[0m 0.8105  \u001b[0m | \u001b[0m 0.08057 \u001b[0m | \u001b[0m 0.1218  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 181     \u001b[0m | \u001b[0m 0.002785\u001b[0m | \u001b[0m 0.6891  \u001b[0m | \u001b[0m 0.7645  \u001b[0m | \u001b[0m 0.6059  \u001b[0m | \u001b[0m 0.03107 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 182     \u001b[0m | \u001b[0m 0.002668\u001b[0m | \u001b[0m 0.6185  \u001b[0m | \u001b[0m 0.5981  \u001b[0m | \u001b[0m 0.03023 \u001b[0m | \u001b[0m 0.1259  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 183     \u001b[0m | \u001b[0m 0.002605\u001b[0m | \u001b[0m 0.8851  \u001b[0m | \u001b[0m 0.9804  \u001b[0m | \u001b[0m 0.4985  \u001b[0m | \u001b[0m 0.1271  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 184     \u001b[0m | \u001b[0m 0.002625\u001b[0m | \u001b[0m 0.1918  \u001b[0m | \u001b[0m 0.8061  \u001b[0m | \u001b[0m 0.3371  \u001b[0m | \u001b[0m 0.1054  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 185     \u001b[0m | \u001b[0m 0.002759\u001b[0m | \u001b[0m 0.7799  \u001b[0m | \u001b[0m 0.9822  \u001b[0m | \u001b[0m 0.4652  \u001b[0m | \u001b[0m 0.01703 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 186     \u001b[0m | \u001b[0m 0.002306\u001b[0m | \u001b[0m 0.2824  \u001b[0m | \u001b[0m 0.03747 \u001b[0m | \u001b[0m 0.7213  \u001b[0m | \u001b[0m 0.1276  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 187     \u001b[0m | \u001b[0m 0.002796\u001b[0m | \u001b[0m 0.9375  \u001b[0m | \u001b[0m 0.3132  \u001b[0m | \u001b[0m 0.635   \u001b[0m | \u001b[0m 0.1178  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 188     \u001b[0m | \u001b[0m 0.002651\u001b[0m | \u001b[0m 0.8739  \u001b[0m | \u001b[0m 0.9557  \u001b[0m | \u001b[0m 0.6511  \u001b[0m | \u001b[0m 0.132   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 189     \u001b[0m | \u001b[0m 0.002665\u001b[0m | \u001b[0m 0.6842  \u001b[0m | \u001b[0m 0.8382  \u001b[0m | \u001b[0m 0.8457  \u001b[0m | \u001b[0m 0.005289\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 190     \u001b[0m | \u001b[0m 0.002489\u001b[0m | \u001b[0m 0.1041  \u001b[0m | \u001b[0m 0.9957  \u001b[0m | \u001b[0m 0.7379  \u001b[0m | \u001b[0m 0.1805  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 191     \u001b[0m | \u001b[0m 0.002398\u001b[0m | \u001b[0m 0.4962  \u001b[0m | \u001b[0m 0.1255  \u001b[0m | \u001b[0m 0.9882  \u001b[0m | \u001b[0m 0.1932  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 192     \u001b[0m | \u001b[0m 0.002737\u001b[0m | \u001b[0m 0.9962  \u001b[0m | \u001b[0m 0.8358  \u001b[0m | \u001b[0m 0.4507  \u001b[0m | \u001b[0m 0.1283  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 193     \u001b[0m | \u001b[0m 0.002268\u001b[0m | \u001b[0m 0.1134  \u001b[0m | \u001b[0m 0.1918  \u001b[0m | \u001b[0m 0.09576 \u001b[0m | \u001b[0m 0.187   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 194     \u001b[0m | \u001b[0m 0.002336\u001b[0m | \u001b[0m 0.2011  \u001b[0m | \u001b[0m 0.05608 \u001b[0m | \u001b[0m 0.7775  \u001b[0m | \u001b[0m 0.1143  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 195     \u001b[0m | \u001b[0m 0.002117\u001b[0m | \u001b[0m 0.06217 \u001b[0m | \u001b[0m 0.9906  \u001b[0m | \u001b[0m 0.1702  \u001b[0m | \u001b[0m 0.1962  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 196     \u001b[0m | \u001b[0m 0.002555\u001b[0m | \u001b[0m 0.8066  \u001b[0m | \u001b[0m 0.6963  \u001b[0m | \u001b[0m 0.8718  \u001b[0m | \u001b[0m 0.1498  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 197     \u001b[0m | \u001b[0m 0.002457\u001b[0m | \u001b[0m 0.9814  \u001b[0m | \u001b[0m 0.1405  \u001b[0m | \u001b[0m 0.9467  \u001b[0m | \u001b[0m 0.0927  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 198     \u001b[0m | \u001b[0m 0.002576\u001b[0m | \u001b[0m 0.6264  \u001b[0m | \u001b[0m 0.8679  \u001b[0m | \u001b[0m 0.05604 \u001b[0m | \u001b[0m 0.1206  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 199     \u001b[0m | \u001b[0m 0.002234\u001b[0m | \u001b[0m 0.8214  \u001b[0m | \u001b[0m 0.005642\u001b[0m | \u001b[0m 0.5293  \u001b[0m | \u001b[0m 0.1604  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 200     \u001b[0m | \u001b[0m 0.002692\u001b[0m | \u001b[0m 0.6623  \u001b[0m | \u001b[0m 0.3193  \u001b[0m | \u001b[0m 0.5168  \u001b[0m | \u001b[0m 0.1928  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 201     \u001b[0m | \u001b[0m 0.002569\u001b[0m | \u001b[0m 0.4546  \u001b[0m | \u001b[0m 0.6433  \u001b[0m | \u001b[0m 0.7553  \u001b[0m | \u001b[0m 0.1861  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "| \u001b[0m 202     \u001b[0m | \u001b[0m 0.002441\u001b[0m | \u001b[0m 0.9044  \u001b[0m | \u001b[0m 0.7801  \u001b[0m | \u001b[0m 0.8794  \u001b[0m | \u001b[0m 0.1713  \u001b[0m |\n",
      "=========================================================================\n",
      "{'target': 0.003057055181762737, 'params': {'bagging_fraction': 0.036200827769789064, 'feature_fraction': 0.6044932041352019, 'lambda_l2': 0.4966203632220777, 'learning_rate': 0.1718972170675549}}\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize as optimize\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "params = {\"learning_rate\": (0.0001, 0.2),\n",
    "            \"feature_fraction\" : (0.0001, 1),\n",
    "            \"bagging_fraction\" : (0.0001, 1),\n",
    "            \"lambda_l2\" : (0 , 1)\n",
    "            }\n",
    "\n",
    "capacity = 1000\n",
    "train_max = 1\n",
    "train_min = 0\n",
    "\n",
    "bo=BayesianOptimization(f=LGB_cv, \n",
    "                    pbounds=params, \n",
    "                    verbose=2, \n",
    "                    random_state=80)\n",
    "\n",
    "\n",
    "bo.maximize(init_points=2, n_iter=200, acq='ei', xi=0.01)\n",
    "\n",
    "print(bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x287ffed9b50>]"
      ]
     },
     "execution_count": 1229,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003057055181762737"
      ]
     },
     "execution_count": 1233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_1[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1245,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'bagging_fraction': 0.41020216462053993,\n",
    " 'feature_fraction': 0.5581894737053765,\n",
    " 'lambda_l2': 0.3966173309760741,\n",
    " 'learning_rate': 0.06895846652196458}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000779 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 45385, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 40.555161\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's score: 12.3417\n"
     ]
    }
   ],
   "source": [
    "capacity = 1000\n",
    "fine_dust_dangjin_model = lgb.train(params, \n",
    "                           train_dataset, \n",
    "                           10000, \n",
    "                           val_dataset, \n",
    "                           feval= nmae_10_lgb, \n",
    "                           verbose_eval=500, \n",
    "                           early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fine_dust_dangjin_model.pkl']"
      ]
     },
     "execution_count": 1246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(fine_dust_dangjin_model,\"fine_dust_dangjin_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1247,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fine_dust_dangjin_model.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1248,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x287f2da5ee0>]"
      ]
     },
     "execution_count": 1248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(y_pred)\n",
    "plt.plot(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.60895215],\n",
       "       [0.60895215, 1.        ]])"
      ]
     },
     "execution_count": 1179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(y_pred, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temperature</th>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humidity</th>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindSpeed</th>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud</th>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_1</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_2</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fall_prob</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sun_radio</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "year         277\n",
       "month        359\n",
       "day          465\n",
       "hour         121\n",
       "Temperature  289\n",
       "Humidity     274\n",
       "WindSpeed    279\n",
       "Cloud        162\n",
       "type_0         9\n",
       "type_1        13\n",
       "type_2         6\n",
       "type_3         2\n",
       "type_4         0\n",
       "fall_prob    137\n",
       "sun_radio     37"
      ]
     },
     "execution_count": 1201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(fine_dust_dangjin_model.feature_importance(),\n",
    "          ['year', \n",
    "           'month', \n",
    "            'day', \n",
    "            'hour', \n",
    "            'Temperature',\n",
    "            'Humidity', \n",
    "            'WindSpeed', \n",
    "            'Cloud',\n",
    "            'type_0',\n",
    "            'type_1',\n",
    "            'type_2',\n",
    "            'type_3',\n",
    "            'type_4',\n",
    "            'fall_prob',\n",
    "             \"sun_radio\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - 울산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmae_10_lgb(y_pred, dataset):\n",
    "    y_true = dataset.get_label()\n",
    "    \n",
    "    mae = sklearn.metrics.mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    return 'score', mae, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, val_x, val_y = train_datast_dust(fine_dust_ulsan[[\"Forecast time\",\"PM10\"]], \n",
    "                                              dangjin_fcst, \n",
    "                                              target='ulsan', \n",
    "                                              sun_target = \"sun_ulsan\",\n",
    "                                             rain_target = \"ulsan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1251,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y[:,-1]\n",
    "val_y = val_y[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_x[:,0] = np.array(pd.Series(train_x[:,0]).astype(\"str\").apply(lambda x : x[2:4]).astype(\"int\"))\\nval_x[:,0] = np.array(pd.Series(val_x[:,0]).astype(\"str\").apply(lambda x : x[2:4]).astype(\"int\"))\\n\\ntrain_min_dangjin = -9\\ntrain_max_dangjin = 100\\n\\ntrain_x_scaled = (np.array(train_x) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)\\nval_x_scaled = (np.array(val_x) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)\\n\\nae_result = Auto_Encoder_dangjin(train_x_scaled) * (train_max_dangjin - train_min_dangjin) + train_min_dangjin\\n\\ntrain_x = np.hstack([train_x, ae_result])\\n\\nae_result = Auto_Encoder_dangjin(val_x_scaled) * (train_max_dangjin - train_min_dangjin) + train_min_dangjin\\n\\nval_x = np.hstack([val_x, ae_result])\\n'"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_x[:,0] = np.array(pd.Series(train_x[:,0]).astype(\"str\").apply(lambda x : x[2:4]).astype(\"int\"))\n",
    "val_x[:,0] = np.array(pd.Series(val_x[:,0]).astype(\"str\").apply(lambda x : x[2:4]).astype(\"int\"))\n",
    "\n",
    "train_min_dangjin = -9\n",
    "train_max_dangjin = 100\n",
    "\n",
    "train_x_scaled = (np.array(train_x) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)\n",
    "val_x_scaled = (np.array(val_x) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)\n",
    "\n",
    "ae_result = Auto_Encoder_dangjin(train_x_scaled) * (train_max_dangjin - train_min_dangjin) + train_min_dangjin\n",
    "\n",
    "train_x = np.hstack([train_x, ae_result])\n",
    "\n",
    "ae_result = Auto_Encoder_dangjin(val_x_scaled) * (train_max_dangjin - train_min_dangjin) + train_min_dangjin\n",
    "\n",
    "val_x = np.hstack([val_x, ae_result])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1252,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = lgb.Dataset(train_x, train_y)\n",
    "val_dataset = lgb.Dataset(val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def LGB_cv(learning_rate, \n",
    "           feature_fraction, \n",
    "           bagging_fraction,\n",
    "           lambda_l2,\n",
    "           silent=True, \n",
    "           nthread=-1):\n",
    "\n",
    "    params = {\"learning_rate\": learning_rate,\n",
    "                \"feature_fraction\" : feature_fraction,\n",
    "                \"bagging_fraction\" : bagging_fraction, \n",
    "               \"lambda_l2\" : lambda_l2,\n",
    "               \"objective\" :  \"regression\",\n",
    "              \"nthread\" : nthread\n",
    "                }\n",
    "    \n",
    "    model = lgb.train(params,\n",
    "                      train_dataset,\n",
    "                      feval = sklearn.metrics.mean_absolute_error\n",
    "                     )\n",
    "\n",
    "    global y_pred\n",
    "    \n",
    "    y_pred = model.predict(val_x)\n",
    "\n",
    "    mae = mean_squared_error(val_y, y_pred)\n",
    "\n",
    "    return 1/mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | lambda_l2 | learni... |\n",
      "-------------------------------------------------------------------------\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.003697\u001b[0m | \u001b[0m 0.2936  \u001b[0m | \u001b[0m 0.4304  \u001b[0m | \u001b[0m 0.7837  \u001b[0m | \u001b[0m 0.04886 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.003779\u001b[0m | \u001b[95m 0.3321  \u001b[0m | \u001b[95m 0.7928  \u001b[0m | \u001b[95m 0.7267  \u001b[0m | \u001b[95m 0.1942  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.003158\u001b[0m | \u001b[0m 0.2709  \u001b[0m | \u001b[0m 0.08986 \u001b[0m | \u001b[0m 0.8599  \u001b[0m | \u001b[0m 0.1006  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.002796\u001b[0m | \u001b[0m 0.3175  \u001b[0m | \u001b[0m 0.2859  \u001b[0m | \u001b[0m 0.347   \u001b[0m | \u001b[0m 0.007252\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.00347 \u001b[0m | \u001b[0m 0.7086  \u001b[0m | \u001b[0m 0.9413  \u001b[0m | \u001b[0m 0.8771  \u001b[0m | \u001b[0m 0.0185  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.003602\u001b[0m | \u001b[0m 0.9888  \u001b[0m | \u001b[0m 0.7208  \u001b[0m | \u001b[0m 0.634   \u001b[0m | \u001b[0m 0.04072 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.003396\u001b[0m | \u001b[0m 0.9126  \u001b[0m | \u001b[0m 0.2649  \u001b[0m | \u001b[0m 0.2021  \u001b[0m | \u001b[0m 0.1628  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.003751\u001b[0m | \u001b[0m 0.3171  \u001b[0m | \u001b[0m 0.9429  \u001b[0m | \u001b[0m 0.1936  \u001b[0m | \u001b[0m 0.08713 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.003684\u001b[0m | \u001b[0m 0.2082  \u001b[0m | \u001b[0m 0.5295  \u001b[0m | \u001b[0m 0.5894  \u001b[0m | \u001b[0m 0.03621 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.002931\u001b[0m | \u001b[0m 0.2135  \u001b[0m | \u001b[0m 0.2129  \u001b[0m | \u001b[0m 0.9711  \u001b[0m | \u001b[0m 0.01307 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.00361 \u001b[0m | \u001b[0m 0.314   \u001b[0m | \u001b[0m 0.7748  \u001b[0m | \u001b[0m 0.2483  \u001b[0m | \u001b[0m 0.02255 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.003881\u001b[0m | \u001b[95m 0.8702  \u001b[0m | \u001b[95m 0.9862  \u001b[0m | \u001b[95m 0.04907 \u001b[0m | \u001b[95m 0.1838  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.003234\u001b[0m | \u001b[0m 0.2004  \u001b[0m | \u001b[0m 0.299   \u001b[0m | \u001b[0m 0.3377  \u001b[0m | \u001b[0m 0.1753  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.002708\u001b[0m | \u001b[0m 0.9954  \u001b[0m | \u001b[0m 0.0698  \u001b[0m | \u001b[0m 0.9954  \u001b[0m | \u001b[0m 0.02355 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.003775\u001b[0m | \u001b[0m 0.000984\u001b[0m | \u001b[0m 0.9434  \u001b[0m | \u001b[0m 0.9849  \u001b[0m | \u001b[0m 0.05834 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[95m 16      \u001b[0m | \u001b[95m 0.003939\u001b[0m | \u001b[95m 0.6063  \u001b[0m | \u001b[95m 0.7582  \u001b[0m | \u001b[95m 0.2204  \u001b[0m | \u001b[95m 0.1393  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.003174\u001b[0m | \u001b[0m 0.04493 \u001b[0m | \u001b[0m 0.05162 \u001b[0m | \u001b[0m 0.005482\u001b[0m | \u001b[0m 0.1162  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.003617\u001b[0m | \u001b[0m 0.9605  \u001b[0m | \u001b[0m 0.4928  \u001b[0m | \u001b[0m 0.7361  \u001b[0m | \u001b[0m 0.03652 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.003702\u001b[0m | \u001b[0m 0.3019  \u001b[0m | \u001b[0m 0.5444  \u001b[0m | \u001b[0m 0.4164  \u001b[0m | \u001b[0m 0.06066 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.003712\u001b[0m | \u001b[0m 0.02068 \u001b[0m | \u001b[0m 0.7323  \u001b[0m | \u001b[0m 0.03431 \u001b[0m | \u001b[0m 0.1848  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.003883\u001b[0m | \u001b[0m 0.5667  \u001b[0m | \u001b[0m 0.7706  \u001b[0m | \u001b[0m 0.2213  \u001b[0m | \u001b[0m 0.1669  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.002634\u001b[0m | \u001b[0m 0.6606  \u001b[0m | \u001b[0m 0.01717 \u001b[0m | \u001b[0m 0.0197  \u001b[0m | \u001b[0m 0.01644 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.003647\u001b[0m | \u001b[0m 0.000369\u001b[0m | \u001b[0m 0.9883  \u001b[0m | \u001b[0m 0.5185  \u001b[0m | \u001b[0m 0.1173  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.00315 \u001b[0m | \u001b[0m 0.6503  \u001b[0m | \u001b[0m 0.001365\u001b[0m | \u001b[0m 0.5518  \u001b[0m | \u001b[0m 0.1887  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.003873\u001b[0m | \u001b[0m 0.9969  \u001b[0m | \u001b[0m 0.9487  \u001b[0m | \u001b[0m 0.9466  \u001b[0m | \u001b[0m 0.1853  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.003381\u001b[0m | \u001b[0m 0.6836  \u001b[0m | \u001b[0m 0.5078  \u001b[0m | \u001b[0m 0.9963  \u001b[0m | \u001b[0m 0.1796  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.003176\u001b[0m | \u001b[0m 0.001285\u001b[0m | \u001b[0m 0.2741  \u001b[0m | \u001b[0m 0.7505  \u001b[0m | \u001b[0m 0.1349  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.003665\u001b[0m | \u001b[0m 0.7614  \u001b[0m | \u001b[0m 0.3834  \u001b[0m | \u001b[0m 0.2771  \u001b[0m | \u001b[0m 0.05635 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.003632\u001b[0m | \u001b[0m 0.9966  \u001b[0m | \u001b[0m 0.5128  \u001b[0m | \u001b[0m 0.01288 \u001b[0m | \u001b[0m 0.05798 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.003585\u001b[0m | \u001b[0m 0.6705  \u001b[0m | \u001b[0m 0.9881  \u001b[0m | \u001b[0m 0.5009  \u001b[0m | \u001b[0m 0.1919  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.003836\u001b[0m | \u001b[0m 0.9749  \u001b[0m | \u001b[0m 0.9431  \u001b[0m | \u001b[0m 0.9594  \u001b[0m | \u001b[0m 0.1624  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.002778\u001b[0m | \u001b[0m 0.005431\u001b[0m | \u001b[0m 0.01858 \u001b[0m | \u001b[0m 0.4177  \u001b[0m | \u001b[0m 0.03078 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.002691\u001b[0m | \u001b[0m 0.9865  \u001b[0m | \u001b[0m 0.003205\u001b[0m | \u001b[0m 0.3975  \u001b[0m | \u001b[0m 0.02191 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.003534\u001b[0m | \u001b[0m 0.6089  \u001b[0m | \u001b[0m 0.7913  \u001b[0m | \u001b[0m 0.6678  \u001b[0m | \u001b[0m 0.1156  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.00371 \u001b[0m | \u001b[0m 0.6384  \u001b[0m | \u001b[0m 0.5776  \u001b[0m | \u001b[0m 0.7788  \u001b[0m | \u001b[0m 0.1932  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.003091\u001b[0m | \u001b[0m 0.2626  \u001b[0m | \u001b[0m 0.31    \u001b[0m | \u001b[0m 0.06895 \u001b[0m | \u001b[0m 0.1937  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.003688\u001b[0m | \u001b[0m 0.7295  \u001b[0m | \u001b[0m 0.5017  \u001b[0m | \u001b[0m 0.6604  \u001b[0m | \u001b[0m 0.1096  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.003793\u001b[0m | \u001b[0m 0.7308  \u001b[0m | \u001b[0m 0.3485  \u001b[0m | \u001b[0m 0.4699  \u001b[0m | \u001b[0m 0.162   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.003873\u001b[0m | \u001b[0m 0.9903  \u001b[0m | \u001b[0m 0.9435  \u001b[0m | \u001b[0m 0.9721  \u001b[0m | \u001b[0m 0.1716  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.003708\u001b[0m | \u001b[0m 0.3049  \u001b[0m | \u001b[0m 0.4541  \u001b[0m | \u001b[0m 0.9078  \u001b[0m | \u001b[0m 0.0551  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.003878\u001b[0m | \u001b[0m 0.296   \u001b[0m | \u001b[0m 0.7468  \u001b[0m | \u001b[0m 0.4234  \u001b[0m | \u001b[0m 0.127   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.003599\u001b[0m | \u001b[0m 0.3347  \u001b[0m | \u001b[0m 0.6639  \u001b[0m | \u001b[0m 0.7108  \u001b[0m | \u001b[0m 0.02559 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.003797\u001b[0m | \u001b[0m 0.4144  \u001b[0m | \u001b[0m 0.9163  \u001b[0m | \u001b[0m 0.7482  \u001b[0m | \u001b[0m 0.07028 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.003713\u001b[0m | \u001b[0m 0.1869  \u001b[0m | \u001b[0m 0.949   \u001b[0m | \u001b[0m 0.781   \u001b[0m | \u001b[0m 0.07121 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.003732\u001b[0m | \u001b[0m 0.1614  \u001b[0m | \u001b[0m 0.5887  \u001b[0m | \u001b[0m 0.4702  \u001b[0m | \u001b[0m 0.08927 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.003347\u001b[0m | \u001b[0m 0.8173  \u001b[0m | \u001b[0m 0.1579  \u001b[0m | \u001b[0m 0.5472  \u001b[0m | \u001b[0m 0.1118  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.003558\u001b[0m | \u001b[0m 0.6419  \u001b[0m | \u001b[0m 0.4472  \u001b[0m | \u001b[0m 0.02502 \u001b[0m | \u001b[0m 0.1916  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.003657\u001b[0m | \u001b[0m 0.01783 \u001b[0m | \u001b[0m 0.506   \u001b[0m | \u001b[0m 0.661   \u001b[0m | \u001b[0m 0.06082 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.003447\u001b[0m | \u001b[0m 0.4118  \u001b[0m | \u001b[0m 0.8674  \u001b[0m | \u001b[0m 0.5631  \u001b[0m | \u001b[0m 0.01835 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.003241\u001b[0m | \u001b[0m 0.491   \u001b[0m | \u001b[0m 0.119   \u001b[0m | \u001b[0m 0.2705  \u001b[0m | \u001b[0m 0.1893  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.003586\u001b[0m | \u001b[0m 0.9904  \u001b[0m | \u001b[0m 0.7947  \u001b[0m | \u001b[0m 0.6984  \u001b[0m | \u001b[0m 0.1159  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.003913\u001b[0m | \u001b[0m 0.7329  \u001b[0m | \u001b[0m 0.8041  \u001b[0m | \u001b[0m 0.9945  \u001b[0m | \u001b[0m 0.1735  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.003568\u001b[0m | \u001b[0m 0.6577  \u001b[0m | \u001b[0m 0.5295  \u001b[0m | \u001b[0m 0.6614  \u001b[0m | \u001b[0m 0.1206  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.003574\u001b[0m | \u001b[0m 0.5697  \u001b[0m | \u001b[0m 0.5311  \u001b[0m | \u001b[0m 0.9543  \u001b[0m | \u001b[0m 0.1867  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.003317\u001b[0m | \u001b[0m 0.5474  \u001b[0m | \u001b[0m 0.3145  \u001b[0m | \u001b[0m 0.1504  \u001b[0m | \u001b[0m 0.03921 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.003787\u001b[0m | \u001b[0m 0.4751  \u001b[0m | \u001b[0m 0.8884  \u001b[0m | \u001b[0m 0.4868  \u001b[0m | \u001b[0m 0.06305 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.003505\u001b[0m | \u001b[0m 0.982   \u001b[0m | \u001b[0m 0.9699  \u001b[0m | \u001b[0m 0.3207  \u001b[0m | \u001b[0m 0.02169 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.002599\u001b[0m | \u001b[0m 0.5734  \u001b[0m | \u001b[0m 0.009413\u001b[0m | \u001b[0m 0.958   \u001b[0m | \u001b[0m 0.01326 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.003803\u001b[0m | \u001b[0m 0.9862  \u001b[0m | \u001b[0m 0.9377  \u001b[0m | \u001b[0m 0.9327  \u001b[0m | \u001b[0m 0.1815  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.003508\u001b[0m | \u001b[0m 0.01394 \u001b[0m | \u001b[0m 0.6211  \u001b[0m | \u001b[0m 0.9858  \u001b[0m | \u001b[0m 0.1787  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.003353\u001b[0m | \u001b[0m 0.5911  \u001b[0m | \u001b[0m 0.9288  \u001b[0m | \u001b[0m 0.001938\u001b[0m | \u001b[0m 0.01564 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.003259\u001b[0m | \u001b[0m 0.03611 \u001b[0m | \u001b[0m 0.9804  \u001b[0m | \u001b[0m 0.1035  \u001b[0m | \u001b[0m 0.01376 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.003698\u001b[0m | \u001b[0m 0.9909  \u001b[0m | \u001b[0m 0.6243  \u001b[0m | \u001b[0m 0.3603  \u001b[0m | \u001b[0m 0.195   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.003143\u001b[0m | \u001b[0m 0.01941 \u001b[0m | \u001b[0m 0.01071 \u001b[0m | \u001b[0m 0.9774  \u001b[0m | \u001b[0m 0.1941  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.003671\u001b[0m | \u001b[0m 0.9635  \u001b[0m | \u001b[0m 0.9354  \u001b[0m | \u001b[0m 0.9298  \u001b[0m | \u001b[0m 0.1877  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.00289 \u001b[0m | \u001b[0m 0.03346 \u001b[0m | \u001b[0m 0.4743  \u001b[0m | \u001b[0m 0.02626 \u001b[0m | \u001b[0m 0.007051\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.003678\u001b[0m | \u001b[0m 0.3074  \u001b[0m | \u001b[0m 0.9782  \u001b[0m | \u001b[0m 0.9933  \u001b[0m | \u001b[0m 0.1854  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.002929\u001b[0m | \u001b[0m 0.9817  \u001b[0m | \u001b[0m 0.005787\u001b[0m | \u001b[0m 0.04465 \u001b[0m | \u001b[0m 0.04862 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.003493\u001b[0m | \u001b[0m 0.02089 \u001b[0m | \u001b[0m 0.7426  \u001b[0m | \u001b[0m 0.03529 \u001b[0m | \u001b[0m 0.1711  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.003629\u001b[0m | \u001b[0m 0.4974  \u001b[0m | \u001b[0m 0.6528  \u001b[0m | \u001b[0m 0.8476  \u001b[0m | \u001b[0m 0.1137  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.00331 \u001b[0m | \u001b[0m 0.868   \u001b[0m | \u001b[0m 0.287   \u001b[0m | \u001b[0m 0.3702  \u001b[0m | \u001b[0m 0.07717 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.002845\u001b[0m | \u001b[0m 0.9706  \u001b[0m | \u001b[0m 0.6347  \u001b[0m | \u001b[0m 0.9829  \u001b[0m | \u001b[0m 0.005362\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.003713\u001b[0m | \u001b[0m 0.2758  \u001b[0m | \u001b[0m 0.6547  \u001b[0m | \u001b[0m 0.000488\u001b[0m | \u001b[0m 0.1937  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.003203\u001b[0m | \u001b[0m 0.9239  \u001b[0m | \u001b[0m 0.7569  \u001b[0m | \u001b[0m 0.02236 \u001b[0m | \u001b[0m 0.01114 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.002842\u001b[0m | \u001b[0m 0.272   \u001b[0m | \u001b[0m 0.7403  \u001b[0m | \u001b[0m 0.9862  \u001b[0m | \u001b[0m 0.00506 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.003121\u001b[0m | \u001b[0m 0.7199  \u001b[0m | \u001b[0m 0.6472  \u001b[0m | \u001b[0m 0.3964  \u001b[0m | \u001b[0m 0.01049 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.003576\u001b[0m | \u001b[0m 0.3626  \u001b[0m | \u001b[0m 0.8296  \u001b[0m | \u001b[0m 0.392   \u001b[0m | \u001b[0m 0.132   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.003377\u001b[0m | \u001b[0m 0.1602  \u001b[0m | \u001b[0m 0.2341  \u001b[0m | \u001b[0m 0.8342  \u001b[0m | \u001b[0m 0.1034  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.003684\u001b[0m | \u001b[0m 0.008979\u001b[0m | \u001b[0m 0.5938  \u001b[0m | \u001b[0m 0.2878  \u001b[0m | \u001b[0m 0.1909  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.003407\u001b[0m | \u001b[0m 0.0345  \u001b[0m | \u001b[0m 0.7252  \u001b[0m | \u001b[0m 0.6861  \u001b[0m | \u001b[0m 0.1892  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.002998\u001b[0m | \u001b[0m 0.4948  \u001b[0m | \u001b[0m 0.2901  \u001b[0m | \u001b[0m 0.7351  \u001b[0m | \u001b[0m 0.1943  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.003558\u001b[0m | \u001b[0m 0.6812  \u001b[0m | \u001b[0m 0.6973  \u001b[0m | \u001b[0m 0.2467  \u001b[0m | \u001b[0m 0.1421  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[95m 83      \u001b[0m | \u001b[95m 0.004277\u001b[0m | \u001b[95m 0.3064  \u001b[0m | \u001b[95m 0.9841  \u001b[0m | \u001b[95m 0.9846  \u001b[0m | \u001b[95m 0.1915  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.003665\u001b[0m | \u001b[0m 0.5885  \u001b[0m | \u001b[0m 0.7957  \u001b[0m | \u001b[0m 0.2167  \u001b[0m | \u001b[0m 0.1226  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.003434\u001b[0m | \u001b[0m 0.6234  \u001b[0m | \u001b[0m 0.5786  \u001b[0m | \u001b[0m 0.7772  \u001b[0m | \u001b[0m 0.1857  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.003731\u001b[0m | \u001b[0m 0.6999  \u001b[0m | \u001b[0m 0.9185  \u001b[0m | \u001b[0m 0.9248  \u001b[0m | \u001b[0m 0.06036 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.003686\u001b[0m | \u001b[0m 0.9771  \u001b[0m | \u001b[0m 0.9846  \u001b[0m | \u001b[0m 0.966   \u001b[0m | \u001b[0m 0.1984  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.003937\u001b[0m | \u001b[0m 0.2963  \u001b[0m | \u001b[0m 0.9985  \u001b[0m | \u001b[0m 0.9694  \u001b[0m | \u001b[0m 0.1487  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.003203\u001b[0m | \u001b[0m 0.1628  \u001b[0m | \u001b[0m 0.3384  \u001b[0m | \u001b[0m 0.6803  \u001b[0m | \u001b[0m 0.1367  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.003957\u001b[0m | \u001b[0m 0.6405  \u001b[0m | \u001b[0m 0.7653  \u001b[0m | \u001b[0m 0.2572  \u001b[0m | \u001b[0m 0.1779  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.003757\u001b[0m | \u001b[0m 0.2911  \u001b[0m | \u001b[0m 0.9537  \u001b[0m | \u001b[0m 0.942   \u001b[0m | \u001b[0m 0.1956  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.003766\u001b[0m | \u001b[0m 0.608   \u001b[0m | \u001b[0m 0.7608  \u001b[0m | \u001b[0m 0.2767  \u001b[0m | \u001b[0m 0.1273  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.003146\u001b[0m | \u001b[0m 0.4765  \u001b[0m | \u001b[0m 0.3249  \u001b[0m | \u001b[0m 0.4645  \u001b[0m | \u001b[0m 0.1656  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.003629\u001b[0m | \u001b[0m 0.321   \u001b[0m | \u001b[0m 0.7669  \u001b[0m | \u001b[0m 0.2495  \u001b[0m | \u001b[0m 0.02876 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.00327 \u001b[0m | \u001b[0m 0.9908  \u001b[0m | \u001b[0m 0.2325  \u001b[0m | \u001b[0m 0.8237  \u001b[0m | \u001b[0m 0.03129 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.003953\u001b[0m | \u001b[0m 0.6812  \u001b[0m | \u001b[0m 0.7781  \u001b[0m | \u001b[0m 0.2452  \u001b[0m | \u001b[0m 0.1267  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.003506\u001b[0m | \u001b[0m 0.6225  \u001b[0m | \u001b[0m 0.6834  \u001b[0m | \u001b[0m 0.2337  \u001b[0m | \u001b[0m 0.1866  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.003674\u001b[0m | \u001b[0m 0.2156  \u001b[0m | \u001b[0m 0.5317  \u001b[0m | \u001b[0m 0.5832  \u001b[0m | \u001b[0m 0.0403  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.003896\u001b[0m | \u001b[0m 0.4174  \u001b[0m | \u001b[0m 0.8097  \u001b[0m | \u001b[0m 0.4758  \u001b[0m | \u001b[0m 0.1558  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.003625\u001b[0m | \u001b[0m 0.1543  \u001b[0m | \u001b[0m 0.7222  \u001b[0m | \u001b[0m 0.9362  \u001b[0m | \u001b[0m 0.153   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 0.003519\u001b[0m | \u001b[0m 0.2227  \u001b[0m | \u001b[0m 0.6812  \u001b[0m | \u001b[0m 0.2642  \u001b[0m | \u001b[0m 0.07993 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 0.003394\u001b[0m | \u001b[0m 0.6951  \u001b[0m | \u001b[0m 0.1332  \u001b[0m | \u001b[0m 0.101   \u001b[0m | \u001b[0m 0.09301 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m 0.003687\u001b[0m | \u001b[0m 0.3486  \u001b[0m | \u001b[0m 0.9912  \u001b[0m | \u001b[0m 0.9158  \u001b[0m | \u001b[0m 0.1633  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m 0.003666\u001b[0m | \u001b[0m 0.6587  \u001b[0m | \u001b[0m 0.8098  \u001b[0m | \u001b[0m 0.2987  \u001b[0m | \u001b[0m 0.1591  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m 0.003534\u001b[0m | \u001b[0m 0.6589  \u001b[0m | \u001b[0m 0.9823  \u001b[0m | \u001b[0m 0.5117  \u001b[0m | \u001b[0m 0.1915  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m 0.003831\u001b[0m | \u001b[0m 0.655   \u001b[0m | \u001b[0m 0.7387  \u001b[0m | \u001b[0m 0.2045  \u001b[0m | \u001b[0m 0.08308 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 107     \u001b[0m | \u001b[0m 0.003651\u001b[0m | \u001b[0m 0.584   \u001b[0m | \u001b[0m 0.7029  \u001b[0m | \u001b[0m 0.1609  \u001b[0m | \u001b[0m 0.1131  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 108     \u001b[0m | \u001b[0m 0.003721\u001b[0m | \u001b[0m 0.6608  \u001b[0m | \u001b[0m 0.8288  \u001b[0m | \u001b[0m 0.214   \u001b[0m | \u001b[0m 0.1647  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 109     \u001b[0m | \u001b[0m 0.003739\u001b[0m | \u001b[0m 0.65    \u001b[0m | \u001b[0m 0.7998  \u001b[0m | \u001b[0m 0.2619  \u001b[0m | \u001b[0m 0.05092 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 110     \u001b[0m | \u001b[0m 0.003253\u001b[0m | \u001b[0m 0.496   \u001b[0m | \u001b[0m 0.4236  \u001b[0m | \u001b[0m 0.4565  \u001b[0m | \u001b[0m 0.158   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 111     \u001b[0m | \u001b[0m 0.00367 \u001b[0m | \u001b[0m 0.7029  \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 0.159   \u001b[0m | \u001b[0m 0.1446  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 112     \u001b[0m | \u001b[0m 0.003669\u001b[0m | \u001b[0m 0.223   \u001b[0m | \u001b[0m 0.9767  \u001b[0m | \u001b[0m 0.9569  \u001b[0m | \u001b[0m 0.1741  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 113     \u001b[0m | \u001b[0m 0.003737\u001b[0m | \u001b[0m 0.732   \u001b[0m | \u001b[0m 0.7734  \u001b[0m | \u001b[0m 0.2467  \u001b[0m | \u001b[0m 0.1819  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 114     \u001b[0m | \u001b[0m 0.003548\u001b[0m | \u001b[0m 0.3914  \u001b[0m | \u001b[0m 0.9275  \u001b[0m | \u001b[0m 0.02195 \u001b[0m | \u001b[0m 0.02148 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 115     \u001b[0m | \u001b[0m 0.003346\u001b[0m | \u001b[0m 0.9827  \u001b[0m | \u001b[0m 0.1872  \u001b[0m | \u001b[0m 0.1924  \u001b[0m | \u001b[0m 0.04642 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 116     \u001b[0m | \u001b[0m 0.003751\u001b[0m | \u001b[0m 0.2034  \u001b[0m | \u001b[0m 0.7038  \u001b[0m | \u001b[0m 0.7125  \u001b[0m | \u001b[0m 0.0549  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 117     \u001b[0m | \u001b[0m 0.003832\u001b[0m | \u001b[0m 0.4679  \u001b[0m | \u001b[0m 0.8025  \u001b[0m | \u001b[0m 0.4668  \u001b[0m | \u001b[0m 0.091   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 118     \u001b[0m | \u001b[0m 0.003726\u001b[0m | \u001b[0m 0.5422  \u001b[0m | \u001b[0m 0.4151  \u001b[0m | \u001b[0m 0.9727  \u001b[0m | \u001b[0m 0.1974  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 119     \u001b[0m | \u001b[0m 0.003828\u001b[0m | \u001b[0m 0.389   \u001b[0m | \u001b[0m 0.8429  \u001b[0m | \u001b[0m 0.4768  \u001b[0m | \u001b[0m 0.07665 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 120     \u001b[0m | \u001b[0m 0.003558\u001b[0m | \u001b[0m 0.7428  \u001b[0m | \u001b[0m 0.5919  \u001b[0m | \u001b[0m 0.308   \u001b[0m | \u001b[0m 0.1237  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 121     \u001b[0m | \u001b[0m 0.003643\u001b[0m | \u001b[0m 0.4029  \u001b[0m | \u001b[0m 0.7493  \u001b[0m | \u001b[0m 0.4426  \u001b[0m | \u001b[0m 0.1077  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 122     \u001b[0m | \u001b[0m 0.00355 \u001b[0m | \u001b[0m 0.3452  \u001b[0m | \u001b[0m 0.7802  \u001b[0m | \u001b[0m 0.5104  \u001b[0m | \u001b[0m 0.1411  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 123     \u001b[0m | \u001b[0m 0.003882\u001b[0m | \u001b[0m 0.452   \u001b[0m | \u001b[0m 0.8219  \u001b[0m | \u001b[0m 0.5396  \u001b[0m | \u001b[0m 0.1046  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 124     \u001b[0m | \u001b[0m 0.003691\u001b[0m | \u001b[0m 0.4672  \u001b[0m | \u001b[0m 0.8856  \u001b[0m | \u001b[0m 0.4706  \u001b[0m | \u001b[0m 0.1525  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 125     \u001b[0m | \u001b[0m 0.003741\u001b[0m | \u001b[0m 0.7448  \u001b[0m | \u001b[0m 0.8134  \u001b[0m | \u001b[0m 0.2326  \u001b[0m | \u001b[0m 0.09744 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 126     \u001b[0m | \u001b[0m 0.003629\u001b[0m | \u001b[0m 0.9107  \u001b[0m | \u001b[0m 0.7161  \u001b[0m | \u001b[0m 0.6277  \u001b[0m | \u001b[0m 0.1076  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 127     \u001b[0m | \u001b[0m 0.003647\u001b[0m | \u001b[0m 0.1311  \u001b[0m | \u001b[0m 0.3657  \u001b[0m | \u001b[0m 0.1637  \u001b[0m | \u001b[0m 0.08869 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 128     \u001b[0m | \u001b[0m 0.003881\u001b[0m | \u001b[0m 0.4488  \u001b[0m | \u001b[0m 0.8121  \u001b[0m | \u001b[0m 0.5577  \u001b[0m | \u001b[0m 0.1911  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 129     \u001b[0m | \u001b[0m 0.003657\u001b[0m | \u001b[0m 0.325   \u001b[0m | \u001b[0m 0.9434  \u001b[0m | \u001b[0m 0.2018  \u001b[0m | \u001b[0m 0.09076 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 130     \u001b[0m | \u001b[0m 0.003087\u001b[0m | \u001b[0m 0.1938  \u001b[0m | \u001b[0m 0.2469  \u001b[0m | \u001b[0m 0.5216  \u001b[0m | \u001b[0m 0.01961 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 131     \u001b[0m | \u001b[0m 0.003613\u001b[0m | \u001b[0m 0.9993  \u001b[0m | \u001b[0m 0.4987  \u001b[0m | \u001b[0m 0.006338\u001b[0m | \u001b[0m 0.05983 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 132     \u001b[0m | \u001b[0m 0.003814\u001b[0m | \u001b[0m 0.4034  \u001b[0m | \u001b[0m 0.8798  \u001b[0m | \u001b[0m 0.5324  \u001b[0m | \u001b[0m 0.1821  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 133     \u001b[0m | \u001b[0m 0.003309\u001b[0m | \u001b[0m 0.2406  \u001b[0m | \u001b[0m 0.1889  \u001b[0m | \u001b[0m 0.1318  \u001b[0m | \u001b[0m 0.1298  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 134     \u001b[0m | \u001b[0m 0.003835\u001b[0m | \u001b[0m 0.02239 \u001b[0m | \u001b[0m 0.8042  \u001b[0m | \u001b[0m 0.9593  \u001b[0m | \u001b[0m 0.09643 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 135     \u001b[0m | \u001b[0m 0.00372 \u001b[0m | \u001b[0m 0.5154  \u001b[0m | \u001b[0m 0.7834  \u001b[0m | \u001b[0m 0.4871  \u001b[0m | \u001b[0m 0.1599  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 136     \u001b[0m | \u001b[0m 0.003632\u001b[0m | \u001b[0m 0.4547  \u001b[0m | \u001b[0m 0.7376  \u001b[0m | \u001b[0m 0.5532  \u001b[0m | \u001b[0m 0.1202  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 137     \u001b[0m | \u001b[0m 0.003693\u001b[0m | \u001b[0m 0.413   \u001b[0m | \u001b[0m 0.6957  \u001b[0m | \u001b[0m 0.4611  \u001b[0m | \u001b[0m 0.1494  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 138     \u001b[0m | \u001b[0m 0.003802\u001b[0m | \u001b[0m 0.4732  \u001b[0m | \u001b[0m 0.9038  \u001b[0m | \u001b[0m 0.5962  \u001b[0m | \u001b[0m 0.1539  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 139     \u001b[0m | \u001b[0m 0.003406\u001b[0m | \u001b[0m 0.587   \u001b[0m | \u001b[0m 0.1958  \u001b[0m | \u001b[0m 0.2871  \u001b[0m | \u001b[0m 0.04249 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 140     \u001b[0m | \u001b[0m 0.003683\u001b[0m | \u001b[0m 0.5549  \u001b[0m | \u001b[0m 0.8421  \u001b[0m | \u001b[0m 0.5548  \u001b[0m | \u001b[0m 0.1397  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 141     \u001b[0m | \u001b[0m 0.00362 \u001b[0m | \u001b[0m 0.3458  \u001b[0m | \u001b[0m 0.5979  \u001b[0m | \u001b[0m 0.8789  \u001b[0m | \u001b[0m 0.196   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 142     \u001b[0m | \u001b[0m 0.003435\u001b[0m | \u001b[0m 0.4368  \u001b[0m | \u001b[0m 0.8409  \u001b[0m | \u001b[0m 0.4199  \u001b[0m | \u001b[0m 0.01932 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 143     \u001b[0m | \u001b[0m 0.003593\u001b[0m | \u001b[0m 0.4078  \u001b[0m | \u001b[0m 0.8217  \u001b[0m | \u001b[0m 0.6339  \u001b[0m | \u001b[0m 0.1366  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 144     \u001b[0m | \u001b[0m 0.003654\u001b[0m | \u001b[0m 0.9279  \u001b[0m | \u001b[0m 0.9588  \u001b[0m | \u001b[0m 0.7631  \u001b[0m | \u001b[0m 0.06182 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 145     \u001b[0m | \u001b[0m 0.003583\u001b[0m | \u001b[0m 0.4633  \u001b[0m | \u001b[0m 0.7845  \u001b[0m | \u001b[0m 0.4133  \u001b[0m | \u001b[0m 0.1913  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 146     \u001b[0m | \u001b[0m 0.003832\u001b[0m | \u001b[0m 0.5635  \u001b[0m | \u001b[0m 0.8393  \u001b[0m | \u001b[0m 0.463   \u001b[0m | \u001b[0m 0.08824 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 147     \u001b[0m | \u001b[0m 0.003797\u001b[0m | \u001b[0m 0.5789  \u001b[0m | \u001b[0m 0.971   \u001b[0m | \u001b[0m 0.1011  \u001b[0m | \u001b[0m 0.1611  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 148     \u001b[0m | \u001b[0m 0.003652\u001b[0m | \u001b[0m 0.5603  \u001b[0m | \u001b[0m 0.5011  \u001b[0m | \u001b[0m 0.945   \u001b[0m | \u001b[0m 0.06936 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 149     \u001b[0m | \u001b[0m 0.003855\u001b[0m | \u001b[0m 0.5518  \u001b[0m | \u001b[0m 0.9175  \u001b[0m | \u001b[0m 0.5291  \u001b[0m | \u001b[0m 0.0902  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 150     \u001b[0m | \u001b[0m 0.003748\u001b[0m | \u001b[0m 0.5275  \u001b[0m | \u001b[0m 0.7723  \u001b[0m | \u001b[0m 0.5241  \u001b[0m | \u001b[0m 0.03937 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 151     \u001b[0m | \u001b[0m 0.003584\u001b[0m | \u001b[0m 0.6014  \u001b[0m | \u001b[0m 0.8562  \u001b[0m | \u001b[0m 0.5329  \u001b[0m | \u001b[0m 0.02468 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 152     \u001b[0m | \u001b[0m 0.003897\u001b[0m | \u001b[0m 0.2658  \u001b[0m | \u001b[0m 0.9909  \u001b[0m | \u001b[0m 0.7487  \u001b[0m | \u001b[0m 0.1586  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 153     \u001b[0m | \u001b[0m 0.003919\u001b[0m | \u001b[0m 0.6737  \u001b[0m | \u001b[0m 0.8383  \u001b[0m | \u001b[0m 0.1863  \u001b[0m | \u001b[0m 0.07942 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 154     \u001b[0m | \u001b[0m 0.003163\u001b[0m | \u001b[0m 0.2803  \u001b[0m | \u001b[0m 0.07951 \u001b[0m | \u001b[0m 0.3498  \u001b[0m | \u001b[0m 0.1734  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 155     \u001b[0m | \u001b[0m 0.003889\u001b[0m | \u001b[0m 0.9674  \u001b[0m | \u001b[0m 0.816   \u001b[0m | \u001b[0m 0.6819  \u001b[0m | \u001b[0m 0.09352 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 156     \u001b[0m | \u001b[0m 0.003792\u001b[0m | \u001b[0m 0.6911  \u001b[0m | \u001b[0m 0.8924  \u001b[0m | \u001b[0m 0.2695  \u001b[0m | \u001b[0m 0.09323 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 157     \u001b[0m | \u001b[0m 0.003156\u001b[0m | \u001b[0m 0.954   \u001b[0m | \u001b[0m 0.005442\u001b[0m | \u001b[0m 0.08583 \u001b[0m | \u001b[0m 0.185   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 158     \u001b[0m | \u001b[0m 0.00382 \u001b[0m | \u001b[0m 0.7265  \u001b[0m | \u001b[0m 0.9098  \u001b[0m | \u001b[0m 0.183   \u001b[0m | \u001b[0m 0.07812 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 159     \u001b[0m | \u001b[0m 0.003648\u001b[0m | \u001b[0m 0.6063  \u001b[0m | \u001b[0m 0.5709  \u001b[0m | \u001b[0m 0.5567  \u001b[0m | \u001b[0m 0.09094 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 160     \u001b[0m | \u001b[0m 0.00374 \u001b[0m | \u001b[0m 0.6491  \u001b[0m | \u001b[0m 0.7648  \u001b[0m | \u001b[0m 0.4324  \u001b[0m | \u001b[0m 0.1295  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000734 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 161     \u001b[0m | \u001b[0m 0.003711\u001b[0m | \u001b[0m 0.6403  \u001b[0m | \u001b[0m 0.9141  \u001b[0m | \u001b[0m 0.1401  \u001b[0m | \u001b[0m 0.1158  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 162     \u001b[0m | \u001b[0m 0.00336 \u001b[0m | \u001b[0m 0.7377  \u001b[0m | \u001b[0m 0.8847  \u001b[0m | \u001b[0m 0.2507  \u001b[0m | \u001b[0m 0.01644 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 163     \u001b[0m | \u001b[0m 0.003723\u001b[0m | \u001b[0m 0.3093  \u001b[0m | \u001b[0m 0.9893  \u001b[0m | \u001b[0m 0.9759  \u001b[0m | \u001b[0m 0.1444  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 164     \u001b[0m | \u001b[0m 0.003782\u001b[0m | \u001b[0m 0.3929  \u001b[0m | \u001b[0m 0.4196  \u001b[0m | \u001b[0m 0.943   \u001b[0m | \u001b[0m 0.1731  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 165     \u001b[0m | \u001b[0m 0.003246\u001b[0m | \u001b[0m 0.6446  \u001b[0m | \u001b[0m 0.7928  \u001b[0m | \u001b[0m 0.1452  \u001b[0m | \u001b[0m 0.0123  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 166     \u001b[0m | \u001b[0m 0.003788\u001b[0m | \u001b[0m 0.5715  \u001b[0m | \u001b[0m 0.9174  \u001b[0m | \u001b[0m 0.4589  \u001b[0m | \u001b[0m 0.1604  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 167     \u001b[0m | \u001b[0m 0.003701\u001b[0m | \u001b[0m 0.9125  \u001b[0m | \u001b[0m 0.6928  \u001b[0m | \u001b[0m 0.5848  \u001b[0m | \u001b[0m 0.05769 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 168     \u001b[0m | \u001b[0m 0.002587\u001b[0m | \u001b[0m 0.8094  \u001b[0m | \u001b[0m 0.07658 \u001b[0m | \u001b[0m 0.009561\u001b[0m | \u001b[0m 0.01211 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 169     \u001b[0m | \u001b[0m 0.003804\u001b[0m | \u001b[0m 0.5452  \u001b[0m | \u001b[0m 0.7426  \u001b[0m | \u001b[0m 0.4155  \u001b[0m | \u001b[0m 0.07982 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 170     \u001b[0m | \u001b[0m 0.003746\u001b[0m | \u001b[0m 0.5072  \u001b[0m | \u001b[0m 0.9852  \u001b[0m | \u001b[0m 0.4545  \u001b[0m | \u001b[0m 0.09909 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 171     \u001b[0m | \u001b[0m 0.003429\u001b[0m | \u001b[0m 0.5911  \u001b[0m | \u001b[0m 0.1685  \u001b[0m | \u001b[0m 0.8637  \u001b[0m | \u001b[0m 0.0698  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 172     \u001b[0m | \u001b[0m 0.003518\u001b[0m | \u001b[0m 0.27    \u001b[0m | \u001b[0m 0.8973  \u001b[0m | \u001b[0m 0.7424  \u001b[0m | \u001b[0m 0.1827  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 173     \u001b[0m | \u001b[0m 0.003788\u001b[0m | \u001b[0m 0.5744  \u001b[0m | \u001b[0m 0.8638  \u001b[0m | \u001b[0m 0.3696  \u001b[0m | \u001b[0m 0.135   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 174     \u001b[0m | \u001b[0m 0.003642\u001b[0m | \u001b[0m 0.6535  \u001b[0m | \u001b[0m 0.879   \u001b[0m | \u001b[0m 0.4247  \u001b[0m | \u001b[0m 0.09895 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 175     \u001b[0m | \u001b[0m 0.003799\u001b[0m | \u001b[0m 0.6055  \u001b[0m | \u001b[0m 0.8124  \u001b[0m | \u001b[0m 0.362   \u001b[0m | \u001b[0m 0.05186 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 176     \u001b[0m | \u001b[0m 0.003837\u001b[0m | \u001b[0m 0.6066  \u001b[0m | \u001b[0m 0.8218  \u001b[0m | \u001b[0m 0.4518  \u001b[0m | \u001b[0m 0.1962  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 177     \u001b[0m | \u001b[0m 0.003891\u001b[0m | \u001b[0m 0.3103  \u001b[0m | \u001b[0m 0.9553  \u001b[0m | \u001b[0m 0.7811  \u001b[0m | \u001b[0m 0.08628 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 178     \u001b[0m | \u001b[0m 0.003743\u001b[0m | \u001b[0m 0.5803  \u001b[0m | \u001b[0m 0.8582  \u001b[0m | \u001b[0m 0.3672  \u001b[0m | \u001b[0m 0.1259  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 179     \u001b[0m | \u001b[0m 0.003678\u001b[0m | \u001b[0m 0.2578  \u001b[0m | \u001b[0m 0.9853  \u001b[0m | \u001b[0m 0.7539  \u001b[0m | \u001b[0m 0.1554  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 180     \u001b[0m | \u001b[0m 0.003907\u001b[0m | \u001b[0m 0.3254  \u001b[0m | \u001b[0m 0.9561  \u001b[0m | \u001b[0m 0.6992  \u001b[0m | \u001b[0m 0.1223  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 181     \u001b[0m | \u001b[0m 0.003922\u001b[0m | \u001b[0m 0.4144  \u001b[0m | \u001b[0m 0.972   \u001b[0m | \u001b[0m 0.7082  \u001b[0m | \u001b[0m 0.1602  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 182     \u001b[0m | \u001b[0m 0.003948\u001b[0m | \u001b[0m 0.9768  \u001b[0m | \u001b[0m 0.9365  \u001b[0m | \u001b[0m 0.9568  \u001b[0m | \u001b[0m 0.166   \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 183     \u001b[0m | \u001b[0m 0.003849\u001b[0m | \u001b[0m 0.3677  \u001b[0m | \u001b[0m 0.9717  \u001b[0m | \u001b[0m 0.8043  \u001b[0m | \u001b[0m 0.1431  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000548 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 184     \u001b[0m | \u001b[0m 0.003744\u001b[0m | \u001b[0m 0.1115  \u001b[0m | \u001b[0m 0.9566  \u001b[0m | \u001b[0m 0.09929 \u001b[0m | \u001b[0m 0.1097  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 185     \u001b[0m | \u001b[0m 0.00388 \u001b[0m | \u001b[0m 0.2561  \u001b[0m | \u001b[0m 0.9863  \u001b[0m | \u001b[0m 0.6557  \u001b[0m | \u001b[0m 0.1224  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 186     \u001b[0m | \u001b[0m 0.003792\u001b[0m | \u001b[0m 0.3922  \u001b[0m | \u001b[0m 0.9728  \u001b[0m | \u001b[0m 0.6121  \u001b[0m | \u001b[0m 0.1344  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 187     \u001b[0m | \u001b[0m 0.003814\u001b[0m | \u001b[0m 0.3888  \u001b[0m | \u001b[0m 0.9731  \u001b[0m | \u001b[0m 0.6733  \u001b[0m | \u001b[0m 0.07017 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 188     \u001b[0m | \u001b[0m 0.003699\u001b[0m | \u001b[0m 0.457   \u001b[0m | \u001b[0m 0.9812  \u001b[0m | \u001b[0m 0.7735  \u001b[0m | \u001b[0m 0.1107  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000790 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 189     \u001b[0m | \u001b[0m 0.003636\u001b[0m | \u001b[0m 0.3391  \u001b[0m | \u001b[0m 0.9565  \u001b[0m | \u001b[0m 0.7491  \u001b[0m | \u001b[0m 0.1989  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 190     \u001b[0m | \u001b[0m 0.003816\u001b[0m | \u001b[0m 0.2958  \u001b[0m | \u001b[0m 0.9554  \u001b[0m | \u001b[0m 0.6779  \u001b[0m | \u001b[0m 0.0402  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 191     \u001b[0m | \u001b[0m 0.003697\u001b[0m | \u001b[0m 0.6333  \u001b[0m | \u001b[0m 0.7587  \u001b[0m | \u001b[0m 0.2113  \u001b[0m | \u001b[0m 0.1293  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 192     \u001b[0m | \u001b[0m 0.003885\u001b[0m | \u001b[0m 0.3569  \u001b[0m | \u001b[0m 0.8848  \u001b[0m | \u001b[0m 0.7783  \u001b[0m | \u001b[0m 0.1266  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 193     \u001b[0m | \u001b[0m 0.003253\u001b[0m | \u001b[0m 0.7524  \u001b[0m | \u001b[0m 0.1661  \u001b[0m | \u001b[0m 0.2211  \u001b[0m | \u001b[0m 0.03681 \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 194     \u001b[0m | \u001b[0m 0.002542\u001b[0m | \u001b[0m 0.4905  \u001b[0m | \u001b[0m 0.5938  \u001b[0m | \u001b[0m 0.4513  \u001b[0m | \u001b[0m 0.001118\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 195     \u001b[0m | \u001b[0m 0.003801\u001b[0m | \u001b[0m 0.3669  \u001b[0m | \u001b[0m 0.915   \u001b[0m | \u001b[0m 0.8515  \u001b[0m | \u001b[0m 0.05796 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 196     \u001b[0m | \u001b[0m 0.002699\u001b[0m | \u001b[0m 0.8781  \u001b[0m | \u001b[0m 0.2238  \u001b[0m | \u001b[0m 0.07815 \u001b[0m | \u001b[0m 0.006216\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 197     \u001b[0m | \u001b[0m 0.00293 \u001b[0m | \u001b[0m 0.313   \u001b[0m | \u001b[0m 0.8949  \u001b[0m | \u001b[0m 0.7742  \u001b[0m | \u001b[0m 0.006306\u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m 198     \u001b[0m | \u001b[0m 0.003352\u001b[0m | \u001b[0m 0.6813  \u001b[0m | \u001b[0m 0.2564  \u001b[0m | \u001b[0m 0.849   \u001b[0m | \u001b[0m 0.1756  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 199     \u001b[0m | \u001b[0m 0.003969\u001b[0m | \u001b[0m 0.453   \u001b[0m | \u001b[0m 0.886   \u001b[0m | \u001b[0m 0.7412  \u001b[0m | \u001b[0m 0.1694  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 200     \u001b[0m | \u001b[0m 0.003697\u001b[0m | \u001b[0m 0.1318  \u001b[0m | \u001b[0m 0.5677  \u001b[0m | \u001b[0m 0.5113  \u001b[0m | \u001b[0m 0.04539 \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 201     \u001b[0m | \u001b[0m 0.003532\u001b[0m | \u001b[0m 0.5173  \u001b[0m | \u001b[0m 0.9453  \u001b[0m | \u001b[0m 0.6942  \u001b[0m | \u001b[0m 0.1822  \u001b[0m |\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "| \u001b[0m 202     \u001b[0m | \u001b[0m 0.003426\u001b[0m | \u001b[0m 0.9924  \u001b[0m | \u001b[0m 0.3886  \u001b[0m | \u001b[0m 0.4582  \u001b[0m | \u001b[0m 0.1814  \u001b[0m |\n",
      "=========================================================================\n",
      "{'target': 0.004277418159210076, 'params': {'bagging_fraction': 0.3064309327445396, 'feature_fraction': 0.9841153868091663, 'lambda_l2': 0.9845686559036195, 'learning_rate': 0.19150635302926877}}\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize as optimize\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "params = {\"learning_rate\": (0.0001, 0.2),\n",
    "            \"feature_fraction\" : (0.0001, 1),\n",
    "            \"bagging_fraction\" : (0.0001, 1),\n",
    "            \"lambda_l2\" : (0 , 1)\n",
    "            }\n",
    "\n",
    "capacity = 1000\n",
    "train_max = 1\n",
    "train_min = 0\n",
    "\n",
    "bo=BayesianOptimization(f=LGB_cv, \n",
    "                    pbounds=params, \n",
    "                    verbose=2, \n",
    "                    random_state=240)\n",
    "\n",
    "\n",
    "bo.maximize(init_points=2, n_iter=200, acq='ei', xi=0.01)\n",
    "\n",
    "print(bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x287f6375160>]"
      ]
     },
     "execution_count": 1254,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004277418159210076"
      ]
     },
     "execution_count": 1256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_2[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1259,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'bagging_fraction': 0.3064309327445396,\n",
    " 'feature_fraction': 0.9841153868091663,\n",
    " 'lambda_l2': 0.9845686559036195,\n",
    " 'learning_rate': 0.19150635302926877}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1002\n",
      "[LightGBM] [Info] Number of data points in the train set: 45241, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 42.689253\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's score: 10.382\n"
     ]
    }
   ],
   "source": [
    "capacity = 1000\n",
    "fine_dust_ulsan_model = lgb.train(params, \n",
    "                           train_dataset, \n",
    "                           10000, \n",
    "                           val_dataset, \n",
    "                           feval= nmae_10_lgb, \n",
    "                           verbose_eval=500, \n",
    "                           early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fine_dust_ulsan_model.pkl']"
      ]
     },
     "execution_count": 1261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(fine_dust_ulsan_model,\"fine_dust_ulsan_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fine_dust_ulsan_model.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x287fd2d5e80>]"
      ]
     },
     "execution_count": 1263,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(y_pred[100:300])\n",
    "plt.plot(val_y[100:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.56549797],\n",
       "       [0.56549797, 1.        ]])"
      ]
     },
     "execution_count": 1264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(y_pred, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['year', \n",
    "'month', \n",
    "'day', \n",
    "'hour', \n",
    "'Temperature',\n",
    "'Humidity', \n",
    "'WindSpeed', \n",
    "'Cloud',\n",
    "'type_0',\n",
    "'type_1',\n",
    "'type_2',\n",
    "'type_3',\n",
    "'type_4',\n",
    "'fall_prob',\n",
    " \"sun_radio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temperature</th>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humidity</th>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WindSpeed</th>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud</th>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fall_prob</th>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sun_radio</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "year         517\n",
       "month        481\n",
       "day          992\n",
       "hour         278\n",
       "Temperature  556\n",
       "Humidity     415\n",
       "WindSpeed    537\n",
       "Cloud        267\n",
       "type_0         3\n",
       "type_1         2\n",
       "type_2         3\n",
       "type_3         0\n",
       "type_4         0\n",
       "fall_prob    392\n",
       "sun_radio     27"
      ]
     },
     "execution_count": 1200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(fine_dust_ulsan_model.feature_importance(),\n",
    "          ['year', \n",
    "           'month', \n",
    "            'day', \n",
    "            'hour', \n",
    "            'Temperature',\n",
    "            'Humidity', \n",
    "            'WindSpeed', \n",
    "            'Cloud',\n",
    "            'type_0',\n",
    "            'type_1',\n",
    "            'type_2',\n",
    "            'type_3',\n",
    "            'type_4',\n",
    "            'fall_prob',\n",
    "             \"sun_radio\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, val_x, val_y = train_datast_dust(fine_dust_dangjin[[\"Forecast time\",\"PM10\"]], \n",
    "                                              dangjin_fcst, \n",
    "                                              target='dangjin', \n",
    "                                              sun_target = \"sun_dangjin\",\n",
    "                                             rain_target = \"dangjin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x[:-1]\n",
    "train_y = train_y[:-1]\n",
    "val_x = val_x[:-1]\n",
    "val_y = val_y[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.stack(DataFrame(train_x).groupby([0,1,2]).apply(lambda x : np.array(x)))\n",
    "val_x = np.stack(DataFrame(val_x).groupby([0,1,2]).apply(lambda x : np.array(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.stack(DataFrame(train_y).groupby([0,1,2]).apply(lambda x : np.array(x[3])))\n",
    "val_y = np.stack(DataFrame(val_y).groupby([0,1,2]).apply(lambda x : np.array(x[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[:,:,0] = np.array(DataFrame(train_x[:,:,0]).astype(\"str\").apply(lambda x : x.str.slice(2,4).astype(\"int\")))\n",
    "val_x[:,:,0] = np.array(DataFrame(val_x[:,:,0]).astype(\"str\").apply(lambda x : x.str.slice(2,4).astype(\"int\")))\n",
    "\n",
    "train_max_dangjin = np.max(train_x)\n",
    "train_min_dangjin = np.min(train_x)\n",
    "\n",
    "train_x_scaled = (np.array(train_x) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)\n",
    "val_x_scaled = (np.array(val_x) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_scaled = (np.array(train_y) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)\n",
    "val_y_scaled = (np.array(val_y) - train_min_dangjin) / (train_max_dangjin - train_min_dangjin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [],
   "source": [
    "class auto_encoder_lstm(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "                 lstm_dim,\n",
    "                input_dim,\n",
    "                output_dense):\n",
    "        \n",
    "        super(auto_encoder_lstm, self).__init__()\n",
    "        \n",
    "        self.lstm_dim = lstm_dim\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.output_dense = output_dense\n",
    "     \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(self.input_dim,\n",
    "                                          activation = \"relu\")\n",
    "        \n",
    "        self.dense_2 = tf.keras.layers.Dense(self.input_dim,\n",
    "                                           activation = \"relu\")\n",
    "        \n",
    "        self.dense_3 = tf.keras.layers.Dense(self.input_dim,\n",
    "                                   activation = \"relu\")\n",
    "        \n",
    "        self.dense_4 = tf.keras.layers.Dense(self.input_dim,\n",
    "                           activation = \"relu\")\n",
    "        \n",
    "        self.dense_5 = tf.keras.layers.Dense(self.input_dim,\n",
    "                           activation = \"relu\")\n",
    "        \n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "\n",
    "        self.lstm = tf.keras.layers.LSTM(self.lstm_dim,\n",
    "                                        return_sequences = True)\n",
    "        \n",
    "        output_layer = tf.keras.layers.Dense(self.output_dense, activation = \"relu\")\n",
    "        \n",
    "        self.outputs = tf.keras.layers.TimeDistributed(output_layer)\n",
    "    \n",
    "    def call(self, input_tensor):\n",
    "        \n",
    "        dense_output = self.dense(input_tensor)\n",
    "        \n",
    "        dense_output = self.dense_2(dense_output)\n",
    "        \n",
    "        #dense_output = self.dense_3(dense_output)\n",
    "        \n",
    "        #dense_output = self.dense_4(dense_output)\n",
    "        \n",
    "        desne_output = self.dropout(dense_output)\n",
    "        \n",
    "        dense_output = self.dense_5(dense_output)\n",
    "        \n",
    "        lstm_output = self.lstm(dense_output)\n",
    "        \n",
    "        output = self.outputs(lstm_output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [],
   "source": [
    "AE = auto_encoder_lstm(200, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def training_LSTM(inp , tar):\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        output = AE(inp)\n",
    "\n",
    "        loss =  loss_function(tar, output)\n",
    "    \n",
    "    gradients = tape.gradient(loss, AE.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, AE.trainable_variables))\n",
    "  \n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy_function(tar * (train_max_dangjin - train_min_dangjin) + train_min_dangjin, \n",
    "                                     output * (train_max_dangjin - train_min_dangjin) + train_min_dangjin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_accuracy(inp, tar):\n",
    "    \n",
    "    tar = tf.expand_dims(tar, -1)\n",
    "    \n",
    "    result = accuracy_function(inp * (train_max_dangjin - train_min_dangjin) + train_min_dangjin\n",
    "                               , tar)\n",
    "    \n",
    "    test_accuracy(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 5 Loss 0.0459 Accuracy 5.4821\n",
      "Epoch 1 Batch 10 Loss 0.0453 Accuracy 5.2670\n",
      "Epoch 1 Batch 15 Loss 0.0458 Accuracy 5.2038\n",
      "Epoch 1 Batch 20 Loss 0.0435 Accuracy 5.1731\n",
      "Epoch 1 Batch 25 Loss 0.0420 Accuracy 5.1168\n",
      "Epoch 1 Batch 30 Loss 0.0412 Accuracy 5.0468\n",
      "Epoch 1 Batch 35 Loss 0.0409 Accuracy 4.9926\n",
      "Time taken for 1 epoch: 1.40 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0898\n",
      "Epoch 2 Batch 5 Loss 0.0415 Accuracy 4.9809\n",
      "Epoch 2 Batch 10 Loss 0.0420 Accuracy 4.9986\n",
      "Epoch 2 Batch 15 Loss 0.0424 Accuracy 5.0120\n",
      "Epoch 2 Batch 20 Loss 0.0422 Accuracy 5.0248\n",
      "Epoch 2 Batch 25 Loss 0.0418 Accuracy 5.0300\n",
      "Epoch 2 Batch 30 Loss 0.0415 Accuracy 5.0281\n",
      "Epoch 2 Batch 35 Loss 0.0414 Accuracy 5.0238\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1184\n",
      "Epoch 3 Batch 5 Loss 0.0415 Accuracy 5.0271\n",
      "Epoch 3 Batch 10 Loss 0.0416 Accuracy 5.0345\n",
      "Epoch 3 Batch 15 Loss 0.0415 Accuracy 5.0391\n",
      "Epoch 3 Batch 20 Loss 0.0413 Accuracy 5.0422\n",
      "Epoch 3 Batch 25 Loss 0.0410 Accuracy 5.0427\n",
      "Epoch 3 Batch 30 Loss 0.0408 Accuracy 5.0402\n",
      "Epoch 3 Batch 35 Loss 0.0407 Accuracy 5.0367\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1075\n",
      "Epoch 4 Batch 5 Loss 0.0408 Accuracy 5.0362\n",
      "Epoch 4 Batch 10 Loss 0.0408 Accuracy 5.0382\n",
      "Epoch 4 Batch 15 Loss 0.0409 Accuracy 5.0391\n",
      "Epoch 4 Batch 20 Loss 0.0407 Accuracy 5.0395\n",
      "Epoch 4 Batch 25 Loss 0.0406 Accuracy 5.0389\n",
      "Epoch 4 Batch 30 Loss 0.0404 Accuracy 5.0368\n",
      "Epoch 4 Batch 35 Loss 0.0404 Accuracy 5.0341\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0931\n",
      "Epoch 5 Batch 5 Loss 0.0404 Accuracy 5.0329\n",
      "Epoch 5 Batch 10 Loss 0.0405 Accuracy 5.0336\n",
      "Epoch 5 Batch 15 Loss 0.0406 Accuracy 5.0339\n",
      "Epoch 5 Batch 20 Loss 0.0406 Accuracy 5.0342\n",
      "Epoch 5 Batch 25 Loss 0.0405 Accuracy 5.0339\n",
      "Epoch 5 Batch 30 Loss 0.0404 Accuracy 5.0330\n",
      "Epoch 5 Batch 35 Loss 0.0405 Accuracy 5.0318\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0875\n",
      "Epoch 6 Batch 5 Loss 0.0405 Accuracy 5.0317\n",
      "Epoch 6 Batch 10 Loss 0.0406 Accuracy 5.0326\n",
      "Epoch 6 Batch 15 Loss 0.0407 Accuracy 5.0333\n",
      "Epoch 6 Batch 20 Loss 0.0407 Accuracy 5.0340\n",
      "Epoch 6 Batch 25 Loss 0.0407 Accuracy 5.0344\n",
      "Epoch 6 Batch 30 Loss 0.0407 Accuracy 5.0344\n",
      "Epoch 6 Batch 35 Loss 0.0407 Accuracy 5.0342\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0899\n",
      "Epoch 7 Batch 5 Loss 0.0409 Accuracy 5.0355\n",
      "Epoch 7 Batch 10 Loss 0.0409 Accuracy 5.0371\n",
      "Epoch 7 Batch 15 Loss 0.0410 Accuracy 5.0384\n",
      "Epoch 7 Batch 20 Loss 0.0410 Accuracy 5.0397\n",
      "Epoch 7 Batch 25 Loss 0.0409 Accuracy 5.0406\n",
      "Epoch 7 Batch 30 Loss 0.0409 Accuracy 5.0412\n",
      "Epoch 7 Batch 35 Loss 0.0409 Accuracy 5.0416\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0937\n",
      "Epoch 8 Batch 5 Loss 0.0410 Accuracy 5.0430\n",
      "Epoch 8 Batch 10 Loss 0.0410 Accuracy 5.0444\n",
      "Epoch 8 Batch 15 Loss 0.0410 Accuracy 5.0456\n",
      "Epoch 8 Batch 20 Loss 0.0410 Accuracy 5.0467\n",
      "Epoch 8 Batch 25 Loss 0.0410 Accuracy 5.0477\n",
      "Epoch 8 Batch 30 Loss 0.0409 Accuracy 5.0483\n",
      "Epoch 8 Batch 35 Loss 0.0410 Accuracy 5.0487\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0973\n",
      "Epoch 9 Batch 5 Loss 0.0410 Accuracy 5.0499\n",
      "Epoch 9 Batch 10 Loss 0.0410 Accuracy 5.0511\n",
      "Epoch 9 Batch 15 Loss 0.0410 Accuracy 5.0521\n",
      "Epoch 9 Batch 20 Loss 0.0410 Accuracy 5.0531\n",
      "Epoch 9 Batch 25 Loss 0.0410 Accuracy 5.0539\n",
      "Epoch 9 Batch 30 Loss 0.0409 Accuracy 5.0544\n",
      "Epoch 9 Batch 35 Loss 0.0409 Accuracy 5.0548\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1002\n",
      "Epoch 10 Batch 5 Loss 0.0410 Accuracy 5.0558\n",
      "Epoch 10 Batch 10 Loss 0.0411 Accuracy 5.0568\n",
      "Epoch 10 Batch 15 Loss 0.0411 Accuracy 5.0578\n",
      "Epoch 10 Batch 20 Loss 0.0411 Accuracy 5.0587\n",
      "Epoch 10 Batch 25 Loss 0.0411 Accuracy 5.0595\n",
      "Epoch 10 Batch 30 Loss 0.0410 Accuracy 5.0601\n",
      "Epoch 10 Batch 35 Loss 0.0410 Accuracy 5.0605\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1031\n",
      "Epoch 11 Batch 5 Loss 0.0410 Accuracy 5.0615\n",
      "Epoch 11 Batch 10 Loss 0.0411 Accuracy 5.0624\n",
      "Epoch 11 Batch 15 Loss 0.0411 Accuracy 5.0633\n",
      "Epoch 11 Batch 20 Loss 0.0411 Accuracy 5.0641\n",
      "Epoch 11 Batch 25 Loss 0.0411 Accuracy 5.0648\n",
      "Epoch 11 Batch 30 Loss 0.0410 Accuracy 5.0653\n",
      "Epoch 11 Batch 35 Loss 0.0411 Accuracy 5.0658\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1063\n",
      "Epoch 12 Batch 5 Loss 0.0411 Accuracy 5.0667\n",
      "Epoch 12 Batch 10 Loss 0.0411 Accuracy 5.0676\n",
      "Epoch 12 Batch 15 Loss 0.0412 Accuracy 5.0683\n",
      "Epoch 12 Batch 20 Loss 0.0411 Accuracy 5.0690\n",
      "Epoch 12 Batch 25 Loss 0.0411 Accuracy 5.0697\n",
      "Epoch 12 Batch 30 Loss 0.0411 Accuracy 5.0701\n",
      "Epoch 12 Batch 35 Loss 0.0411 Accuracy 5.0705\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1086\n",
      "Epoch 13 Batch 5 Loss 0.0411 Accuracy 5.0713\n",
      "Epoch 13 Batch 10 Loss 0.0411 Accuracy 5.0720\n",
      "Epoch 13 Batch 15 Loss 0.0411 Accuracy 5.0727\n",
      "Epoch 13 Batch 20 Loss 0.0411 Accuracy 5.0733\n",
      "Epoch 13 Batch 25 Loss 0.0411 Accuracy 5.0739\n",
      "Epoch 13 Batch 30 Loss 0.0411 Accuracy 5.0743\n",
      "Epoch 13 Batch 35 Loss 0.0411 Accuracy 5.0747\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1107\n",
      "Epoch 14 Batch 5 Loss 0.0411 Accuracy 5.0754\n",
      "Epoch 14 Batch 10 Loss 0.0411 Accuracy 5.0761\n",
      "Epoch 14 Batch 15 Loss 0.0412 Accuracy 5.0767\n",
      "Epoch 14 Batch 20 Loss 0.0411 Accuracy 5.0772\n",
      "Epoch 14 Batch 25 Loss 0.0411 Accuracy 5.0777\n",
      "Epoch 14 Batch 30 Loss 0.0411 Accuracy 5.0782\n",
      "Epoch 14 Batch 35 Loss 0.0411 Accuracy 5.0785\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1134\n",
      "Epoch 15 Batch 5 Loss 0.0412 Accuracy 5.0793\n",
      "Epoch 15 Batch 10 Loss 0.0412 Accuracy 5.0800\n",
      "Epoch 15 Batch 15 Loss 0.0413 Accuracy 5.0806\n",
      "Epoch 15 Batch 20 Loss 0.0412 Accuracy 5.0812\n",
      "Epoch 15 Batch 25 Loss 0.0412 Accuracy 5.0817\n",
      "Epoch 15 Batch 30 Loss 0.0412 Accuracy 5.0822\n",
      "Epoch 15 Batch 35 Loss 0.0412 Accuracy 5.0826\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1163\n",
      "Epoch 16 Batch 5 Loss 0.0413 Accuracy 5.0834\n",
      "Epoch 16 Batch 10 Loss 0.0413 Accuracy 5.0841\n",
      "Epoch 16 Batch 15 Loss 0.0413 Accuracy 5.0848\n",
      "Epoch 16 Batch 20 Loss 0.0413 Accuracy 5.0854\n",
      "Epoch 16 Batch 25 Loss 0.0413 Accuracy 5.0860\n",
      "Epoch 16 Batch 30 Loss 0.0413 Accuracy 5.0865\n",
      "Epoch 16 Batch 35 Loss 0.0413 Accuracy 5.0869\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1193\n",
      "Epoch 17 Batch 5 Loss 0.0414 Accuracy 5.0877\n",
      "Epoch 17 Batch 10 Loss 0.0414 Accuracy 5.0884\n",
      "Epoch 17 Batch 15 Loss 0.0414 Accuracy 5.0891\n",
      "Epoch 17 Batch 20 Loss 0.0414 Accuracy 5.0897\n",
      "Epoch 17 Batch 25 Loss 0.0414 Accuracy 5.0903\n",
      "Epoch 17 Batch 30 Loss 0.0414 Accuracy 5.0908\n",
      "Epoch 17 Batch 35 Loss 0.0414 Accuracy 5.0913\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1226\n",
      "Epoch 18 Batch 5 Loss 0.0415 Accuracy 5.0922\n",
      "Epoch 18 Batch 10 Loss 0.0415 Accuracy 5.0929\n",
      "Epoch 18 Batch 15 Loss 0.0415 Accuracy 5.0935\n",
      "Epoch 18 Batch 20 Loss 0.0415 Accuracy 5.0942\n",
      "Epoch 18 Batch 25 Loss 0.0415 Accuracy 5.0949\n",
      "Epoch 18 Batch 30 Loss 0.0415 Accuracy 5.0954\n",
      "Epoch 18 Batch 35 Loss 0.0415 Accuracy 5.0960\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1262\n",
      "Epoch 19 Batch 5 Loss 0.0416 Accuracy 5.0969\n",
      "Epoch 19 Batch 10 Loss 0.0416 Accuracy 5.0976\n",
      "Epoch 19 Batch 15 Loss 0.0416 Accuracy 5.0982\n",
      "Epoch 19 Batch 20 Loss 0.0416 Accuracy 5.0989\n",
      "Epoch 19 Batch 25 Loss 0.0416 Accuracy 5.0995\n",
      "Epoch 19 Batch 30 Loss 0.0416 Accuracy 5.1001\n",
      "Epoch 19 Batch 35 Loss 0.0416 Accuracy 5.1007\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1299\n",
      "Epoch 20 Batch 5 Loss 0.0416 Accuracy 5.1015\n",
      "Epoch 20 Batch 10 Loss 0.0416 Accuracy 5.1022\n",
      "Epoch 20 Batch 15 Loss 0.0417 Accuracy 5.1028\n",
      "Epoch 20 Batch 20 Loss 0.0416 Accuracy 5.1035\n",
      "Epoch 20 Batch 25 Loss 0.0416 Accuracy 5.1041\n",
      "Epoch 20 Batch 30 Loss 0.0416 Accuracy 5.1046\n",
      "Epoch 20 Batch 35 Loss 0.0416 Accuracy 5.1051\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1332\n",
      "Epoch 21 Batch 5 Loss 0.0416 Accuracy 5.1059\n",
      "Epoch 21 Batch 10 Loss 0.0416 Accuracy 5.1065\n",
      "Epoch 21 Batch 15 Loss 0.0416 Accuracy 5.1071\n",
      "Epoch 21 Batch 20 Loss 0.0416 Accuracy 5.1076\n",
      "Epoch 21 Batch 25 Loss 0.0416 Accuracy 5.1081\n",
      "Epoch 21 Batch 30 Loss 0.0416 Accuracy 5.1086\n",
      "Epoch 21 Batch 35 Loss 0.0416 Accuracy 5.1090\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1361\n",
      "Epoch 22 Batch 5 Loss 0.0416 Accuracy 5.1097\n",
      "Epoch 22 Batch 10 Loss 0.0416 Accuracy 5.1102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Batch 15 Loss 0.0416 Accuracy 5.1107\n",
      "Epoch 22 Batch 20 Loss 0.0416 Accuracy 5.1112\n",
      "Epoch 22 Batch 25 Loss 0.0415 Accuracy 5.1116\n",
      "Epoch 22 Batch 30 Loss 0.0415 Accuracy 5.1120\n",
      "Epoch 22 Batch 35 Loss 0.0415 Accuracy 5.1124\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1386\n",
      "Epoch 23 Batch 5 Loss 0.0416 Accuracy 5.1130\n",
      "Epoch 23 Batch 10 Loss 0.0416 Accuracy 5.1135\n",
      "Epoch 23 Batch 15 Loss 0.0416 Accuracy 5.1139\n",
      "Epoch 23 Batch 20 Loss 0.0415 Accuracy 5.1143\n",
      "Epoch 23 Batch 25 Loss 0.0415 Accuracy 5.1147\n",
      "Epoch 23 Batch 30 Loss 0.0415 Accuracy 5.1151\n",
      "Epoch 23 Batch 35 Loss 0.0415 Accuracy 5.1154\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1407\n",
      "Epoch 24 Batch 5 Loss 0.0415 Accuracy 5.1160\n",
      "Epoch 24 Batch 10 Loss 0.0416 Accuracy 5.1164\n",
      "Epoch 24 Batch 15 Loss 0.0416 Accuracy 5.1168\n",
      "Epoch 24 Batch 20 Loss 0.0416 Accuracy 5.1172\n",
      "Epoch 24 Batch 25 Loss 0.0415 Accuracy 5.1176\n",
      "Epoch 24 Batch 30 Loss 0.0415 Accuracy 5.1179\n",
      "Epoch 24 Batch 35 Loss 0.0416 Accuracy 5.1182\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1429\n",
      "Epoch 25 Batch 5 Loss 0.0416 Accuracy 5.1188\n",
      "Epoch 25 Batch 10 Loss 0.0416 Accuracy 5.1192\n",
      "Epoch 25 Batch 15 Loss 0.0416 Accuracy 5.1196\n",
      "Epoch 25 Batch 20 Loss 0.0416 Accuracy 5.1200\n",
      "Epoch 25 Batch 25 Loss 0.0416 Accuracy 5.1204\n",
      "Epoch 25 Batch 30 Loss 0.0416 Accuracy 5.1208\n",
      "Epoch 25 Batch 35 Loss 0.0416 Accuracy 5.1211\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1451\n",
      "Epoch 26 Batch 5 Loss 0.0417 Accuracy 5.1216\n",
      "Epoch 26 Batch 10 Loss 0.0417 Accuracy 5.1221\n",
      "Epoch 26 Batch 15 Loss 0.0417 Accuracy 5.1225\n",
      "Epoch 26 Batch 20 Loss 0.0417 Accuracy 5.1229\n",
      "Epoch 26 Batch 25 Loss 0.0417 Accuracy 5.1234\n",
      "Epoch 26 Batch 30 Loss 0.0417 Accuracy 5.1237\n",
      "Epoch 26 Batch 35 Loss 0.0417 Accuracy 5.1241\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1475\n",
      "Epoch 27 Batch 5 Loss 0.0417 Accuracy 5.1247\n",
      "Epoch 27 Batch 10 Loss 0.0418 Accuracy 5.1251\n",
      "Epoch 27 Batch 15 Loss 0.0418 Accuracy 5.1255\n",
      "Epoch 27 Batch 20 Loss 0.0418 Accuracy 5.1260\n",
      "Epoch 27 Batch 25 Loss 0.0418 Accuracy 5.1264\n",
      "Epoch 27 Batch 30 Loss 0.0418 Accuracy 5.1269\n",
      "Epoch 27 Batch 35 Loss 0.0418 Accuracy 5.1273\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1503\n",
      "Epoch 28 Batch 5 Loss 0.0419 Accuracy 5.1279\n",
      "Epoch 28 Batch 10 Loss 0.0419 Accuracy 5.1284\n",
      "Epoch 28 Batch 15 Loss 0.0419 Accuracy 5.1289\n",
      "Epoch 28 Batch 20 Loss 0.0420 Accuracy 5.1294\n",
      "Epoch 28 Batch 25 Loss 0.0420 Accuracy 5.1299\n",
      "Epoch 28 Batch 30 Loss 0.0420 Accuracy 5.1303\n",
      "Epoch 28 Batch 35 Loss 0.0420 Accuracy 5.1308\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1535\n",
      "Epoch 29 Batch 5 Loss 0.0420 Accuracy 5.1315\n",
      "Epoch 29 Batch 10 Loss 0.0420 Accuracy 5.1320\n",
      "Epoch 29 Batch 15 Loss 0.0420 Accuracy 5.1326\n",
      "Epoch 29 Batch 20 Loss 0.0420 Accuracy 5.1331\n",
      "Epoch 29 Batch 25 Loss 0.0420 Accuracy 5.1336\n",
      "Epoch 29 Batch 30 Loss 0.0420 Accuracy 5.1341\n",
      "Epoch 29 Batch 35 Loss 0.0420 Accuracy 5.1345\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1568\n",
      "Epoch 30 Batch 5 Loss 0.0421 Accuracy 5.1352\n",
      "Epoch 30 Batch 10 Loss 0.0421 Accuracy 5.1358\n",
      "Epoch 30 Batch 15 Loss 0.0421 Accuracy 5.1363\n",
      "Epoch 30 Batch 20 Loss 0.0421 Accuracy 5.1368\n",
      "Epoch 30 Batch 25 Loss 0.0421 Accuracy 5.1373\n",
      "Epoch 30 Batch 30 Loss 0.0421 Accuracy 5.1378\n",
      "Epoch 30 Batch 35 Loss 0.0421 Accuracy 5.1382\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1600\n",
      "Epoch 31 Batch 5 Loss 0.0421 Accuracy 5.1389\n",
      "Epoch 31 Batch 10 Loss 0.0422 Accuracy 5.1395\n",
      "Epoch 31 Batch 15 Loss 0.0422 Accuracy 5.1400\n",
      "Epoch 31 Batch 20 Loss 0.0422 Accuracy 5.1405\n",
      "Epoch 31 Batch 25 Loss 0.0422 Accuracy 5.1411\n",
      "Epoch 31 Batch 30 Loss 0.0422 Accuracy 5.1416\n",
      "Epoch 31 Batch 35 Loss 0.0422 Accuracy 5.1421\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1635\n",
      "Epoch 32 Batch 5 Loss 0.0423 Accuracy 5.1428\n",
      "Epoch 32 Batch 10 Loss 0.0423 Accuracy 5.1434\n",
      "Epoch 32 Batch 15 Loss 0.0424 Accuracy 5.1440\n",
      "Epoch 32 Batch 20 Loss 0.0424 Accuracy 5.1446\n",
      "Epoch 32 Batch 25 Loss 0.0424 Accuracy 5.1452\n",
      "Epoch 32 Batch 30 Loss 0.0424 Accuracy 5.1457\n",
      "Epoch 32 Batch 35 Loss 0.0424 Accuracy 5.1463\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1673\n",
      "Epoch 33 Batch 5 Loss 0.0425 Accuracy 5.1471\n",
      "Epoch 33 Batch 10 Loss 0.0425 Accuracy 5.1477\n",
      "Epoch 33 Batch 15 Loss 0.0426 Accuracy 5.1484\n",
      "Epoch 33 Batch 20 Loss 0.0426 Accuracy 5.1490\n",
      "Epoch 33 Batch 25 Loss 0.0426 Accuracy 5.1496\n",
      "Epoch 33 Batch 30 Loss 0.0426 Accuracy 5.1503\n",
      "Epoch 33 Batch 35 Loss 0.0426 Accuracy 5.1509\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1717\n",
      "Epoch 34 Batch 5 Loss 0.0427 Accuracy 5.1518\n",
      "Epoch 34 Batch 10 Loss 0.0427 Accuracy 5.1525\n",
      "Epoch 34 Batch 15 Loss 0.0428 Accuracy 5.1531\n",
      "Epoch 34 Batch 20 Loss 0.0428 Accuracy 5.1538\n",
      "Epoch 34 Batch 25 Loss 0.0428 Accuracy 5.1545\n",
      "Epoch 34 Batch 30 Loss 0.0428 Accuracy 5.1552\n",
      "Epoch 34 Batch 35 Loss 0.0429 Accuracy 5.1559\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1767\n",
      "Epoch 35 Batch 5 Loss 0.0430 Accuracy 5.1569\n",
      "Epoch 35 Batch 10 Loss 0.0430 Accuracy 5.1577\n",
      "Epoch 35 Batch 15 Loss 0.0430 Accuracy 5.1584\n",
      "Epoch 35 Batch 20 Loss 0.0431 Accuracy 5.1592\n",
      "Epoch 35 Batch 25 Loss 0.0431 Accuracy 5.1600\n",
      "Epoch 35 Batch 30 Loss 0.0431 Accuracy 5.1608\n",
      "Epoch 35 Batch 35 Loss 0.0431 Accuracy 5.1615\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1823\n",
      "Epoch 36 Batch 5 Loss 0.0432 Accuracy 5.1626\n",
      "Epoch 36 Batch 10 Loss 0.0432 Accuracy 5.1635\n",
      "Epoch 36 Batch 15 Loss 0.0433 Accuracy 5.1643\n",
      "Epoch 36 Batch 20 Loss 0.0433 Accuracy 5.1651\n",
      "Epoch 36 Batch 25 Loss 0.0433 Accuracy 5.1659\n",
      "Epoch 36 Batch 30 Loss 0.0433 Accuracy 5.1667\n",
      "Epoch 36 Batch 35 Loss 0.0433 Accuracy 5.1675\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1881\n",
      "Epoch 37 Batch 5 Loss 0.0434 Accuracy 5.1687\n",
      "Epoch 37 Batch 10 Loss 0.0434 Accuracy 5.1695\n",
      "Epoch 37 Batch 15 Loss 0.0434 Accuracy 5.1704\n",
      "Epoch 37 Batch 20 Loss 0.0435 Accuracy 5.1712\n",
      "Epoch 37 Batch 25 Loss 0.0435 Accuracy 5.1721\n",
      "Epoch 37 Batch 30 Loss 0.0435 Accuracy 5.1729\n",
      "Epoch 37 Batch 35 Loss 0.0435 Accuracy 5.1738\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1942\n",
      "Epoch 38 Batch 5 Loss 0.0435 Accuracy 5.1750\n",
      "Epoch 38 Batch 10 Loss 0.0436 Accuracy 5.1758\n",
      "Epoch 38 Batch 15 Loss 0.0436 Accuracy 5.1767\n",
      "Epoch 38 Batch 20 Loss 0.0436 Accuracy 5.1776\n",
      "Epoch 38 Batch 25 Loss 0.0436 Accuracy 5.1784\n",
      "Epoch 38 Batch 30 Loss 0.0436 Accuracy 5.1793\n",
      "Epoch 38 Batch 35 Loss 0.0437 Accuracy 5.1801\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2005\n",
      "Epoch 39 Batch 5 Loss 0.0438 Accuracy 5.1814\n",
      "Epoch 39 Batch 10 Loss 0.0438 Accuracy 5.1823\n",
      "Epoch 39 Batch 15 Loss 0.0438 Accuracy 5.1832\n",
      "Epoch 39 Batch 20 Loss 0.0438 Accuracy 5.1841\n",
      "Epoch 39 Batch 25 Loss 0.0438 Accuracy 5.1850\n",
      "Epoch 39 Batch 30 Loss 0.0438 Accuracy 5.1859\n",
      "Epoch 39 Batch 35 Loss 0.0439 Accuracy 5.1868\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2070\n",
      "Epoch 40 Batch 5 Loss 0.0439 Accuracy 5.1881\n",
      "Epoch 40 Batch 10 Loss 0.0439 Accuracy 5.1890\n",
      "Epoch 40 Batch 15 Loss 0.0439 Accuracy 5.1899\n",
      "Epoch 40 Batch 20 Loss 0.0439 Accuracy 5.1908\n",
      "Epoch 40 Batch 25 Loss 0.0439 Accuracy 5.1917\n",
      "Epoch 40 Batch 30 Loss 0.0439 Accuracy 5.1926\n",
      "Epoch 40 Batch 35 Loss 0.0439 Accuracy 5.1935\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2133\n",
      "Epoch 41 Batch 5 Loss 0.0440 Accuracy 5.1947\n",
      "Epoch 41 Batch 10 Loss 0.0440 Accuracy 5.1957\n",
      "Epoch 41 Batch 15 Loss 0.0440 Accuracy 5.1965\n",
      "Epoch 41 Batch 20 Loss 0.0440 Accuracy 5.1974\n",
      "Epoch 41 Batch 25 Loss 0.0440 Accuracy 5.1983\n",
      "Epoch 41 Batch 30 Loss 0.0440 Accuracy 5.1992\n",
      "Epoch 41 Batch 35 Loss 0.0440 Accuracy 5.2001\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2196\n",
      "Epoch 42 Batch 5 Loss 0.0440 Accuracy 5.2013\n",
      "Epoch 42 Batch 10 Loss 0.0440 Accuracy 5.2022\n",
      "Epoch 42 Batch 15 Loss 0.0441 Accuracy 5.2030\n",
      "Epoch 42 Batch 20 Loss 0.0441 Accuracy 5.2039\n",
      "Epoch 42 Batch 25 Loss 0.0441 Accuracy 5.2048\n",
      "Epoch 42 Batch 30 Loss 0.0441 Accuracy 5.2056\n",
      "Epoch 42 Batch 35 Loss 0.0441 Accuracy 5.2065\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2257\n",
      "Epoch 43 Batch 5 Loss 0.0441 Accuracy 5.2077\n",
      "Epoch 43 Batch 10 Loss 0.0441 Accuracy 5.2085\n",
      "Epoch 43 Batch 15 Loss 0.0441 Accuracy 5.2094\n",
      "Epoch 43 Batch 20 Loss 0.0441 Accuracy 5.2102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Batch 25 Loss 0.0441 Accuracy 5.2110\n",
      "Epoch 43 Batch 30 Loss 0.0441 Accuracy 5.2119\n",
      "Epoch 43 Batch 35 Loss 0.0441 Accuracy 5.2127\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2316\n",
      "Epoch 44 Batch 5 Loss 0.0442 Accuracy 5.2139\n",
      "Epoch 44 Batch 10 Loss 0.0442 Accuracy 5.2147\n",
      "Epoch 44 Batch 15 Loss 0.0442 Accuracy 5.2156\n",
      "Epoch 44 Batch 20 Loss 0.0442 Accuracy 5.2164\n",
      "Epoch 44 Batch 25 Loss 0.0442 Accuracy 5.2172\n",
      "Epoch 44 Batch 30 Loss 0.0442 Accuracy 5.2181\n",
      "Epoch 44 Batch 35 Loss 0.0442 Accuracy 5.2189\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2376\n",
      "Epoch 45 Batch 5 Loss 0.0442 Accuracy 5.2200\n",
      "Epoch 45 Batch 10 Loss 0.0443 Accuracy 5.2209\n",
      "Epoch 45 Batch 15 Loss 0.0443 Accuracy 5.2217\n",
      "Epoch 45 Batch 20 Loss 0.0443 Accuracy 5.2226\n",
      "Epoch 45 Batch 25 Loss 0.0443 Accuracy 5.2234\n",
      "Epoch 45 Batch 30 Loss 0.0443 Accuracy 5.2242\n",
      "Epoch 45 Batch 35 Loss 0.0443 Accuracy 5.2250\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2434\n",
      "Epoch 46 Batch 5 Loss 0.0443 Accuracy 5.2261\n",
      "Epoch 46 Batch 10 Loss 0.0443 Accuracy 5.2270\n",
      "Epoch 46 Batch 15 Loss 0.0443 Accuracy 5.2278\n",
      "Epoch 46 Batch 20 Loss 0.0444 Accuracy 5.2286\n",
      "Epoch 46 Batch 25 Loss 0.0444 Accuracy 5.2294\n",
      "Epoch 46 Batch 30 Loss 0.0443 Accuracy 5.2302\n",
      "Epoch 46 Batch 35 Loss 0.0444 Accuracy 5.2310\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2492\n",
      "Epoch 47 Batch 5 Loss 0.0444 Accuracy 5.2321\n",
      "Epoch 47 Batch 10 Loss 0.0444 Accuracy 5.2329\n",
      "Epoch 47 Batch 15 Loss 0.0444 Accuracy 5.2337\n",
      "Epoch 47 Batch 20 Loss 0.0444 Accuracy 5.2345\n",
      "Epoch 47 Batch 25 Loss 0.0444 Accuracy 5.2353\n",
      "Epoch 47 Batch 30 Loss 0.0444 Accuracy 5.2361\n",
      "Epoch 47 Batch 35 Loss 0.0444 Accuracy 5.2368\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2546\n",
      "Epoch 48 Batch 5 Loss 0.0443 Accuracy 5.2379\n",
      "Epoch 48 Batch 10 Loss 0.0443 Accuracy 5.2386\n",
      "Epoch 48 Batch 15 Loss 0.0443 Accuracy 5.2394\n",
      "Epoch 48 Batch 20 Loss 0.0443 Accuracy 5.2401\n",
      "Epoch 48 Batch 25 Loss 0.0443 Accuracy 5.2409\n",
      "Epoch 48 Batch 30 Loss 0.0443 Accuracy 5.2416\n",
      "Epoch 48 Batch 35 Loss 0.0443 Accuracy 5.2423\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2597\n",
      "Epoch 49 Batch 5 Loss 0.0443 Accuracy 5.2433\n",
      "Epoch 49 Batch 10 Loss 0.0443 Accuracy 5.2440\n",
      "Epoch 49 Batch 15 Loss 0.0443 Accuracy 5.2447\n",
      "Epoch 49 Batch 20 Loss 0.0443 Accuracy 5.2454\n",
      "Epoch 49 Batch 25 Loss 0.0442 Accuracy 5.2461\n",
      "Epoch 49 Batch 30 Loss 0.0442 Accuracy 5.2468\n",
      "Epoch 49 Batch 35 Loss 0.0442 Accuracy 5.2474\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2645\n",
      "Epoch 50 Batch 5 Loss 0.0442 Accuracy 5.2483\n",
      "Epoch 50 Batch 10 Loss 0.0442 Accuracy 5.2490\n",
      "Epoch 50 Batch 15 Loss 0.0442 Accuracy 5.2497\n",
      "Epoch 50 Batch 20 Loss 0.0442 Accuracy 5.2503\n",
      "Epoch 50 Batch 25 Loss 0.0442 Accuracy 5.2509\n",
      "Epoch 50 Batch 30 Loss 0.0441 Accuracy 5.2516\n",
      "Epoch 50 Batch 35 Loss 0.0441 Accuracy 5.2522\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2688\n",
      "Epoch 51 Batch 5 Loss 0.0441 Accuracy 5.2530\n",
      "Epoch 51 Batch 10 Loss 0.0441 Accuracy 5.2536\n",
      "Epoch 51 Batch 15 Loss 0.0441 Accuracy 5.2542\n",
      "Epoch 51 Batch 20 Loss 0.0441 Accuracy 5.2548\n",
      "Epoch 51 Batch 25 Loss 0.0441 Accuracy 5.2554\n",
      "Epoch 51 Batch 30 Loss 0.0441 Accuracy 5.2560\n",
      "Epoch 51 Batch 35 Loss 0.0441 Accuracy 5.2566\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2729\n",
      "Epoch 52 Batch 5 Loss 0.0441 Accuracy 5.2574\n",
      "Epoch 52 Batch 10 Loss 0.0441 Accuracy 5.2580\n",
      "Epoch 52 Batch 15 Loss 0.0441 Accuracy 5.2586\n",
      "Epoch 52 Batch 20 Loss 0.0441 Accuracy 5.2591\n",
      "Epoch 52 Batch 25 Loss 0.0441 Accuracy 5.2597\n",
      "Epoch 52 Batch 30 Loss 0.0441 Accuracy 5.2602\n",
      "Epoch 52 Batch 35 Loss 0.0441 Accuracy 5.2608\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2768\n",
      "Epoch 53 Batch 5 Loss 0.0441 Accuracy 5.2615\n",
      "Epoch 53 Batch 10 Loss 0.0441 Accuracy 5.2621\n",
      "Epoch 53 Batch 15 Loss 0.0441 Accuracy 5.2626\n",
      "Epoch 53 Batch 20 Loss 0.0440 Accuracy 5.2631\n",
      "Epoch 53 Batch 25 Loss 0.0440 Accuracy 5.2637\n",
      "Epoch 53 Batch 30 Loss 0.0440 Accuracy 5.2642\n",
      "Epoch 53 Batch 35 Loss 0.0440 Accuracy 5.2647\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2804\n",
      "Epoch 54 Batch 5 Loss 0.0440 Accuracy 5.2654\n",
      "Epoch 54 Batch 10 Loss 0.0440 Accuracy 5.2659\n",
      "Epoch 54 Batch 15 Loss 0.0440 Accuracy 5.2664\n",
      "Epoch 54 Batch 20 Loss 0.0440 Accuracy 5.2669\n",
      "Epoch 54 Batch 25 Loss 0.0440 Accuracy 5.2674\n",
      "Epoch 54 Batch 30 Loss 0.0440 Accuracy 5.2679\n",
      "Epoch 54 Batch 35 Loss 0.0439 Accuracy 5.2684\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2837\n",
      "Epoch 55 Batch 5 Loss 0.0439 Accuracy 5.2690\n",
      "Epoch 55 Batch 10 Loss 0.0439 Accuracy 5.2695\n",
      "Epoch 55 Batch 15 Loss 0.0439 Accuracy 5.2700\n",
      "Epoch 55 Batch 20 Loss 0.0439 Accuracy 5.2704\n",
      "Epoch 55 Batch 25 Loss 0.0439 Accuracy 5.2709\n",
      "Epoch 55 Batch 30 Loss 0.0439 Accuracy 5.2713\n",
      "Epoch 55 Batch 35 Loss 0.0439 Accuracy 5.2717\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2868\n",
      "Epoch 56 Batch 5 Loss 0.0439 Accuracy 5.2724\n",
      "Epoch 56 Batch 10 Loss 0.0439 Accuracy 5.2728\n",
      "Epoch 56 Batch 15 Loss 0.0439 Accuracy 5.2732\n",
      "Epoch 56 Batch 20 Loss 0.0439 Accuracy 5.2737\n",
      "Epoch 56 Batch 25 Loss 0.0438 Accuracy 5.2741\n",
      "Epoch 56 Batch 30 Loss 0.0438 Accuracy 5.2745\n",
      "Epoch 56 Batch 35 Loss 0.0438 Accuracy 5.2749\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2897\n",
      "Epoch 57 Batch 5 Loss 0.0438 Accuracy 5.2755\n",
      "Epoch 57 Batch 10 Loss 0.0438 Accuracy 5.2759\n",
      "Epoch 57 Batch 15 Loss 0.0438 Accuracy 5.2763\n",
      "Epoch 57 Batch 20 Loss 0.0438 Accuracy 5.2767\n",
      "Epoch 57 Batch 25 Loss 0.0438 Accuracy 5.2771\n",
      "Epoch 57 Batch 30 Loss 0.0438 Accuracy 5.2775\n",
      "Epoch 57 Batch 35 Loss 0.0438 Accuracy 5.2779\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2924\n",
      "Epoch 58 Batch 5 Loss 0.0438 Accuracy 5.2784\n",
      "Epoch 58 Batch 10 Loss 0.0438 Accuracy 5.2788\n",
      "Epoch 58 Batch 15 Loss 0.0438 Accuracy 5.2792\n",
      "Epoch 58 Batch 20 Loss 0.0438 Accuracy 5.2795\n",
      "Epoch 58 Batch 25 Loss 0.0438 Accuracy 5.2799\n",
      "Epoch 58 Batch 30 Loss 0.0438 Accuracy 5.2803\n",
      "Epoch 58 Batch 35 Loss 0.0438 Accuracy 5.2806\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2949\n",
      "Epoch 59 Batch 5 Loss 0.0438 Accuracy 5.2811\n",
      "Epoch 59 Batch 10 Loss 0.0438 Accuracy 5.2815\n",
      "Epoch 59 Batch 15 Loss 0.0437 Accuracy 5.2819\n",
      "Epoch 59 Batch 20 Loss 0.0437 Accuracy 5.2822\n",
      "Epoch 59 Batch 25 Loss 0.0437 Accuracy 5.2826\n",
      "Epoch 59 Batch 30 Loss 0.0437 Accuracy 5.2829\n",
      "Epoch 59 Batch 35 Loss 0.0437 Accuracy 5.2832\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2973\n",
      "Epoch 60 Batch 5 Loss 0.0437 Accuracy 5.2837\n",
      "Epoch 60 Batch 10 Loss 0.0437 Accuracy 5.2841\n",
      "Epoch 60 Batch 15 Loss 0.0437 Accuracy 5.2844\n",
      "Epoch 60 Batch 20 Loss 0.0437 Accuracy 5.2847\n",
      "Epoch 60 Batch 25 Loss 0.0437 Accuracy 5.2851\n",
      "Epoch 60 Batch 30 Loss 0.0437 Accuracy 5.2854\n",
      "Epoch 60 Batch 35 Loss 0.0437 Accuracy 5.2857\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2995\n",
      "Epoch 61 Batch 5 Loss 0.0437 Accuracy 5.2861\n",
      "Epoch 61 Batch 10 Loss 0.0437 Accuracy 5.2865\n",
      "Epoch 61 Batch 15 Loss 0.0437 Accuracy 5.2868\n",
      "Epoch 61 Batch 20 Loss 0.0437 Accuracy 5.2871\n",
      "Epoch 61 Batch 25 Loss 0.0437 Accuracy 5.2874\n",
      "Epoch 61 Batch 30 Loss 0.0436 Accuracy 5.2877\n",
      "Epoch 61 Batch 35 Loss 0.0436 Accuracy 5.2880\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3016\n",
      "Epoch 62 Batch 5 Loss 0.0437 Accuracy 5.2884\n",
      "Epoch 62 Batch 10 Loss 0.0437 Accuracy 5.2887\n",
      "Epoch 62 Batch 15 Loss 0.0437 Accuracy 5.2890\n",
      "Epoch 62 Batch 20 Loss 0.0436 Accuracy 5.2893\n",
      "Epoch 62 Batch 25 Loss 0.0436 Accuracy 5.2896\n",
      "Epoch 62 Batch 30 Loss 0.0436 Accuracy 5.2899\n",
      "Epoch 62 Batch 35 Loss 0.0436 Accuracy 5.2902\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3036\n",
      "Epoch 63 Batch 5 Loss 0.0436 Accuracy 5.2906\n",
      "Epoch 63 Batch 10 Loss 0.0436 Accuracy 5.2909\n",
      "Epoch 63 Batch 15 Loss 0.0436 Accuracy 5.2912\n",
      "Epoch 63 Batch 20 Loss 0.0436 Accuracy 5.2915\n",
      "Epoch 63 Batch 25 Loss 0.0436 Accuracy 5.2918\n",
      "Epoch 63 Batch 30 Loss 0.0436 Accuracy 5.2920\n",
      "Epoch 63 Batch 35 Loss 0.0436 Accuracy 5.2923\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3055\n",
      "Epoch 64 Batch 5 Loss 0.0436 Accuracy 5.2927\n",
      "Epoch 64 Batch 10 Loss 0.0436 Accuracy 5.2930\n",
      "Epoch 64 Batch 15 Loss 0.0436 Accuracy 5.2933\n",
      "Epoch 64 Batch 20 Loss 0.0436 Accuracy 5.2935\n",
      "Epoch 64 Batch 25 Loss 0.0436 Accuracy 5.2938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Batch 30 Loss 0.0436 Accuracy 5.2941\n",
      "Epoch 64 Batch 35 Loss 0.0436 Accuracy 5.2943\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3074\n",
      "Epoch 65 Batch 5 Loss 0.0436 Accuracy 5.2947\n",
      "Epoch 65 Batch 10 Loss 0.0436 Accuracy 5.2950\n",
      "Epoch 65 Batch 15 Loss 0.0436 Accuracy 5.2953\n",
      "Epoch 65 Batch 20 Loss 0.0436 Accuracy 5.2955\n",
      "Epoch 65 Batch 25 Loss 0.0436 Accuracy 5.2958\n",
      "Epoch 65 Batch 30 Loss 0.0436 Accuracy 5.2960\n",
      "Epoch 65 Batch 35 Loss 0.0436 Accuracy 5.2963\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3091\n",
      "Epoch 66 Batch 5 Loss 0.0436 Accuracy 5.2967\n",
      "Epoch 66 Batch 10 Loss 0.0436 Accuracy 5.2969\n",
      "Epoch 66 Batch 15 Loss 0.0436 Accuracy 5.2972\n",
      "Epoch 66 Batch 20 Loss 0.0436 Accuracy 5.2974\n",
      "Epoch 66 Batch 25 Loss 0.0436 Accuracy 5.2977\n",
      "Epoch 66 Batch 30 Loss 0.0436 Accuracy 5.2979\n",
      "Epoch 66 Batch 35 Loss 0.0436 Accuracy 5.2982\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3108\n",
      "Epoch 67 Batch 5 Loss 0.0436 Accuracy 5.2985\n",
      "Epoch 67 Batch 10 Loss 0.0436 Accuracy 5.2988\n",
      "Epoch 67 Batch 15 Loss 0.0436 Accuracy 5.2990\n",
      "Epoch 67 Batch 20 Loss 0.0436 Accuracy 5.2992\n",
      "Epoch 67 Batch 25 Loss 0.0436 Accuracy 5.2995\n",
      "Epoch 67 Batch 30 Loss 0.0435 Accuracy 5.2997\n",
      "Epoch 67 Batch 35 Loss 0.0435 Accuracy 5.2999\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3124\n",
      "Epoch 68 Batch 5 Loss 0.0435 Accuracy 5.3002\n",
      "Epoch 68 Batch 10 Loss 0.0435 Accuracy 5.3005\n",
      "Epoch 68 Batch 15 Loss 0.0435 Accuracy 5.3007\n",
      "Epoch 68 Batch 20 Loss 0.0435 Accuracy 5.3009\n",
      "Epoch 68 Batch 25 Loss 0.0435 Accuracy 5.3011\n",
      "Epoch 68 Batch 30 Loss 0.0435 Accuracy 5.3013\n",
      "Epoch 68 Batch 35 Loss 0.0435 Accuracy 5.3015\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3137\n",
      "Epoch 69 Batch 5 Loss 0.0434 Accuracy 5.3018\n",
      "Epoch 69 Batch 10 Loss 0.0434 Accuracy 5.3020\n",
      "Epoch 69 Batch 15 Loss 0.0434 Accuracy 5.3022\n",
      "Epoch 69 Batch 20 Loss 0.0434 Accuracy 5.3024\n",
      "Epoch 69 Batch 25 Loss 0.0434 Accuracy 5.3026\n",
      "Epoch 69 Batch 30 Loss 0.0434 Accuracy 5.3028\n",
      "Epoch 69 Batch 35 Loss 0.0434 Accuracy 5.3030\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3150\n",
      "Epoch 70 Batch 5 Loss 0.0434 Accuracy 5.3032\n",
      "Epoch 70 Batch 10 Loss 0.0434 Accuracy 5.3034\n",
      "Epoch 70 Batch 15 Loss 0.0434 Accuracy 5.3036\n",
      "Epoch 70 Batch 20 Loss 0.0434 Accuracy 5.3037\n",
      "Epoch 70 Batch 25 Loss 0.0434 Accuracy 5.3039\n",
      "Epoch 70 Batch 30 Loss 0.0433 Accuracy 5.3041\n",
      "Epoch 70 Batch 35 Loss 0.0433 Accuracy 5.3042\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3161\n",
      "Epoch 71 Batch 5 Loss 0.0433 Accuracy 5.3045\n",
      "Epoch 71 Batch 10 Loss 0.0433 Accuracy 5.3046\n",
      "Epoch 71 Batch 15 Loss 0.0433 Accuracy 5.3048\n",
      "Epoch 71 Batch 20 Loss 0.0433 Accuracy 5.3050\n",
      "Epoch 71 Batch 25 Loss 0.0433 Accuracy 5.3051\n",
      "Epoch 71 Batch 30 Loss 0.0433 Accuracy 5.3053\n",
      "Epoch 71 Batch 35 Loss 0.0433 Accuracy 5.3054\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3171\n",
      "Epoch 72 Batch 5 Loss 0.0433 Accuracy 5.3057\n",
      "Epoch 72 Batch 10 Loss 0.0433 Accuracy 5.3058\n",
      "Epoch 72 Batch 15 Loss 0.0433 Accuracy 5.3060\n",
      "Epoch 72 Batch 20 Loss 0.0433 Accuracy 5.3061\n",
      "Epoch 72 Batch 25 Loss 0.0433 Accuracy 5.3063\n",
      "Epoch 72 Batch 30 Loss 0.0433 Accuracy 5.3064\n",
      "Epoch 72 Batch 35 Loss 0.0433 Accuracy 5.3065\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3180\n",
      "Epoch 73 Batch 5 Loss 0.0433 Accuracy 5.3067\n",
      "Epoch 73 Batch 10 Loss 0.0433 Accuracy 5.3069\n",
      "Epoch 73 Batch 15 Loss 0.0433 Accuracy 5.3070\n",
      "Epoch 73 Batch 20 Loss 0.0433 Accuracy 5.3072\n",
      "Epoch 73 Batch 25 Loss 0.0433 Accuracy 5.3073\n",
      "Epoch 73 Batch 30 Loss 0.0433 Accuracy 5.3074\n",
      "Epoch 73 Batch 35 Loss 0.0433 Accuracy 5.3076\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3189\n",
      "Epoch 74 Batch 5 Loss 0.0433 Accuracy 5.3078\n",
      "Epoch 74 Batch 10 Loss 0.0433 Accuracy 5.3079\n",
      "Epoch 74 Batch 15 Loss 0.0433 Accuracy 5.3080\n",
      "Epoch 74 Batch 20 Loss 0.0433 Accuracy 5.3082\n",
      "Epoch 74 Batch 25 Loss 0.0433 Accuracy 5.3083\n",
      "Epoch 74 Batch 30 Loss 0.0432 Accuracy 5.3085\n",
      "Epoch 74 Batch 35 Loss 0.0432 Accuracy 5.3086\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3198\n",
      "Epoch 75 Batch 5 Loss 0.0433 Accuracy 5.3088\n",
      "Epoch 75 Batch 10 Loss 0.0433 Accuracy 5.3089\n",
      "Epoch 75 Batch 15 Loss 0.0433 Accuracy 5.3090\n",
      "Epoch 75 Batch 20 Loss 0.0433 Accuracy 5.3092\n",
      "Epoch 75 Batch 25 Loss 0.0433 Accuracy 5.3093\n",
      "Epoch 75 Batch 30 Loss 0.0432 Accuracy 5.3094\n",
      "Epoch 75 Batch 35 Loss 0.0432 Accuracy 5.3095\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3206\n",
      "Epoch 76 Batch 5 Loss 0.0432 Accuracy 5.3097\n",
      "Epoch 76 Batch 10 Loss 0.0432 Accuracy 5.3098\n",
      "Epoch 76 Batch 15 Loss 0.0432 Accuracy 5.3100\n",
      "Epoch 76 Batch 20 Loss 0.0432 Accuracy 5.3101\n",
      "Epoch 76 Batch 25 Loss 0.0432 Accuracy 5.3102\n",
      "Epoch 76 Batch 30 Loss 0.0432 Accuracy 5.3103\n",
      "Epoch 76 Batch 35 Loss 0.0432 Accuracy 5.3104\n",
      "Time taken for 1 epoch: 0.54 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3214\n",
      "Epoch 77 Batch 5 Loss 0.0432 Accuracy 5.3106\n",
      "Epoch 77 Batch 10 Loss 0.0432 Accuracy 5.3107\n",
      "Epoch 77 Batch 15 Loss 0.0432 Accuracy 5.3108\n",
      "Epoch 77 Batch 20 Loss 0.0432 Accuracy 5.3110\n",
      "Epoch 77 Batch 25 Loss 0.0432 Accuracy 5.3111\n",
      "Epoch 77 Batch 30 Loss 0.0432 Accuracy 5.3112\n",
      "Epoch 77 Batch 35 Loss 0.0432 Accuracy 5.3113\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3220\n",
      "Epoch 78 Batch 5 Loss 0.0432 Accuracy 5.3114\n",
      "Epoch 78 Batch 10 Loss 0.0432 Accuracy 5.3115\n",
      "Epoch 78 Batch 15 Loss 0.0432 Accuracy 5.3116\n",
      "Epoch 78 Batch 20 Loss 0.0432 Accuracy 5.3117\n",
      "Epoch 78 Batch 25 Loss 0.0432 Accuracy 5.3118\n",
      "Epoch 78 Batch 30 Loss 0.0432 Accuracy 5.3119\n",
      "Epoch 78 Batch 35 Loss 0.0432 Accuracy 5.3120\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3227\n",
      "Epoch 79 Batch 5 Loss 0.0432 Accuracy 5.3122\n",
      "Epoch 79 Batch 10 Loss 0.0432 Accuracy 5.3123\n",
      "Epoch 79 Batch 15 Loss 0.0432 Accuracy 5.3124\n",
      "Epoch 79 Batch 20 Loss 0.0432 Accuracy 5.3125\n",
      "Epoch 79 Batch 25 Loss 0.0432 Accuracy 5.3126\n",
      "Epoch 79 Batch 30 Loss 0.0432 Accuracy 5.3127\n",
      "Epoch 79 Batch 35 Loss 0.0432 Accuracy 5.3128\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3234\n",
      "Epoch 80 Batch 5 Loss 0.0432 Accuracy 5.3129\n",
      "Epoch 80 Batch 10 Loss 0.0432 Accuracy 5.3130\n",
      "Epoch 80 Batch 15 Loss 0.0432 Accuracy 5.3131\n",
      "Epoch 80 Batch 20 Loss 0.0432 Accuracy 5.3132\n",
      "Epoch 80 Batch 25 Loss 0.0432 Accuracy 5.3133\n",
      "Epoch 80 Batch 30 Loss 0.0432 Accuracy 5.3134\n",
      "Epoch 80 Batch 35 Loss 0.0432 Accuracy 5.3135\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3240\n",
      "Epoch 81 Batch 5 Loss 0.0432 Accuracy 5.3137\n",
      "Epoch 81 Batch 10 Loss 0.0432 Accuracy 5.3138\n",
      "Epoch 81 Batch 15 Loss 0.0432 Accuracy 5.3139\n",
      "Epoch 81 Batch 20 Loss 0.0432 Accuracy 5.3140\n",
      "Epoch 81 Batch 25 Loss 0.0432 Accuracy 5.3141\n",
      "Epoch 81 Batch 30 Loss 0.0432 Accuracy 5.3142\n",
      "Epoch 81 Batch 35 Loss 0.0432 Accuracy 5.3143\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3246\n",
      "Epoch 82 Batch 5 Loss 0.0432 Accuracy 5.3144\n",
      "Epoch 82 Batch 10 Loss 0.0432 Accuracy 5.3145\n",
      "Epoch 82 Batch 15 Loss 0.0432 Accuracy 5.3146\n",
      "Epoch 82 Batch 20 Loss 0.0432 Accuracy 5.3147\n",
      "Epoch 82 Batch 25 Loss 0.0432 Accuracy 5.3148\n",
      "Epoch 82 Batch 30 Loss 0.0432 Accuracy 5.3149\n",
      "Epoch 82 Batch 35 Loss 0.0432 Accuracy 5.3150\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3253\n",
      "Epoch 83 Batch 5 Loss 0.0432 Accuracy 5.3152\n",
      "Epoch 83 Batch 10 Loss 0.0432 Accuracy 5.3153\n",
      "Epoch 83 Batch 15 Loss 0.0432 Accuracy 5.3154\n",
      "Epoch 83 Batch 20 Loss 0.0432 Accuracy 5.3155\n",
      "Epoch 83 Batch 25 Loss 0.0432 Accuracy 5.3156\n",
      "Epoch 83 Batch 30 Loss 0.0432 Accuracy 5.3157\n",
      "Epoch 83 Batch 35 Loss 0.0432 Accuracy 5.3158\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3259\n",
      "Epoch 84 Batch 5 Loss 0.0432 Accuracy 5.3159\n",
      "Epoch 84 Batch 10 Loss 0.0432 Accuracy 5.3160\n",
      "Epoch 84 Batch 15 Loss 0.0432 Accuracy 5.3161\n",
      "Epoch 84 Batch 20 Loss 0.0432 Accuracy 5.3162\n",
      "Epoch 84 Batch 25 Loss 0.0432 Accuracy 5.3163\n",
      "Epoch 84 Batch 30 Loss 0.0432 Accuracy 5.3164\n",
      "Epoch 84 Batch 35 Loss 0.0432 Accuracy 5.3165\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3265\n",
      "Epoch 85 Batch 5 Loss 0.0432 Accuracy 5.3166\n",
      "Epoch 85 Batch 10 Loss 0.0432 Accuracy 5.3167\n",
      "Epoch 85 Batch 15 Loss 0.0432 Accuracy 5.3168\n",
      "Epoch 85 Batch 20 Loss 0.0432 Accuracy 5.3169\n",
      "Epoch 85 Batch 25 Loss 0.0432 Accuracy 5.3170\n",
      "Epoch 85 Batch 30 Loss 0.0431 Accuracy 5.3170\n",
      "Epoch 85 Batch 35 Loss 0.0431 Accuracy 5.3171\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Batch 5 Loss 0.0431 Accuracy 5.3172\n",
      "Epoch 86 Batch 10 Loss 0.0431 Accuracy 5.3173\n",
      "Epoch 86 Batch 15 Loss 0.0431 Accuracy 5.3174\n",
      "Epoch 86 Batch 20 Loss 0.0431 Accuracy 5.3175\n",
      "Epoch 86 Batch 25 Loss 0.0431 Accuracy 5.3175\n",
      "Epoch 86 Batch 30 Loss 0.0431 Accuracy 5.3176\n",
      "Epoch 86 Batch 35 Loss 0.0431 Accuracy 5.3177\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3274\n",
      "Epoch 87 Batch 5 Loss 0.0431 Accuracy 5.3178\n",
      "Epoch 87 Batch 10 Loss 0.0431 Accuracy 5.3178\n",
      "Epoch 87 Batch 15 Loss 0.0431 Accuracy 5.3179\n",
      "Epoch 87 Batch 20 Loss 0.0431 Accuracy 5.3180\n",
      "Epoch 87 Batch 25 Loss 0.0430 Accuracy 5.3180\n",
      "Epoch 87 Batch 30 Loss 0.0430 Accuracy 5.3181\n",
      "Epoch 87 Batch 35 Loss 0.0430 Accuracy 5.3182\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3278\n",
      "Epoch 88 Batch 5 Loss 0.0430 Accuracy 5.3182\n",
      "Epoch 88 Batch 10 Loss 0.0430 Accuracy 5.3183\n",
      "Epoch 88 Batch 15 Loss 0.0430 Accuracy 5.3184\n",
      "Epoch 88 Batch 20 Loss 0.0430 Accuracy 5.3184\n",
      "Epoch 88 Batch 25 Loss 0.0430 Accuracy 5.3185\n",
      "Epoch 88 Batch 30 Loss 0.0430 Accuracy 5.3185\n",
      "Epoch 88 Batch 35 Loss 0.0430 Accuracy 5.3186\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3281\n",
      "Epoch 89 Batch 5 Loss 0.0430 Accuracy 5.3187\n",
      "Epoch 89 Batch 10 Loss 0.0430 Accuracy 5.3187\n",
      "Epoch 89 Batch 15 Loss 0.0430 Accuracy 5.3188\n",
      "Epoch 89 Batch 20 Loss 0.0430 Accuracy 5.3188\n",
      "Epoch 89 Batch 25 Loss 0.0430 Accuracy 5.3189\n",
      "Epoch 89 Batch 30 Loss 0.0430 Accuracy 5.3189\n",
      "Epoch 89 Batch 35 Loss 0.0430 Accuracy 5.3190\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3284\n",
      "Epoch 90 Batch 5 Loss 0.0430 Accuracy 5.3190\n",
      "Epoch 90 Batch 10 Loss 0.0430 Accuracy 5.3191\n",
      "Epoch 90 Batch 15 Loss 0.0430 Accuracy 5.3191\n",
      "Epoch 90 Batch 20 Loss 0.0429 Accuracy 5.3192\n",
      "Epoch 90 Batch 25 Loss 0.0429 Accuracy 5.3192\n",
      "Epoch 90 Batch 30 Loss 0.0429 Accuracy 5.3192\n",
      "Epoch 90 Batch 35 Loss 0.0429 Accuracy 5.3193\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3286\n",
      "Epoch 91 Batch 5 Loss 0.0429 Accuracy 5.3193\n",
      "Epoch 91 Batch 10 Loss 0.0429 Accuracy 5.3194\n",
      "Epoch 91 Batch 15 Loss 0.0429 Accuracy 5.3194\n",
      "Epoch 91 Batch 20 Loss 0.0429 Accuracy 5.3194\n",
      "Epoch 91 Batch 25 Loss 0.0429 Accuracy 5.3195\n",
      "Epoch 91 Batch 30 Loss 0.0429 Accuracy 5.3195\n",
      "Epoch 91 Batch 35 Loss 0.0429 Accuracy 5.3195\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3287\n",
      "Epoch 92 Batch 5 Loss 0.0429 Accuracy 5.3196\n",
      "Epoch 92 Batch 10 Loss 0.0429 Accuracy 5.3196\n",
      "Epoch 92 Batch 15 Loss 0.0429 Accuracy 5.3197\n",
      "Epoch 92 Batch 20 Loss 0.0429 Accuracy 5.3197\n",
      "Epoch 92 Batch 25 Loss 0.0429 Accuracy 5.3197\n",
      "Epoch 92 Batch 30 Loss 0.0429 Accuracy 5.3197\n",
      "Epoch 92 Batch 35 Loss 0.0429 Accuracy 5.3198\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3288\n",
      "Epoch 93 Batch 5 Loss 0.0429 Accuracy 5.3198\n",
      "Epoch 93 Batch 10 Loss 0.0429 Accuracy 5.3198\n",
      "Epoch 93 Batch 15 Loss 0.0428 Accuracy 5.3199\n",
      "Epoch 93 Batch 20 Loss 0.0428 Accuracy 5.3199\n",
      "Epoch 93 Batch 25 Loss 0.0428 Accuracy 5.3199\n",
      "Epoch 93 Batch 30 Loss 0.0428 Accuracy 5.3199\n",
      "Epoch 93 Batch 35 Loss 0.0428 Accuracy 5.3199\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3289\n",
      "Epoch 94 Batch 5 Loss 0.0428 Accuracy 5.3200\n",
      "Epoch 94 Batch 10 Loss 0.0428 Accuracy 5.3200\n",
      "Epoch 94 Batch 15 Loss 0.0428 Accuracy 5.3200\n",
      "Epoch 94 Batch 20 Loss 0.0428 Accuracy 5.3200\n",
      "Epoch 94 Batch 25 Loss 0.0428 Accuracy 5.3200\n",
      "Epoch 94 Batch 30 Loss 0.0428 Accuracy 5.3200\n",
      "Epoch 94 Batch 35 Loss 0.0428 Accuracy 5.3200\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3289\n",
      "Epoch 95 Batch 5 Loss 0.0428 Accuracy 5.3200\n",
      "Epoch 95 Batch 10 Loss 0.0428 Accuracy 5.3201\n",
      "Epoch 95 Batch 15 Loss 0.0427 Accuracy 5.3201\n",
      "Epoch 95 Batch 20 Loss 0.0427 Accuracy 5.3201\n",
      "Epoch 95 Batch 25 Loss 0.0427 Accuracy 5.3201\n",
      "Epoch 95 Batch 30 Loss 0.0427 Accuracy 5.3201\n",
      "Epoch 95 Batch 35 Loss 0.0427 Accuracy 5.3201\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3288\n",
      "Epoch 96 Batch 5 Loss 0.0427 Accuracy 5.3201\n",
      "Epoch 96 Batch 10 Loss 0.0427 Accuracy 5.3201\n",
      "Epoch 96 Batch 15 Loss 0.0427 Accuracy 5.3201\n",
      "Epoch 96 Batch 20 Loss 0.0427 Accuracy 5.3201\n",
      "Epoch 96 Batch 25 Loss 0.0427 Accuracy 5.3201\n",
      "Epoch 96 Batch 30 Loss 0.0427 Accuracy 5.3201\n",
      "Epoch 96 Batch 35 Loss 0.0427 Accuracy 5.3201\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3287\n",
      "Epoch 97 Batch 5 Loss 0.0427 Accuracy 5.3201\n",
      "Epoch 97 Batch 10 Loss 0.0426 Accuracy 5.3200\n",
      "Epoch 97 Batch 15 Loss 0.0426 Accuracy 5.3200\n",
      "Epoch 97 Batch 20 Loss 0.0426 Accuracy 5.3200\n",
      "Epoch 97 Batch 25 Loss 0.0426 Accuracy 5.3200\n",
      "Epoch 97 Batch 30 Loss 0.0426 Accuracy 5.3200\n",
      "Epoch 97 Batch 35 Loss 0.0426 Accuracy 5.3200\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3285\n",
      "Epoch 98 Batch 5 Loss 0.0426 Accuracy 5.3200\n",
      "Epoch 98 Batch 10 Loss 0.0426 Accuracy 5.3200\n",
      "Epoch 98 Batch 15 Loss 0.0426 Accuracy 5.3199\n",
      "Epoch 98 Batch 20 Loss 0.0426 Accuracy 5.3199\n",
      "Epoch 98 Batch 25 Loss 0.0426 Accuracy 5.3199\n",
      "Epoch 98 Batch 30 Loss 0.0426 Accuracy 5.3199\n",
      "Epoch 98 Batch 35 Loss 0.0426 Accuracy 5.3199\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3283\n",
      "Epoch 99 Batch 5 Loss 0.0426 Accuracy 5.3198\n",
      "Epoch 99 Batch 10 Loss 0.0426 Accuracy 5.3198\n",
      "Epoch 99 Batch 15 Loss 0.0426 Accuracy 5.3198\n",
      "Epoch 99 Batch 20 Loss 0.0426 Accuracy 5.3198\n",
      "Epoch 99 Batch 25 Loss 0.0426 Accuracy 5.3198\n",
      "Epoch 99 Batch 30 Loss 0.0425 Accuracy 5.3197\n",
      "Epoch 99 Batch 35 Loss 0.0425 Accuracy 5.3197\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3280\n",
      "Epoch 100 Batch 5 Loss 0.0425 Accuracy 5.3197\n",
      "Epoch 100 Batch 10 Loss 0.0425 Accuracy 5.3196\n",
      "Epoch 100 Batch 15 Loss 0.0425 Accuracy 5.3196\n",
      "Epoch 100 Batch 20 Loss 0.0425 Accuracy 5.3196\n",
      "Epoch 100 Batch 25 Loss 0.0425 Accuracy 5.3196\n",
      "Epoch 100 Batch 30 Loss 0.0425 Accuracy 5.3195\n",
      "Epoch 100 Batch 35 Loss 0.0425 Accuracy 5.3195\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3278\n",
      "Epoch 101 Batch 5 Loss 0.0425 Accuracy 5.3195\n",
      "Epoch 101 Batch 10 Loss 0.0425 Accuracy 5.3194\n",
      "Epoch 101 Batch 15 Loss 0.0425 Accuracy 5.3194\n",
      "Epoch 101 Batch 20 Loss 0.0425 Accuracy 5.3194\n",
      "Epoch 101 Batch 25 Loss 0.0425 Accuracy 5.3193\n",
      "Epoch 101 Batch 30 Loss 0.0425 Accuracy 5.3193\n",
      "Epoch 101 Batch 35 Loss 0.0425 Accuracy 5.3193\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3274\n",
      "Epoch 102 Batch 5 Loss 0.0425 Accuracy 5.3192\n",
      "Epoch 102 Batch 10 Loss 0.0425 Accuracy 5.3192\n",
      "Epoch 102 Batch 15 Loss 0.0425 Accuracy 5.3192\n",
      "Epoch 102 Batch 20 Loss 0.0424 Accuracy 5.3191\n",
      "Epoch 102 Batch 25 Loss 0.0424 Accuracy 5.3191\n",
      "Epoch 102 Batch 30 Loss 0.0424 Accuracy 5.3191\n",
      "Epoch 102 Batch 35 Loss 0.0424 Accuracy 5.3190\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3271\n",
      "Epoch 103 Batch 5 Loss 0.0424 Accuracy 5.3190\n",
      "Epoch 103 Batch 10 Loss 0.0424 Accuracy 5.3189\n",
      "Epoch 103 Batch 15 Loss 0.0424 Accuracy 5.3189\n",
      "Epoch 103 Batch 20 Loss 0.0424 Accuracy 5.3188\n",
      "Epoch 103 Batch 25 Loss 0.0424 Accuracy 5.3188\n",
      "Epoch 103 Batch 30 Loss 0.0424 Accuracy 5.3187\n",
      "Epoch 103 Batch 35 Loss 0.0424 Accuracy 5.3187\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3267\n",
      "Epoch 104 Batch 5 Loss 0.0424 Accuracy 5.3186\n",
      "Epoch 104 Batch 10 Loss 0.0424 Accuracy 5.3186\n",
      "Epoch 104 Batch 15 Loss 0.0424 Accuracy 5.3185\n",
      "Epoch 104 Batch 20 Loss 0.0424 Accuracy 5.3185\n",
      "Epoch 104 Batch 25 Loss 0.0423 Accuracy 5.3184\n",
      "Epoch 104 Batch 30 Loss 0.0423 Accuracy 5.3184\n",
      "Epoch 104 Batch 35 Loss 0.0423 Accuracy 5.3183\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3262\n",
      "Epoch 105 Batch 5 Loss 0.0423 Accuracy 5.3183\n",
      "Epoch 105 Batch 10 Loss 0.0423 Accuracy 5.3182\n",
      "Epoch 105 Batch 15 Loss 0.0423 Accuracy 5.3182\n",
      "Epoch 105 Batch 20 Loss 0.0423 Accuracy 5.3181\n",
      "Epoch 105 Batch 25 Loss 0.0423 Accuracy 5.3180\n",
      "Epoch 105 Batch 30 Loss 0.0423 Accuracy 5.3180\n",
      "Epoch 105 Batch 35 Loss 0.0423 Accuracy 5.3179\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3257\n",
      "Epoch 106 Batch 5 Loss 0.0423 Accuracy 5.3178\n",
      "Epoch 106 Batch 10 Loss 0.0423 Accuracy 5.3178\n",
      "Epoch 106 Batch 15 Loss 0.0423 Accuracy 5.3177\n",
      "Epoch 106 Batch 20 Loss 0.0423 Accuracy 5.3177\n",
      "Epoch 106 Batch 25 Loss 0.0423 Accuracy 5.3176\n",
      "Epoch 106 Batch 30 Loss 0.0422 Accuracy 5.3175\n",
      "Epoch 106 Batch 35 Loss 0.0422 Accuracy 5.3175\n",
      "Time taken for 1 epoch: 0.41 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3252\n",
      "Epoch 107 Batch 5 Loss 0.0422 Accuracy 5.3174\n",
      "Epoch 107 Batch 10 Loss 0.0422 Accuracy 5.3173\n",
      "Epoch 107 Batch 15 Loss 0.0422 Accuracy 5.3173\n",
      "Epoch 107 Batch 20 Loss 0.0422 Accuracy 5.3172\n",
      "Epoch 107 Batch 25 Loss 0.0422 Accuracy 5.3172\n",
      "Epoch 107 Batch 30 Loss 0.0422 Accuracy 5.3171\n",
      "Epoch 107 Batch 35 Loss 0.0422 Accuracy 5.3170\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3247\n",
      "Epoch 108 Batch 5 Loss 0.0422 Accuracy 5.3169\n",
      "Epoch 108 Batch 10 Loss 0.0422 Accuracy 5.3169\n",
      "Epoch 108 Batch 15 Loss 0.0422 Accuracy 5.3168\n",
      "Epoch 108 Batch 20 Loss 0.0422 Accuracy 5.3167\n",
      "Epoch 108 Batch 25 Loss 0.0422 Accuracy 5.3167\n",
      "Epoch 108 Batch 30 Loss 0.0422 Accuracy 5.3166\n",
      "Epoch 108 Batch 35 Loss 0.0422 Accuracy 5.3165\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3241\n",
      "Epoch 109 Batch 5 Loss 0.0422 Accuracy 5.3164\n",
      "Epoch 109 Batch 10 Loss 0.0422 Accuracy 5.3164\n",
      "Epoch 109 Batch 15 Loss 0.0422 Accuracy 5.3163\n",
      "Epoch 109 Batch 20 Loss 0.0422 Accuracy 5.3162\n",
      "Epoch 109 Batch 25 Loss 0.0422 Accuracy 5.3162\n",
      "Epoch 109 Batch 30 Loss 0.0422 Accuracy 5.3161\n",
      "Epoch 109 Batch 35 Loss 0.0422 Accuracy 5.3160\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3235\n",
      "Epoch 110 Batch 5 Loss 0.0422 Accuracy 5.3159\n",
      "Epoch 110 Batch 10 Loss 0.0422 Accuracy 5.3159\n",
      "Epoch 110 Batch 15 Loss 0.0422 Accuracy 5.3158\n",
      "Epoch 110 Batch 20 Loss 0.0422 Accuracy 5.3157\n",
      "Epoch 110 Batch 25 Loss 0.0422 Accuracy 5.3157\n",
      "Epoch 110 Batch 30 Loss 0.0421 Accuracy 5.3156\n",
      "Epoch 110 Batch 35 Loss 0.0421 Accuracy 5.3155\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3230\n",
      "Epoch 111 Batch 5 Loss 0.0421 Accuracy 5.3154\n",
      "Epoch 111 Batch 10 Loss 0.0421 Accuracy 5.3154\n",
      "Epoch 111 Batch 15 Loss 0.0421 Accuracy 5.3153\n",
      "Epoch 111 Batch 20 Loss 0.0421 Accuracy 5.3152\n",
      "Epoch 111 Batch 25 Loss 0.0421 Accuracy 5.3151\n",
      "Epoch 111 Batch 30 Loss 0.0421 Accuracy 5.3151\n",
      "Epoch 111 Batch 35 Loss 0.0421 Accuracy 5.3150\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3223\n",
      "Epoch 112 Batch 5 Loss 0.0421 Accuracy 5.3149\n",
      "Epoch 112 Batch 10 Loss 0.0421 Accuracy 5.3148\n",
      "Epoch 112 Batch 15 Loss 0.0421 Accuracy 5.3147\n",
      "Epoch 112 Batch 20 Loss 0.0421 Accuracy 5.3147\n",
      "Epoch 112 Batch 25 Loss 0.0421 Accuracy 5.3146\n",
      "Epoch 112 Batch 30 Loss 0.0421 Accuracy 5.3145\n",
      "Epoch 112 Batch 35 Loss 0.0421 Accuracy 5.3144\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3217\n",
      "Epoch 113 Batch 5 Loss 0.0421 Accuracy 5.3143\n",
      "Epoch 113 Batch 10 Loss 0.0421 Accuracy 5.3142\n",
      "Epoch 113 Batch 15 Loss 0.0421 Accuracy 5.3142\n",
      "Epoch 113 Batch 20 Loss 0.0421 Accuracy 5.3141\n",
      "Epoch 113 Batch 25 Loss 0.0421 Accuracy 5.3140\n",
      "Epoch 113 Batch 30 Loss 0.0421 Accuracy 5.3139\n",
      "Epoch 113 Batch 35 Loss 0.0421 Accuracy 5.3139\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3211\n",
      "Epoch 114 Batch 5 Loss 0.0421 Accuracy 5.3137\n",
      "Epoch 114 Batch 10 Loss 0.0421 Accuracy 5.3137\n",
      "Epoch 114 Batch 15 Loss 0.0421 Accuracy 5.3136\n",
      "Epoch 114 Batch 20 Loss 0.0420 Accuracy 5.3135\n",
      "Epoch 114 Batch 25 Loss 0.0420 Accuracy 5.3134\n",
      "Epoch 114 Batch 30 Loss 0.0420 Accuracy 5.3133\n",
      "Epoch 114 Batch 35 Loss 0.0420 Accuracy 5.3133\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3204\n",
      "Epoch 115 Batch 5 Loss 0.0420 Accuracy 5.3132\n",
      "Epoch 115 Batch 10 Loss 0.0420 Accuracy 5.3131\n",
      "Epoch 115 Batch 15 Loss 0.0420 Accuracy 5.3130\n",
      "Epoch 115 Batch 20 Loss 0.0420 Accuracy 5.3129\n",
      "Epoch 115 Batch 25 Loss 0.0420 Accuracy 5.3128\n",
      "Epoch 115 Batch 30 Loss 0.0420 Accuracy 5.3127\n",
      "Epoch 115 Batch 35 Loss 0.0420 Accuracy 5.3127\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3198\n",
      "Epoch 116 Batch 5 Loss 0.0420 Accuracy 5.3126\n",
      "Epoch 116 Batch 10 Loss 0.0420 Accuracy 5.3125\n",
      "Epoch 116 Batch 15 Loss 0.0420 Accuracy 5.3124\n",
      "Epoch 116 Batch 20 Loss 0.0420 Accuracy 5.3123\n",
      "Epoch 116 Batch 25 Loss 0.0420 Accuracy 5.3122\n",
      "Epoch 116 Batch 30 Loss 0.0420 Accuracy 5.3121\n",
      "Epoch 116 Batch 35 Loss 0.0420 Accuracy 5.3121\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3191\n",
      "Epoch 117 Batch 5 Loss 0.0420 Accuracy 5.3120\n",
      "Epoch 117 Batch 10 Loss 0.0420 Accuracy 5.3119\n",
      "Epoch 117 Batch 15 Loss 0.0420 Accuracy 5.3118\n",
      "Epoch 117 Batch 20 Loss 0.0420 Accuracy 5.3117\n",
      "Epoch 117 Batch 25 Loss 0.0420 Accuracy 5.3116\n",
      "Epoch 117 Batch 30 Loss 0.0420 Accuracy 5.3116\n",
      "Epoch 117 Batch 35 Loss 0.0420 Accuracy 5.3115\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3185\n",
      "Epoch 118 Batch 5 Loss 0.0420 Accuracy 5.3114\n",
      "Epoch 118 Batch 10 Loss 0.0420 Accuracy 5.3113\n",
      "Epoch 118 Batch 15 Loss 0.0420 Accuracy 5.3112\n",
      "Epoch 118 Batch 20 Loss 0.0420 Accuracy 5.3112\n",
      "Epoch 118 Batch 25 Loss 0.0420 Accuracy 5.3111\n",
      "Epoch 118 Batch 30 Loss 0.0420 Accuracy 5.3110\n",
      "Epoch 118 Batch 35 Loss 0.0420 Accuracy 5.3109\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3179\n",
      "Epoch 119 Batch 5 Loss 0.0421 Accuracy 5.3108\n",
      "Epoch 119 Batch 10 Loss 0.0421 Accuracy 5.3108\n",
      "Epoch 119 Batch 15 Loss 0.0421 Accuracy 5.3107\n",
      "Epoch 119 Batch 20 Loss 0.0421 Accuracy 5.3106\n",
      "Epoch 119 Batch 25 Loss 0.0421 Accuracy 5.3106\n",
      "Epoch 119 Batch 30 Loss 0.0421 Accuracy 5.3105\n",
      "Epoch 119 Batch 35 Loss 0.0421 Accuracy 5.3104\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3174\n",
      "Epoch 120 Batch 5 Loss 0.0421 Accuracy 5.3103\n",
      "Epoch 120 Batch 10 Loss 0.0421 Accuracy 5.3102\n",
      "Epoch 120 Batch 15 Loss 0.0421 Accuracy 5.3102\n",
      "Epoch 120 Batch 20 Loss 0.0421 Accuracy 5.3101\n",
      "Epoch 120 Batch 25 Loss 0.0421 Accuracy 5.3100\n",
      "Epoch 120 Batch 30 Loss 0.0421 Accuracy 5.3100\n",
      "Epoch 120 Batch 35 Loss 0.0421 Accuracy 5.3099\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3168\n",
      "Epoch 121 Batch 5 Loss 0.0421 Accuracy 5.3098\n",
      "Epoch 121 Batch 10 Loss 0.0421 Accuracy 5.3097\n",
      "Epoch 121 Batch 15 Loss 0.0421 Accuracy 5.3097\n",
      "Epoch 121 Batch 20 Loss 0.0421 Accuracy 5.3096\n",
      "Epoch 121 Batch 25 Loss 0.0421 Accuracy 5.3095\n",
      "Epoch 121 Batch 30 Loss 0.0421 Accuracy 5.3095\n",
      "Epoch 121 Batch 35 Loss 0.0421 Accuracy 5.3094\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3163\n",
      "Epoch 122 Batch 5 Loss 0.0421 Accuracy 5.3093\n",
      "Epoch 122 Batch 10 Loss 0.0421 Accuracy 5.3092\n",
      "Epoch 122 Batch 15 Loss 0.0421 Accuracy 5.3092\n",
      "Epoch 122 Batch 20 Loss 0.0421 Accuracy 5.3091\n",
      "Epoch 122 Batch 25 Loss 0.0421 Accuracy 5.3090\n",
      "Epoch 122 Batch 30 Loss 0.0421 Accuracy 5.3090\n",
      "Epoch 122 Batch 35 Loss 0.0421 Accuracy 5.3089\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3157\n",
      "Epoch 123 Batch 5 Loss 0.0421 Accuracy 5.3088\n",
      "Epoch 123 Batch 10 Loss 0.0421 Accuracy 5.3087\n",
      "Epoch 123 Batch 15 Loss 0.0421 Accuracy 5.3087\n",
      "Epoch 123 Batch 20 Loss 0.0421 Accuracy 5.3086\n",
      "Epoch 123 Batch 25 Loss 0.0421 Accuracy 5.3086\n",
      "Epoch 123 Batch 30 Loss 0.0421 Accuracy 5.3085\n",
      "Epoch 123 Batch 35 Loss 0.0421 Accuracy 5.3084\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3152\n",
      "Epoch 124 Batch 5 Loss 0.0421 Accuracy 5.3083\n",
      "Epoch 124 Batch 10 Loss 0.0421 Accuracy 5.3083\n",
      "Epoch 124 Batch 15 Loss 0.0421 Accuracy 5.3082\n",
      "Epoch 124 Batch 20 Loss 0.0421 Accuracy 5.3081\n",
      "Epoch 124 Batch 25 Loss 0.0421 Accuracy 5.3081\n",
      "Epoch 124 Batch 30 Loss 0.0421 Accuracy 5.3080\n",
      "Epoch 124 Batch 35 Loss 0.0421 Accuracy 5.3079\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3147\n",
      "Epoch 125 Batch 5 Loss 0.0421 Accuracy 5.3078\n",
      "Epoch 125 Batch 10 Loss 0.0421 Accuracy 5.3078\n",
      "Epoch 125 Batch 15 Loss 0.0421 Accuracy 5.3077\n",
      "Epoch 125 Batch 20 Loss 0.0421 Accuracy 5.3077\n",
      "Epoch 125 Batch 25 Loss 0.0421 Accuracy 5.3076\n",
      "Epoch 125 Batch 30 Loss 0.0420 Accuracy 5.3075\n",
      "Epoch 125 Batch 35 Loss 0.0420 Accuracy 5.3075\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3141\n",
      "Epoch 126 Batch 5 Loss 0.0420 Accuracy 5.3074\n",
      "Epoch 126 Batch 10 Loss 0.0420 Accuracy 5.3073\n",
      "Epoch 126 Batch 15 Loss 0.0420 Accuracy 5.3072\n",
      "Epoch 126 Batch 20 Loss 0.0420 Accuracy 5.3072\n",
      "Epoch 126 Batch 25 Loss 0.0420 Accuracy 5.3071\n",
      "Epoch 126 Batch 30 Loss 0.0420 Accuracy 5.3070\n",
      "Epoch 126 Batch 35 Loss 0.0420 Accuracy 5.3070\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3136\n",
      "Epoch 127 Batch 5 Loss 0.0420 Accuracy 5.3069\n",
      "Epoch 127 Batch 10 Loss 0.0420 Accuracy 5.3068\n",
      "Epoch 127 Batch 15 Loss 0.0420 Accuracy 5.3067\n",
      "Epoch 127 Batch 20 Loss 0.0420 Accuracy 5.3067\n",
      "Epoch 127 Batch 25 Loss 0.0420 Accuracy 5.3066\n",
      "Epoch 127 Batch 30 Loss 0.0420 Accuracy 5.3065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127 Batch 35 Loss 0.0420 Accuracy 5.3064\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3130\n",
      "Epoch 128 Batch 5 Loss 0.0420 Accuracy 5.3063\n",
      "Epoch 128 Batch 10 Loss 0.0420 Accuracy 5.3063\n",
      "Epoch 128 Batch 15 Loss 0.0420 Accuracy 5.3062\n",
      "Epoch 128 Batch 20 Loss 0.0420 Accuracy 5.3061\n",
      "Epoch 128 Batch 25 Loss 0.0420 Accuracy 5.3061\n",
      "Epoch 128 Batch 30 Loss 0.0420 Accuracy 5.3060\n",
      "Epoch 128 Batch 35 Loss 0.0420 Accuracy 5.3059\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3124\n",
      "Epoch 129 Batch 5 Loss 0.0420 Accuracy 5.3058\n",
      "Epoch 129 Batch 10 Loss 0.0420 Accuracy 5.3057\n",
      "Epoch 129 Batch 15 Loss 0.0419 Accuracy 5.3057\n",
      "Epoch 129 Batch 20 Loss 0.0419 Accuracy 5.3056\n",
      "Epoch 129 Batch 25 Loss 0.0419 Accuracy 5.3055\n",
      "Epoch 129 Batch 30 Loss 0.0419 Accuracy 5.3054\n",
      "Epoch 129 Batch 35 Loss 0.0419 Accuracy 5.3054\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3118\n",
      "Epoch 130 Batch 5 Loss 0.0419 Accuracy 5.3053\n",
      "Epoch 130 Batch 10 Loss 0.0419 Accuracy 5.3052\n",
      "Epoch 130 Batch 15 Loss 0.0419 Accuracy 5.3051\n",
      "Epoch 130 Batch 20 Loss 0.0419 Accuracy 5.3050\n",
      "Epoch 130 Batch 25 Loss 0.0419 Accuracy 5.3050\n",
      "Epoch 130 Batch 30 Loss 0.0419 Accuracy 5.3049\n",
      "Epoch 130 Batch 35 Loss 0.0419 Accuracy 5.3048\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3112\n",
      "Epoch 131 Batch 5 Loss 0.0419 Accuracy 5.3047\n",
      "Epoch 131 Batch 10 Loss 0.0419 Accuracy 5.3046\n",
      "Epoch 131 Batch 15 Loss 0.0419 Accuracy 5.3046\n",
      "Epoch 131 Batch 20 Loss 0.0419 Accuracy 5.3045\n",
      "Epoch 131 Batch 25 Loss 0.0419 Accuracy 5.3044\n",
      "Epoch 131 Batch 30 Loss 0.0419 Accuracy 5.3043\n",
      "Epoch 131 Batch 35 Loss 0.0419 Accuracy 5.3042\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3106\n",
      "Epoch 132 Batch 5 Loss 0.0419 Accuracy 5.3041\n",
      "Epoch 132 Batch 10 Loss 0.0419 Accuracy 5.3041\n",
      "Epoch 132 Batch 15 Loss 0.0419 Accuracy 5.3040\n",
      "Epoch 132 Batch 20 Loss 0.0419 Accuracy 5.3039\n",
      "Epoch 132 Batch 25 Loss 0.0419 Accuracy 5.3038\n",
      "Epoch 132 Batch 30 Loss 0.0419 Accuracy 5.3037\n",
      "Epoch 132 Batch 35 Loss 0.0419 Accuracy 5.3037\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3100\n",
      "Epoch 133 Batch 5 Loss 0.0419 Accuracy 5.3035\n",
      "Epoch 133 Batch 10 Loss 0.0419 Accuracy 5.3035\n",
      "Epoch 133 Batch 15 Loss 0.0418 Accuracy 5.3034\n",
      "Epoch 133 Batch 20 Loss 0.0418 Accuracy 5.3033\n",
      "Epoch 133 Batch 25 Loss 0.0418 Accuracy 5.3032\n",
      "Epoch 133 Batch 30 Loss 0.0418 Accuracy 5.3031\n",
      "Epoch 133 Batch 35 Loss 0.0418 Accuracy 5.3031\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3093\n",
      "Epoch 134 Batch 5 Loss 0.0418 Accuracy 5.3029\n",
      "Epoch 134 Batch 10 Loss 0.0418 Accuracy 5.3029\n",
      "Epoch 134 Batch 15 Loss 0.0418 Accuracy 5.3028\n",
      "Epoch 134 Batch 20 Loss 0.0418 Accuracy 5.3027\n",
      "Epoch 134 Batch 25 Loss 0.0418 Accuracy 5.3026\n",
      "Epoch 134 Batch 30 Loss 0.0418 Accuracy 5.3025\n",
      "Epoch 134 Batch 35 Loss 0.0418 Accuracy 5.3024\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3086\n",
      "Epoch 135 Batch 5 Loss 0.0418 Accuracy 5.3023\n",
      "Epoch 135 Batch 10 Loss 0.0418 Accuracy 5.3022\n",
      "Epoch 135 Batch 15 Loss 0.0418 Accuracy 5.3021\n",
      "Epoch 135 Batch 20 Loss 0.0418 Accuracy 5.3021\n",
      "Epoch 135 Batch 25 Loss 0.0418 Accuracy 5.3020\n",
      "Epoch 135 Batch 30 Loss 0.0418 Accuracy 5.3019\n",
      "Epoch 135 Batch 35 Loss 0.0418 Accuracy 5.3018\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3079\n",
      "Epoch 136 Batch 5 Loss 0.0417 Accuracy 5.3017\n",
      "Epoch 136 Batch 10 Loss 0.0417 Accuracy 5.3016\n",
      "Epoch 136 Batch 15 Loss 0.0417 Accuracy 5.3015\n",
      "Epoch 136 Batch 20 Loss 0.0417 Accuracy 5.3014\n",
      "Epoch 136 Batch 25 Loss 0.0417 Accuracy 5.3013\n",
      "Epoch 136 Batch 30 Loss 0.0417 Accuracy 5.3012\n",
      "Epoch 136 Batch 35 Loss 0.0417 Accuracy 5.3011\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3072\n",
      "Epoch 137 Batch 5 Loss 0.0417 Accuracy 5.3010\n",
      "Epoch 137 Batch 10 Loss 0.0417 Accuracy 5.3009\n",
      "Epoch 137 Batch 15 Loss 0.0417 Accuracy 5.3008\n",
      "Epoch 137 Batch 20 Loss 0.0417 Accuracy 5.3007\n",
      "Epoch 137 Batch 25 Loss 0.0417 Accuracy 5.3007\n",
      "Epoch 137 Batch 30 Loss 0.0417 Accuracy 5.3006\n",
      "Epoch 137 Batch 35 Loss 0.0417 Accuracy 5.3005\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3065\n",
      "Epoch 138 Batch 5 Loss 0.0417 Accuracy 5.3003\n",
      "Epoch 138 Batch 10 Loss 0.0417 Accuracy 5.3003\n",
      "Epoch 138 Batch 15 Loss 0.0417 Accuracy 5.3002\n",
      "Epoch 138 Batch 20 Loss 0.0417 Accuracy 5.3001\n",
      "Epoch 138 Batch 25 Loss 0.0417 Accuracy 5.3000\n",
      "Epoch 138 Batch 30 Loss 0.0417 Accuracy 5.2999\n",
      "Epoch 138 Batch 35 Loss 0.0417 Accuracy 5.2998\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3058\n",
      "Epoch 139 Batch 5 Loss 0.0417 Accuracy 5.2997\n",
      "Epoch 139 Batch 10 Loss 0.0417 Accuracy 5.2996\n",
      "Epoch 139 Batch 15 Loss 0.0417 Accuracy 5.2995\n",
      "Epoch 139 Batch 20 Loss 0.0417 Accuracy 5.2994\n",
      "Epoch 139 Batch 25 Loss 0.0417 Accuracy 5.2993\n",
      "Epoch 139 Batch 30 Loss 0.0417 Accuracy 5.2992\n",
      "Epoch 139 Batch 35 Loss 0.0417 Accuracy 5.2991\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3050\n",
      "Epoch 140 Batch 5 Loss 0.0417 Accuracy 5.2990\n",
      "Epoch 140 Batch 10 Loss 0.0417 Accuracy 5.2989\n",
      "Epoch 140 Batch 15 Loss 0.0417 Accuracy 5.2988\n",
      "Epoch 140 Batch 20 Loss 0.0416 Accuracy 5.2987\n",
      "Epoch 140 Batch 25 Loss 0.0416 Accuracy 5.2986\n",
      "Epoch 140 Batch 30 Loss 0.0416 Accuracy 5.2985\n",
      "Epoch 140 Batch 35 Loss 0.0416 Accuracy 5.2984\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3043\n",
      "Epoch 141 Batch 5 Loss 0.0416 Accuracy 5.2983\n",
      "Epoch 141 Batch 10 Loss 0.0416 Accuracy 5.2982\n",
      "Epoch 141 Batch 15 Loss 0.0416 Accuracy 5.2981\n",
      "Epoch 141 Batch 20 Loss 0.0416 Accuracy 5.2980\n",
      "Epoch 141 Batch 25 Loss 0.0416 Accuracy 5.2979\n",
      "Epoch 141 Batch 30 Loss 0.0416 Accuracy 5.2978\n",
      "Epoch 141 Batch 35 Loss 0.0416 Accuracy 5.2977\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3036\n",
      "Epoch 142 Batch 5 Loss 0.0416 Accuracy 5.2976\n",
      "Epoch 142 Batch 10 Loss 0.0416 Accuracy 5.2975\n",
      "Epoch 142 Batch 15 Loss 0.0416 Accuracy 5.2974\n",
      "Epoch 142 Batch 20 Loss 0.0416 Accuracy 5.2973\n",
      "Epoch 142 Batch 25 Loss 0.0416 Accuracy 5.2972\n",
      "Epoch 142 Batch 30 Loss 0.0416 Accuracy 5.2971\n",
      "Epoch 142 Batch 35 Loss 0.0416 Accuracy 5.2970\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3028\n",
      "Epoch 143 Batch 5 Loss 0.0416 Accuracy 5.2969\n",
      "Epoch 143 Batch 10 Loss 0.0416 Accuracy 5.2968\n",
      "Epoch 143 Batch 15 Loss 0.0416 Accuracy 5.2967\n",
      "Epoch 143 Batch 20 Loss 0.0416 Accuracy 5.2966\n",
      "Epoch 143 Batch 25 Loss 0.0415 Accuracy 5.2965\n",
      "Epoch 143 Batch 30 Loss 0.0415 Accuracy 5.2964\n",
      "Epoch 143 Batch 35 Loss 0.0415 Accuracy 5.2963\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3020\n",
      "Epoch 144 Batch 5 Loss 0.0415 Accuracy 5.2961\n",
      "Epoch 144 Batch 10 Loss 0.0415 Accuracy 5.2960\n",
      "Epoch 144 Batch 15 Loss 0.0415 Accuracy 5.2959\n",
      "Epoch 144 Batch 20 Loss 0.0415 Accuracy 5.2958\n",
      "Epoch 144 Batch 25 Loss 0.0415 Accuracy 5.2957\n",
      "Epoch 144 Batch 30 Loss 0.0415 Accuracy 5.2956\n",
      "Epoch 144 Batch 35 Loss 0.0415 Accuracy 5.2955\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3012\n",
      "Epoch 145 Batch 5 Loss 0.0415 Accuracy 5.2954\n",
      "Epoch 145 Batch 10 Loss 0.0415 Accuracy 5.2953\n",
      "Epoch 145 Batch 15 Loss 0.0415 Accuracy 5.2952\n",
      "Epoch 145 Batch 20 Loss 0.0415 Accuracy 5.2950\n",
      "Epoch 145 Batch 25 Loss 0.0415 Accuracy 5.2949\n",
      "Epoch 145 Batch 30 Loss 0.0415 Accuracy 5.2948\n",
      "Epoch 145 Batch 35 Loss 0.0415 Accuracy 5.2947\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.3004\n",
      "Epoch 146 Batch 5 Loss 0.0415 Accuracy 5.2946\n",
      "Epoch 146 Batch 10 Loss 0.0414 Accuracy 5.2945\n",
      "Epoch 146 Batch 15 Loss 0.0414 Accuracy 5.2944\n",
      "Epoch 146 Batch 20 Loss 0.0414 Accuracy 5.2943\n",
      "Epoch 146 Batch 25 Loss 0.0414 Accuracy 5.2942\n",
      "Epoch 146 Batch 30 Loss 0.0414 Accuracy 5.2940\n",
      "Epoch 146 Batch 35 Loss 0.0414 Accuracy 5.2939\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2995\n",
      "Epoch 147 Batch 5 Loss 0.0414 Accuracy 5.2938\n",
      "Epoch 147 Batch 10 Loss 0.0414 Accuracy 5.2937\n",
      "Epoch 147 Batch 15 Loss 0.0414 Accuracy 5.2936\n",
      "Epoch 147 Batch 20 Loss 0.0414 Accuracy 5.2935\n",
      "Epoch 147 Batch 25 Loss 0.0414 Accuracy 5.2933\n",
      "Epoch 147 Batch 30 Loss 0.0414 Accuracy 5.2932\n",
      "Epoch 147 Batch 35 Loss 0.0414 Accuracy 5.2931\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2987\n",
      "Epoch 148 Batch 5 Loss 0.0414 Accuracy 5.2930\n",
      "Epoch 148 Batch 10 Loss 0.0414 Accuracy 5.2929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148 Batch 15 Loss 0.0414 Accuracy 5.2928\n",
      "Epoch 148 Batch 20 Loss 0.0414 Accuracy 5.2926\n",
      "Epoch 148 Batch 25 Loss 0.0414 Accuracy 5.2925\n",
      "Epoch 148 Batch 30 Loss 0.0414 Accuracy 5.2924\n",
      "Epoch 148 Batch 35 Loss 0.0414 Accuracy 5.2923\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2978\n",
      "Epoch 149 Batch 5 Loss 0.0414 Accuracy 5.2921\n",
      "Epoch 149 Batch 10 Loss 0.0414 Accuracy 5.2920\n",
      "Epoch 149 Batch 15 Loss 0.0414 Accuracy 5.2919\n",
      "Epoch 149 Batch 20 Loss 0.0414 Accuracy 5.2918\n",
      "Epoch 149 Batch 25 Loss 0.0414 Accuracy 5.2917\n",
      "Epoch 149 Batch 30 Loss 0.0413 Accuracy 5.2916\n",
      "Epoch 149 Batch 35 Loss 0.0413 Accuracy 5.2915\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2970\n",
      "Epoch 150 Batch 5 Loss 0.0413 Accuracy 5.2913\n",
      "Epoch 150 Batch 10 Loss 0.0413 Accuracy 5.2912\n",
      "Epoch 150 Batch 15 Loss 0.0413 Accuracy 5.2911\n",
      "Epoch 150 Batch 20 Loss 0.0413 Accuracy 5.2910\n",
      "Epoch 150 Batch 25 Loss 0.0413 Accuracy 5.2909\n",
      "Epoch 150 Batch 30 Loss 0.0413 Accuracy 5.2908\n",
      "Epoch 150 Batch 35 Loss 0.0413 Accuracy 5.2907\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2961\n",
      "Epoch 151 Batch 5 Loss 0.0413 Accuracy 5.2905\n",
      "Epoch 151 Batch 10 Loss 0.0413 Accuracy 5.2904\n",
      "Epoch 151 Batch 15 Loss 0.0413 Accuracy 5.2903\n",
      "Epoch 151 Batch 20 Loss 0.0413 Accuracy 5.2902\n",
      "Epoch 151 Batch 25 Loss 0.0413 Accuracy 5.2900\n",
      "Epoch 151 Batch 30 Loss 0.0413 Accuracy 5.2899\n",
      "Epoch 151 Batch 35 Loss 0.0413 Accuracy 5.2898\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2952\n",
      "Epoch 152 Batch 5 Loss 0.0413 Accuracy 5.2896\n",
      "Epoch 152 Batch 10 Loss 0.0413 Accuracy 5.2895\n",
      "Epoch 152 Batch 15 Loss 0.0413 Accuracy 5.2894\n",
      "Epoch 152 Batch 20 Loss 0.0413 Accuracy 5.2893\n",
      "Epoch 152 Batch 25 Loss 0.0413 Accuracy 5.2892\n",
      "Epoch 152 Batch 30 Loss 0.0413 Accuracy 5.2891\n",
      "Epoch 152 Batch 35 Loss 0.0412 Accuracy 5.2890\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2943\n",
      "Epoch 153 Batch 5 Loss 0.0412 Accuracy 5.2888\n",
      "Epoch 153 Batch 10 Loss 0.0412 Accuracy 5.2887\n",
      "Epoch 153 Batch 15 Loss 0.0412 Accuracy 5.2886\n",
      "Epoch 153 Batch 20 Loss 0.0412 Accuracy 5.2884\n",
      "Epoch 153 Batch 25 Loss 0.0412 Accuracy 5.2883\n",
      "Epoch 153 Batch 30 Loss 0.0412 Accuracy 5.2882\n",
      "Epoch 153 Batch 35 Loss 0.0412 Accuracy 5.2881\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2934\n",
      "Epoch 154 Batch 5 Loss 0.0412 Accuracy 5.2879\n",
      "Epoch 154 Batch 10 Loss 0.0412 Accuracy 5.2878\n",
      "Epoch 154 Batch 15 Loss 0.0412 Accuracy 5.2877\n",
      "Epoch 154 Batch 20 Loss 0.0412 Accuracy 5.2876\n",
      "Epoch 154 Batch 25 Loss 0.0412 Accuracy 5.2875\n",
      "Epoch 154 Batch 30 Loss 0.0412 Accuracy 5.2873\n",
      "Epoch 154 Batch 35 Loss 0.0412 Accuracy 5.2872\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2925\n",
      "Epoch 155 Batch 5 Loss 0.0412 Accuracy 5.2870\n",
      "Epoch 155 Batch 10 Loss 0.0412 Accuracy 5.2869\n",
      "Epoch 155 Batch 15 Loss 0.0412 Accuracy 5.2868\n",
      "Epoch 155 Batch 20 Loss 0.0412 Accuracy 5.2867\n",
      "Epoch 155 Batch 25 Loss 0.0412 Accuracy 5.2866\n",
      "Epoch 155 Batch 30 Loss 0.0412 Accuracy 5.2864\n",
      "Epoch 155 Batch 35 Loss 0.0412 Accuracy 5.2863\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2916\n",
      "Epoch 156 Batch 5 Loss 0.0412 Accuracy 5.2862\n",
      "Epoch 156 Batch 10 Loss 0.0412 Accuracy 5.2860\n",
      "Epoch 156 Batch 15 Loss 0.0412 Accuracy 5.2859\n",
      "Epoch 156 Batch 20 Loss 0.0411 Accuracy 5.2858\n",
      "Epoch 156 Batch 25 Loss 0.0411 Accuracy 5.2857\n",
      "Epoch 156 Batch 30 Loss 0.0411 Accuracy 5.2855\n",
      "Epoch 156 Batch 35 Loss 0.0411 Accuracy 5.2854\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2906\n",
      "Epoch 157 Batch 5 Loss 0.0411 Accuracy 5.2853\n",
      "Epoch 157 Batch 10 Loss 0.0411 Accuracy 5.2851\n",
      "Epoch 157 Batch 15 Loss 0.0411 Accuracy 5.2850\n",
      "Epoch 157 Batch 20 Loss 0.0411 Accuracy 5.2849\n",
      "Epoch 157 Batch 25 Loss 0.0411 Accuracy 5.2848\n",
      "Epoch 157 Batch 30 Loss 0.0411 Accuracy 5.2846\n",
      "Epoch 157 Batch 35 Loss 0.0411 Accuracy 5.2845\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2897\n",
      "Epoch 158 Batch 5 Loss 0.0411 Accuracy 5.2843\n",
      "Epoch 158 Batch 10 Loss 0.0411 Accuracy 5.2842\n",
      "Epoch 158 Batch 15 Loss 0.0411 Accuracy 5.2841\n",
      "Epoch 158 Batch 20 Loss 0.0411 Accuracy 5.2840\n",
      "Epoch 158 Batch 25 Loss 0.0411 Accuracy 5.2838\n",
      "Epoch 158 Batch 30 Loss 0.0411 Accuracy 5.2837\n",
      "Epoch 158 Batch 35 Loss 0.0411 Accuracy 5.2836\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2887\n",
      "Epoch 159 Batch 5 Loss 0.0411 Accuracy 5.2834\n",
      "Epoch 159 Batch 10 Loss 0.0411 Accuracy 5.2833\n",
      "Epoch 159 Batch 15 Loss 0.0411 Accuracy 5.2832\n",
      "Epoch 159 Batch 20 Loss 0.0411 Accuracy 5.2830\n",
      "Epoch 159 Batch 25 Loss 0.0410 Accuracy 5.2829\n",
      "Epoch 159 Batch 30 Loss 0.0410 Accuracy 5.2828\n",
      "Epoch 159 Batch 35 Loss 0.0410 Accuracy 5.2827\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2878\n",
      "Epoch 160 Batch 5 Loss 0.0410 Accuracy 5.2825\n",
      "Epoch 160 Batch 10 Loss 0.0410 Accuracy 5.2824\n",
      "Epoch 160 Batch 15 Loss 0.0410 Accuracy 5.2822\n",
      "Epoch 160 Batch 20 Loss 0.0410 Accuracy 5.2821\n",
      "Epoch 160 Batch 25 Loss 0.0410 Accuracy 5.2820\n",
      "Epoch 160 Batch 30 Loss 0.0410 Accuracy 5.2819\n",
      "Epoch 160 Batch 35 Loss 0.0410 Accuracy 5.2817\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2868\n",
      "Epoch 161 Batch 5 Loss 0.0410 Accuracy 5.2815\n",
      "Epoch 161 Batch 10 Loss 0.0410 Accuracy 5.2814\n",
      "Epoch 161 Batch 15 Loss 0.0410 Accuracy 5.2813\n",
      "Epoch 161 Batch 20 Loss 0.0410 Accuracy 5.2812\n",
      "Epoch 161 Batch 25 Loss 0.0410 Accuracy 5.2810\n",
      "Epoch 161 Batch 30 Loss 0.0410 Accuracy 5.2809\n",
      "Epoch 161 Batch 35 Loss 0.0410 Accuracy 5.2808\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2858\n",
      "Epoch 162 Batch 5 Loss 0.0410 Accuracy 5.2806\n",
      "Epoch 162 Batch 10 Loss 0.0410 Accuracy 5.2805\n",
      "Epoch 162 Batch 15 Loss 0.0410 Accuracy 5.2803\n",
      "Epoch 162 Batch 20 Loss 0.0410 Accuracy 5.2802\n",
      "Epoch 162 Batch 25 Loss 0.0410 Accuracy 5.2801\n",
      "Epoch 162 Batch 30 Loss 0.0410 Accuracy 5.2800\n",
      "Epoch 162 Batch 35 Loss 0.0409 Accuracy 5.2798\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2848\n",
      "Epoch 163 Batch 5 Loss 0.0409 Accuracy 5.2796\n",
      "Epoch 163 Batch 10 Loss 0.0409 Accuracy 5.2795\n",
      "Epoch 163 Batch 15 Loss 0.0409 Accuracy 5.2794\n",
      "Epoch 163 Batch 20 Loss 0.0409 Accuracy 5.2793\n",
      "Epoch 163 Batch 25 Loss 0.0409 Accuracy 5.2791\n",
      "Epoch 163 Batch 30 Loss 0.0409 Accuracy 5.2790\n",
      "Epoch 163 Batch 35 Loss 0.0409 Accuracy 5.2789\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2838\n",
      "Epoch 164 Batch 5 Loss 0.0409 Accuracy 5.2787\n",
      "Epoch 164 Batch 10 Loss 0.0409 Accuracy 5.2785\n",
      "Epoch 164 Batch 15 Loss 0.0409 Accuracy 5.2784\n",
      "Epoch 164 Batch 20 Loss 0.0409 Accuracy 5.2783\n",
      "Epoch 164 Batch 25 Loss 0.0409 Accuracy 5.2781\n",
      "Epoch 164 Batch 30 Loss 0.0409 Accuracy 5.2780\n",
      "Epoch 164 Batch 35 Loss 0.0409 Accuracy 5.2779\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2828\n",
      "Epoch 165 Batch 5 Loss 0.0409 Accuracy 5.2777\n",
      "Epoch 165 Batch 10 Loss 0.0409 Accuracy 5.2776\n",
      "Epoch 165 Batch 15 Loss 0.0409 Accuracy 5.2774\n",
      "Epoch 165 Batch 20 Loss 0.0409 Accuracy 5.2773\n",
      "Epoch 165 Batch 25 Loss 0.0409 Accuracy 5.2772\n",
      "Epoch 165 Batch 30 Loss 0.0408 Accuracy 5.2770\n",
      "Epoch 165 Batch 35 Loss 0.0408 Accuracy 5.2769\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2817\n",
      "Epoch 166 Batch 5 Loss 0.0408 Accuracy 5.2767\n",
      "Epoch 166 Batch 10 Loss 0.0408 Accuracy 5.2766\n",
      "Epoch 166 Batch 15 Loss 0.0408 Accuracy 5.2764\n",
      "Epoch 166 Batch 20 Loss 0.0408 Accuracy 5.2763\n",
      "Epoch 166 Batch 25 Loss 0.0408 Accuracy 5.2762\n",
      "Epoch 166 Batch 30 Loss 0.0408 Accuracy 5.2760\n",
      "Epoch 166 Batch 35 Loss 0.0408 Accuracy 5.2759\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2807\n",
      "Epoch 167 Batch 5 Loss 0.0408 Accuracy 5.2757\n",
      "Epoch 167 Batch 10 Loss 0.0408 Accuracy 5.2756\n",
      "Epoch 167 Batch 15 Loss 0.0408 Accuracy 5.2754\n",
      "Epoch 167 Batch 20 Loss 0.0408 Accuracy 5.2753\n",
      "Epoch 167 Batch 25 Loss 0.0408 Accuracy 5.2751\n",
      "Epoch 167 Batch 30 Loss 0.0408 Accuracy 5.2750\n",
      "Epoch 167 Batch 35 Loss 0.0408 Accuracy 5.2749\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2797\n",
      "Epoch 168 Batch 5 Loss 0.0408 Accuracy 5.2747\n",
      "Epoch 168 Batch 10 Loss 0.0408 Accuracy 5.2745\n",
      "Epoch 168 Batch 15 Loss 0.0408 Accuracy 5.2744\n",
      "Epoch 168 Batch 20 Loss 0.0408 Accuracy 5.2743\n",
      "Epoch 168 Batch 25 Loss 0.0408 Accuracy 5.2741\n",
      "Epoch 168 Batch 30 Loss 0.0408 Accuracy 5.2740\n",
      "Epoch 168 Batch 35 Loss 0.0408 Accuracy 5.2739\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2786\n",
      "Epoch 169 Batch 5 Loss 0.0408 Accuracy 5.2737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169 Batch 10 Loss 0.0408 Accuracy 5.2735\n",
      "Epoch 169 Batch 15 Loss 0.0407 Accuracy 5.2734\n",
      "Epoch 169 Batch 20 Loss 0.0407 Accuracy 5.2733\n",
      "Epoch 169 Batch 25 Loss 0.0407 Accuracy 5.2731\n",
      "Epoch 169 Batch 30 Loss 0.0407 Accuracy 5.2730\n",
      "Epoch 169 Batch 35 Loss 0.0407 Accuracy 5.2728\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2776\n",
      "Epoch 170 Batch 5 Loss 0.0407 Accuracy 5.2726\n",
      "Epoch 170 Batch 10 Loss 0.0407 Accuracy 5.2725\n",
      "Epoch 170 Batch 15 Loss 0.0407 Accuracy 5.2724\n",
      "Epoch 170 Batch 20 Loss 0.0407 Accuracy 5.2722\n",
      "Epoch 170 Batch 25 Loss 0.0407 Accuracy 5.2721\n",
      "Epoch 170 Batch 30 Loss 0.0407 Accuracy 5.2719\n",
      "Epoch 170 Batch 35 Loss 0.0407 Accuracy 5.2718\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2765\n",
      "Epoch 171 Batch 5 Loss 0.0407 Accuracy 5.2716\n",
      "Epoch 171 Batch 10 Loss 0.0407 Accuracy 5.2715\n",
      "Epoch 171 Batch 15 Loss 0.0407 Accuracy 5.2713\n",
      "Epoch 171 Batch 20 Loss 0.0407 Accuracy 5.2712\n",
      "Epoch 171 Batch 25 Loss 0.0407 Accuracy 5.2711\n",
      "Epoch 171 Batch 30 Loss 0.0407 Accuracy 5.2709\n",
      "Epoch 171 Batch 35 Loss 0.0407 Accuracy 5.2708\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2755\n",
      "Epoch 172 Batch 5 Loss 0.0407 Accuracy 5.2706\n",
      "Epoch 172 Batch 10 Loss 0.0407 Accuracy 5.2704\n",
      "Epoch 172 Batch 15 Loss 0.0407 Accuracy 5.2703\n",
      "Epoch 172 Batch 20 Loss 0.0407 Accuracy 5.2702\n",
      "Epoch 172 Batch 25 Loss 0.0407 Accuracy 5.2700\n",
      "Epoch 172 Batch 30 Loss 0.0407 Accuracy 5.2699\n",
      "Epoch 172 Batch 35 Loss 0.0407 Accuracy 5.2698\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2744\n",
      "Epoch 173 Batch 5 Loss 0.0407 Accuracy 5.2696\n",
      "Epoch 173 Batch 10 Loss 0.0407 Accuracy 5.2694\n",
      "Epoch 173 Batch 15 Loss 0.0407 Accuracy 5.2693\n",
      "Epoch 173 Batch 20 Loss 0.0407 Accuracy 5.2691\n",
      "Epoch 173 Batch 25 Loss 0.0407 Accuracy 5.2690\n",
      "Epoch 173 Batch 30 Loss 0.0406 Accuracy 5.2689\n",
      "Epoch 173 Batch 35 Loss 0.0406 Accuracy 5.2687\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2733\n",
      "Epoch 174 Batch 5 Loss 0.0406 Accuracy 5.2685\n",
      "Epoch 174 Batch 10 Loss 0.0406 Accuracy 5.2684\n",
      "Epoch 174 Batch 15 Loss 0.0406 Accuracy 5.2682\n",
      "Epoch 174 Batch 20 Loss 0.0406 Accuracy 5.2681\n",
      "Epoch 174 Batch 25 Loss 0.0406 Accuracy 5.2680\n",
      "Epoch 174 Batch 30 Loss 0.0406 Accuracy 5.2678\n",
      "Epoch 174 Batch 35 Loss 0.0406 Accuracy 5.2677\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2723\n",
      "Epoch 175 Batch 5 Loss 0.0406 Accuracy 5.2675\n",
      "Epoch 175 Batch 10 Loss 0.0406 Accuracy 5.2674\n",
      "Epoch 175 Batch 15 Loss 0.0406 Accuracy 5.2672\n",
      "Epoch 175 Batch 20 Loss 0.0406 Accuracy 5.2671\n",
      "Epoch 175 Batch 25 Loss 0.0406 Accuracy 5.2669\n",
      "Epoch 175 Batch 30 Loss 0.0406 Accuracy 5.2668\n",
      "Epoch 175 Batch 35 Loss 0.0406 Accuracy 5.2667\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2712\n",
      "Epoch 176 Batch 5 Loss 0.0406 Accuracy 5.2665\n",
      "Epoch 176 Batch 10 Loss 0.0406 Accuracy 5.2663\n",
      "Epoch 176 Batch 15 Loss 0.0406 Accuracy 5.2662\n",
      "Epoch 176 Batch 20 Loss 0.0406 Accuracy 5.2661\n",
      "Epoch 176 Batch 25 Loss 0.0406 Accuracy 5.2659\n",
      "Epoch 176 Batch 30 Loss 0.0406 Accuracy 5.2658\n",
      "Epoch 176 Batch 35 Loss 0.0406 Accuracy 5.2656\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2702\n",
      "Epoch 177 Batch 5 Loss 0.0406 Accuracy 5.2654\n",
      "Epoch 177 Batch 10 Loss 0.0406 Accuracy 5.2653\n",
      "Epoch 177 Batch 15 Loss 0.0406 Accuracy 5.2652\n",
      "Epoch 177 Batch 20 Loss 0.0406 Accuracy 5.2650\n",
      "Epoch 177 Batch 25 Loss 0.0406 Accuracy 5.2649\n",
      "Epoch 177 Batch 30 Loss 0.0406 Accuracy 5.2648\n",
      "Epoch 177 Batch 35 Loss 0.0406 Accuracy 5.2646\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2691\n",
      "Epoch 178 Batch 5 Loss 0.0406 Accuracy 5.2644\n",
      "Epoch 178 Batch 10 Loss 0.0406 Accuracy 5.2643\n",
      "Epoch 178 Batch 15 Loss 0.0406 Accuracy 5.2641\n",
      "Epoch 178 Batch 20 Loss 0.0406 Accuracy 5.2640\n",
      "Epoch 178 Batch 25 Loss 0.0406 Accuracy 5.2639\n",
      "Epoch 178 Batch 30 Loss 0.0406 Accuracy 5.2637\n",
      "Epoch 178 Batch 35 Loss 0.0406 Accuracy 5.2636\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2681\n",
      "Epoch 179 Batch 5 Loss 0.0406 Accuracy 5.2634\n",
      "Epoch 179 Batch 10 Loss 0.0406 Accuracy 5.2633\n",
      "Epoch 179 Batch 15 Loss 0.0406 Accuracy 5.2631\n",
      "Epoch 179 Batch 20 Loss 0.0406 Accuracy 5.2630\n",
      "Epoch 179 Batch 25 Loss 0.0405 Accuracy 5.2628\n",
      "Epoch 179 Batch 30 Loss 0.0405 Accuracy 5.2627\n",
      "Epoch 179 Batch 35 Loss 0.0405 Accuracy 5.2626\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2670\n",
      "Epoch 180 Batch 5 Loss 0.0405 Accuracy 5.2624\n",
      "Epoch 180 Batch 10 Loss 0.0405 Accuracy 5.2622\n",
      "Epoch 180 Batch 15 Loss 0.0405 Accuracy 5.2621\n",
      "Epoch 180 Batch 20 Loss 0.0405 Accuracy 5.2620\n",
      "Epoch 180 Batch 25 Loss 0.0405 Accuracy 5.2618\n",
      "Epoch 180 Batch 30 Loss 0.0405 Accuracy 5.2617\n",
      "Epoch 180 Batch 35 Loss 0.0405 Accuracy 5.2615\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2660\n",
      "Epoch 181 Batch 5 Loss 0.0405 Accuracy 5.2613\n",
      "Epoch 181 Batch 10 Loss 0.0405 Accuracy 5.2612\n",
      "Epoch 181 Batch 15 Loss 0.0405 Accuracy 5.2611\n",
      "Epoch 181 Batch 20 Loss 0.0405 Accuracy 5.2609\n",
      "Epoch 181 Batch 25 Loss 0.0405 Accuracy 5.2608\n",
      "Epoch 181 Batch 30 Loss 0.0405 Accuracy 5.2607\n",
      "Epoch 181 Batch 35 Loss 0.0405 Accuracy 5.2605\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2649\n",
      "Epoch 182 Batch 5 Loss 0.0405 Accuracy 5.2603\n",
      "Epoch 182 Batch 10 Loss 0.0405 Accuracy 5.2602\n",
      "Epoch 182 Batch 15 Loss 0.0405 Accuracy 5.2600\n",
      "Epoch 182 Batch 20 Loss 0.0405 Accuracy 5.2599\n",
      "Epoch 182 Batch 25 Loss 0.0405 Accuracy 5.2598\n",
      "Epoch 182 Batch 30 Loss 0.0405 Accuracy 5.2596\n",
      "Epoch 182 Batch 35 Loss 0.0405 Accuracy 5.2595\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2639\n",
      "Epoch 183 Batch 5 Loss 0.0405 Accuracy 5.2593\n",
      "Epoch 183 Batch 10 Loss 0.0405 Accuracy 5.2592\n",
      "Epoch 183 Batch 15 Loss 0.0405 Accuracy 5.2590\n",
      "Epoch 183 Batch 20 Loss 0.0405 Accuracy 5.2589\n",
      "Epoch 183 Batch 25 Loss 0.0405 Accuracy 5.2587\n",
      "Epoch 183 Batch 30 Loss 0.0405 Accuracy 5.2586\n",
      "Epoch 183 Batch 35 Loss 0.0405 Accuracy 5.2585\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2628\n",
      "Epoch 184 Batch 5 Loss 0.0405 Accuracy 5.2583\n",
      "Epoch 184 Batch 10 Loss 0.0405 Accuracy 5.2581\n",
      "Epoch 184 Batch 15 Loss 0.0405 Accuracy 5.2580\n",
      "Epoch 184 Batch 20 Loss 0.0405 Accuracy 5.2578\n",
      "Epoch 184 Batch 25 Loss 0.0404 Accuracy 5.2577\n",
      "Epoch 184 Batch 30 Loss 0.0404 Accuracy 5.2576\n",
      "Epoch 184 Batch 35 Loss 0.0404 Accuracy 5.2574\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2618\n",
      "Epoch 185 Batch 5 Loss 0.0404 Accuracy 5.2572\n",
      "Epoch 185 Batch 10 Loss 0.0404 Accuracy 5.2571\n",
      "Epoch 185 Batch 15 Loss 0.0404 Accuracy 5.2569\n",
      "Epoch 185 Batch 20 Loss 0.0404 Accuracy 5.2568\n",
      "Epoch 185 Batch 25 Loss 0.0404 Accuracy 5.2567\n",
      "Epoch 185 Batch 30 Loss 0.0404 Accuracy 5.2565\n",
      "Epoch 185 Batch 35 Loss 0.0404 Accuracy 5.2564\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2607\n",
      "Epoch 186 Batch 5 Loss 0.0404 Accuracy 5.2562\n",
      "Epoch 186 Batch 10 Loss 0.0404 Accuracy 5.2561\n",
      "Epoch 186 Batch 15 Loss 0.0404 Accuracy 5.2559\n",
      "Epoch 186 Batch 20 Loss 0.0404 Accuracy 5.2558\n",
      "Epoch 186 Batch 25 Loss 0.0404 Accuracy 5.2556\n",
      "Epoch 186 Batch 30 Loss 0.0404 Accuracy 5.2555\n",
      "Epoch 186 Batch 35 Loss 0.0404 Accuracy 5.2554\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2596\n",
      "Epoch 187 Batch 5 Loss 0.0404 Accuracy 5.2552\n",
      "Epoch 187 Batch 10 Loss 0.0404 Accuracy 5.2550\n",
      "Epoch 187 Batch 15 Loss 0.0404 Accuracy 5.2549\n",
      "Epoch 187 Batch 20 Loss 0.0404 Accuracy 5.2547\n",
      "Epoch 187 Batch 25 Loss 0.0404 Accuracy 5.2546\n",
      "Epoch 187 Batch 30 Loss 0.0404 Accuracy 5.2545\n",
      "Epoch 187 Batch 35 Loss 0.0404 Accuracy 5.2543\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2586\n",
      "Epoch 188 Batch 5 Loss 0.0404 Accuracy 5.2541\n",
      "Epoch 188 Batch 10 Loss 0.0404 Accuracy 5.2540\n",
      "Epoch 188 Batch 15 Loss 0.0404 Accuracy 5.2538\n",
      "Epoch 188 Batch 20 Loss 0.0404 Accuracy 5.2537\n",
      "Epoch 188 Batch 25 Loss 0.0404 Accuracy 5.2536\n",
      "Epoch 188 Batch 30 Loss 0.0404 Accuracy 5.2534\n",
      "Epoch 188 Batch 35 Loss 0.0404 Accuracy 5.2533\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2575\n",
      "Epoch 189 Batch 5 Loss 0.0404 Accuracy 5.2531\n",
      "Epoch 189 Batch 10 Loss 0.0404 Accuracy 5.2530\n",
      "Epoch 189 Batch 15 Loss 0.0404 Accuracy 5.2528\n",
      "Epoch 189 Batch 20 Loss 0.0404 Accuracy 5.2527\n",
      "Epoch 189 Batch 25 Loss 0.0404 Accuracy 5.2526\n",
      "Epoch 189 Batch 30 Loss 0.0404 Accuracy 5.2524\n",
      "Epoch 189 Batch 35 Loss 0.0404 Accuracy 5.2523\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190 Batch 5 Loss 0.0404 Accuracy 5.2521\n",
      "Epoch 190 Batch 10 Loss 0.0404 Accuracy 5.2520\n",
      "Epoch 190 Batch 15 Loss 0.0404 Accuracy 5.2518\n",
      "Epoch 190 Batch 20 Loss 0.0404 Accuracy 5.2517\n",
      "Epoch 190 Batch 25 Loss 0.0404 Accuracy 5.2515\n",
      "Epoch 190 Batch 30 Loss 0.0404 Accuracy 5.2514\n",
      "Epoch 190 Batch 35 Loss 0.0404 Accuracy 5.2513\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2555\n",
      "Epoch 191 Batch 5 Loss 0.0404 Accuracy 5.2511\n",
      "Epoch 191 Batch 10 Loss 0.0404 Accuracy 5.2509\n",
      "Epoch 191 Batch 15 Loss 0.0404 Accuracy 5.2508\n",
      "Epoch 191 Batch 20 Loss 0.0403 Accuracy 5.2507\n",
      "Epoch 191 Batch 25 Loss 0.0403 Accuracy 5.2505\n",
      "Epoch 191 Batch 30 Loss 0.0403 Accuracy 5.2504\n",
      "Epoch 191 Batch 35 Loss 0.0403 Accuracy 5.2502\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2544\n",
      "Epoch 192 Batch 5 Loss 0.0403 Accuracy 5.2501\n",
      "Epoch 192 Batch 10 Loss 0.0403 Accuracy 5.2499\n",
      "Epoch 192 Batch 15 Loss 0.0403 Accuracy 5.2498\n",
      "Epoch 192 Batch 20 Loss 0.0403 Accuracy 5.2496\n",
      "Epoch 192 Batch 25 Loss 0.0403 Accuracy 5.2495\n",
      "Epoch 192 Batch 30 Loss 0.0403 Accuracy 5.2494\n",
      "Epoch 192 Batch 35 Loss 0.0403 Accuracy 5.2492\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2534\n",
      "Epoch 193 Batch 5 Loss 0.0403 Accuracy 5.2490\n",
      "Epoch 193 Batch 10 Loss 0.0403 Accuracy 5.2489\n",
      "Epoch 193 Batch 15 Loss 0.0403 Accuracy 5.2488\n",
      "Epoch 193 Batch 20 Loss 0.0403 Accuracy 5.2486\n",
      "Epoch 193 Batch 25 Loss 0.0403 Accuracy 5.2485\n",
      "Epoch 193 Batch 30 Loss 0.0403 Accuracy 5.2483\n",
      "Epoch 193 Batch 35 Loss 0.0403 Accuracy 5.2482\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2523\n",
      "Epoch 194 Batch 5 Loss 0.0403 Accuracy 5.2480\n",
      "Epoch 194 Batch 10 Loss 0.0403 Accuracy 5.2479\n",
      "Epoch 194 Batch 15 Loss 0.0403 Accuracy 5.2477\n",
      "Epoch 194 Batch 20 Loss 0.0403 Accuracy 5.2476\n",
      "Epoch 194 Batch 25 Loss 0.0403 Accuracy 5.2474\n",
      "Epoch 194 Batch 30 Loss 0.0403 Accuracy 5.2473\n",
      "Epoch 194 Batch 35 Loss 0.0403 Accuracy 5.2472\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2513\n",
      "Epoch 195 Batch 5 Loss 0.0403 Accuracy 5.2470\n",
      "Epoch 195 Batch 10 Loss 0.0403 Accuracy 5.2468\n",
      "Epoch 195 Batch 15 Loss 0.0402 Accuracy 5.2467\n",
      "Epoch 195 Batch 20 Loss 0.0402 Accuracy 5.2466\n",
      "Epoch 195 Batch 25 Loss 0.0402 Accuracy 5.2464\n",
      "Epoch 195 Batch 30 Loss 0.0402 Accuracy 5.2463\n",
      "Epoch 195 Batch 35 Loss 0.0402 Accuracy 5.2461\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2502\n",
      "Epoch 196 Batch 5 Loss 0.0402 Accuracy 5.2459\n",
      "Epoch 196 Batch 10 Loss 0.0402 Accuracy 5.2458\n",
      "Epoch 196 Batch 15 Loss 0.0402 Accuracy 5.2457\n",
      "Epoch 196 Batch 20 Loss 0.0402 Accuracy 5.2455\n",
      "Epoch 196 Batch 25 Loss 0.0402 Accuracy 5.2454\n",
      "Epoch 196 Batch 30 Loss 0.0402 Accuracy 5.2452\n",
      "Epoch 196 Batch 35 Loss 0.0402 Accuracy 5.2451\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2491\n",
      "Epoch 197 Batch 5 Loss 0.0402 Accuracy 5.2449\n",
      "Epoch 197 Batch 10 Loss 0.0402 Accuracy 5.2448\n",
      "Epoch 197 Batch 15 Loss 0.0402 Accuracy 5.2446\n",
      "Epoch 197 Batch 20 Loss 0.0402 Accuracy 5.2445\n",
      "Epoch 197 Batch 25 Loss 0.0402 Accuracy 5.2443\n",
      "Epoch 197 Batch 30 Loss 0.0402 Accuracy 5.2442\n",
      "Epoch 197 Batch 35 Loss 0.0402 Accuracy 5.2441\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2481\n",
      "Epoch 198 Batch 5 Loss 0.0402 Accuracy 5.2439\n",
      "Epoch 198 Batch 10 Loss 0.0402 Accuracy 5.2437\n",
      "Epoch 198 Batch 15 Loss 0.0402 Accuracy 5.2436\n",
      "Epoch 198 Batch 20 Loss 0.0402 Accuracy 5.2435\n",
      "Epoch 198 Batch 25 Loss 0.0402 Accuracy 5.2433\n",
      "Epoch 198 Batch 30 Loss 0.0402 Accuracy 5.2432\n",
      "Epoch 198 Batch 35 Loss 0.0402 Accuracy 5.2430\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2470\n",
      "Epoch 199 Batch 5 Loss 0.0402 Accuracy 5.2428\n",
      "Epoch 199 Batch 10 Loss 0.0402 Accuracy 5.2427\n",
      "Epoch 199 Batch 15 Loss 0.0402 Accuracy 5.2426\n",
      "Epoch 199 Batch 20 Loss 0.0402 Accuracy 5.2424\n",
      "Epoch 199 Batch 25 Loss 0.0402 Accuracy 5.2423\n",
      "Epoch 199 Batch 30 Loss 0.0402 Accuracy 5.2421\n",
      "Epoch 199 Batch 35 Loss 0.0402 Accuracy 5.2420\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2460\n",
      "Epoch 200 Batch 5 Loss 0.0401 Accuracy 5.2418\n",
      "Epoch 200 Batch 10 Loss 0.0401 Accuracy 5.2417\n",
      "Epoch 200 Batch 15 Loss 0.0401 Accuracy 5.2415\n",
      "Epoch 200 Batch 20 Loss 0.0401 Accuracy 5.2414\n",
      "Epoch 200 Batch 25 Loss 0.0401 Accuracy 5.2412\n",
      "Epoch 200 Batch 30 Loss 0.0401 Accuracy 5.2411\n",
      "Epoch 200 Batch 35 Loss 0.0401 Accuracy 5.2410\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2449\n",
      "Epoch 201 Batch 5 Loss 0.0401 Accuracy 5.2408\n",
      "Epoch 201 Batch 10 Loss 0.0401 Accuracy 5.2406\n",
      "Epoch 201 Batch 15 Loss 0.0401 Accuracy 5.2405\n",
      "Epoch 201 Batch 20 Loss 0.0401 Accuracy 5.2403\n",
      "Epoch 201 Batch 25 Loss 0.0401 Accuracy 5.2402\n",
      "Epoch 201 Batch 30 Loss 0.0401 Accuracy 5.2400\n",
      "Epoch 201 Batch 35 Loss 0.0401 Accuracy 5.2399\n",
      "Time taken for 1 epoch: 0.41 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2438\n",
      "Epoch 202 Batch 5 Loss 0.0401 Accuracy 5.2397\n",
      "Epoch 202 Batch 10 Loss 0.0401 Accuracy 5.2396\n",
      "Epoch 202 Batch 15 Loss 0.0401 Accuracy 5.2394\n",
      "Epoch 202 Batch 20 Loss 0.0401 Accuracy 5.2393\n",
      "Epoch 202 Batch 25 Loss 0.0401 Accuracy 5.2391\n",
      "Epoch 202 Batch 30 Loss 0.0401 Accuracy 5.2390\n",
      "Epoch 202 Batch 35 Loss 0.0401 Accuracy 5.2388\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2428\n",
      "Epoch 203 Batch 5 Loss 0.0401 Accuracy 5.2386\n",
      "Epoch 203 Batch 10 Loss 0.0401 Accuracy 5.2385\n",
      "Epoch 203 Batch 15 Loss 0.0401 Accuracy 5.2384\n",
      "Epoch 203 Batch 20 Loss 0.0401 Accuracy 5.2382\n",
      "Epoch 203 Batch 25 Loss 0.0401 Accuracy 5.2381\n",
      "Epoch 203 Batch 30 Loss 0.0400 Accuracy 5.2379\n",
      "Epoch 203 Batch 35 Loss 0.0400 Accuracy 5.2378\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2417\n",
      "Epoch 204 Batch 5 Loss 0.0400 Accuracy 5.2376\n",
      "Epoch 204 Batch 10 Loss 0.0400 Accuracy 5.2375\n",
      "Epoch 204 Batch 15 Loss 0.0400 Accuracy 5.2373\n",
      "Epoch 204 Batch 20 Loss 0.0400 Accuracy 5.2372\n",
      "Epoch 204 Batch 25 Loss 0.0400 Accuracy 5.2370\n",
      "Epoch 204 Batch 30 Loss 0.0400 Accuracy 5.2369\n",
      "Epoch 204 Batch 35 Loss 0.0400 Accuracy 5.2367\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2406\n",
      "Epoch 205 Batch 5 Loss 0.0400 Accuracy 5.2365\n",
      "Epoch 205 Batch 10 Loss 0.0400 Accuracy 5.2364\n",
      "Epoch 205 Batch 15 Loss 0.0400 Accuracy 5.2363\n",
      "Epoch 205 Batch 20 Loss 0.0400 Accuracy 5.2361\n",
      "Epoch 205 Batch 25 Loss 0.0400 Accuracy 5.2360\n",
      "Epoch 205 Batch 30 Loss 0.0400 Accuracy 5.2358\n",
      "Epoch 205 Batch 35 Loss 0.0400 Accuracy 5.2357\n",
      "Time taken for 1 epoch: 0.55 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2395\n",
      "Epoch 206 Batch 5 Loss 0.0400 Accuracy 5.2355\n",
      "Epoch 206 Batch 10 Loss 0.0400 Accuracy 5.2354\n",
      "Epoch 206 Batch 15 Loss 0.0400 Accuracy 5.2352\n",
      "Epoch 206 Batch 20 Loss 0.0400 Accuracy 5.2351\n",
      "Epoch 206 Batch 25 Loss 0.0400 Accuracy 5.2349\n",
      "Epoch 206 Batch 30 Loss 0.0400 Accuracy 5.2348\n",
      "Epoch 206 Batch 35 Loss 0.0400 Accuracy 5.2346\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2385\n",
      "Epoch 207 Batch 5 Loss 0.0400 Accuracy 5.2344\n",
      "Epoch 207 Batch 10 Loss 0.0400 Accuracy 5.2343\n",
      "Epoch 207 Batch 15 Loss 0.0400 Accuracy 5.2342\n",
      "Epoch 207 Batch 20 Loss 0.0400 Accuracy 5.2340\n",
      "Epoch 207 Batch 25 Loss 0.0400 Accuracy 5.2339\n",
      "Epoch 207 Batch 30 Loss 0.0400 Accuracy 5.2337\n",
      "Epoch 207 Batch 35 Loss 0.0400 Accuracy 5.2336\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2374\n",
      "Epoch 208 Batch 5 Loss 0.0400 Accuracy 5.2334\n",
      "Epoch 208 Batch 10 Loss 0.0400 Accuracy 5.2333\n",
      "Epoch 208 Batch 15 Loss 0.0400 Accuracy 5.2331\n",
      "Epoch 208 Batch 20 Loss 0.0400 Accuracy 5.2330\n",
      "Epoch 208 Batch 25 Loss 0.0400 Accuracy 5.2329\n",
      "Epoch 208 Batch 30 Loss 0.0400 Accuracy 5.2327\n",
      "Epoch 208 Batch 35 Loss 0.0400 Accuracy 5.2326\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2364\n",
      "Epoch 209 Batch 5 Loss 0.0400 Accuracy 5.2324\n",
      "Epoch 209 Batch 10 Loss 0.0400 Accuracy 5.2322\n",
      "Epoch 209 Batch 15 Loss 0.0400 Accuracy 5.2321\n",
      "Epoch 209 Batch 20 Loss 0.0400 Accuracy 5.2320\n",
      "Epoch 209 Batch 25 Loss 0.0400 Accuracy 5.2318\n",
      "Epoch 209 Batch 30 Loss 0.0400 Accuracy 5.2317\n",
      "Epoch 209 Batch 35 Loss 0.0400 Accuracy 5.2315\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2353\n",
      "Epoch 210 Batch 5 Loss 0.0400 Accuracy 5.2314\n",
      "Epoch 210 Batch 10 Loss 0.0400 Accuracy 5.2312\n",
      "Epoch 210 Batch 15 Loss 0.0400 Accuracy 5.2311\n",
      "Epoch 210 Batch 20 Loss 0.0400 Accuracy 5.2309\n",
      "Epoch 210 Batch 25 Loss 0.0400 Accuracy 5.2308\n",
      "Epoch 210 Batch 30 Loss 0.0400 Accuracy 5.2307\n",
      "Epoch 210 Batch 35 Loss 0.0400 Accuracy 5.2305\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211 Batch 5 Loss 0.0400 Accuracy 5.2303\n",
      "Epoch 211 Batch 10 Loss 0.0400 Accuracy 5.2302\n",
      "Epoch 211 Batch 15 Loss 0.0400 Accuracy 5.2300\n",
      "Epoch 211 Batch 20 Loss 0.0400 Accuracy 5.2299\n",
      "Epoch 211 Batch 25 Loss 0.0400 Accuracy 5.2298\n",
      "Epoch 211 Batch 30 Loss 0.0400 Accuracy 5.2296\n",
      "Epoch 211 Batch 35 Loss 0.0400 Accuracy 5.2295\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2332\n",
      "Epoch 212 Batch 5 Loss 0.0400 Accuracy 5.2293\n",
      "Epoch 212 Batch 10 Loss 0.0400 Accuracy 5.2292\n",
      "Epoch 212 Batch 15 Loss 0.0400 Accuracy 5.2290\n",
      "Epoch 212 Batch 20 Loss 0.0400 Accuracy 5.2289\n",
      "Epoch 212 Batch 25 Loss 0.0400 Accuracy 5.2288\n",
      "Epoch 212 Batch 30 Loss 0.0399 Accuracy 5.2286\n",
      "Epoch 212 Batch 35 Loss 0.0399 Accuracy 5.2285\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2322\n",
      "Epoch 213 Batch 5 Loss 0.0399 Accuracy 5.2283\n",
      "Epoch 213 Batch 10 Loss 0.0399 Accuracy 5.2281\n",
      "Epoch 213 Batch 15 Loss 0.0399 Accuracy 5.2280\n",
      "Epoch 213 Batch 20 Loss 0.0399 Accuracy 5.2279\n",
      "Epoch 213 Batch 25 Loss 0.0399 Accuracy 5.2277\n",
      "Epoch 213 Batch 30 Loss 0.0399 Accuracy 5.2276\n",
      "Epoch 213 Batch 35 Loss 0.0399 Accuracy 5.2275\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2312\n",
      "Epoch 214 Batch 5 Loss 0.0399 Accuracy 5.2273\n",
      "Epoch 214 Batch 10 Loss 0.0399 Accuracy 5.2271\n",
      "Epoch 214 Batch 15 Loss 0.0399 Accuracy 5.2270\n",
      "Epoch 214 Batch 20 Loss 0.0399 Accuracy 5.2268\n",
      "Epoch 214 Batch 25 Loss 0.0399 Accuracy 5.2267\n",
      "Epoch 214 Batch 30 Loss 0.0399 Accuracy 5.2266\n",
      "Epoch 214 Batch 35 Loss 0.0399 Accuracy 5.2264\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2301\n",
      "Epoch 215 Batch 5 Loss 0.0399 Accuracy 5.2262\n",
      "Epoch 215 Batch 10 Loss 0.0399 Accuracy 5.2261\n",
      "Epoch 215 Batch 15 Loss 0.0399 Accuracy 5.2260\n",
      "Epoch 215 Batch 20 Loss 0.0399 Accuracy 5.2258\n",
      "Epoch 215 Batch 25 Loss 0.0399 Accuracy 5.2257\n",
      "Epoch 215 Batch 30 Loss 0.0399 Accuracy 5.2256\n",
      "Epoch 215 Batch 35 Loss 0.0399 Accuracy 5.2254\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2291\n",
      "Epoch 216 Batch 5 Loss 0.0399 Accuracy 5.2252\n",
      "Epoch 216 Batch 10 Loss 0.0399 Accuracy 5.2251\n",
      "Epoch 216 Batch 15 Loss 0.0399 Accuracy 5.2249\n",
      "Epoch 216 Batch 20 Loss 0.0399 Accuracy 5.2248\n",
      "Epoch 216 Batch 25 Loss 0.0399 Accuracy 5.2247\n",
      "Epoch 216 Batch 30 Loss 0.0399 Accuracy 5.2245\n",
      "Epoch 216 Batch 35 Loss 0.0399 Accuracy 5.2244\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2280\n",
      "Epoch 217 Batch 5 Loss 0.0399 Accuracy 5.2242\n",
      "Epoch 217 Batch 10 Loss 0.0399 Accuracy 5.2241\n",
      "Epoch 217 Batch 15 Loss 0.0399 Accuracy 5.2239\n",
      "Epoch 217 Batch 20 Loss 0.0399 Accuracy 5.2238\n",
      "Epoch 217 Batch 25 Loss 0.0399 Accuracy 5.2237\n",
      "Epoch 217 Batch 30 Loss 0.0399 Accuracy 5.2235\n",
      "Epoch 217 Batch 35 Loss 0.0399 Accuracy 5.2234\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2270\n",
      "Epoch 218 Batch 5 Loss 0.0399 Accuracy 5.2232\n",
      "Epoch 218 Batch 10 Loss 0.0399 Accuracy 5.2230\n",
      "Epoch 218 Batch 15 Loss 0.0399 Accuracy 5.2229\n",
      "Epoch 218 Batch 20 Loss 0.0399 Accuracy 5.2228\n",
      "Epoch 218 Batch 25 Loss 0.0398 Accuracy 5.2226\n",
      "Epoch 218 Batch 30 Loss 0.0398 Accuracy 5.2225\n",
      "Epoch 218 Batch 35 Loss 0.0398 Accuracy 5.2224\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2260\n",
      "Epoch 219 Batch 5 Loss 0.0398 Accuracy 5.2222\n",
      "Epoch 219 Batch 10 Loss 0.0398 Accuracy 5.2220\n",
      "Epoch 219 Batch 15 Loss 0.0398 Accuracy 5.2219\n",
      "Epoch 219 Batch 20 Loss 0.0398 Accuracy 5.2217\n",
      "Epoch 219 Batch 25 Loss 0.0398 Accuracy 5.2216\n",
      "Epoch 219 Batch 30 Loss 0.0398 Accuracy 5.2215\n",
      "Epoch 219 Batch 35 Loss 0.0398 Accuracy 5.2213\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2249\n",
      "Epoch 220 Batch 5 Loss 0.0398 Accuracy 5.2211\n",
      "Epoch 220 Batch 10 Loss 0.0398 Accuracy 5.2210\n",
      "Epoch 220 Batch 15 Loss 0.0398 Accuracy 5.2209\n",
      "Epoch 220 Batch 20 Loss 0.0398 Accuracy 5.2207\n",
      "Epoch 220 Batch 25 Loss 0.0398 Accuracy 5.2206\n",
      "Epoch 220 Batch 30 Loss 0.0398 Accuracy 5.2205\n",
      "Epoch 220 Batch 35 Loss 0.0398 Accuracy 5.2203\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2239\n",
      "Epoch 221 Batch 5 Loss 0.0398 Accuracy 5.2201\n",
      "Epoch 221 Batch 10 Loss 0.0398 Accuracy 5.2200\n",
      "Epoch 221 Batch 15 Loss 0.0398 Accuracy 5.2198\n",
      "Epoch 221 Batch 20 Loss 0.0398 Accuracy 5.2197\n",
      "Epoch 221 Batch 25 Loss 0.0398 Accuracy 5.2196\n",
      "Epoch 221 Batch 30 Loss 0.0398 Accuracy 5.2194\n",
      "Epoch 221 Batch 35 Loss 0.0398 Accuracy 5.2193\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2229\n",
      "Epoch 222 Batch 5 Loss 0.0398 Accuracy 5.2191\n",
      "Epoch 222 Batch 10 Loss 0.0398 Accuracy 5.2190\n",
      "Epoch 222 Batch 15 Loss 0.0398 Accuracy 5.2188\n",
      "Epoch 222 Batch 20 Loss 0.0398 Accuracy 5.2187\n",
      "Epoch 222 Batch 25 Loss 0.0398 Accuracy 5.2185\n",
      "Epoch 222 Batch 30 Loss 0.0398 Accuracy 5.2184\n",
      "Epoch 222 Batch 35 Loss 0.0398 Accuracy 5.2183\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2218\n",
      "Epoch 223 Batch 5 Loss 0.0398 Accuracy 5.2181\n",
      "Epoch 223 Batch 10 Loss 0.0398 Accuracy 5.2179\n",
      "Epoch 223 Batch 15 Loss 0.0398 Accuracy 5.2178\n",
      "Epoch 223 Batch 20 Loss 0.0398 Accuracy 5.2177\n",
      "Epoch 223 Batch 25 Loss 0.0398 Accuracy 5.2175\n",
      "Epoch 223 Batch 30 Loss 0.0398 Accuracy 5.2174\n",
      "Epoch 223 Batch 35 Loss 0.0398 Accuracy 5.2172\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2208\n",
      "Epoch 224 Batch 5 Loss 0.0398 Accuracy 5.2171\n",
      "Epoch 224 Batch 10 Loss 0.0398 Accuracy 5.2169\n",
      "Epoch 224 Batch 15 Loss 0.0398 Accuracy 5.2168\n",
      "Epoch 224 Batch 20 Loss 0.0398 Accuracy 5.2166\n",
      "Epoch 224 Batch 25 Loss 0.0398 Accuracy 5.2165\n",
      "Epoch 224 Batch 30 Loss 0.0398 Accuracy 5.2164\n",
      "Epoch 224 Batch 35 Loss 0.0398 Accuracy 5.2162\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2198\n",
      "Epoch 225 Batch 5 Loss 0.0398 Accuracy 5.2161\n",
      "Epoch 225 Batch 10 Loss 0.0398 Accuracy 5.2159\n",
      "Epoch 225 Batch 15 Loss 0.0398 Accuracy 5.2158\n",
      "Epoch 225 Batch 20 Loss 0.0398 Accuracy 5.2156\n",
      "Epoch 225 Batch 25 Loss 0.0398 Accuracy 5.2155\n",
      "Epoch 225 Batch 30 Loss 0.0398 Accuracy 5.2154\n",
      "Epoch 225 Batch 35 Loss 0.0398 Accuracy 5.2152\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2187\n",
      "Epoch 226 Batch 5 Loss 0.0398 Accuracy 5.2151\n",
      "Epoch 226 Batch 10 Loss 0.0398 Accuracy 5.2149\n",
      "Epoch 226 Batch 15 Loss 0.0398 Accuracy 5.2148\n",
      "Epoch 226 Batch 20 Loss 0.0398 Accuracy 5.2147\n",
      "Epoch 226 Batch 25 Loss 0.0398 Accuracy 5.2145\n",
      "Epoch 226 Batch 30 Loss 0.0398 Accuracy 5.2144\n",
      "Epoch 226 Batch 35 Loss 0.0398 Accuracy 5.2143\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2177\n",
      "Epoch 227 Batch 5 Loss 0.0398 Accuracy 5.2141\n",
      "Epoch 227 Batch 10 Loss 0.0398 Accuracy 5.2139\n",
      "Epoch 227 Batch 15 Loss 0.0398 Accuracy 5.2138\n",
      "Epoch 227 Batch 20 Loss 0.0398 Accuracy 5.2137\n",
      "Epoch 227 Batch 25 Loss 0.0398 Accuracy 5.2135\n",
      "Epoch 227 Batch 30 Loss 0.0398 Accuracy 5.2134\n",
      "Epoch 227 Batch 35 Loss 0.0398 Accuracy 5.2133\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2168\n",
      "Epoch 228 Batch 5 Loss 0.0398 Accuracy 5.2131\n",
      "Epoch 228 Batch 10 Loss 0.0398 Accuracy 5.2130\n",
      "Epoch 228 Batch 15 Loss 0.0398 Accuracy 5.2128\n",
      "Epoch 228 Batch 20 Loss 0.0398 Accuracy 5.2127\n",
      "Epoch 228 Batch 25 Loss 0.0398 Accuracy 5.2126\n",
      "Epoch 228 Batch 30 Loss 0.0398 Accuracy 5.2124\n",
      "Epoch 228 Batch 35 Loss 0.0398 Accuracy 5.2123\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2158\n",
      "Epoch 229 Batch 5 Loss 0.0398 Accuracy 5.2121\n",
      "Epoch 229 Batch 10 Loss 0.0398 Accuracy 5.2120\n",
      "Epoch 229 Batch 15 Loss 0.0398 Accuracy 5.2119\n",
      "Epoch 229 Batch 20 Loss 0.0398 Accuracy 5.2117\n",
      "Epoch 229 Batch 25 Loss 0.0398 Accuracy 5.2116\n",
      "Epoch 229 Batch 30 Loss 0.0398 Accuracy 5.2115\n",
      "Epoch 229 Batch 35 Loss 0.0398 Accuracy 5.2113\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2148\n",
      "Epoch 230 Batch 5 Loss 0.0398 Accuracy 5.2112\n",
      "Epoch 230 Batch 10 Loss 0.0398 Accuracy 5.2110\n",
      "Epoch 230 Batch 15 Loss 0.0398 Accuracy 5.2109\n",
      "Epoch 230 Batch 20 Loss 0.0398 Accuracy 5.2108\n",
      "Epoch 230 Batch 25 Loss 0.0398 Accuracy 5.2107\n",
      "Epoch 230 Batch 30 Loss 0.0398 Accuracy 5.2105\n",
      "Epoch 230 Batch 35 Loss 0.0398 Accuracy 5.2104\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2138\n",
      "Epoch 231 Batch 5 Loss 0.0398 Accuracy 5.2102\n",
      "Epoch 231 Batch 10 Loss 0.0398 Accuracy 5.2101\n",
      "Epoch 231 Batch 15 Loss 0.0398 Accuracy 5.2100\n",
      "Epoch 231 Batch 20 Loss 0.0398 Accuracy 5.2098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231 Batch 25 Loss 0.0398 Accuracy 5.2097\n",
      "Epoch 231 Batch 30 Loss 0.0398 Accuracy 5.2096\n",
      "Epoch 231 Batch 35 Loss 0.0398 Accuracy 5.2094\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2129\n",
      "Epoch 232 Batch 5 Loss 0.0398 Accuracy 5.2093\n",
      "Epoch 232 Batch 10 Loss 0.0398 Accuracy 5.2091\n",
      "Epoch 232 Batch 15 Loss 0.0398 Accuracy 5.2090\n",
      "Epoch 232 Batch 20 Loss 0.0398 Accuracy 5.2089\n",
      "Epoch 232 Batch 25 Loss 0.0398 Accuracy 5.2088\n",
      "Epoch 232 Batch 30 Loss 0.0398 Accuracy 5.2086\n",
      "Epoch 232 Batch 35 Loss 0.0398 Accuracy 5.2085\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2119\n",
      "Epoch 233 Batch 5 Loss 0.0397 Accuracy 5.2083\n",
      "Epoch 233 Batch 10 Loss 0.0397 Accuracy 5.2082\n",
      "Epoch 233 Batch 15 Loss 0.0397 Accuracy 5.2081\n",
      "Epoch 233 Batch 20 Loss 0.0397 Accuracy 5.2079\n",
      "Epoch 233 Batch 25 Loss 0.0397 Accuracy 5.2078\n",
      "Epoch 233 Batch 30 Loss 0.0397 Accuracy 5.2077\n",
      "Epoch 233 Batch 35 Loss 0.0397 Accuracy 5.2076\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2110\n",
      "Epoch 234 Batch 5 Loss 0.0397 Accuracy 5.2074\n",
      "Epoch 234 Batch 10 Loss 0.0397 Accuracy 5.2073\n",
      "Epoch 234 Batch 15 Loss 0.0397 Accuracy 5.2071\n",
      "Epoch 234 Batch 20 Loss 0.0397 Accuracy 5.2070\n",
      "Epoch 234 Batch 25 Loss 0.0397 Accuracy 5.2069\n",
      "Epoch 234 Batch 30 Loss 0.0397 Accuracy 5.2068\n",
      "Epoch 234 Batch 35 Loss 0.0397 Accuracy 5.2066\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2100\n",
      "Epoch 235 Batch 5 Loss 0.0397 Accuracy 5.2064\n",
      "Epoch 235 Batch 10 Loss 0.0397 Accuracy 5.2063\n",
      "Epoch 235 Batch 15 Loss 0.0397 Accuracy 5.2062\n",
      "Epoch 235 Batch 20 Loss 0.0397 Accuracy 5.2061\n",
      "Epoch 235 Batch 25 Loss 0.0397 Accuracy 5.2059\n",
      "Epoch 235 Batch 30 Loss 0.0397 Accuracy 5.2058\n",
      "Epoch 235 Batch 35 Loss 0.0397 Accuracy 5.2057\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2091\n",
      "Epoch 236 Batch 5 Loss 0.0397 Accuracy 5.2055\n",
      "Epoch 236 Batch 10 Loss 0.0397 Accuracy 5.2054\n",
      "Epoch 236 Batch 15 Loss 0.0397 Accuracy 5.2053\n",
      "Epoch 236 Batch 20 Loss 0.0397 Accuracy 5.2051\n",
      "Epoch 236 Batch 25 Loss 0.0397 Accuracy 5.2050\n",
      "Epoch 236 Batch 30 Loss 0.0397 Accuracy 5.2049\n",
      "Epoch 236 Batch 35 Loss 0.0397 Accuracy 5.2047\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2081\n",
      "Epoch 237 Batch 5 Loss 0.0397 Accuracy 5.2046\n",
      "Epoch 237 Batch 10 Loss 0.0397 Accuracy 5.2044\n",
      "Epoch 237 Batch 15 Loss 0.0397 Accuracy 5.2043\n",
      "Epoch 237 Batch 20 Loss 0.0397 Accuracy 5.2042\n",
      "Epoch 237 Batch 25 Loss 0.0397 Accuracy 5.2041\n",
      "Epoch 237 Batch 30 Loss 0.0397 Accuracy 5.2039\n",
      "Epoch 237 Batch 35 Loss 0.0397 Accuracy 5.2038\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2072\n",
      "Epoch 238 Batch 5 Loss 0.0397 Accuracy 5.2036\n",
      "Epoch 238 Batch 10 Loss 0.0397 Accuracy 5.2035\n",
      "Epoch 238 Batch 15 Loss 0.0397 Accuracy 5.2034\n",
      "Epoch 238 Batch 20 Loss 0.0397 Accuracy 5.2033\n",
      "Epoch 238 Batch 25 Loss 0.0397 Accuracy 5.2031\n",
      "Epoch 238 Batch 30 Loss 0.0397 Accuracy 5.2030\n",
      "Epoch 238 Batch 35 Loss 0.0397 Accuracy 5.2029\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2062\n",
      "Epoch 239 Batch 5 Loss 0.0397 Accuracy 5.2027\n",
      "Epoch 239 Batch 10 Loss 0.0397 Accuracy 5.2026\n",
      "Epoch 239 Batch 15 Loss 0.0397 Accuracy 5.2025\n",
      "Epoch 239 Batch 20 Loss 0.0397 Accuracy 5.2023\n",
      "Epoch 239 Batch 25 Loss 0.0397 Accuracy 5.2022\n",
      "Epoch 239 Batch 30 Loss 0.0397 Accuracy 5.2021\n",
      "Epoch 239 Batch 35 Loss 0.0397 Accuracy 5.2020\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2053\n",
      "Epoch 240 Batch 5 Loss 0.0397 Accuracy 5.2018\n",
      "Epoch 240 Batch 10 Loss 0.0397 Accuracy 5.2016\n",
      "Epoch 240 Batch 15 Loss 0.0397 Accuracy 5.2015\n",
      "Epoch 240 Batch 20 Loss 0.0397 Accuracy 5.2014\n",
      "Epoch 240 Batch 25 Loss 0.0397 Accuracy 5.2013\n",
      "Epoch 240 Batch 30 Loss 0.0397 Accuracy 5.2012\n",
      "Epoch 240 Batch 35 Loss 0.0396 Accuracy 5.2010\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2043\n",
      "Epoch 241 Batch 5 Loss 0.0396 Accuracy 5.2008\n",
      "Epoch 241 Batch 10 Loss 0.0396 Accuracy 5.2007\n",
      "Epoch 241 Batch 15 Loss 0.0396 Accuracy 5.2006\n",
      "Epoch 241 Batch 20 Loss 0.0396 Accuracy 5.2005\n",
      "Epoch 241 Batch 25 Loss 0.0396 Accuracy 5.2003\n",
      "Epoch 241 Batch 30 Loss 0.0396 Accuracy 5.2002\n",
      "Epoch 241 Batch 35 Loss 0.0396 Accuracy 5.2001\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2034\n",
      "Epoch 242 Batch 5 Loss 0.0396 Accuracy 5.1999\n",
      "Epoch 242 Batch 10 Loss 0.0396 Accuracy 5.1998\n",
      "Epoch 242 Batch 15 Loss 0.0396 Accuracy 5.1997\n",
      "Epoch 242 Batch 20 Loss 0.0396 Accuracy 5.1995\n",
      "Epoch 242 Batch 25 Loss 0.0396 Accuracy 5.1994\n",
      "Epoch 242 Batch 30 Loss 0.0396 Accuracy 5.1993\n",
      "Epoch 242 Batch 35 Loss 0.0396 Accuracy 5.1992\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2024\n",
      "Epoch 243 Batch 5 Loss 0.0396 Accuracy 5.1990\n",
      "Epoch 243 Batch 10 Loss 0.0396 Accuracy 5.1989\n",
      "Epoch 243 Batch 15 Loss 0.0396 Accuracy 5.1987\n",
      "Epoch 243 Batch 20 Loss 0.0396 Accuracy 5.1986\n",
      "Epoch 243 Batch 25 Loss 0.0396 Accuracy 5.1985\n",
      "Epoch 243 Batch 30 Loss 0.0396 Accuracy 5.1984\n",
      "Epoch 243 Batch 35 Loss 0.0396 Accuracy 5.1982\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2015\n",
      "Epoch 244 Batch 5 Loss 0.0396 Accuracy 5.1981\n",
      "Epoch 244 Batch 10 Loss 0.0396 Accuracy 5.1979\n",
      "Epoch 244 Batch 15 Loss 0.0396 Accuracy 5.1978\n",
      "Epoch 244 Batch 20 Loss 0.0396 Accuracy 5.1977\n",
      "Epoch 244 Batch 25 Loss 0.0396 Accuracy 5.1976\n",
      "Epoch 244 Batch 30 Loss 0.0396 Accuracy 5.1974\n",
      "Epoch 244 Batch 35 Loss 0.0396 Accuracy 5.1973\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.2006\n",
      "Epoch 245 Batch 5 Loss 0.0396 Accuracy 5.1971\n",
      "Epoch 245 Batch 10 Loss 0.0396 Accuracy 5.1970\n",
      "Epoch 245 Batch 15 Loss 0.0396 Accuracy 5.1969\n",
      "Epoch 245 Batch 20 Loss 0.0396 Accuracy 5.1968\n",
      "Epoch 245 Batch 25 Loss 0.0396 Accuracy 5.1966\n",
      "Epoch 245 Batch 30 Loss 0.0396 Accuracy 5.1965\n",
      "Epoch 245 Batch 35 Loss 0.0396 Accuracy 5.1964\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1996\n",
      "Epoch 246 Batch 5 Loss 0.0396 Accuracy 5.1962\n",
      "Epoch 246 Batch 10 Loss 0.0396 Accuracy 5.1961\n",
      "Epoch 246 Batch 15 Loss 0.0396 Accuracy 5.1960\n",
      "Epoch 246 Batch 20 Loss 0.0396 Accuracy 5.1958\n",
      "Epoch 246 Batch 25 Loss 0.0396 Accuracy 5.1957\n",
      "Epoch 246 Batch 30 Loss 0.0396 Accuracy 5.1956\n",
      "Epoch 246 Batch 35 Loss 0.0396 Accuracy 5.1955\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1987\n",
      "Epoch 247 Batch 5 Loss 0.0396 Accuracy 5.1953\n",
      "Epoch 247 Batch 10 Loss 0.0396 Accuracy 5.1952\n",
      "Epoch 247 Batch 15 Loss 0.0396 Accuracy 5.1950\n",
      "Epoch 247 Batch 20 Loss 0.0396 Accuracy 5.1949\n",
      "Epoch 247 Batch 25 Loss 0.0396 Accuracy 5.1948\n",
      "Epoch 247 Batch 30 Loss 0.0396 Accuracy 5.1947\n",
      "Epoch 247 Batch 35 Loss 0.0396 Accuracy 5.1946\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1978\n",
      "Epoch 248 Batch 5 Loss 0.0396 Accuracy 5.1944\n",
      "Epoch 248 Batch 10 Loss 0.0396 Accuracy 5.1943\n",
      "Epoch 248 Batch 15 Loss 0.0396 Accuracy 5.1941\n",
      "Epoch 248 Batch 20 Loss 0.0396 Accuracy 5.1940\n",
      "Epoch 248 Batch 25 Loss 0.0396 Accuracy 5.1939\n",
      "Epoch 248 Batch 30 Loss 0.0396 Accuracy 5.1938\n",
      "Epoch 248 Batch 35 Loss 0.0396 Accuracy 5.1937\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1969\n",
      "Epoch 249 Batch 5 Loss 0.0396 Accuracy 5.1935\n",
      "Epoch 249 Batch 10 Loss 0.0396 Accuracy 5.1934\n",
      "Epoch 249 Batch 15 Loss 0.0396 Accuracy 5.1932\n",
      "Epoch 249 Batch 20 Loss 0.0396 Accuracy 5.1931\n",
      "Epoch 249 Batch 25 Loss 0.0396 Accuracy 5.1930\n",
      "Epoch 249 Batch 30 Loss 0.0396 Accuracy 5.1929\n",
      "Epoch 249 Batch 35 Loss 0.0396 Accuracy 5.1928\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1960\n",
      "Epoch 250 Batch 5 Loss 0.0396 Accuracy 5.1926\n",
      "Epoch 250 Batch 10 Loss 0.0396 Accuracy 5.1925\n",
      "Epoch 250 Batch 15 Loss 0.0396 Accuracy 5.1924\n",
      "Epoch 250 Batch 20 Loss 0.0396 Accuracy 5.1922\n",
      "Epoch 250 Batch 25 Loss 0.0396 Accuracy 5.1921\n",
      "Epoch 250 Batch 30 Loss 0.0396 Accuracy 5.1920\n",
      "Epoch 250 Batch 35 Loss 0.0396 Accuracy 5.1919\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1951\n",
      "Epoch 251 Batch 5 Loss 0.0396 Accuracy 5.1917\n",
      "Epoch 251 Batch 10 Loss 0.0396 Accuracy 5.1916\n",
      "Epoch 251 Batch 15 Loss 0.0396 Accuracy 5.1915\n",
      "Epoch 251 Batch 20 Loss 0.0396 Accuracy 5.1914\n",
      "Epoch 251 Batch 25 Loss 0.0396 Accuracy 5.1912\n",
      "Epoch 251 Batch 30 Loss 0.0396 Accuracy 5.1911\n",
      "Epoch 251 Batch 35 Loss 0.0396 Accuracy 5.1910\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252 Batch 5 Loss 0.0396 Accuracy 5.1908\n",
      "Epoch 252 Batch 10 Loss 0.0396 Accuracy 5.1907\n",
      "Epoch 252 Batch 15 Loss 0.0396 Accuracy 5.1906\n",
      "Epoch 252 Batch 20 Loss 0.0396 Accuracy 5.1905\n",
      "Epoch 252 Batch 25 Loss 0.0396 Accuracy 5.1904\n",
      "Epoch 252 Batch 30 Loss 0.0396 Accuracy 5.1903\n",
      "Epoch 252 Batch 35 Loss 0.0396 Accuracy 5.1902\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1933\n",
      "Epoch 253 Batch 5 Loss 0.0396 Accuracy 5.1900\n",
      "Epoch 253 Batch 10 Loss 0.0396 Accuracy 5.1899\n",
      "Epoch 253 Batch 15 Loss 0.0396 Accuracy 5.1898\n",
      "Epoch 253 Batch 20 Loss 0.0396 Accuracy 5.1896\n",
      "Epoch 253 Batch 25 Loss 0.0396 Accuracy 5.1895\n",
      "Epoch 253 Batch 30 Loss 0.0396 Accuracy 5.1894\n",
      "Epoch 253 Batch 35 Loss 0.0396 Accuracy 5.1893\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1925\n",
      "Epoch 254 Batch 5 Loss 0.0396 Accuracy 5.1891\n",
      "Epoch 254 Batch 10 Loss 0.0396 Accuracy 5.1890\n",
      "Epoch 254 Batch 15 Loss 0.0396 Accuracy 5.1889\n",
      "Epoch 254 Batch 20 Loss 0.0396 Accuracy 5.1888\n",
      "Epoch 254 Batch 25 Loss 0.0396 Accuracy 5.1887\n",
      "Epoch 254 Batch 30 Loss 0.0396 Accuracy 5.1886\n",
      "Epoch 254 Batch 35 Loss 0.0396 Accuracy 5.1884\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1916\n",
      "Epoch 255 Batch 5 Loss 0.0396 Accuracy 5.1883\n",
      "Epoch 255 Batch 10 Loss 0.0396 Accuracy 5.1882\n",
      "Epoch 255 Batch 15 Loss 0.0396 Accuracy 5.1881\n",
      "Epoch 255 Batch 20 Loss 0.0396 Accuracy 5.1879\n",
      "Epoch 255 Batch 25 Loss 0.0396 Accuracy 5.1878\n",
      "Epoch 255 Batch 30 Loss 0.0396 Accuracy 5.1877\n",
      "Epoch 255 Batch 35 Loss 0.0396 Accuracy 5.1876\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1907\n",
      "Epoch 256 Batch 5 Loss 0.0396 Accuracy 5.1874\n",
      "Epoch 256 Batch 10 Loss 0.0396 Accuracy 5.1873\n",
      "Epoch 256 Batch 15 Loss 0.0396 Accuracy 5.1872\n",
      "Epoch 256 Batch 20 Loss 0.0396 Accuracy 5.1871\n",
      "Epoch 256 Batch 25 Loss 0.0396 Accuracy 5.1870\n",
      "Epoch 256 Batch 30 Loss 0.0396 Accuracy 5.1869\n",
      "Epoch 256 Batch 35 Loss 0.0396 Accuracy 5.1867\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1899\n",
      "Epoch 257 Batch 5 Loss 0.0396 Accuracy 5.1866\n",
      "Epoch 257 Batch 10 Loss 0.0396 Accuracy 5.1865\n",
      "Epoch 257 Batch 15 Loss 0.0396 Accuracy 5.1864\n",
      "Epoch 257 Batch 20 Loss 0.0396 Accuracy 5.1862\n",
      "Epoch 257 Batch 25 Loss 0.0396 Accuracy 5.1861\n",
      "Epoch 257 Batch 30 Loss 0.0396 Accuracy 5.1860\n",
      "Epoch 257 Batch 35 Loss 0.0396 Accuracy 5.1859\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1890\n",
      "Epoch 258 Batch 5 Loss 0.0396 Accuracy 5.1857\n",
      "Epoch 258 Batch 10 Loss 0.0396 Accuracy 5.1856\n",
      "Epoch 258 Batch 15 Loss 0.0396 Accuracy 5.1855\n",
      "Epoch 258 Batch 20 Loss 0.0396 Accuracy 5.1854\n",
      "Epoch 258 Batch 25 Loss 0.0396 Accuracy 5.1853\n",
      "Epoch 258 Batch 30 Loss 0.0396 Accuracy 5.1852\n",
      "Epoch 258 Batch 35 Loss 0.0396 Accuracy 5.1851\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1882\n",
      "Epoch 259 Batch 5 Loss 0.0396 Accuracy 5.1849\n",
      "Epoch 259 Batch 10 Loss 0.0396 Accuracy 5.1848\n",
      "Epoch 259 Batch 15 Loss 0.0396 Accuracy 5.1847\n",
      "Epoch 259 Batch 20 Loss 0.0396 Accuracy 5.1846\n",
      "Epoch 259 Batch 25 Loss 0.0396 Accuracy 5.1845\n",
      "Epoch 259 Batch 30 Loss 0.0396 Accuracy 5.1843\n",
      "Epoch 259 Batch 35 Loss 0.0396 Accuracy 5.1842\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1873\n",
      "Epoch 260 Batch 5 Loss 0.0396 Accuracy 5.1841\n",
      "Epoch 260 Batch 10 Loss 0.0396 Accuracy 5.1840\n",
      "Epoch 260 Batch 15 Loss 0.0396 Accuracy 5.1838\n",
      "Epoch 260 Batch 20 Loss 0.0396 Accuracy 5.1837\n",
      "Epoch 260 Batch 25 Loss 0.0396 Accuracy 5.1836\n",
      "Epoch 260 Batch 30 Loss 0.0396 Accuracy 5.1835\n",
      "Epoch 260 Batch 35 Loss 0.0396 Accuracy 5.1834\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1865\n",
      "Epoch 261 Batch 5 Loss 0.0396 Accuracy 5.1832\n",
      "Epoch 261 Batch 10 Loss 0.0396 Accuracy 5.1831\n",
      "Epoch 261 Batch 15 Loss 0.0396 Accuracy 5.1830\n",
      "Epoch 261 Batch 20 Loss 0.0396 Accuracy 5.1829\n",
      "Epoch 261 Batch 25 Loss 0.0396 Accuracy 5.1828\n",
      "Epoch 261 Batch 30 Loss 0.0395 Accuracy 5.1827\n",
      "Epoch 261 Batch 35 Loss 0.0395 Accuracy 5.1826\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1857\n",
      "Epoch 262 Batch 5 Loss 0.0395 Accuracy 5.1824\n",
      "Epoch 262 Batch 10 Loss 0.0395 Accuracy 5.1823\n",
      "Epoch 262 Batch 15 Loss 0.0395 Accuracy 5.1822\n",
      "Epoch 262 Batch 20 Loss 0.0395 Accuracy 5.1821\n",
      "Epoch 262 Batch 25 Loss 0.0395 Accuracy 5.1820\n",
      "Epoch 262 Batch 30 Loss 0.0395 Accuracy 5.1819\n",
      "Epoch 262 Batch 35 Loss 0.0395 Accuracy 5.1818\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1848\n",
      "Epoch 263 Batch 5 Loss 0.0395 Accuracy 5.1816\n",
      "Epoch 263 Batch 10 Loss 0.0395 Accuracy 5.1815\n",
      "Epoch 263 Batch 15 Loss 0.0395 Accuracy 5.1814\n",
      "Epoch 263 Batch 20 Loss 0.0395 Accuracy 5.1813\n",
      "Epoch 263 Batch 25 Loss 0.0395 Accuracy 5.1812\n",
      "Epoch 263 Batch 30 Loss 0.0395 Accuracy 5.1810\n",
      "Epoch 263 Batch 35 Loss 0.0395 Accuracy 5.1809\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1840\n",
      "Epoch 264 Batch 5 Loss 0.0395 Accuracy 5.1808\n",
      "Epoch 264 Batch 10 Loss 0.0395 Accuracy 5.1807\n",
      "Epoch 264 Batch 15 Loss 0.0395 Accuracy 5.1806\n",
      "Epoch 264 Batch 20 Loss 0.0395 Accuracy 5.1804\n",
      "Epoch 264 Batch 25 Loss 0.0395 Accuracy 5.1803\n",
      "Epoch 264 Batch 30 Loss 0.0395 Accuracy 5.1802\n",
      "Epoch 264 Batch 35 Loss 0.0395 Accuracy 5.1801\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1832\n",
      "Epoch 265 Batch 5 Loss 0.0395 Accuracy 5.1800\n",
      "Epoch 265 Batch 10 Loss 0.0395 Accuracy 5.1798\n",
      "Epoch 265 Batch 15 Loss 0.0395 Accuracy 5.1797\n",
      "Epoch 265 Batch 20 Loss 0.0395 Accuracy 5.1796\n",
      "Epoch 265 Batch 25 Loss 0.0395 Accuracy 5.1795\n",
      "Epoch 265 Batch 30 Loss 0.0395 Accuracy 5.1794\n",
      "Epoch 265 Batch 35 Loss 0.0395 Accuracy 5.1793\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1823\n",
      "Epoch 266 Batch 5 Loss 0.0395 Accuracy 5.1791\n",
      "Epoch 266 Batch 10 Loss 0.0395 Accuracy 5.1790\n",
      "Epoch 266 Batch 15 Loss 0.0395 Accuracy 5.1789\n",
      "Epoch 266 Batch 20 Loss 0.0395 Accuracy 5.1788\n",
      "Epoch 266 Batch 25 Loss 0.0395 Accuracy 5.1787\n",
      "Epoch 266 Batch 30 Loss 0.0395 Accuracy 5.1786\n",
      "Epoch 266 Batch 35 Loss 0.0395 Accuracy 5.1785\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1815\n",
      "Epoch 267 Batch 5 Loss 0.0395 Accuracy 5.1783\n",
      "Epoch 267 Batch 10 Loss 0.0395 Accuracy 5.1782\n",
      "Epoch 267 Batch 15 Loss 0.0395 Accuracy 5.1781\n",
      "Epoch 267 Batch 20 Loss 0.0395 Accuracy 5.1780\n",
      "Epoch 267 Batch 25 Loss 0.0395 Accuracy 5.1779\n",
      "Epoch 267 Batch 30 Loss 0.0395 Accuracy 5.1778\n",
      "Epoch 267 Batch 35 Loss 0.0395 Accuracy 5.1776\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1807\n",
      "Epoch 268 Batch 5 Loss 0.0395 Accuracy 5.1775\n",
      "Epoch 268 Batch 10 Loss 0.0395 Accuracy 5.1774\n",
      "Epoch 268 Batch 15 Loss 0.0395 Accuracy 5.1773\n",
      "Epoch 268 Batch 20 Loss 0.0395 Accuracy 5.1772\n",
      "Epoch 268 Batch 25 Loss 0.0395 Accuracy 5.1770\n",
      "Epoch 268 Batch 30 Loss 0.0395 Accuracy 5.1769\n",
      "Epoch 268 Batch 35 Loss 0.0395 Accuracy 5.1768\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1798\n",
      "Epoch 269 Batch 5 Loss 0.0395 Accuracy 5.1767\n",
      "Epoch 269 Batch 10 Loss 0.0395 Accuracy 5.1766\n",
      "Epoch 269 Batch 15 Loss 0.0395 Accuracy 5.1764\n",
      "Epoch 269 Batch 20 Loss 0.0395 Accuracy 5.1763\n",
      "Epoch 269 Batch 25 Loss 0.0394 Accuracy 5.1762\n",
      "Epoch 269 Batch 30 Loss 0.0394 Accuracy 5.1761\n",
      "Epoch 269 Batch 35 Loss 0.0394 Accuracy 5.1760\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1790\n",
      "Epoch 270 Batch 5 Loss 0.0394 Accuracy 5.1759\n",
      "Epoch 270 Batch 10 Loss 0.0394 Accuracy 5.1757\n",
      "Epoch 270 Batch 15 Loss 0.0394 Accuracy 5.1756\n",
      "Epoch 270 Batch 20 Loss 0.0394 Accuracy 5.1755\n",
      "Epoch 270 Batch 25 Loss 0.0394 Accuracy 5.1754\n",
      "Epoch 270 Batch 30 Loss 0.0394 Accuracy 5.1753\n",
      "Epoch 270 Batch 35 Loss 0.0394 Accuracy 5.1752\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1782\n",
      "Epoch 271 Batch 5 Loss 0.0394 Accuracy 5.1750\n",
      "Epoch 271 Batch 10 Loss 0.0394 Accuracy 5.1749\n",
      "Epoch 271 Batch 15 Loss 0.0394 Accuracy 5.1748\n",
      "Epoch 271 Batch 20 Loss 0.0394 Accuracy 5.1747\n",
      "Epoch 271 Batch 25 Loss 0.0394 Accuracy 5.1746\n",
      "Epoch 271 Batch 30 Loss 0.0394 Accuracy 5.1745\n",
      "Epoch 271 Batch 35 Loss 0.0394 Accuracy 5.1744\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1773\n",
      "Epoch 272 Batch 5 Loss 0.0394 Accuracy 5.1742\n",
      "Epoch 272 Batch 10 Loss 0.0394 Accuracy 5.1741\n",
      "Epoch 272 Batch 15 Loss 0.0394 Accuracy 5.1740\n",
      "Epoch 272 Batch 20 Loss 0.0394 Accuracy 5.1739\n",
      "Epoch 272 Batch 25 Loss 0.0394 Accuracy 5.1738\n",
      "Epoch 272 Batch 30 Loss 0.0394 Accuracy 5.1737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272 Batch 35 Loss 0.0394 Accuracy 5.1736\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1765\n",
      "Epoch 273 Batch 5 Loss 0.0394 Accuracy 5.1734\n",
      "Epoch 273 Batch 10 Loss 0.0394 Accuracy 5.1733\n",
      "Epoch 273 Batch 15 Loss 0.0394 Accuracy 5.1732\n",
      "Epoch 273 Batch 20 Loss 0.0394 Accuracy 5.1731\n",
      "Epoch 273 Batch 25 Loss 0.0394 Accuracy 5.1730\n",
      "Epoch 273 Batch 30 Loss 0.0394 Accuracy 5.1728\n",
      "Epoch 273 Batch 35 Loss 0.0394 Accuracy 5.1727\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1757\n",
      "Epoch 274 Batch 5 Loss 0.0394 Accuracy 5.1726\n",
      "Epoch 274 Batch 10 Loss 0.0394 Accuracy 5.1725\n",
      "Epoch 274 Batch 15 Loss 0.0394 Accuracy 5.1724\n",
      "Epoch 274 Batch 20 Loss 0.0394 Accuracy 5.1723\n",
      "Epoch 274 Batch 25 Loss 0.0394 Accuracy 5.1721\n",
      "Epoch 274 Batch 30 Loss 0.0394 Accuracy 5.1720\n",
      "Epoch 274 Batch 35 Loss 0.0394 Accuracy 5.1719\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1748\n",
      "Epoch 275 Batch 5 Loss 0.0394 Accuracy 5.1718\n",
      "Epoch 275 Batch 10 Loss 0.0394 Accuracy 5.1717\n",
      "Epoch 275 Batch 15 Loss 0.0394 Accuracy 5.1715\n",
      "Epoch 275 Batch 20 Loss 0.0394 Accuracy 5.1714\n",
      "Epoch 275 Batch 25 Loss 0.0394 Accuracy 5.1713\n",
      "Epoch 275 Batch 30 Loss 0.0393 Accuracy 5.1712\n",
      "Epoch 275 Batch 35 Loss 0.0393 Accuracy 5.1711\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1740\n",
      "Epoch 276 Batch 5 Loss 0.0393 Accuracy 5.1709\n",
      "Epoch 276 Batch 10 Loss 0.0393 Accuracy 5.1708\n",
      "Epoch 276 Batch 15 Loss 0.0393 Accuracy 5.1707\n",
      "Epoch 276 Batch 20 Loss 0.0393 Accuracy 5.1706\n",
      "Epoch 276 Batch 25 Loss 0.0393 Accuracy 5.1705\n",
      "Epoch 276 Batch 30 Loss 0.0393 Accuracy 5.1704\n",
      "Epoch 276 Batch 35 Loss 0.0393 Accuracy 5.1703\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1732\n",
      "Epoch 277 Batch 5 Loss 0.0393 Accuracy 5.1701\n",
      "Epoch 277 Batch 10 Loss 0.0393 Accuracy 5.1700\n",
      "Epoch 277 Batch 15 Loss 0.0393 Accuracy 5.1699\n",
      "Epoch 277 Batch 20 Loss 0.0393 Accuracy 5.1698\n",
      "Epoch 277 Batch 25 Loss 0.0393 Accuracy 5.1697\n",
      "Epoch 277 Batch 30 Loss 0.0393 Accuracy 5.1696\n",
      "Epoch 277 Batch 35 Loss 0.0393 Accuracy 5.1695\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1723\n",
      "Epoch 278 Batch 5 Loss 0.0393 Accuracy 5.1693\n",
      "Epoch 278 Batch 10 Loss 0.0393 Accuracy 5.1692\n",
      "Epoch 278 Batch 15 Loss 0.0393 Accuracy 5.1691\n",
      "Epoch 278 Batch 20 Loss 0.0393 Accuracy 5.1690\n",
      "Epoch 278 Batch 25 Loss 0.0393 Accuracy 5.1689\n",
      "Epoch 278 Batch 30 Loss 0.0393 Accuracy 5.1687\n",
      "Epoch 278 Batch 35 Loss 0.0393 Accuracy 5.1686\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1715\n",
      "Epoch 279 Batch 5 Loss 0.0393 Accuracy 5.1685\n",
      "Epoch 279 Batch 10 Loss 0.0393 Accuracy 5.1684\n",
      "Epoch 279 Batch 15 Loss 0.0393 Accuracy 5.1683\n",
      "Epoch 279 Batch 20 Loss 0.0393 Accuracy 5.1681\n",
      "Epoch 279 Batch 25 Loss 0.0393 Accuracy 5.1680\n",
      "Epoch 279 Batch 30 Loss 0.0393 Accuracy 5.1679\n",
      "Epoch 279 Batch 35 Loss 0.0393 Accuracy 5.1678\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1707\n",
      "Epoch 280 Batch 5 Loss 0.0393 Accuracy 5.1677\n",
      "Epoch 280 Batch 10 Loss 0.0393 Accuracy 5.1676\n",
      "Epoch 280 Batch 15 Loss 0.0393 Accuracy 5.1674\n",
      "Epoch 280 Batch 20 Loss 0.0393 Accuracy 5.1673\n",
      "Epoch 280 Batch 25 Loss 0.0393 Accuracy 5.1672\n",
      "Epoch 280 Batch 30 Loss 0.0393 Accuracy 5.1671\n",
      "Epoch 280 Batch 35 Loss 0.0393 Accuracy 5.1670\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1699\n",
      "Epoch 281 Batch 5 Loss 0.0393 Accuracy 5.1668\n",
      "Epoch 281 Batch 10 Loss 0.0393 Accuracy 5.1667\n",
      "Epoch 281 Batch 15 Loss 0.0393 Accuracy 5.1666\n",
      "Epoch 281 Batch 20 Loss 0.0393 Accuracy 5.1665\n",
      "Epoch 281 Batch 25 Loss 0.0393 Accuracy 5.1664\n",
      "Epoch 281 Batch 30 Loss 0.0393 Accuracy 5.1663\n",
      "Epoch 281 Batch 35 Loss 0.0393 Accuracy 5.1662\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1690\n",
      "Epoch 282 Batch 5 Loss 0.0393 Accuracy 5.1660\n",
      "Epoch 282 Batch 10 Loss 0.0393 Accuracy 5.1659\n",
      "Epoch 282 Batch 15 Loss 0.0393 Accuracy 5.1658\n",
      "Epoch 282 Batch 20 Loss 0.0393 Accuracy 5.1657\n",
      "Epoch 282 Batch 25 Loss 0.0393 Accuracy 5.1656\n",
      "Epoch 282 Batch 30 Loss 0.0393 Accuracy 5.1655\n",
      "Epoch 282 Batch 35 Loss 0.0393 Accuracy 5.1654\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1682\n",
      "Epoch 283 Batch 5 Loss 0.0393 Accuracy 5.1652\n",
      "Epoch 283 Batch 10 Loss 0.0393 Accuracy 5.1651\n",
      "Epoch 283 Batch 15 Loss 0.0393 Accuracy 5.1650\n",
      "Epoch 283 Batch 20 Loss 0.0393 Accuracy 5.1649\n",
      "Epoch 283 Batch 25 Loss 0.0393 Accuracy 5.1648\n",
      "Epoch 283 Batch 30 Loss 0.0393 Accuracy 5.1647\n",
      "Epoch 283 Batch 35 Loss 0.0393 Accuracy 5.1646\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1674\n",
      "Epoch 284 Batch 5 Loss 0.0393 Accuracy 5.1644\n",
      "Epoch 284 Batch 10 Loss 0.0393 Accuracy 5.1643\n",
      "Epoch 284 Batch 15 Loss 0.0393 Accuracy 5.1642\n",
      "Epoch 284 Batch 20 Loss 0.0393 Accuracy 5.1641\n",
      "Epoch 284 Batch 25 Loss 0.0393 Accuracy 5.1640\n",
      "Epoch 284 Batch 30 Loss 0.0393 Accuracy 5.1639\n",
      "Epoch 284 Batch 35 Loss 0.0393 Accuracy 5.1638\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1666\n",
      "Epoch 285 Batch 5 Loss 0.0393 Accuracy 5.1636\n",
      "Epoch 285 Batch 10 Loss 0.0393 Accuracy 5.1635\n",
      "Epoch 285 Batch 15 Loss 0.0393 Accuracy 5.1634\n",
      "Epoch 285 Batch 20 Loss 0.0393 Accuracy 5.1633\n",
      "Epoch 285 Batch 25 Loss 0.0393 Accuracy 5.1632\n",
      "Epoch 285 Batch 30 Loss 0.0393 Accuracy 5.1631\n",
      "Epoch 285 Batch 35 Loss 0.0392 Accuracy 5.1630\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1658\n",
      "Epoch 286 Batch 5 Loss 0.0392 Accuracy 5.1628\n",
      "Epoch 286 Batch 10 Loss 0.0392 Accuracy 5.1627\n",
      "Epoch 286 Batch 15 Loss 0.0392 Accuracy 5.1626\n",
      "Epoch 286 Batch 20 Loss 0.0392 Accuracy 5.1625\n",
      "Epoch 286 Batch 25 Loss 0.0392 Accuracy 5.1624\n",
      "Epoch 286 Batch 30 Loss 0.0392 Accuracy 5.1623\n",
      "Epoch 286 Batch 35 Loss 0.0392 Accuracy 5.1622\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1650\n",
      "Epoch 287 Batch 5 Loss 0.0392 Accuracy 5.1620\n",
      "Epoch 287 Batch 10 Loss 0.0392 Accuracy 5.1619\n",
      "Epoch 287 Batch 15 Loss 0.0392 Accuracy 5.1618\n",
      "Epoch 287 Batch 20 Loss 0.0392 Accuracy 5.1617\n",
      "Epoch 287 Batch 25 Loss 0.0392 Accuracy 5.1616\n",
      "Epoch 287 Batch 30 Loss 0.0392 Accuracy 5.1615\n",
      "Epoch 287 Batch 35 Loss 0.0392 Accuracy 5.1614\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1642\n",
      "Epoch 288 Batch 5 Loss 0.0392 Accuracy 5.1612\n",
      "Epoch 288 Batch 10 Loss 0.0392 Accuracy 5.1611\n",
      "Epoch 288 Batch 15 Loss 0.0392 Accuracy 5.1610\n",
      "Epoch 288 Batch 20 Loss 0.0392 Accuracy 5.1609\n",
      "Epoch 288 Batch 25 Loss 0.0392 Accuracy 5.1608\n",
      "Epoch 288 Batch 30 Loss 0.0392 Accuracy 5.1607\n",
      "Epoch 288 Batch 35 Loss 0.0392 Accuracy 5.1606\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1633\n",
      "Epoch 289 Batch 5 Loss 0.0392 Accuracy 5.1604\n",
      "Epoch 289 Batch 10 Loss 0.0392 Accuracy 5.1603\n",
      "Epoch 289 Batch 15 Loss 0.0392 Accuracy 5.1602\n",
      "Epoch 289 Batch 20 Loss 0.0392 Accuracy 5.1601\n",
      "Epoch 289 Batch 25 Loss 0.0392 Accuracy 5.1600\n",
      "Epoch 289 Batch 30 Loss 0.0392 Accuracy 5.1599\n",
      "Epoch 289 Batch 35 Loss 0.0392 Accuracy 5.1598\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1625\n",
      "Epoch 290 Batch 5 Loss 0.0392 Accuracy 5.1596\n",
      "Epoch 290 Batch 10 Loss 0.0392 Accuracy 5.1595\n",
      "Epoch 290 Batch 15 Loss 0.0392 Accuracy 5.1594\n",
      "Epoch 290 Batch 20 Loss 0.0392 Accuracy 5.1593\n",
      "Epoch 290 Batch 25 Loss 0.0392 Accuracy 5.1592\n",
      "Epoch 290 Batch 30 Loss 0.0392 Accuracy 5.1591\n",
      "Epoch 290 Batch 35 Loss 0.0392 Accuracy 5.1590\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1617\n",
      "Epoch 291 Batch 5 Loss 0.0392 Accuracy 5.1588\n",
      "Epoch 291 Batch 10 Loss 0.0392 Accuracy 5.1587\n",
      "Epoch 291 Batch 15 Loss 0.0392 Accuracy 5.1586\n",
      "Epoch 291 Batch 20 Loss 0.0392 Accuracy 5.1585\n",
      "Epoch 291 Batch 25 Loss 0.0392 Accuracy 5.1584\n",
      "Epoch 291 Batch 30 Loss 0.0392 Accuracy 5.1583\n",
      "Epoch 291 Batch 35 Loss 0.0392 Accuracy 5.1582\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1609\n",
      "Epoch 292 Batch 5 Loss 0.0392 Accuracy 5.1580\n",
      "Epoch 292 Batch 10 Loss 0.0392 Accuracy 5.1579\n",
      "Epoch 292 Batch 15 Loss 0.0392 Accuracy 5.1578\n",
      "Epoch 292 Batch 20 Loss 0.0392 Accuracy 5.1577\n",
      "Epoch 292 Batch 25 Loss 0.0392 Accuracy 5.1576\n",
      "Epoch 292 Batch 30 Loss 0.0392 Accuracy 5.1575\n",
      "Epoch 292 Batch 35 Loss 0.0392 Accuracy 5.1574\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1601\n",
      "Epoch 293 Batch 5 Loss 0.0392 Accuracy 5.1573\n",
      "Epoch 293 Batch 10 Loss 0.0392 Accuracy 5.1571\n",
      "Epoch 293 Batch 15 Loss 0.0392 Accuracy 5.1570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293 Batch 20 Loss 0.0392 Accuracy 5.1569\n",
      "Epoch 293 Batch 25 Loss 0.0392 Accuracy 5.1568\n",
      "Epoch 293 Batch 30 Loss 0.0392 Accuracy 5.1567\n",
      "Epoch 293 Batch 35 Loss 0.0392 Accuracy 5.1566\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1594\n",
      "Epoch 294 Batch 5 Loss 0.0392 Accuracy 5.1565\n",
      "Epoch 294 Batch 10 Loss 0.0392 Accuracy 5.1564\n",
      "Epoch 294 Batch 15 Loss 0.0392 Accuracy 5.1563\n",
      "Epoch 294 Batch 20 Loss 0.0392 Accuracy 5.1561\n",
      "Epoch 294 Batch 25 Loss 0.0392 Accuracy 5.1560\n",
      "Epoch 294 Batch 30 Loss 0.0392 Accuracy 5.1559\n",
      "Epoch 294 Batch 35 Loss 0.0392 Accuracy 5.1558\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1586\n",
      "Epoch 295 Batch 5 Loss 0.0392 Accuracy 5.1557\n",
      "Epoch 295 Batch 10 Loss 0.0392 Accuracy 5.1556\n",
      "Epoch 295 Batch 15 Loss 0.0392 Accuracy 5.1555\n",
      "Epoch 295 Batch 20 Loss 0.0392 Accuracy 5.1554\n",
      "Epoch 295 Batch 25 Loss 0.0392 Accuracy 5.1553\n",
      "Epoch 295 Batch 30 Loss 0.0392 Accuracy 5.1552\n",
      "Epoch 295 Batch 35 Loss 0.0392 Accuracy 5.1550\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1578\n",
      "Epoch 296 Batch 5 Loss 0.0392 Accuracy 5.1549\n",
      "Epoch 296 Batch 10 Loss 0.0392 Accuracy 5.1548\n",
      "Epoch 296 Batch 15 Loss 0.0392 Accuracy 5.1547\n",
      "Epoch 296 Batch 20 Loss 0.0392 Accuracy 5.1546\n",
      "Epoch 296 Batch 25 Loss 0.0392 Accuracy 5.1545\n",
      "Epoch 296 Batch 30 Loss 0.0392 Accuracy 5.1544\n",
      "Epoch 296 Batch 35 Loss 0.0392 Accuracy 5.1543\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1570\n",
      "Epoch 297 Batch 5 Loss 0.0392 Accuracy 5.1541\n",
      "Epoch 297 Batch 10 Loss 0.0392 Accuracy 5.1540\n",
      "Epoch 297 Batch 15 Loss 0.0392 Accuracy 5.1539\n",
      "Epoch 297 Batch 20 Loss 0.0392 Accuracy 5.1538\n",
      "Epoch 297 Batch 25 Loss 0.0392 Accuracy 5.1537\n",
      "Epoch 297 Batch 30 Loss 0.0392 Accuracy 5.1536\n",
      "Epoch 297 Batch 35 Loss 0.0392 Accuracy 5.1535\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1562\n",
      "Epoch 298 Batch 5 Loss 0.0392 Accuracy 5.1534\n",
      "Epoch 298 Batch 10 Loss 0.0392 Accuracy 5.1532\n",
      "Epoch 298 Batch 15 Loss 0.0392 Accuracy 5.1531\n",
      "Epoch 298 Batch 20 Loss 0.0392 Accuracy 5.1530\n",
      "Epoch 298 Batch 25 Loss 0.0392 Accuracy 5.1529\n",
      "Epoch 298 Batch 30 Loss 0.0392 Accuracy 5.1528\n",
      "Epoch 298 Batch 35 Loss 0.0392 Accuracy 5.1527\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1554\n",
      "Epoch 299 Batch 5 Loss 0.0392 Accuracy 5.1526\n",
      "Epoch 299 Batch 10 Loss 0.0392 Accuracy 5.1525\n",
      "Epoch 299 Batch 15 Loss 0.0392 Accuracy 5.1524\n",
      "Epoch 299 Batch 20 Loss 0.0392 Accuracy 5.1523\n",
      "Epoch 299 Batch 25 Loss 0.0392 Accuracy 5.1522\n",
      "Epoch 299 Batch 30 Loss 0.0392 Accuracy 5.1521\n",
      "Epoch 299 Batch 35 Loss 0.0392 Accuracy 5.1520\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1547\n",
      "Epoch 300 Batch 5 Loss 0.0392 Accuracy 5.1518\n",
      "Epoch 300 Batch 10 Loss 0.0392 Accuracy 5.1517\n",
      "Epoch 300 Batch 15 Loss 0.0392 Accuracy 5.1516\n",
      "Epoch 300 Batch 20 Loss 0.0392 Accuracy 5.1515\n",
      "Epoch 300 Batch 25 Loss 0.0392 Accuracy 5.1514\n",
      "Epoch 300 Batch 30 Loss 0.0392 Accuracy 5.1513\n",
      "Epoch 300 Batch 35 Loss 0.0392 Accuracy 5.1512\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1539\n",
      "Epoch 301 Batch 5 Loss 0.0392 Accuracy 5.1511\n",
      "Epoch 301 Batch 10 Loss 0.0392 Accuracy 5.1510\n",
      "Epoch 301 Batch 15 Loss 0.0392 Accuracy 5.1509\n",
      "Epoch 301 Batch 20 Loss 0.0392 Accuracy 5.1508\n",
      "Epoch 301 Batch 25 Loss 0.0392 Accuracy 5.1507\n",
      "Epoch 301 Batch 30 Loss 0.0392 Accuracy 5.1506\n",
      "Epoch 301 Batch 35 Loss 0.0392 Accuracy 5.1505\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1531\n",
      "Epoch 302 Batch 5 Loss 0.0391 Accuracy 5.1503\n",
      "Epoch 302 Batch 10 Loss 0.0391 Accuracy 5.1502\n",
      "Epoch 302 Batch 15 Loss 0.0391 Accuracy 5.1501\n",
      "Epoch 302 Batch 20 Loss 0.0391 Accuracy 5.1500\n",
      "Epoch 302 Batch 25 Loss 0.0391 Accuracy 5.1499\n",
      "Epoch 302 Batch 30 Loss 0.0391 Accuracy 5.1498\n",
      "Epoch 302 Batch 35 Loss 0.0391 Accuracy 5.1497\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1524\n",
      "Epoch 303 Batch 5 Loss 0.0391 Accuracy 5.1496\n",
      "Epoch 303 Batch 10 Loss 0.0391 Accuracy 5.1495\n",
      "Epoch 303 Batch 15 Loss 0.0391 Accuracy 5.1494\n",
      "Epoch 303 Batch 20 Loss 0.0391 Accuracy 5.1493\n",
      "Epoch 303 Batch 25 Loss 0.0391 Accuracy 5.1492\n",
      "Epoch 303 Batch 30 Loss 0.0391 Accuracy 5.1491\n",
      "Epoch 303 Batch 35 Loss 0.0391 Accuracy 5.1490\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1516\n",
      "Epoch 304 Batch 5 Loss 0.0391 Accuracy 5.1488\n",
      "Epoch 304 Batch 10 Loss 0.0391 Accuracy 5.1487\n",
      "Epoch 304 Batch 15 Loss 0.0391 Accuracy 5.1486\n",
      "Epoch 304 Batch 20 Loss 0.0391 Accuracy 5.1485\n",
      "Epoch 304 Batch 25 Loss 0.0391 Accuracy 5.1484\n",
      "Epoch 304 Batch 30 Loss 0.0391 Accuracy 5.1483\n",
      "Epoch 304 Batch 35 Loss 0.0391 Accuracy 5.1482\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1508\n",
      "Epoch 305 Batch 5 Loss 0.0391 Accuracy 5.1481\n",
      "Epoch 305 Batch 10 Loss 0.0391 Accuracy 5.1479\n",
      "Epoch 305 Batch 15 Loss 0.0391 Accuracy 5.1478\n",
      "Epoch 305 Batch 20 Loss 0.0391 Accuracy 5.1477\n",
      "Epoch 305 Batch 25 Loss 0.0391 Accuracy 5.1476\n",
      "Epoch 305 Batch 30 Loss 0.0391 Accuracy 5.1475\n",
      "Epoch 305 Batch 35 Loss 0.0391 Accuracy 5.1474\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1501\n",
      "Epoch 306 Batch 5 Loss 0.0391 Accuracy 5.1473\n",
      "Epoch 306 Batch 10 Loss 0.0391 Accuracy 5.1472\n",
      "Epoch 306 Batch 15 Loss 0.0391 Accuracy 5.1471\n",
      "Epoch 306 Batch 20 Loss 0.0391 Accuracy 5.1470\n",
      "Epoch 306 Batch 25 Loss 0.0391 Accuracy 5.1469\n",
      "Epoch 306 Batch 30 Loss 0.0391 Accuracy 5.1468\n",
      "Epoch 306 Batch 35 Loss 0.0391 Accuracy 5.1467\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1493\n",
      "Epoch 307 Batch 5 Loss 0.0391 Accuracy 5.1465\n",
      "Epoch 307 Batch 10 Loss 0.0391 Accuracy 5.1464\n",
      "Epoch 307 Batch 15 Loss 0.0391 Accuracy 5.1463\n",
      "Epoch 307 Batch 20 Loss 0.0391 Accuracy 5.1462\n",
      "Epoch 307 Batch 25 Loss 0.0391 Accuracy 5.1461\n",
      "Epoch 307 Batch 30 Loss 0.0391 Accuracy 5.1460\n",
      "Epoch 307 Batch 35 Loss 0.0391 Accuracy 5.1459\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1485\n",
      "Epoch 308 Batch 5 Loss 0.0391 Accuracy 5.1458\n",
      "Epoch 308 Batch 10 Loss 0.0391 Accuracy 5.1457\n",
      "Epoch 308 Batch 15 Loss 0.0391 Accuracy 5.1456\n",
      "Epoch 308 Batch 20 Loss 0.0391 Accuracy 5.1455\n",
      "Epoch 308 Batch 25 Loss 0.0391 Accuracy 5.1454\n",
      "Epoch 308 Batch 30 Loss 0.0390 Accuracy 5.1453\n",
      "Epoch 308 Batch 35 Loss 0.0390 Accuracy 5.1452\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1478\n",
      "Epoch 309 Batch 5 Loss 0.0391 Accuracy 5.1450\n",
      "Epoch 309 Batch 10 Loss 0.0391 Accuracy 5.1449\n",
      "Epoch 309 Batch 15 Loss 0.0391 Accuracy 5.1448\n",
      "Epoch 309 Batch 20 Loss 0.0391 Accuracy 5.1447\n",
      "Epoch 309 Batch 25 Loss 0.0391 Accuracy 5.1446\n",
      "Epoch 309 Batch 30 Loss 0.0391 Accuracy 5.1445\n",
      "Epoch 309 Batch 35 Loss 0.0391 Accuracy 5.1444\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1470\n",
      "Epoch 310 Batch 5 Loss 0.0391 Accuracy 5.1443\n",
      "Epoch 310 Batch 10 Loss 0.0391 Accuracy 5.1442\n",
      "Epoch 310 Batch 15 Loss 0.0391 Accuracy 5.1441\n",
      "Epoch 310 Batch 20 Loss 0.0391 Accuracy 5.1440\n",
      "Epoch 310 Batch 25 Loss 0.0391 Accuracy 5.1439\n",
      "Epoch 310 Batch 30 Loss 0.0391 Accuracy 5.1438\n",
      "Epoch 310 Batch 35 Loss 0.0390 Accuracy 5.1437\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1462\n",
      "Epoch 311 Batch 5 Loss 0.0390 Accuracy 5.1435\n",
      "Epoch 311 Batch 10 Loss 0.0390 Accuracy 5.1434\n",
      "Epoch 311 Batch 15 Loss 0.0390 Accuracy 5.1433\n",
      "Epoch 311 Batch 20 Loss 0.0390 Accuracy 5.1432\n",
      "Epoch 311 Batch 25 Loss 0.0390 Accuracy 5.1431\n",
      "Epoch 311 Batch 30 Loss 0.0390 Accuracy 5.1430\n",
      "Epoch 311 Batch 35 Loss 0.0390 Accuracy 5.1429\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1455\n",
      "Epoch 312 Batch 5 Loss 0.0390 Accuracy 5.1428\n",
      "Epoch 312 Batch 10 Loss 0.0390 Accuracy 5.1427\n",
      "Epoch 312 Batch 15 Loss 0.0390 Accuracy 5.1426\n",
      "Epoch 312 Batch 20 Loss 0.0390 Accuracy 5.1425\n",
      "Epoch 312 Batch 25 Loss 0.0390 Accuracy 5.1424\n",
      "Epoch 312 Batch 30 Loss 0.0390 Accuracy 5.1423\n",
      "Epoch 312 Batch 35 Loss 0.0390 Accuracy 5.1422\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1447\n",
      "Epoch 313 Batch 5 Loss 0.0390 Accuracy 5.1420\n",
      "Epoch 313 Batch 10 Loss 0.0390 Accuracy 5.1419\n",
      "Epoch 313 Batch 15 Loss 0.0390 Accuracy 5.1418\n",
      "Epoch 313 Batch 20 Loss 0.0390 Accuracy 5.1417\n",
      "Epoch 313 Batch 25 Loss 0.0390 Accuracy 5.1416\n",
      "Epoch 313 Batch 30 Loss 0.0390 Accuracy 5.1415\n",
      "Epoch 313 Batch 35 Loss 0.0390 Accuracy 5.1414\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1440\n",
      "Epoch 314 Batch 5 Loss 0.0390 Accuracy 5.1413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 314 Batch 10 Loss 0.0390 Accuracy 5.1412\n",
      "Epoch 314 Batch 15 Loss 0.0390 Accuracy 5.1411\n",
      "Epoch 314 Batch 20 Loss 0.0390 Accuracy 5.1410\n",
      "Epoch 314 Batch 25 Loss 0.0390 Accuracy 5.1409\n",
      "Epoch 314 Batch 30 Loss 0.0390 Accuracy 5.1408\n",
      "Epoch 314 Batch 35 Loss 0.0390 Accuracy 5.1407\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1432\n",
      "Epoch 315 Batch 5 Loss 0.0390 Accuracy 5.1405\n",
      "Epoch 315 Batch 10 Loss 0.0390 Accuracy 5.1404\n",
      "Epoch 315 Batch 15 Loss 0.0390 Accuracy 5.1403\n",
      "Epoch 315 Batch 20 Loss 0.0390 Accuracy 5.1402\n",
      "Epoch 315 Batch 25 Loss 0.0390 Accuracy 5.1401\n",
      "Epoch 315 Batch 30 Loss 0.0390 Accuracy 5.1400\n",
      "Epoch 315 Batch 35 Loss 0.0390 Accuracy 5.1399\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1425\n",
      "Epoch 316 Batch 5 Loss 0.0390 Accuracy 5.1398\n",
      "Epoch 316 Batch 10 Loss 0.0390 Accuracy 5.1397\n",
      "Epoch 316 Batch 15 Loss 0.0390 Accuracy 5.1396\n",
      "Epoch 316 Batch 20 Loss 0.0390 Accuracy 5.1395\n",
      "Epoch 316 Batch 25 Loss 0.0390 Accuracy 5.1394\n",
      "Epoch 316 Batch 30 Loss 0.0390 Accuracy 5.1393\n",
      "Epoch 316 Batch 35 Loss 0.0390 Accuracy 5.1392\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1417\n",
      "Epoch 317 Batch 5 Loss 0.0390 Accuracy 5.1390\n",
      "Epoch 317 Batch 10 Loss 0.0390 Accuracy 5.1389\n",
      "Epoch 317 Batch 15 Loss 0.0390 Accuracy 5.1388\n",
      "Epoch 317 Batch 20 Loss 0.0390 Accuracy 5.1387\n",
      "Epoch 317 Batch 25 Loss 0.0390 Accuracy 5.1386\n",
      "Epoch 317 Batch 30 Loss 0.0390 Accuracy 5.1385\n",
      "Epoch 317 Batch 35 Loss 0.0390 Accuracy 5.1384\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1409\n",
      "Epoch 318 Batch 5 Loss 0.0390 Accuracy 5.1383\n",
      "Epoch 318 Batch 10 Loss 0.0390 Accuracy 5.1382\n",
      "Epoch 318 Batch 15 Loss 0.0390 Accuracy 5.1381\n",
      "Epoch 318 Batch 20 Loss 0.0390 Accuracy 5.1380\n",
      "Epoch 318 Batch 25 Loss 0.0390 Accuracy 5.1379\n",
      "Epoch 318 Batch 30 Loss 0.0390 Accuracy 5.1378\n",
      "Epoch 318 Batch 35 Loss 0.0389 Accuracy 5.1377\n",
      "Time taken for 1 epoch: 0.55 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1402\n",
      "Epoch 319 Batch 5 Loss 0.0389 Accuracy 5.1375\n",
      "Epoch 319 Batch 10 Loss 0.0389 Accuracy 5.1374\n",
      "Epoch 319 Batch 15 Loss 0.0389 Accuracy 5.1373\n",
      "Epoch 319 Batch 20 Loss 0.0389 Accuracy 5.1372\n",
      "Epoch 319 Batch 25 Loss 0.0389 Accuracy 5.1371\n",
      "Epoch 319 Batch 30 Loss 0.0389 Accuracy 5.1370\n",
      "Epoch 319 Batch 35 Loss 0.0389 Accuracy 5.1369\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1394\n",
      "Epoch 320 Batch 5 Loss 0.0389 Accuracy 5.1368\n",
      "Epoch 320 Batch 10 Loss 0.0389 Accuracy 5.1367\n",
      "Epoch 320 Batch 15 Loss 0.0389 Accuracy 5.1366\n",
      "Epoch 320 Batch 20 Loss 0.0389 Accuracy 5.1365\n",
      "Epoch 320 Batch 25 Loss 0.0389 Accuracy 5.1364\n",
      "Epoch 320 Batch 30 Loss 0.0389 Accuracy 5.1363\n",
      "Epoch 320 Batch 35 Loss 0.0389 Accuracy 5.1362\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1387\n",
      "Epoch 321 Batch 5 Loss 0.0389 Accuracy 5.1360\n",
      "Epoch 321 Batch 10 Loss 0.0389 Accuracy 5.1359\n",
      "Epoch 321 Batch 15 Loss 0.0389 Accuracy 5.1358\n",
      "Epoch 321 Batch 20 Loss 0.0389 Accuracy 5.1357\n",
      "Epoch 321 Batch 25 Loss 0.0389 Accuracy 5.1356\n",
      "Epoch 321 Batch 30 Loss 0.0389 Accuracy 5.1355\n",
      "Epoch 321 Batch 35 Loss 0.0389 Accuracy 5.1354\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1379\n",
      "Epoch 322 Batch 5 Loss 0.0389 Accuracy 5.1353\n",
      "Epoch 322 Batch 10 Loss 0.0389 Accuracy 5.1352\n",
      "Epoch 322 Batch 15 Loss 0.0389 Accuracy 5.1351\n",
      "Epoch 322 Batch 20 Loss 0.0389 Accuracy 5.1350\n",
      "Epoch 322 Batch 25 Loss 0.0389 Accuracy 5.1349\n",
      "Epoch 322 Batch 30 Loss 0.0389 Accuracy 5.1348\n",
      "Epoch 322 Batch 35 Loss 0.0389 Accuracy 5.1347\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1372\n",
      "Epoch 323 Batch 5 Loss 0.0389 Accuracy 5.1346\n",
      "Epoch 323 Batch 10 Loss 0.0389 Accuracy 5.1345\n",
      "Epoch 323 Batch 15 Loss 0.0389 Accuracy 5.1344\n",
      "Epoch 323 Batch 20 Loss 0.0389 Accuracy 5.1343\n",
      "Epoch 323 Batch 25 Loss 0.0389 Accuracy 5.1342\n",
      "Epoch 323 Batch 30 Loss 0.0389 Accuracy 5.1341\n",
      "Epoch 323 Batch 35 Loss 0.0389 Accuracy 5.1340\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1364\n",
      "Epoch 324 Batch 5 Loss 0.0389 Accuracy 5.1338\n",
      "Epoch 324 Batch 10 Loss 0.0389 Accuracy 5.1337\n",
      "Epoch 324 Batch 15 Loss 0.0389 Accuracy 5.1336\n",
      "Epoch 324 Batch 20 Loss 0.0389 Accuracy 5.1335\n",
      "Epoch 324 Batch 25 Loss 0.0389 Accuracy 5.1334\n",
      "Epoch 324 Batch 30 Loss 0.0389 Accuracy 5.1333\n",
      "Epoch 324 Batch 35 Loss 0.0389 Accuracy 5.1332\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1357\n",
      "Epoch 325 Batch 5 Loss 0.0389 Accuracy 5.1331\n",
      "Epoch 325 Batch 10 Loss 0.0389 Accuracy 5.1330\n",
      "Epoch 325 Batch 15 Loss 0.0389 Accuracy 5.1329\n",
      "Epoch 325 Batch 20 Loss 0.0389 Accuracy 5.1328\n",
      "Epoch 325 Batch 25 Loss 0.0389 Accuracy 5.1327\n",
      "Epoch 325 Batch 30 Loss 0.0389 Accuracy 5.1326\n",
      "Epoch 325 Batch 35 Loss 0.0389 Accuracy 5.1325\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1349\n",
      "Epoch 326 Batch 5 Loss 0.0389 Accuracy 5.1323\n",
      "Epoch 326 Batch 10 Loss 0.0389 Accuracy 5.1322\n",
      "Epoch 326 Batch 15 Loss 0.0389 Accuracy 5.1321\n",
      "Epoch 326 Batch 20 Loss 0.0389 Accuracy 5.1320\n",
      "Epoch 326 Batch 25 Loss 0.0389 Accuracy 5.1319\n",
      "Epoch 326 Batch 30 Loss 0.0389 Accuracy 5.1318\n",
      "Epoch 326 Batch 35 Loss 0.0389 Accuracy 5.1317\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1342\n",
      "Epoch 327 Batch 5 Loss 0.0389 Accuracy 5.1316\n",
      "Epoch 327 Batch 10 Loss 0.0389 Accuracy 5.1315\n",
      "Epoch 327 Batch 15 Loss 0.0389 Accuracy 5.1314\n",
      "Epoch 327 Batch 20 Loss 0.0389 Accuracy 5.1313\n",
      "Epoch 327 Batch 25 Loss 0.0389 Accuracy 5.1312\n",
      "Epoch 327 Batch 30 Loss 0.0389 Accuracy 5.1311\n",
      "Epoch 327 Batch 35 Loss 0.0389 Accuracy 5.1310\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1335\n",
      "Epoch 328 Batch 5 Loss 0.0389 Accuracy 5.1309\n",
      "Epoch 328 Batch 10 Loss 0.0389 Accuracy 5.1308\n",
      "Epoch 328 Batch 15 Loss 0.0389 Accuracy 5.1307\n",
      "Epoch 328 Batch 20 Loss 0.0389 Accuracy 5.1306\n",
      "Epoch 328 Batch 25 Loss 0.0389 Accuracy 5.1305\n",
      "Epoch 328 Batch 30 Loss 0.0389 Accuracy 5.1304\n",
      "Epoch 328 Batch 35 Loss 0.0389 Accuracy 5.1303\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1327\n",
      "Epoch 329 Batch 5 Loss 0.0389 Accuracy 5.1302\n",
      "Epoch 329 Batch 10 Loss 0.0389 Accuracy 5.1301\n",
      "Epoch 329 Batch 15 Loss 0.0389 Accuracy 5.1300\n",
      "Epoch 329 Batch 20 Loss 0.0389 Accuracy 5.1299\n",
      "Epoch 329 Batch 25 Loss 0.0389 Accuracy 5.1298\n",
      "Epoch 329 Batch 30 Loss 0.0389 Accuracy 5.1297\n",
      "Epoch 329 Batch 35 Loss 0.0389 Accuracy 5.1296\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1320\n",
      "Epoch 330 Batch 5 Loss 0.0389 Accuracy 5.1294\n",
      "Epoch 330 Batch 10 Loss 0.0389 Accuracy 5.1294\n",
      "Epoch 330 Batch 15 Loss 0.0389 Accuracy 5.1293\n",
      "Epoch 330 Batch 20 Loss 0.0389 Accuracy 5.1292\n",
      "Epoch 330 Batch 25 Loss 0.0389 Accuracy 5.1291\n",
      "Epoch 330 Batch 30 Loss 0.0389 Accuracy 5.1290\n",
      "Epoch 330 Batch 35 Loss 0.0389 Accuracy 5.1289\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1313\n",
      "Epoch 331 Batch 5 Loss 0.0389 Accuracy 5.1287\n",
      "Epoch 331 Batch 10 Loss 0.0389 Accuracy 5.1286\n",
      "Epoch 331 Batch 15 Loss 0.0389 Accuracy 5.1285\n",
      "Epoch 331 Batch 20 Loss 0.0389 Accuracy 5.1284\n",
      "Epoch 331 Batch 25 Loss 0.0389 Accuracy 5.1283\n",
      "Epoch 331 Batch 30 Loss 0.0389 Accuracy 5.1283\n",
      "Epoch 331 Batch 35 Loss 0.0389 Accuracy 5.1282\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1306\n",
      "Epoch 332 Batch 5 Loss 0.0389 Accuracy 5.1280\n",
      "Epoch 332 Batch 10 Loss 0.0389 Accuracy 5.1279\n",
      "Epoch 332 Batch 15 Loss 0.0389 Accuracy 5.1278\n",
      "Epoch 332 Batch 20 Loss 0.0389 Accuracy 5.1277\n",
      "Epoch 332 Batch 25 Loss 0.0389 Accuracy 5.1276\n",
      "Epoch 332 Batch 30 Loss 0.0389 Accuracy 5.1275\n",
      "Epoch 332 Batch 35 Loss 0.0389 Accuracy 5.1274\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1298\n",
      "Epoch 333 Batch 5 Loss 0.0389 Accuracy 5.1273\n",
      "Epoch 333 Batch 10 Loss 0.0389 Accuracy 5.1272\n",
      "Epoch 333 Batch 15 Loss 0.0389 Accuracy 5.1271\n",
      "Epoch 333 Batch 20 Loss 0.0389 Accuracy 5.1270\n",
      "Epoch 333 Batch 25 Loss 0.0389 Accuracy 5.1269\n",
      "Epoch 333 Batch 30 Loss 0.0389 Accuracy 5.1268\n",
      "Epoch 333 Batch 35 Loss 0.0389 Accuracy 5.1267\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1291\n",
      "Epoch 334 Batch 5 Loss 0.0389 Accuracy 5.1266\n",
      "Epoch 334 Batch 10 Loss 0.0389 Accuracy 5.1265\n",
      "Epoch 334 Batch 15 Loss 0.0389 Accuracy 5.1264\n",
      "Epoch 334 Batch 20 Loss 0.0389 Accuracy 5.1263\n",
      "Epoch 334 Batch 25 Loss 0.0389 Accuracy 5.1262\n",
      "Epoch 334 Batch 30 Loss 0.0389 Accuracy 5.1261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334 Batch 35 Loss 0.0389 Accuracy 5.1260\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1284\n",
      "Epoch 335 Batch 5 Loss 0.0389 Accuracy 5.1259\n",
      "Epoch 335 Batch 10 Loss 0.0389 Accuracy 5.1258\n",
      "Epoch 335 Batch 15 Loss 0.0389 Accuracy 5.1257\n",
      "Epoch 335 Batch 20 Loss 0.0389 Accuracy 5.1256\n",
      "Epoch 335 Batch 25 Loss 0.0389 Accuracy 5.1255\n",
      "Epoch 335 Batch 30 Loss 0.0389 Accuracy 5.1254\n",
      "Epoch 335 Batch 35 Loss 0.0389 Accuracy 5.1253\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1277\n",
      "Epoch 336 Batch 5 Loss 0.0389 Accuracy 5.1252\n",
      "Epoch 336 Batch 10 Loss 0.0389 Accuracy 5.1251\n",
      "Epoch 336 Batch 15 Loss 0.0389 Accuracy 5.1250\n",
      "Epoch 336 Batch 20 Loss 0.0389 Accuracy 5.1249\n",
      "Epoch 336 Batch 25 Loss 0.0389 Accuracy 5.1248\n",
      "Epoch 336 Batch 30 Loss 0.0389 Accuracy 5.1247\n",
      "Epoch 336 Batch 35 Loss 0.0389 Accuracy 5.1246\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1270\n",
      "Epoch 337 Batch 5 Loss 0.0389 Accuracy 5.1245\n",
      "Epoch 337 Batch 10 Loss 0.0389 Accuracy 5.1244\n",
      "Epoch 337 Batch 15 Loss 0.0389 Accuracy 5.1243\n",
      "Epoch 337 Batch 20 Loss 0.0389 Accuracy 5.1242\n",
      "Epoch 337 Batch 25 Loss 0.0389 Accuracy 5.1241\n",
      "Epoch 337 Batch 30 Loss 0.0389 Accuracy 5.1240\n",
      "Epoch 337 Batch 35 Loss 0.0389 Accuracy 5.1239\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1263\n",
      "Epoch 338 Batch 5 Loss 0.0389 Accuracy 5.1238\n",
      "Epoch 338 Batch 10 Loss 0.0389 Accuracy 5.1237\n",
      "Epoch 338 Batch 15 Loss 0.0389 Accuracy 5.1236\n",
      "Epoch 338 Batch 20 Loss 0.0389 Accuracy 5.1235\n",
      "Epoch 338 Batch 25 Loss 0.0389 Accuracy 5.1234\n",
      "Epoch 338 Batch 30 Loss 0.0389 Accuracy 5.1233\n",
      "Epoch 338 Batch 35 Loss 0.0388 Accuracy 5.1233\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1256\n",
      "Epoch 339 Batch 5 Loss 0.0388 Accuracy 5.1231\n",
      "Epoch 339 Batch 10 Loss 0.0388 Accuracy 5.1230\n",
      "Epoch 339 Batch 15 Loss 0.0388 Accuracy 5.1229\n",
      "Epoch 339 Batch 20 Loss 0.0388 Accuracy 5.1228\n",
      "Epoch 339 Batch 25 Loss 0.0388 Accuracy 5.1228\n",
      "Epoch 339 Batch 30 Loss 0.0388 Accuracy 5.1227\n",
      "Epoch 339 Batch 35 Loss 0.0388 Accuracy 5.1226\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1249\n",
      "Epoch 340 Batch 5 Loss 0.0388 Accuracy 5.1224\n",
      "Epoch 340 Batch 10 Loss 0.0388 Accuracy 5.1223\n",
      "Epoch 340 Batch 15 Loss 0.0388 Accuracy 5.1222\n",
      "Epoch 340 Batch 20 Loss 0.0388 Accuracy 5.1221\n",
      "Epoch 340 Batch 25 Loss 0.0388 Accuracy 5.1221\n",
      "Epoch 340 Batch 30 Loss 0.0388 Accuracy 5.1220\n",
      "Epoch 340 Batch 35 Loss 0.0388 Accuracy 5.1219\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1242\n",
      "Epoch 341 Batch 5 Loss 0.0388 Accuracy 5.1217\n",
      "Epoch 341 Batch 10 Loss 0.0388 Accuracy 5.1216\n",
      "Epoch 341 Batch 15 Loss 0.0388 Accuracy 5.1216\n",
      "Epoch 341 Batch 20 Loss 0.0388 Accuracy 5.1215\n",
      "Epoch 341 Batch 25 Loss 0.0388 Accuracy 5.1214\n",
      "Epoch 341 Batch 30 Loss 0.0388 Accuracy 5.1213\n",
      "Epoch 341 Batch 35 Loss 0.0388 Accuracy 5.1212\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1235\n",
      "Epoch 342 Batch 5 Loss 0.0388 Accuracy 5.1210\n",
      "Epoch 342 Batch 10 Loss 0.0388 Accuracy 5.1210\n",
      "Epoch 342 Batch 15 Loss 0.0388 Accuracy 5.1209\n",
      "Epoch 342 Batch 20 Loss 0.0388 Accuracy 5.1208\n",
      "Epoch 342 Batch 25 Loss 0.0388 Accuracy 5.1207\n",
      "Epoch 342 Batch 30 Loss 0.0388 Accuracy 5.1206\n",
      "Epoch 342 Batch 35 Loss 0.0388 Accuracy 5.1205\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1228\n",
      "Epoch 343 Batch 5 Loss 0.0388 Accuracy 5.1204\n",
      "Epoch 343 Batch 10 Loss 0.0388 Accuracy 5.1203\n",
      "Epoch 343 Batch 15 Loss 0.0388 Accuracy 5.1202\n",
      "Epoch 343 Batch 20 Loss 0.0388 Accuracy 5.1201\n",
      "Epoch 343 Batch 25 Loss 0.0388 Accuracy 5.1200\n",
      "Epoch 343 Batch 30 Loss 0.0388 Accuracy 5.1199\n",
      "Epoch 343 Batch 35 Loss 0.0388 Accuracy 5.1198\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1221\n",
      "Epoch 344 Batch 5 Loss 0.0388 Accuracy 5.1197\n",
      "Epoch 344 Batch 10 Loss 0.0388 Accuracy 5.1196\n",
      "Epoch 344 Batch 15 Loss 0.0388 Accuracy 5.1195\n",
      "Epoch 344 Batch 20 Loss 0.0388 Accuracy 5.1194\n",
      "Epoch 344 Batch 25 Loss 0.0388 Accuracy 5.1193\n",
      "Epoch 344 Batch 30 Loss 0.0388 Accuracy 5.1192\n",
      "Epoch 344 Batch 35 Loss 0.0388 Accuracy 5.1191\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1214\n",
      "Epoch 345 Batch 5 Loss 0.0388 Accuracy 5.1190\n",
      "Epoch 345 Batch 10 Loss 0.0388 Accuracy 5.1189\n",
      "Epoch 345 Batch 15 Loss 0.0388 Accuracy 5.1188\n",
      "Epoch 345 Batch 20 Loss 0.0388 Accuracy 5.1187\n",
      "Epoch 345 Batch 25 Loss 0.0388 Accuracy 5.1186\n",
      "Epoch 345 Batch 30 Loss 0.0388 Accuracy 5.1185\n",
      "Epoch 345 Batch 35 Loss 0.0388 Accuracy 5.1184\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1208\n",
      "Epoch 346 Batch 5 Loss 0.0388 Accuracy 5.1183\n",
      "Epoch 346 Batch 10 Loss 0.0388 Accuracy 5.1182\n",
      "Epoch 346 Batch 15 Loss 0.0388 Accuracy 5.1181\n",
      "Epoch 346 Batch 20 Loss 0.0388 Accuracy 5.1180\n",
      "Epoch 346 Batch 25 Loss 0.0388 Accuracy 5.1179\n",
      "Epoch 346 Batch 30 Loss 0.0388 Accuracy 5.1178\n",
      "Epoch 346 Batch 35 Loss 0.0388 Accuracy 5.1177\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1201\n",
      "Epoch 347 Batch 5 Loss 0.0388 Accuracy 5.1176\n",
      "Epoch 347 Batch 10 Loss 0.0388 Accuracy 5.1175\n",
      "Epoch 347 Batch 15 Loss 0.0388 Accuracy 5.1174\n",
      "Epoch 347 Batch 20 Loss 0.0388 Accuracy 5.1173\n",
      "Epoch 347 Batch 25 Loss 0.0388 Accuracy 5.1173\n",
      "Epoch 347 Batch 30 Loss 0.0388 Accuracy 5.1172\n",
      "Epoch 347 Batch 35 Loss 0.0387 Accuracy 5.1171\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1194\n",
      "Epoch 348 Batch 5 Loss 0.0387 Accuracy 5.1169\n",
      "Epoch 348 Batch 10 Loss 0.0387 Accuracy 5.1168\n",
      "Epoch 348 Batch 15 Loss 0.0387 Accuracy 5.1167\n",
      "Epoch 348 Batch 20 Loss 0.0387 Accuracy 5.1166\n",
      "Epoch 348 Batch 25 Loss 0.0387 Accuracy 5.1166\n",
      "Epoch 348 Batch 30 Loss 0.0387 Accuracy 5.1165\n",
      "Epoch 348 Batch 35 Loss 0.0387 Accuracy 5.1164\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1187\n",
      "Epoch 349 Batch 5 Loss 0.0387 Accuracy 5.1162\n",
      "Epoch 349 Batch 10 Loss 0.0387 Accuracy 5.1161\n",
      "Epoch 349 Batch 15 Loss 0.0387 Accuracy 5.1160\n",
      "Epoch 349 Batch 20 Loss 0.0387 Accuracy 5.1160\n",
      "Epoch 349 Batch 25 Loss 0.0387 Accuracy 5.1159\n",
      "Epoch 349 Batch 30 Loss 0.0387 Accuracy 5.1158\n",
      "Epoch 349 Batch 35 Loss 0.0387 Accuracy 5.1157\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1180\n",
      "Epoch 350 Batch 5 Loss 0.0387 Accuracy 5.1155\n",
      "Epoch 350 Batch 10 Loss 0.0387 Accuracy 5.1155\n",
      "Epoch 350 Batch 15 Loss 0.0387 Accuracy 5.1154\n",
      "Epoch 350 Batch 20 Loss 0.0387 Accuracy 5.1153\n",
      "Epoch 350 Batch 25 Loss 0.0387 Accuracy 5.1152\n",
      "Epoch 350 Batch 30 Loss 0.0387 Accuracy 5.1151\n",
      "Epoch 350 Batch 35 Loss 0.0387 Accuracy 5.1150\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1173\n",
      "Epoch 351 Batch 5 Loss 0.0387 Accuracy 5.1149\n",
      "Epoch 351 Batch 10 Loss 0.0387 Accuracy 5.1148\n",
      "Epoch 351 Batch 15 Loss 0.0387 Accuracy 5.1147\n",
      "Epoch 351 Batch 20 Loss 0.0387 Accuracy 5.1146\n",
      "Epoch 351 Batch 25 Loss 0.0387 Accuracy 5.1145\n",
      "Epoch 351 Batch 30 Loss 0.0387 Accuracy 5.1144\n",
      "Epoch 351 Batch 35 Loss 0.0387 Accuracy 5.1143\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1166\n",
      "Epoch 352 Batch 5 Loss 0.0387 Accuracy 5.1142\n",
      "Epoch 352 Batch 10 Loss 0.0387 Accuracy 5.1141\n",
      "Epoch 352 Batch 15 Loss 0.0387 Accuracy 5.1140\n",
      "Epoch 352 Batch 20 Loss 0.0387 Accuracy 5.1139\n",
      "Epoch 352 Batch 25 Loss 0.0387 Accuracy 5.1138\n",
      "Epoch 352 Batch 30 Loss 0.0387 Accuracy 5.1137\n",
      "Epoch 352 Batch 35 Loss 0.0387 Accuracy 5.1136\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1159\n",
      "Epoch 353 Batch 5 Loss 0.0387 Accuracy 5.1135\n",
      "Epoch 353 Batch 10 Loss 0.0387 Accuracy 5.1134\n",
      "Epoch 353 Batch 15 Loss 0.0387 Accuracy 5.1133\n",
      "Epoch 353 Batch 20 Loss 0.0387 Accuracy 5.1132\n",
      "Epoch 353 Batch 25 Loss 0.0387 Accuracy 5.1131\n",
      "Epoch 353 Batch 30 Loss 0.0387 Accuracy 5.1130\n",
      "Epoch 353 Batch 35 Loss 0.0387 Accuracy 5.1129\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1152\n",
      "Epoch 354 Batch 5 Loss 0.0387 Accuracy 5.1128\n",
      "Epoch 354 Batch 10 Loss 0.0387 Accuracy 5.1127\n",
      "Epoch 354 Batch 15 Loss 0.0387 Accuracy 5.1126\n",
      "Epoch 354 Batch 20 Loss 0.0387 Accuracy 5.1125\n",
      "Epoch 354 Batch 25 Loss 0.0387 Accuracy 5.1124\n",
      "Epoch 354 Batch 30 Loss 0.0387 Accuracy 5.1123\n",
      "Epoch 354 Batch 35 Loss 0.0387 Accuracy 5.1122\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1145\n",
      "Epoch 355 Batch 5 Loss 0.0387 Accuracy 5.1121\n",
      "Epoch 355 Batch 10 Loss 0.0387 Accuracy 5.1120\n",
      "Epoch 355 Batch 15 Loss 0.0387 Accuracy 5.1119\n",
      "Epoch 355 Batch 20 Loss 0.0387 Accuracy 5.1118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355 Batch 25 Loss 0.0387 Accuracy 5.1117\n",
      "Epoch 355 Batch 30 Loss 0.0387 Accuracy 5.1116\n",
      "Epoch 355 Batch 35 Loss 0.0387 Accuracy 5.1115\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1138\n",
      "Epoch 356 Batch 5 Loss 0.0387 Accuracy 5.1114\n",
      "Epoch 356 Batch 10 Loss 0.0387 Accuracy 5.1113\n",
      "Epoch 356 Batch 15 Loss 0.0387 Accuracy 5.1112\n",
      "Epoch 356 Batch 20 Loss 0.0387 Accuracy 5.1111\n",
      "Epoch 356 Batch 25 Loss 0.0387 Accuracy 5.1110\n",
      "Epoch 356 Batch 30 Loss 0.0387 Accuracy 5.1109\n",
      "Epoch 356 Batch 35 Loss 0.0387 Accuracy 5.1108\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1131\n",
      "Epoch 357 Batch 5 Loss 0.0386 Accuracy 5.1107\n",
      "Epoch 357 Batch 10 Loss 0.0386 Accuracy 5.1106\n",
      "Epoch 357 Batch 15 Loss 0.0386 Accuracy 5.1105\n",
      "Epoch 357 Batch 20 Loss 0.0386 Accuracy 5.1104\n",
      "Epoch 357 Batch 25 Loss 0.0386 Accuracy 5.1103\n",
      "Epoch 357 Batch 30 Loss 0.0386 Accuracy 5.1102\n",
      "Epoch 357 Batch 35 Loss 0.0386 Accuracy 5.1101\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1124\n",
      "Epoch 358 Batch 5 Loss 0.0386 Accuracy 5.1100\n",
      "Epoch 358 Batch 10 Loss 0.0386 Accuracy 5.1099\n",
      "Epoch 358 Batch 15 Loss 0.0386 Accuracy 5.1098\n",
      "Epoch 358 Batch 20 Loss 0.0386 Accuracy 5.1097\n",
      "Epoch 358 Batch 25 Loss 0.0386 Accuracy 5.1097\n",
      "Epoch 358 Batch 30 Loss 0.0386 Accuracy 5.1096\n",
      "Epoch 358 Batch 35 Loss 0.0386 Accuracy 5.1095\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1117\n",
      "Epoch 359 Batch 5 Loss 0.0386 Accuracy 5.1093\n",
      "Epoch 359 Batch 10 Loss 0.0386 Accuracy 5.1092\n",
      "Epoch 359 Batch 15 Loss 0.0386 Accuracy 5.1092\n",
      "Epoch 359 Batch 20 Loss 0.0386 Accuracy 5.1091\n",
      "Epoch 359 Batch 25 Loss 0.0386 Accuracy 5.1090\n",
      "Epoch 359 Batch 30 Loss 0.0386 Accuracy 5.1089\n",
      "Epoch 359 Batch 35 Loss 0.0386 Accuracy 5.1088\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1110\n",
      "Epoch 360 Batch 5 Loss 0.0386 Accuracy 5.1087\n",
      "Epoch 360 Batch 10 Loss 0.0386 Accuracy 5.1086\n",
      "Epoch 360 Batch 15 Loss 0.0386 Accuracy 5.1085\n",
      "Epoch 360 Batch 20 Loss 0.0386 Accuracy 5.1084\n",
      "Epoch 360 Batch 25 Loss 0.0386 Accuracy 5.1083\n",
      "Epoch 360 Batch 30 Loss 0.0386 Accuracy 5.1082\n",
      "Epoch 360 Batch 35 Loss 0.0386 Accuracy 5.1081\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1103\n",
      "Epoch 361 Batch 5 Loss 0.0386 Accuracy 5.1080\n",
      "Epoch 361 Batch 10 Loss 0.0386 Accuracy 5.1079\n",
      "Epoch 361 Batch 15 Loss 0.0386 Accuracy 5.1078\n",
      "Epoch 361 Batch 20 Loss 0.0386 Accuracy 5.1077\n",
      "Epoch 361 Batch 25 Loss 0.0386 Accuracy 5.1076\n",
      "Epoch 361 Batch 30 Loss 0.0386 Accuracy 5.1075\n",
      "Epoch 361 Batch 35 Loss 0.0386 Accuracy 5.1074\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1096\n",
      "Epoch 362 Batch 5 Loss 0.0386 Accuracy 5.1073\n",
      "Epoch 362 Batch 10 Loss 0.0386 Accuracy 5.1072\n",
      "Epoch 362 Batch 15 Loss 0.0386 Accuracy 5.1071\n",
      "Epoch 362 Batch 20 Loss 0.0386 Accuracy 5.1070\n",
      "Epoch 362 Batch 25 Loss 0.0386 Accuracy 5.1069\n",
      "Epoch 362 Batch 30 Loss 0.0386 Accuracy 5.1068\n",
      "Epoch 362 Batch 35 Loss 0.0386 Accuracy 5.1067\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1089\n",
      "Epoch 363 Batch 5 Loss 0.0386 Accuracy 5.1066\n",
      "Epoch 363 Batch 10 Loss 0.0386 Accuracy 5.1065\n",
      "Epoch 363 Batch 15 Loss 0.0386 Accuracy 5.1064\n",
      "Epoch 363 Batch 20 Loss 0.0386 Accuracy 5.1063\n",
      "Epoch 363 Batch 25 Loss 0.0385 Accuracy 5.1062\n",
      "Epoch 363 Batch 30 Loss 0.0385 Accuracy 5.1061\n",
      "Epoch 363 Batch 35 Loss 0.0385 Accuracy 5.1060\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1082\n",
      "Epoch 364 Batch 5 Loss 0.0385 Accuracy 5.1059\n",
      "Epoch 364 Batch 10 Loss 0.0385 Accuracy 5.1058\n",
      "Epoch 364 Batch 15 Loss 0.0385 Accuracy 5.1057\n",
      "Epoch 364 Batch 20 Loss 0.0385 Accuracy 5.1056\n",
      "Epoch 364 Batch 25 Loss 0.0385 Accuracy 5.1055\n",
      "Epoch 364 Batch 30 Loss 0.0385 Accuracy 5.1054\n",
      "Epoch 364 Batch 35 Loss 0.0385 Accuracy 5.1053\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1075\n",
      "Epoch 365 Batch 5 Loss 0.0385 Accuracy 5.1052\n",
      "Epoch 365 Batch 10 Loss 0.0385 Accuracy 5.1051\n",
      "Epoch 365 Batch 15 Loss 0.0385 Accuracy 5.1050\n",
      "Epoch 365 Batch 20 Loss 0.0385 Accuracy 5.1049\n",
      "Epoch 365 Batch 25 Loss 0.0385 Accuracy 5.1048\n",
      "Epoch 365 Batch 30 Loss 0.0385 Accuracy 5.1047\n",
      "Epoch 365 Batch 35 Loss 0.0385 Accuracy 5.1046\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1068\n",
      "Epoch 366 Batch 5 Loss 0.0385 Accuracy 5.1045\n",
      "Epoch 366 Batch 10 Loss 0.0385 Accuracy 5.1044\n",
      "Epoch 366 Batch 15 Loss 0.0385 Accuracy 5.1043\n",
      "Epoch 366 Batch 20 Loss 0.0385 Accuracy 5.1042\n",
      "Epoch 366 Batch 25 Loss 0.0385 Accuracy 5.1041\n",
      "Epoch 366 Batch 30 Loss 0.0385 Accuracy 5.1040\n",
      "Epoch 366 Batch 35 Loss 0.0385 Accuracy 5.1039\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1061\n",
      "Epoch 367 Batch 5 Loss 0.0385 Accuracy 5.1038\n",
      "Epoch 367 Batch 10 Loss 0.0385 Accuracy 5.1037\n",
      "Epoch 367 Batch 15 Loss 0.0385 Accuracy 5.1036\n",
      "Epoch 367 Batch 20 Loss 0.0385 Accuracy 5.1035\n",
      "Epoch 367 Batch 25 Loss 0.0385 Accuracy 5.1034\n",
      "Epoch 367 Batch 30 Loss 0.0385 Accuracy 5.1034\n",
      "Epoch 367 Batch 35 Loss 0.0385 Accuracy 5.1033\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1054\n",
      "Epoch 368 Batch 5 Loss 0.0385 Accuracy 5.1031\n",
      "Epoch 368 Batch 10 Loss 0.0385 Accuracy 5.1030\n",
      "Epoch 368 Batch 15 Loss 0.0385 Accuracy 5.1029\n",
      "Epoch 368 Batch 20 Loss 0.0385 Accuracy 5.1028\n",
      "Epoch 368 Batch 25 Loss 0.0385 Accuracy 5.1028\n",
      "Epoch 368 Batch 30 Loss 0.0385 Accuracy 5.1027\n",
      "Epoch 368 Batch 35 Loss 0.0385 Accuracy 5.1026\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1047\n",
      "Epoch 369 Batch 5 Loss 0.0385 Accuracy 5.1024\n",
      "Epoch 369 Batch 10 Loss 0.0385 Accuracy 5.1023\n",
      "Epoch 369 Batch 15 Loss 0.0385 Accuracy 5.1022\n",
      "Epoch 369 Batch 20 Loss 0.0385 Accuracy 5.1022\n",
      "Epoch 369 Batch 25 Loss 0.0385 Accuracy 5.1021\n",
      "Epoch 369 Batch 30 Loss 0.0385 Accuracy 5.1020\n",
      "Epoch 369 Batch 35 Loss 0.0385 Accuracy 5.1019\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1040\n",
      "Epoch 370 Batch 5 Loss 0.0385 Accuracy 5.1017\n",
      "Epoch 370 Batch 10 Loss 0.0385 Accuracy 5.1016\n",
      "Epoch 370 Batch 15 Loss 0.0385 Accuracy 5.1016\n",
      "Epoch 370 Batch 20 Loss 0.0385 Accuracy 5.1015\n",
      "Epoch 370 Batch 25 Loss 0.0385 Accuracy 5.1014\n",
      "Epoch 370 Batch 30 Loss 0.0384 Accuracy 5.1013\n",
      "Epoch 370 Batch 35 Loss 0.0384 Accuracy 5.1012\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1033\n",
      "Epoch 371 Batch 5 Loss 0.0384 Accuracy 5.1010\n",
      "Epoch 371 Batch 10 Loss 0.0384 Accuracy 5.1009\n",
      "Epoch 371 Batch 15 Loss 0.0384 Accuracy 5.1009\n",
      "Epoch 371 Batch 20 Loss 0.0384 Accuracy 5.1008\n",
      "Epoch 371 Batch 25 Loss 0.0384 Accuracy 5.1007\n",
      "Epoch 371 Batch 30 Loss 0.0384 Accuracy 5.1006\n",
      "Epoch 371 Batch 35 Loss 0.0384 Accuracy 5.1005\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1026\n",
      "Epoch 372 Batch 5 Loss 0.0384 Accuracy 5.1003\n",
      "Epoch 372 Batch 10 Loss 0.0384 Accuracy 5.1003\n",
      "Epoch 372 Batch 15 Loss 0.0384 Accuracy 5.1002\n",
      "Epoch 372 Batch 20 Loss 0.0384 Accuracy 5.1001\n",
      "Epoch 372 Batch 25 Loss 0.0384 Accuracy 5.1000\n",
      "Epoch 372 Batch 30 Loss 0.0384 Accuracy 5.0999\n",
      "Epoch 372 Batch 35 Loss 0.0384 Accuracy 5.0998\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1019\n",
      "Epoch 373 Batch 5 Loss 0.0384 Accuracy 5.0997\n",
      "Epoch 373 Batch 10 Loss 0.0384 Accuracy 5.0996\n",
      "Epoch 373 Batch 15 Loss 0.0384 Accuracy 5.0995\n",
      "Epoch 373 Batch 20 Loss 0.0384 Accuracy 5.0994\n",
      "Epoch 373 Batch 25 Loss 0.0384 Accuracy 5.0993\n",
      "Epoch 373 Batch 30 Loss 0.0384 Accuracy 5.0992\n",
      "Epoch 373 Batch 35 Loss 0.0384 Accuracy 5.0991\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1012\n",
      "Epoch 374 Batch 5 Loss 0.0384 Accuracy 5.0990\n",
      "Epoch 374 Batch 10 Loss 0.0384 Accuracy 5.0989\n",
      "Epoch 374 Batch 15 Loss 0.0384 Accuracy 5.0988\n",
      "Epoch 374 Batch 20 Loss 0.0384 Accuracy 5.0987\n",
      "Epoch 374 Batch 25 Loss 0.0384 Accuracy 5.0986\n",
      "Epoch 374 Batch 30 Loss 0.0384 Accuracy 5.0985\n",
      "Epoch 374 Batch 35 Loss 0.0384 Accuracy 5.0984\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.1005\n",
      "Epoch 375 Batch 5 Loss 0.0384 Accuracy 5.0983\n",
      "Epoch 375 Batch 10 Loss 0.0384 Accuracy 5.0982\n",
      "Epoch 375 Batch 15 Loss 0.0384 Accuracy 5.0981\n",
      "Epoch 375 Batch 20 Loss 0.0384 Accuracy 5.0980\n",
      "Epoch 375 Batch 25 Loss 0.0384 Accuracy 5.0979\n",
      "Epoch 375 Batch 30 Loss 0.0384 Accuracy 5.0978\n",
      "Epoch 375 Batch 35 Loss 0.0384 Accuracy 5.0977\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0998\n",
      "Epoch 376 Batch 5 Loss 0.0384 Accuracy 5.0976\n",
      "Epoch 376 Batch 10 Loss 0.0384 Accuracy 5.0975\n",
      "Epoch 376 Batch 15 Loss 0.0384 Accuracy 5.0974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376 Batch 20 Loss 0.0384 Accuracy 5.0973\n",
      "Epoch 376 Batch 25 Loss 0.0384 Accuracy 5.0972\n",
      "Epoch 376 Batch 30 Loss 0.0384 Accuracy 5.0971\n",
      "Epoch 376 Batch 35 Loss 0.0384 Accuracy 5.0970\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0991\n",
      "Epoch 377 Batch 5 Loss 0.0384 Accuracy 5.0969\n",
      "Epoch 377 Batch 10 Loss 0.0384 Accuracy 5.0968\n",
      "Epoch 377 Batch 15 Loss 0.0384 Accuracy 5.0967\n",
      "Epoch 377 Batch 20 Loss 0.0384 Accuracy 5.0966\n",
      "Epoch 377 Batch 25 Loss 0.0384 Accuracy 5.0965\n",
      "Epoch 377 Batch 30 Loss 0.0384 Accuracy 5.0964\n",
      "Epoch 377 Batch 35 Loss 0.0384 Accuracy 5.0963\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0984\n",
      "Epoch 378 Batch 5 Loss 0.0384 Accuracy 5.0962\n",
      "Epoch 378 Batch 10 Loss 0.0383 Accuracy 5.0961\n",
      "Epoch 378 Batch 15 Loss 0.0383 Accuracy 5.0960\n",
      "Epoch 378 Batch 20 Loss 0.0383 Accuracy 5.0959\n",
      "Epoch 378 Batch 25 Loss 0.0383 Accuracy 5.0958\n",
      "Epoch 378 Batch 30 Loss 0.0383 Accuracy 5.0957\n",
      "Epoch 378 Batch 35 Loss 0.0383 Accuracy 5.0956\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0977\n",
      "Epoch 379 Batch 5 Loss 0.0383 Accuracy 5.0955\n",
      "Epoch 379 Batch 10 Loss 0.0383 Accuracy 5.0954\n",
      "Epoch 379 Batch 15 Loss 0.0383 Accuracy 5.0953\n",
      "Epoch 379 Batch 20 Loss 0.0383 Accuracy 5.0952\n",
      "Epoch 379 Batch 25 Loss 0.0383 Accuracy 5.0951\n",
      "Epoch 379 Batch 30 Loss 0.0383 Accuracy 5.0950\n",
      "Epoch 379 Batch 35 Loss 0.0383 Accuracy 5.0949\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0970\n",
      "Epoch 380 Batch 5 Loss 0.0383 Accuracy 5.0948\n",
      "Epoch 380 Batch 10 Loss 0.0383 Accuracy 5.0947\n",
      "Epoch 380 Batch 15 Loss 0.0383 Accuracy 5.0946\n",
      "Epoch 380 Batch 20 Loss 0.0383 Accuracy 5.0945\n",
      "Epoch 380 Batch 25 Loss 0.0383 Accuracy 5.0944\n",
      "Epoch 380 Batch 30 Loss 0.0383 Accuracy 5.0943\n",
      "Epoch 380 Batch 35 Loss 0.0383 Accuracy 5.0942\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0963\n",
      "Epoch 381 Batch 5 Loss 0.0383 Accuracy 5.0941\n",
      "Epoch 381 Batch 10 Loss 0.0383 Accuracy 5.0940\n",
      "Epoch 381 Batch 15 Loss 0.0383 Accuracy 5.0939\n",
      "Epoch 381 Batch 20 Loss 0.0383 Accuracy 5.0938\n",
      "Epoch 381 Batch 25 Loss 0.0383 Accuracy 5.0937\n",
      "Epoch 381 Batch 30 Loss 0.0383 Accuracy 5.0936\n",
      "Epoch 381 Batch 35 Loss 0.0383 Accuracy 5.0935\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0956\n",
      "Epoch 382 Batch 5 Loss 0.0383 Accuracy 5.0934\n",
      "Epoch 382 Batch 10 Loss 0.0383 Accuracy 5.0933\n",
      "Epoch 382 Batch 15 Loss 0.0383 Accuracy 5.0932\n",
      "Epoch 382 Batch 20 Loss 0.0383 Accuracy 5.0931\n",
      "Epoch 382 Batch 25 Loss 0.0383 Accuracy 5.0930\n",
      "Epoch 382 Batch 30 Loss 0.0383 Accuracy 5.0929\n",
      "Epoch 382 Batch 35 Loss 0.0383 Accuracy 5.0928\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0949\n",
      "Epoch 383 Batch 5 Loss 0.0383 Accuracy 5.0927\n",
      "Epoch 383 Batch 10 Loss 0.0383 Accuracy 5.0926\n",
      "Epoch 383 Batch 15 Loss 0.0383 Accuracy 5.0925\n",
      "Epoch 383 Batch 20 Loss 0.0383 Accuracy 5.0924\n",
      "Epoch 383 Batch 25 Loss 0.0383 Accuracy 5.0923\n",
      "Epoch 383 Batch 30 Loss 0.0383 Accuracy 5.0922\n",
      "Epoch 383 Batch 35 Loss 0.0383 Accuracy 5.0921\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0942\n",
      "Epoch 384 Batch 5 Loss 0.0383 Accuracy 5.0920\n",
      "Epoch 384 Batch 10 Loss 0.0383 Accuracy 5.0919\n",
      "Epoch 384 Batch 15 Loss 0.0383 Accuracy 5.0918\n",
      "Epoch 384 Batch 20 Loss 0.0382 Accuracy 5.0917\n",
      "Epoch 384 Batch 25 Loss 0.0382 Accuracy 5.0916\n",
      "Epoch 384 Batch 30 Loss 0.0382 Accuracy 5.0915\n",
      "Epoch 384 Batch 35 Loss 0.0382 Accuracy 5.0914\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0935\n",
      "Epoch 385 Batch 5 Loss 0.0382 Accuracy 5.0913\n",
      "Epoch 385 Batch 10 Loss 0.0382 Accuracy 5.0912\n",
      "Epoch 385 Batch 15 Loss 0.0382 Accuracy 5.0911\n",
      "Epoch 385 Batch 20 Loss 0.0382 Accuracy 5.0910\n",
      "Epoch 385 Batch 25 Loss 0.0382 Accuracy 5.0909\n",
      "Epoch 385 Batch 30 Loss 0.0382 Accuracy 5.0908\n",
      "Epoch 385 Batch 35 Loss 0.0382 Accuracy 5.0907\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0928\n",
      "Epoch 386 Batch 5 Loss 0.0382 Accuracy 5.0906\n",
      "Epoch 386 Batch 10 Loss 0.0382 Accuracy 5.0905\n",
      "Epoch 386 Batch 15 Loss 0.0382 Accuracy 5.0904\n",
      "Epoch 386 Batch 20 Loss 0.0382 Accuracy 5.0903\n",
      "Epoch 386 Batch 25 Loss 0.0382 Accuracy 5.0902\n",
      "Epoch 386 Batch 30 Loss 0.0382 Accuracy 5.0901\n",
      "Epoch 386 Batch 35 Loss 0.0382 Accuracy 5.0900\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0920\n",
      "Epoch 387 Batch 5 Loss 0.0382 Accuracy 5.0899\n",
      "Epoch 387 Batch 10 Loss 0.0382 Accuracy 5.0898\n",
      "Epoch 387 Batch 15 Loss 0.0382 Accuracy 5.0897\n",
      "Epoch 387 Batch 20 Loss 0.0382 Accuracy 5.0896\n",
      "Epoch 387 Batch 25 Loss 0.0382 Accuracy 5.0895\n",
      "Epoch 387 Batch 30 Loss 0.0382 Accuracy 5.0894\n",
      "Epoch 387 Batch 35 Loss 0.0382 Accuracy 5.0893\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0913\n",
      "Epoch 388 Batch 5 Loss 0.0382 Accuracy 5.0892\n",
      "Epoch 388 Batch 10 Loss 0.0382 Accuracy 5.0891\n",
      "Epoch 388 Batch 15 Loss 0.0382 Accuracy 5.0890\n",
      "Epoch 388 Batch 20 Loss 0.0382 Accuracy 5.0889\n",
      "Epoch 388 Batch 25 Loss 0.0382 Accuracy 5.0888\n",
      "Epoch 388 Batch 30 Loss 0.0382 Accuracy 5.0887\n",
      "Epoch 388 Batch 35 Loss 0.0382 Accuracy 5.0886\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0906\n",
      "Epoch 389 Batch 5 Loss 0.0382 Accuracy 5.0885\n",
      "Epoch 389 Batch 10 Loss 0.0382 Accuracy 5.0884\n",
      "Epoch 389 Batch 15 Loss 0.0382 Accuracy 5.0883\n",
      "Epoch 389 Batch 20 Loss 0.0382 Accuracy 5.0882\n",
      "Epoch 389 Batch 25 Loss 0.0382 Accuracy 5.0881\n",
      "Epoch 389 Batch 30 Loss 0.0382 Accuracy 5.0880\n",
      "Epoch 389 Batch 35 Loss 0.0382 Accuracy 5.0879\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0899\n",
      "Epoch 390 Batch 5 Loss 0.0381 Accuracy 5.0877\n",
      "Epoch 390 Batch 10 Loss 0.0381 Accuracy 5.0876\n",
      "Epoch 390 Batch 15 Loss 0.0381 Accuracy 5.0876\n",
      "Epoch 390 Batch 20 Loss 0.0381 Accuracy 5.0875\n",
      "Epoch 390 Batch 25 Loss 0.0381 Accuracy 5.0874\n",
      "Epoch 390 Batch 30 Loss 0.0381 Accuracy 5.0873\n",
      "Epoch 390 Batch 35 Loss 0.0381 Accuracy 5.0872\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0892\n",
      "Epoch 391 Batch 5 Loss 0.0381 Accuracy 5.0870\n",
      "Epoch 391 Batch 10 Loss 0.0381 Accuracy 5.0869\n",
      "Epoch 391 Batch 15 Loss 0.0381 Accuracy 5.0868\n",
      "Epoch 391 Batch 20 Loss 0.0381 Accuracy 5.0868\n",
      "Epoch 391 Batch 25 Loss 0.0381 Accuracy 5.0867\n",
      "Epoch 391 Batch 30 Loss 0.0381 Accuracy 5.0866\n",
      "Epoch 391 Batch 35 Loss 0.0381 Accuracy 5.0865\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0885\n",
      "Epoch 392 Batch 5 Loss 0.0381 Accuracy 5.0863\n",
      "Epoch 392 Batch 10 Loss 0.0381 Accuracy 5.0862\n",
      "Epoch 392 Batch 15 Loss 0.0381 Accuracy 5.0861\n",
      "Epoch 392 Batch 20 Loss 0.0381 Accuracy 5.0860\n",
      "Epoch 392 Batch 25 Loss 0.0381 Accuracy 5.0859\n",
      "Epoch 392 Batch 30 Loss 0.0381 Accuracy 5.0858\n",
      "Epoch 392 Batch 35 Loss 0.0381 Accuracy 5.0857\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0877\n",
      "Epoch 393 Batch 5 Loss 0.0381 Accuracy 5.0856\n",
      "Epoch 393 Batch 10 Loss 0.0381 Accuracy 5.0855\n",
      "Epoch 393 Batch 15 Loss 0.0381 Accuracy 5.0854\n",
      "Epoch 393 Batch 20 Loss 0.0381 Accuracy 5.0853\n",
      "Epoch 393 Batch 25 Loss 0.0381 Accuracy 5.0852\n",
      "Epoch 393 Batch 30 Loss 0.0381 Accuracy 5.0851\n",
      "Epoch 393 Batch 35 Loss 0.0381 Accuracy 5.0850\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0870\n",
      "Epoch 394 Batch 5 Loss 0.0381 Accuracy 5.0849\n",
      "Epoch 394 Batch 10 Loss 0.0381 Accuracy 5.0848\n",
      "Epoch 394 Batch 15 Loss 0.0381 Accuracy 5.0847\n",
      "Epoch 394 Batch 20 Loss 0.0381 Accuracy 5.0846\n",
      "Epoch 394 Batch 25 Loss 0.0381 Accuracy 5.0845\n",
      "Epoch 394 Batch 30 Loss 0.0381 Accuracy 5.0844\n",
      "Epoch 394 Batch 35 Loss 0.0381 Accuracy 5.0843\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0863\n",
      "Epoch 395 Batch 5 Loss 0.0381 Accuracy 5.0842\n",
      "Epoch 395 Batch 10 Loss 0.0381 Accuracy 5.0841\n",
      "Epoch 395 Batch 15 Loss 0.0381 Accuracy 5.0840\n",
      "Epoch 395 Batch 20 Loss 0.0381 Accuracy 5.0839\n",
      "Epoch 395 Batch 25 Loss 0.0381 Accuracy 5.0838\n",
      "Epoch 395 Batch 30 Loss 0.0381 Accuracy 5.0837\n",
      "Epoch 395 Batch 35 Loss 0.0381 Accuracy 5.0836\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0856\n",
      "Epoch 396 Batch 5 Loss 0.0380 Accuracy 5.0835\n",
      "Epoch 396 Batch 10 Loss 0.0380 Accuracy 5.0834\n",
      "Epoch 396 Batch 15 Loss 0.0380 Accuracy 5.0833\n",
      "Epoch 396 Batch 20 Loss 0.0380 Accuracy 5.0832\n",
      "Epoch 396 Batch 25 Loss 0.0380 Accuracy 5.0831\n",
      "Epoch 396 Batch 30 Loss 0.0380 Accuracy 5.0830\n",
      "Epoch 396 Batch 35 Loss 0.0380 Accuracy 5.0829\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0849\n",
      "Epoch 397 Batch 5 Loss 0.0380 Accuracy 5.0827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397 Batch 10 Loss 0.0380 Accuracy 5.0826\n",
      "Epoch 397 Batch 15 Loss 0.0380 Accuracy 5.0825\n",
      "Epoch 397 Batch 20 Loss 0.0380 Accuracy 5.0824\n",
      "Epoch 397 Batch 25 Loss 0.0380 Accuracy 5.0823\n",
      "Epoch 397 Batch 30 Loss 0.0380 Accuracy 5.0823\n",
      "Epoch 397 Batch 35 Loss 0.0380 Accuracy 5.0822\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0841\n",
      "Epoch 398 Batch 5 Loss 0.0380 Accuracy 5.0820\n",
      "Epoch 398 Batch 10 Loss 0.0380 Accuracy 5.0819\n",
      "Epoch 398 Batch 15 Loss 0.0380 Accuracy 5.0818\n",
      "Epoch 398 Batch 20 Loss 0.0380 Accuracy 5.0817\n",
      "Epoch 398 Batch 25 Loss 0.0380 Accuracy 5.0816\n",
      "Epoch 398 Batch 30 Loss 0.0380 Accuracy 5.0815\n",
      "Epoch 398 Batch 35 Loss 0.0380 Accuracy 5.0814\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0834\n",
      "Epoch 399 Batch 5 Loss 0.0380 Accuracy 5.0813\n",
      "Epoch 399 Batch 10 Loss 0.0380 Accuracy 5.0812\n",
      "Epoch 399 Batch 15 Loss 0.0380 Accuracy 5.0811\n",
      "Epoch 399 Batch 20 Loss 0.0380 Accuracy 5.0810\n",
      "Epoch 399 Batch 25 Loss 0.0380 Accuracy 5.0809\n",
      "Epoch 399 Batch 30 Loss 0.0380 Accuracy 5.0808\n",
      "Epoch 399 Batch 35 Loss 0.0380 Accuracy 5.0807\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0827\n",
      "Epoch 400 Batch 5 Loss 0.0380 Accuracy 5.0806\n",
      "Epoch 400 Batch 10 Loss 0.0380 Accuracy 5.0805\n",
      "Epoch 400 Batch 15 Loss 0.0380 Accuracy 5.0804\n",
      "Epoch 400 Batch 20 Loss 0.0380 Accuracy 5.0803\n",
      "Epoch 400 Batch 25 Loss 0.0380 Accuracy 5.0802\n",
      "Epoch 400 Batch 30 Loss 0.0380 Accuracy 5.0801\n",
      "Epoch 400 Batch 35 Loss 0.0380 Accuracy 5.0800\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0819\n",
      "Epoch 401 Batch 5 Loss 0.0380 Accuracy 5.0798\n",
      "Epoch 401 Batch 10 Loss 0.0380 Accuracy 5.0797\n",
      "Epoch 401 Batch 15 Loss 0.0380 Accuracy 5.0796\n",
      "Epoch 401 Batch 20 Loss 0.0379 Accuracy 5.0796\n",
      "Epoch 401 Batch 25 Loss 0.0379 Accuracy 5.0795\n",
      "Epoch 401 Batch 30 Loss 0.0379 Accuracy 5.0794\n",
      "Epoch 401 Batch 35 Loss 0.0379 Accuracy 5.0793\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0812\n",
      "Epoch 402 Batch 5 Loss 0.0379 Accuracy 5.0791\n",
      "Epoch 402 Batch 10 Loss 0.0379 Accuracy 5.0790\n",
      "Epoch 402 Batch 15 Loss 0.0379 Accuracy 5.0789\n",
      "Epoch 402 Batch 20 Loss 0.0379 Accuracy 5.0788\n",
      "Epoch 402 Batch 25 Loss 0.0379 Accuracy 5.0787\n",
      "Epoch 402 Batch 30 Loss 0.0379 Accuracy 5.0786\n",
      "Epoch 402 Batch 35 Loss 0.0379 Accuracy 5.0785\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0805\n",
      "Epoch 403 Batch 5 Loss 0.0379 Accuracy 5.0784\n",
      "Epoch 403 Batch 10 Loss 0.0379 Accuracy 5.0783\n",
      "Epoch 403 Batch 15 Loss 0.0379 Accuracy 5.0782\n",
      "Epoch 403 Batch 20 Loss 0.0379 Accuracy 5.0781\n",
      "Epoch 403 Batch 25 Loss 0.0379 Accuracy 5.0780\n",
      "Epoch 403 Batch 30 Loss 0.0379 Accuracy 5.0779\n",
      "Epoch 403 Batch 35 Loss 0.0379 Accuracy 5.0778\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0797\n",
      "Epoch 404 Batch 5 Loss 0.0379 Accuracy 5.0777\n",
      "Epoch 404 Batch 10 Loss 0.0379 Accuracy 5.0776\n",
      "Epoch 404 Batch 15 Loss 0.0379 Accuracy 5.0775\n",
      "Epoch 404 Batch 20 Loss 0.0379 Accuracy 5.0774\n",
      "Epoch 404 Batch 25 Loss 0.0379 Accuracy 5.0773\n",
      "Epoch 404 Batch 30 Loss 0.0379 Accuracy 5.0772\n",
      "Epoch 404 Batch 35 Loss 0.0379 Accuracy 5.0771\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0790\n",
      "Epoch 405 Batch 5 Loss 0.0379 Accuracy 5.0769\n",
      "Epoch 405 Batch 10 Loss 0.0379 Accuracy 5.0768\n",
      "Epoch 405 Batch 15 Loss 0.0379 Accuracy 5.0768\n",
      "Epoch 405 Batch 20 Loss 0.0379 Accuracy 5.0767\n",
      "Epoch 405 Batch 25 Loss 0.0379 Accuracy 5.0766\n",
      "Epoch 405 Batch 30 Loss 0.0379 Accuracy 5.0765\n",
      "Epoch 405 Batch 35 Loss 0.0379 Accuracy 5.0764\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0783\n",
      "Epoch 406 Batch 5 Loss 0.0379 Accuracy 5.0762\n",
      "Epoch 406 Batch 10 Loss 0.0379 Accuracy 5.0761\n",
      "Epoch 406 Batch 15 Loss 0.0379 Accuracy 5.0760\n",
      "Epoch 406 Batch 20 Loss 0.0379 Accuracy 5.0759\n",
      "Epoch 406 Batch 25 Loss 0.0379 Accuracy 5.0758\n",
      "Epoch 406 Batch 30 Loss 0.0379 Accuracy 5.0757\n",
      "Epoch 406 Batch 35 Loss 0.0379 Accuracy 5.0756\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0775\n",
      "Epoch 407 Batch 5 Loss 0.0379 Accuracy 5.0755\n",
      "Epoch 407 Batch 10 Loss 0.0379 Accuracy 5.0754\n",
      "Epoch 407 Batch 15 Loss 0.0379 Accuracy 5.0753\n",
      "Epoch 407 Batch 20 Loss 0.0379 Accuracy 5.0752\n",
      "Epoch 407 Batch 25 Loss 0.0379 Accuracy 5.0751\n",
      "Epoch 407 Batch 30 Loss 0.0379 Accuracy 5.0750\n",
      "Epoch 407 Batch 35 Loss 0.0379 Accuracy 5.0749\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0768\n",
      "Epoch 408 Batch 5 Loss 0.0379 Accuracy 5.0748\n",
      "Epoch 408 Batch 10 Loss 0.0379 Accuracy 5.0747\n",
      "Epoch 408 Batch 15 Loss 0.0379 Accuracy 5.0746\n",
      "Epoch 408 Batch 20 Loss 0.0379 Accuracy 5.0745\n",
      "Epoch 408 Batch 25 Loss 0.0379 Accuracy 5.0744\n",
      "Epoch 408 Batch 30 Loss 0.0379 Accuracy 5.0743\n",
      "Epoch 408 Batch 35 Loss 0.0379 Accuracy 5.0742\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0761\n",
      "Epoch 409 Batch 5 Loss 0.0379 Accuracy 5.0740\n",
      "Epoch 409 Batch 10 Loss 0.0379 Accuracy 5.0740\n",
      "Epoch 409 Batch 15 Loss 0.0379 Accuracy 5.0739\n",
      "Epoch 409 Batch 20 Loss 0.0379 Accuracy 5.0738\n",
      "Epoch 409 Batch 25 Loss 0.0379 Accuracy 5.0737\n",
      "Epoch 409 Batch 30 Loss 0.0378 Accuracy 5.0736\n",
      "Epoch 409 Batch 35 Loss 0.0378 Accuracy 5.0735\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0754\n",
      "Epoch 410 Batch 5 Loss 0.0378 Accuracy 5.0733\n",
      "Epoch 410 Batch 10 Loss 0.0378 Accuracy 5.0732\n",
      "Epoch 410 Batch 15 Loss 0.0378 Accuracy 5.0731\n",
      "Epoch 410 Batch 20 Loss 0.0378 Accuracy 5.0730\n",
      "Epoch 410 Batch 25 Loss 0.0378 Accuracy 5.0729\n",
      "Epoch 410 Batch 30 Loss 0.0378 Accuracy 5.0728\n",
      "Epoch 410 Batch 35 Loss 0.0378 Accuracy 5.0727\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0746\n",
      "Epoch 411 Batch 5 Loss 0.0378 Accuracy 5.0726\n",
      "Epoch 411 Batch 10 Loss 0.0378 Accuracy 5.0725\n",
      "Epoch 411 Batch 15 Loss 0.0378 Accuracy 5.0724\n",
      "Epoch 411 Batch 20 Loss 0.0378 Accuracy 5.0723\n",
      "Epoch 411 Batch 25 Loss 0.0378 Accuracy 5.0722\n",
      "Epoch 411 Batch 30 Loss 0.0378 Accuracy 5.0721\n",
      "Epoch 411 Batch 35 Loss 0.0378 Accuracy 5.0720\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0739\n",
      "Epoch 412 Batch 5 Loss 0.0378 Accuracy 5.0719\n",
      "Epoch 412 Batch 10 Loss 0.0378 Accuracy 5.0718\n",
      "Epoch 412 Batch 15 Loss 0.0378 Accuracy 5.0717\n",
      "Epoch 412 Batch 20 Loss 0.0378 Accuracy 5.0716\n",
      "Epoch 412 Batch 25 Loss 0.0378 Accuracy 5.0715\n",
      "Epoch 412 Batch 30 Loss 0.0378 Accuracy 5.0714\n",
      "Epoch 412 Batch 35 Loss 0.0378 Accuracy 5.0713\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0732\n",
      "Epoch 413 Batch 5 Loss 0.0378 Accuracy 5.0711\n",
      "Epoch 413 Batch 10 Loss 0.0378 Accuracy 5.0710\n",
      "Epoch 413 Batch 15 Loss 0.0378 Accuracy 5.0709\n",
      "Epoch 413 Batch 20 Loss 0.0378 Accuracy 5.0709\n",
      "Epoch 413 Batch 25 Loss 0.0378 Accuracy 5.0708\n",
      "Epoch 413 Batch 30 Loss 0.0378 Accuracy 5.0707\n",
      "Epoch 413 Batch 35 Loss 0.0378 Accuracy 5.0706\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0724\n",
      "Epoch 414 Batch 5 Loss 0.0378 Accuracy 5.0704\n",
      "Epoch 414 Batch 10 Loss 0.0378 Accuracy 5.0703\n",
      "Epoch 414 Batch 15 Loss 0.0378 Accuracy 5.0702\n",
      "Epoch 414 Batch 20 Loss 0.0378 Accuracy 5.0701\n",
      "Epoch 414 Batch 25 Loss 0.0378 Accuracy 5.0700\n",
      "Epoch 414 Batch 30 Loss 0.0378 Accuracy 5.0699\n",
      "Epoch 414 Batch 35 Loss 0.0378 Accuracy 5.0698\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0717\n",
      "Epoch 415 Batch 5 Loss 0.0378 Accuracy 5.0697\n",
      "Epoch 415 Batch 10 Loss 0.0378 Accuracy 5.0696\n",
      "Epoch 415 Batch 15 Loss 0.0378 Accuracy 5.0695\n",
      "Epoch 415 Batch 20 Loss 0.0378 Accuracy 5.0694\n",
      "Epoch 415 Batch 25 Loss 0.0378 Accuracy 5.0693\n",
      "Epoch 415 Batch 30 Loss 0.0378 Accuracy 5.0692\n",
      "Epoch 415 Batch 35 Loss 0.0378 Accuracy 5.0691\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0710\n",
      "Epoch 416 Batch 5 Loss 0.0378 Accuracy 5.0690\n",
      "Epoch 416 Batch 10 Loss 0.0378 Accuracy 5.0689\n",
      "Epoch 416 Batch 15 Loss 0.0378 Accuracy 5.0688\n",
      "Epoch 416 Batch 20 Loss 0.0378 Accuracy 5.0687\n",
      "Epoch 416 Batch 25 Loss 0.0378 Accuracy 5.0686\n",
      "Epoch 416 Batch 30 Loss 0.0378 Accuracy 5.0685\n",
      "Epoch 416 Batch 35 Loss 0.0378 Accuracy 5.0684\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0703\n",
      "Epoch 417 Batch 5 Loss 0.0378 Accuracy 5.0683\n",
      "Epoch 417 Batch 10 Loss 0.0378 Accuracy 5.0682\n",
      "Epoch 417 Batch 15 Loss 0.0378 Accuracy 5.0681\n",
      "Epoch 417 Batch 20 Loss 0.0378 Accuracy 5.0680\n",
      "Epoch 417 Batch 25 Loss 0.0378 Accuracy 5.0679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417 Batch 30 Loss 0.0378 Accuracy 5.0678\n",
      "Epoch 417 Batch 35 Loss 0.0378 Accuracy 5.0677\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0696\n",
      "Epoch 418 Batch 5 Loss 0.0378 Accuracy 5.0676\n",
      "Epoch 418 Batch 10 Loss 0.0378 Accuracy 5.0675\n",
      "Epoch 418 Batch 15 Loss 0.0378 Accuracy 5.0674\n",
      "Epoch 418 Batch 20 Loss 0.0378 Accuracy 5.0673\n",
      "Epoch 418 Batch 25 Loss 0.0378 Accuracy 5.0672\n",
      "Epoch 418 Batch 30 Loss 0.0378 Accuracy 5.0671\n",
      "Epoch 418 Batch 35 Loss 0.0378 Accuracy 5.0670\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0688\n",
      "Epoch 419 Batch 5 Loss 0.0378 Accuracy 5.0669\n",
      "Epoch 419 Batch 10 Loss 0.0378 Accuracy 5.0668\n",
      "Epoch 419 Batch 15 Loss 0.0378 Accuracy 5.0667\n",
      "Epoch 419 Batch 20 Loss 0.0378 Accuracy 5.0666\n",
      "Epoch 419 Batch 25 Loss 0.0378 Accuracy 5.0665\n",
      "Epoch 419 Batch 30 Loss 0.0378 Accuracy 5.0664\n",
      "Epoch 419 Batch 35 Loss 0.0378 Accuracy 5.0663\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0681\n",
      "Epoch 420 Batch 5 Loss 0.0378 Accuracy 5.0662\n",
      "Epoch 420 Batch 10 Loss 0.0378 Accuracy 5.0661\n",
      "Epoch 420 Batch 15 Loss 0.0378 Accuracy 5.0660\n",
      "Epoch 420 Batch 20 Loss 0.0378 Accuracy 5.0659\n",
      "Epoch 420 Batch 25 Loss 0.0378 Accuracy 5.0658\n",
      "Epoch 420 Batch 30 Loss 0.0378 Accuracy 5.0657\n",
      "Epoch 420 Batch 35 Loss 0.0378 Accuracy 5.0656\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0674\n",
      "Epoch 421 Batch 5 Loss 0.0378 Accuracy 5.0655\n",
      "Epoch 421 Batch 10 Loss 0.0378 Accuracy 5.0654\n",
      "Epoch 421 Batch 15 Loss 0.0378 Accuracy 5.0653\n",
      "Epoch 421 Batch 20 Loss 0.0378 Accuracy 5.0652\n",
      "Epoch 421 Batch 25 Loss 0.0378 Accuracy 5.0651\n",
      "Epoch 421 Batch 30 Loss 0.0378 Accuracy 5.0650\n",
      "Epoch 421 Batch 35 Loss 0.0378 Accuracy 5.0649\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0667\n",
      "Epoch 422 Batch 5 Loss 0.0378 Accuracy 5.0648\n",
      "Epoch 422 Batch 10 Loss 0.0378 Accuracy 5.0647\n",
      "Epoch 422 Batch 15 Loss 0.0378 Accuracy 5.0646\n",
      "Epoch 422 Batch 20 Loss 0.0378 Accuracy 5.0645\n",
      "Epoch 422 Batch 25 Loss 0.0378 Accuracy 5.0644\n",
      "Epoch 422 Batch 30 Loss 0.0378 Accuracy 5.0643\n",
      "Epoch 422 Batch 35 Loss 0.0378 Accuracy 5.0642\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0660\n",
      "Epoch 423 Batch 5 Loss 0.0378 Accuracy 5.0641\n",
      "Epoch 423 Batch 10 Loss 0.0378 Accuracy 5.0640\n",
      "Epoch 423 Batch 15 Loss 0.0378 Accuracy 5.0639\n",
      "Epoch 423 Batch 20 Loss 0.0378 Accuracy 5.0638\n",
      "Epoch 423 Batch 25 Loss 0.0378 Accuracy 5.0637\n",
      "Epoch 423 Batch 30 Loss 0.0378 Accuracy 5.0636\n",
      "Epoch 423 Batch 35 Loss 0.0378 Accuracy 5.0635\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0653\n",
      "Epoch 424 Batch 5 Loss 0.0378 Accuracy 5.0634\n",
      "Epoch 424 Batch 10 Loss 0.0378 Accuracy 5.0633\n",
      "Epoch 424 Batch 15 Loss 0.0378 Accuracy 5.0632\n",
      "Epoch 424 Batch 20 Loss 0.0378 Accuracy 5.0631\n",
      "Epoch 424 Batch 25 Loss 0.0378 Accuracy 5.0630\n",
      "Epoch 424 Batch 30 Loss 0.0377 Accuracy 5.0629\n",
      "Epoch 424 Batch 35 Loss 0.0377 Accuracy 5.0628\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0646\n",
      "Epoch 425 Batch 5 Loss 0.0377 Accuracy 5.0627\n",
      "Epoch 425 Batch 10 Loss 0.0377 Accuracy 5.0626\n",
      "Epoch 425 Batch 15 Loss 0.0377 Accuracy 5.0625\n",
      "Epoch 425 Batch 20 Loss 0.0377 Accuracy 5.0624\n",
      "Epoch 425 Batch 25 Loss 0.0377 Accuracy 5.0623\n",
      "Epoch 425 Batch 30 Loss 0.0377 Accuracy 5.0622\n",
      "Epoch 425 Batch 35 Loss 0.0377 Accuracy 5.0621\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0639\n",
      "Epoch 426 Batch 5 Loss 0.0377 Accuracy 5.0620\n",
      "Epoch 426 Batch 10 Loss 0.0377 Accuracy 5.0619\n",
      "Epoch 426 Batch 15 Loss 0.0377 Accuracy 5.0618\n",
      "Epoch 426 Batch 20 Loss 0.0377 Accuracy 5.0617\n",
      "Epoch 426 Batch 25 Loss 0.0377 Accuracy 5.0616\n",
      "Epoch 426 Batch 30 Loss 0.0377 Accuracy 5.0615\n",
      "Epoch 426 Batch 35 Loss 0.0377 Accuracy 5.0614\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0632\n",
      "Epoch 427 Batch 5 Loss 0.0377 Accuracy 5.0613\n",
      "Epoch 427 Batch 10 Loss 0.0377 Accuracy 5.0612\n",
      "Epoch 427 Batch 15 Loss 0.0377 Accuracy 5.0611\n",
      "Epoch 427 Batch 20 Loss 0.0377 Accuracy 5.0610\n",
      "Epoch 427 Batch 25 Loss 0.0377 Accuracy 5.0609\n",
      "Epoch 427 Batch 30 Loss 0.0377 Accuracy 5.0608\n",
      "Epoch 427 Batch 35 Loss 0.0377 Accuracy 5.0607\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0625\n",
      "Epoch 428 Batch 5 Loss 0.0377 Accuracy 5.0606\n",
      "Epoch 428 Batch 10 Loss 0.0377 Accuracy 5.0605\n",
      "Epoch 428 Batch 15 Loss 0.0377 Accuracy 5.0604\n",
      "Epoch 428 Batch 20 Loss 0.0377 Accuracy 5.0603\n",
      "Epoch 428 Batch 25 Loss 0.0377 Accuracy 5.0602\n",
      "Epoch 428 Batch 30 Loss 0.0377 Accuracy 5.0601\n",
      "Epoch 428 Batch 35 Loss 0.0377 Accuracy 5.0600\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0618\n",
      "Epoch 429 Batch 5 Loss 0.0377 Accuracy 5.0599\n",
      "Epoch 429 Batch 10 Loss 0.0377 Accuracy 5.0598\n",
      "Epoch 429 Batch 15 Loss 0.0377 Accuracy 5.0597\n",
      "Epoch 429 Batch 20 Loss 0.0377 Accuracy 5.0596\n",
      "Epoch 429 Batch 25 Loss 0.0377 Accuracy 5.0595\n",
      "Epoch 429 Batch 30 Loss 0.0377 Accuracy 5.0594\n",
      "Epoch 429 Batch 35 Loss 0.0377 Accuracy 5.0593\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0611\n",
      "Epoch 430 Batch 5 Loss 0.0377 Accuracy 5.0592\n",
      "Epoch 430 Batch 10 Loss 0.0377 Accuracy 5.0591\n",
      "Epoch 430 Batch 15 Loss 0.0377 Accuracy 5.0590\n",
      "Epoch 430 Batch 20 Loss 0.0377 Accuracy 5.0589\n",
      "Epoch 430 Batch 25 Loss 0.0377 Accuracy 5.0588\n",
      "Epoch 430 Batch 30 Loss 0.0377 Accuracy 5.0587\n",
      "Epoch 430 Batch 35 Loss 0.0377 Accuracy 5.0586\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0604\n",
      "Epoch 431 Batch 5 Loss 0.0377 Accuracy 5.0585\n",
      "Epoch 431 Batch 10 Loss 0.0377 Accuracy 5.0584\n",
      "Epoch 431 Batch 15 Loss 0.0377 Accuracy 5.0583\n",
      "Epoch 431 Batch 20 Loss 0.0377 Accuracy 5.0582\n",
      "Epoch 431 Batch 25 Loss 0.0377 Accuracy 5.0581\n",
      "Epoch 431 Batch 30 Loss 0.0377 Accuracy 5.0580\n",
      "Epoch 431 Batch 35 Loss 0.0377 Accuracy 5.0579\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0597\n",
      "Epoch 432 Batch 5 Loss 0.0377 Accuracy 5.0578\n",
      "Epoch 432 Batch 10 Loss 0.0377 Accuracy 5.0577\n",
      "Epoch 432 Batch 15 Loss 0.0377 Accuracy 5.0576\n",
      "Epoch 432 Batch 20 Loss 0.0377 Accuracy 5.0575\n",
      "Epoch 432 Batch 25 Loss 0.0377 Accuracy 5.0574\n",
      "Epoch 432 Batch 30 Loss 0.0377 Accuracy 5.0573\n",
      "Epoch 432 Batch 35 Loss 0.0377 Accuracy 5.0572\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0590\n",
      "Epoch 433 Batch 5 Loss 0.0377 Accuracy 5.0571\n",
      "Epoch 433 Batch 10 Loss 0.0377 Accuracy 5.0570\n",
      "Epoch 433 Batch 15 Loss 0.0377 Accuracy 5.0569\n",
      "Epoch 433 Batch 20 Loss 0.0377 Accuracy 5.0568\n",
      "Epoch 433 Batch 25 Loss 0.0377 Accuracy 5.0567\n",
      "Epoch 433 Batch 30 Loss 0.0377 Accuracy 5.0566\n",
      "Epoch 433 Batch 35 Loss 0.0377 Accuracy 5.0565\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0583\n",
      "Epoch 434 Batch 5 Loss 0.0377 Accuracy 5.0564\n",
      "Epoch 434 Batch 10 Loss 0.0377 Accuracy 5.0563\n",
      "Epoch 434 Batch 15 Loss 0.0377 Accuracy 5.0562\n",
      "Epoch 434 Batch 20 Loss 0.0376 Accuracy 5.0561\n",
      "Epoch 434 Batch 25 Loss 0.0376 Accuracy 5.0560\n",
      "Epoch 434 Batch 30 Loss 0.0376 Accuracy 5.0559\n",
      "Epoch 434 Batch 35 Loss 0.0376 Accuracy 5.0558\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0576\n",
      "Epoch 435 Batch 5 Loss 0.0376 Accuracy 5.0557\n",
      "Epoch 435 Batch 10 Loss 0.0376 Accuracy 5.0556\n",
      "Epoch 435 Batch 15 Loss 0.0376 Accuracy 5.0555\n",
      "Epoch 435 Batch 20 Loss 0.0376 Accuracy 5.0554\n",
      "Epoch 435 Batch 25 Loss 0.0376 Accuracy 5.0553\n",
      "Epoch 435 Batch 30 Loss 0.0376 Accuracy 5.0552\n",
      "Epoch 435 Batch 35 Loss 0.0376 Accuracy 5.0551\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0569\n",
      "Epoch 436 Batch 5 Loss 0.0376 Accuracy 5.0550\n",
      "Epoch 436 Batch 10 Loss 0.0376 Accuracy 5.0549\n",
      "Epoch 436 Batch 15 Loss 0.0376 Accuracy 5.0548\n",
      "Epoch 436 Batch 20 Loss 0.0376 Accuracy 5.0547\n",
      "Epoch 436 Batch 25 Loss 0.0376 Accuracy 5.0546\n",
      "Epoch 436 Batch 30 Loss 0.0376 Accuracy 5.0545\n",
      "Epoch 436 Batch 35 Loss 0.0376 Accuracy 5.0544\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0562\n",
      "Epoch 437 Batch 5 Loss 0.0376 Accuracy 5.0543\n",
      "Epoch 437 Batch 10 Loss 0.0376 Accuracy 5.0542\n",
      "Epoch 437 Batch 15 Loss 0.0376 Accuracy 5.0541\n",
      "Epoch 437 Batch 20 Loss 0.0376 Accuracy 5.0540\n",
      "Epoch 437 Batch 25 Loss 0.0376 Accuracy 5.0539\n",
      "Epoch 437 Batch 30 Loss 0.0376 Accuracy 5.0538\n",
      "Epoch 437 Batch 35 Loss 0.0376 Accuracy 5.0537\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0555\n",
      "Epoch 438 Batch 5 Loss 0.0376 Accuracy 5.0536\n",
      "Epoch 438 Batch 10 Loss 0.0376 Accuracy 5.0535\n",
      "Epoch 438 Batch 15 Loss 0.0376 Accuracy 5.0534\n",
      "Epoch 438 Batch 20 Loss 0.0376 Accuracy 5.0533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438 Batch 25 Loss 0.0376 Accuracy 5.0532\n",
      "Epoch 438 Batch 30 Loss 0.0376 Accuracy 5.0531\n",
      "Epoch 438 Batch 35 Loss 0.0376 Accuracy 5.0530\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0548\n",
      "Epoch 439 Batch 5 Loss 0.0376 Accuracy 5.0529\n",
      "Epoch 439 Batch 10 Loss 0.0376 Accuracy 5.0528\n",
      "Epoch 439 Batch 15 Loss 0.0376 Accuracy 5.0527\n",
      "Epoch 439 Batch 20 Loss 0.0376 Accuracy 5.0526\n",
      "Epoch 439 Batch 25 Loss 0.0376 Accuracy 5.0525\n",
      "Epoch 439 Batch 30 Loss 0.0376 Accuracy 5.0524\n",
      "Epoch 439 Batch 35 Loss 0.0376 Accuracy 5.0523\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0541\n",
      "Epoch 440 Batch 5 Loss 0.0376 Accuracy 5.0522\n",
      "Epoch 440 Batch 10 Loss 0.0376 Accuracy 5.0521\n",
      "Epoch 440 Batch 15 Loss 0.0376 Accuracy 5.0520\n",
      "Epoch 440 Batch 20 Loss 0.0376 Accuracy 5.0519\n",
      "Epoch 440 Batch 25 Loss 0.0376 Accuracy 5.0518\n",
      "Epoch 440 Batch 30 Loss 0.0376 Accuracy 5.0517\n",
      "Epoch 440 Batch 35 Loss 0.0376 Accuracy 5.0516\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0534\n",
      "Epoch 441 Batch 5 Loss 0.0376 Accuracy 5.0515\n",
      "Epoch 441 Batch 10 Loss 0.0376 Accuracy 5.0514\n",
      "Epoch 441 Batch 15 Loss 0.0376 Accuracy 5.0513\n",
      "Epoch 441 Batch 20 Loss 0.0376 Accuracy 5.0512\n",
      "Epoch 441 Batch 25 Loss 0.0376 Accuracy 5.0511\n",
      "Epoch 441 Batch 30 Loss 0.0376 Accuracy 5.0510\n",
      "Epoch 441 Batch 35 Loss 0.0376 Accuracy 5.0509\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0527\n",
      "Epoch 442 Batch 5 Loss 0.0376 Accuracy 5.0508\n",
      "Epoch 442 Batch 10 Loss 0.0376 Accuracy 5.0507\n",
      "Epoch 442 Batch 15 Loss 0.0376 Accuracy 5.0506\n",
      "Epoch 442 Batch 20 Loss 0.0376 Accuracy 5.0505\n",
      "Epoch 442 Batch 25 Loss 0.0376 Accuracy 5.0504\n",
      "Epoch 442 Batch 30 Loss 0.0376 Accuracy 5.0503\n",
      "Epoch 442 Batch 35 Loss 0.0376 Accuracy 5.0502\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0520\n",
      "Epoch 443 Batch 5 Loss 0.0376 Accuracy 5.0501\n",
      "Epoch 443 Batch 10 Loss 0.0376 Accuracy 5.0500\n",
      "Epoch 443 Batch 15 Loss 0.0376 Accuracy 5.0499\n",
      "Epoch 443 Batch 20 Loss 0.0376 Accuracy 5.0498\n",
      "Epoch 443 Batch 25 Loss 0.0376 Accuracy 5.0497\n",
      "Epoch 443 Batch 30 Loss 0.0376 Accuracy 5.0496\n",
      "Epoch 443 Batch 35 Loss 0.0376 Accuracy 5.0496\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0513\n",
      "Epoch 444 Batch 5 Loss 0.0376 Accuracy 5.0494\n",
      "Epoch 444 Batch 10 Loss 0.0376 Accuracy 5.0493\n",
      "Epoch 444 Batch 15 Loss 0.0375 Accuracy 5.0492\n",
      "Epoch 444 Batch 20 Loss 0.0375 Accuracy 5.0491\n",
      "Epoch 444 Batch 25 Loss 0.0375 Accuracy 5.0490\n",
      "Epoch 444 Batch 30 Loss 0.0375 Accuracy 5.0490\n",
      "Epoch 444 Batch 35 Loss 0.0375 Accuracy 5.0489\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0506\n",
      "Epoch 445 Batch 5 Loss 0.0375 Accuracy 5.0487\n",
      "Epoch 445 Batch 10 Loss 0.0375 Accuracy 5.0486\n",
      "Epoch 445 Batch 15 Loss 0.0375 Accuracy 5.0485\n",
      "Epoch 445 Batch 20 Loss 0.0375 Accuracy 5.0485\n",
      "Epoch 445 Batch 25 Loss 0.0375 Accuracy 5.0484\n",
      "Epoch 445 Batch 30 Loss 0.0375 Accuracy 5.0483\n",
      "Epoch 445 Batch 35 Loss 0.0375 Accuracy 5.0482\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0499\n",
      "Epoch 446 Batch 5 Loss 0.0375 Accuracy 5.0480\n",
      "Epoch 446 Batch 10 Loss 0.0375 Accuracy 5.0479\n",
      "Epoch 446 Batch 15 Loss 0.0375 Accuracy 5.0479\n",
      "Epoch 446 Batch 20 Loss 0.0375 Accuracy 5.0478\n",
      "Epoch 446 Batch 25 Loss 0.0375 Accuracy 5.0477\n",
      "Epoch 446 Batch 30 Loss 0.0375 Accuracy 5.0476\n",
      "Epoch 446 Batch 35 Loss 0.0375 Accuracy 5.0475\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0492\n",
      "Epoch 447 Batch 5 Loss 0.0375 Accuracy 5.0474\n",
      "Epoch 447 Batch 10 Loss 0.0375 Accuracy 5.0473\n",
      "Epoch 447 Batch 15 Loss 0.0375 Accuracy 5.0472\n",
      "Epoch 447 Batch 20 Loss 0.0375 Accuracy 5.0471\n",
      "Epoch 447 Batch 25 Loss 0.0375 Accuracy 5.0470\n",
      "Epoch 447 Batch 30 Loss 0.0375 Accuracy 5.0469\n",
      "Epoch 447 Batch 35 Loss 0.0375 Accuracy 5.0468\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0485\n",
      "Epoch 448 Batch 5 Loss 0.0375 Accuracy 5.0467\n",
      "Epoch 448 Batch 10 Loss 0.0375 Accuracy 5.0466\n",
      "Epoch 448 Batch 15 Loss 0.0375 Accuracy 5.0465\n",
      "Epoch 448 Batch 20 Loss 0.0375 Accuracy 5.0464\n",
      "Epoch 448 Batch 25 Loss 0.0375 Accuracy 5.0463\n",
      "Epoch 448 Batch 30 Loss 0.0375 Accuracy 5.0462\n",
      "Epoch 448 Batch 35 Loss 0.0375 Accuracy 5.0461\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0478\n",
      "Epoch 449 Batch 5 Loss 0.0375 Accuracy 5.0460\n",
      "Epoch 449 Batch 10 Loss 0.0375 Accuracy 5.0459\n",
      "Epoch 449 Batch 15 Loss 0.0375 Accuracy 5.0458\n",
      "Epoch 449 Batch 20 Loss 0.0375 Accuracy 5.0457\n",
      "Epoch 449 Batch 25 Loss 0.0375 Accuracy 5.0456\n",
      "Epoch 449 Batch 30 Loss 0.0375 Accuracy 5.0455\n",
      "Epoch 449 Batch 35 Loss 0.0375 Accuracy 5.0454\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0471\n",
      "Epoch 450 Batch 5 Loss 0.0375 Accuracy 5.0453\n",
      "Epoch 450 Batch 10 Loss 0.0375 Accuracy 5.0452\n",
      "Epoch 450 Batch 15 Loss 0.0375 Accuracy 5.0451\n",
      "Epoch 450 Batch 20 Loss 0.0375 Accuracy 5.0450\n",
      "Epoch 450 Batch 25 Loss 0.0375 Accuracy 5.0449\n",
      "Epoch 450 Batch 30 Loss 0.0375 Accuracy 5.0448\n",
      "Epoch 450 Batch 35 Loss 0.0375 Accuracy 5.0447\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0464\n",
      "Epoch 451 Batch 5 Loss 0.0375 Accuracy 5.0446\n",
      "Epoch 451 Batch 10 Loss 0.0375 Accuracy 5.0445\n",
      "Epoch 451 Batch 15 Loss 0.0375 Accuracy 5.0444\n",
      "Epoch 451 Batch 20 Loss 0.0375 Accuracy 5.0443\n",
      "Epoch 451 Batch 25 Loss 0.0375 Accuracy 5.0442\n",
      "Epoch 451 Batch 30 Loss 0.0375 Accuracy 5.0441\n",
      "Epoch 451 Batch 35 Loss 0.0375 Accuracy 5.0440\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0457\n",
      "Epoch 452 Batch 5 Loss 0.0374 Accuracy 5.0439\n",
      "Epoch 452 Batch 10 Loss 0.0374 Accuracy 5.0438\n",
      "Epoch 452 Batch 15 Loss 0.0374 Accuracy 5.0437\n",
      "Epoch 452 Batch 20 Loss 0.0374 Accuracy 5.0436\n",
      "Epoch 452 Batch 25 Loss 0.0374 Accuracy 5.0435\n",
      "Epoch 452 Batch 30 Loss 0.0374 Accuracy 5.0434\n",
      "Epoch 452 Batch 35 Loss 0.0374 Accuracy 5.0433\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0450\n",
      "Epoch 453 Batch 5 Loss 0.0374 Accuracy 5.0432\n",
      "Epoch 453 Batch 10 Loss 0.0374 Accuracy 5.0431\n",
      "Epoch 453 Batch 15 Loss 0.0374 Accuracy 5.0430\n",
      "Epoch 453 Batch 20 Loss 0.0374 Accuracy 5.0429\n",
      "Epoch 453 Batch 25 Loss 0.0374 Accuracy 5.0428\n",
      "Epoch 453 Batch 30 Loss 0.0374 Accuracy 5.0427\n",
      "Epoch 453 Batch 35 Loss 0.0374 Accuracy 5.0426\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0443\n",
      "Epoch 454 Batch 5 Loss 0.0374 Accuracy 5.0425\n",
      "Epoch 454 Batch 10 Loss 0.0374 Accuracy 5.0424\n",
      "Epoch 454 Batch 15 Loss 0.0374 Accuracy 5.0423\n",
      "Epoch 454 Batch 20 Loss 0.0374 Accuracy 5.0422\n",
      "Epoch 454 Batch 25 Loss 0.0374 Accuracy 5.0421\n",
      "Epoch 454 Batch 30 Loss 0.0374 Accuracy 5.0420\n",
      "Epoch 454 Batch 35 Loss 0.0374 Accuracy 5.0420\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0436\n",
      "Epoch 455 Batch 5 Loss 0.0374 Accuracy 5.0418\n",
      "Epoch 455 Batch 10 Loss 0.0374 Accuracy 5.0417\n",
      "Epoch 455 Batch 15 Loss 0.0374 Accuracy 5.0416\n",
      "Epoch 455 Batch 20 Loss 0.0374 Accuracy 5.0415\n",
      "Epoch 455 Batch 25 Loss 0.0374 Accuracy 5.0414\n",
      "Epoch 455 Batch 30 Loss 0.0374 Accuracy 5.0414\n",
      "Epoch 455 Batch 35 Loss 0.0374 Accuracy 5.0413\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0429\n",
      "Epoch 456 Batch 5 Loss 0.0374 Accuracy 5.0411\n",
      "Epoch 456 Batch 10 Loss 0.0374 Accuracy 5.0410\n",
      "Epoch 456 Batch 15 Loss 0.0374 Accuracy 5.0409\n",
      "Epoch 456 Batch 20 Loss 0.0374 Accuracy 5.0408\n",
      "Epoch 456 Batch 25 Loss 0.0374 Accuracy 5.0408\n",
      "Epoch 456 Batch 30 Loss 0.0374 Accuracy 5.0407\n",
      "Epoch 456 Batch 35 Loss 0.0374 Accuracy 5.0406\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0423\n",
      "Epoch 457 Batch 5 Loss 0.0374 Accuracy 5.0404\n",
      "Epoch 457 Batch 10 Loss 0.0374 Accuracy 5.0403\n",
      "Epoch 457 Batch 15 Loss 0.0374 Accuracy 5.0403\n",
      "Epoch 457 Batch 20 Loss 0.0374 Accuracy 5.0402\n",
      "Epoch 457 Batch 25 Loss 0.0374 Accuracy 5.0401\n",
      "Epoch 457 Batch 30 Loss 0.0374 Accuracy 5.0400\n",
      "Epoch 457 Batch 35 Loss 0.0374 Accuracy 5.0399\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0416\n",
      "Epoch 458 Batch 5 Loss 0.0374 Accuracy 5.0398\n",
      "Epoch 458 Batch 10 Loss 0.0374 Accuracy 5.0397\n",
      "Epoch 458 Batch 15 Loss 0.0374 Accuracy 5.0396\n",
      "Epoch 458 Batch 20 Loss 0.0374 Accuracy 5.0395\n",
      "Epoch 458 Batch 25 Loss 0.0374 Accuracy 5.0394\n",
      "Epoch 458 Batch 30 Loss 0.0374 Accuracy 5.0393\n",
      "Epoch 458 Batch 35 Loss 0.0374 Accuracy 5.0392\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0409\n",
      "Epoch 459 Batch 5 Loss 0.0374 Accuracy 5.0391\n",
      "Epoch 459 Batch 10 Loss 0.0374 Accuracy 5.0390\n",
      "Epoch 459 Batch 15 Loss 0.0374 Accuracy 5.0389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459 Batch 20 Loss 0.0374 Accuracy 5.0388\n",
      "Epoch 459 Batch 25 Loss 0.0374 Accuracy 5.0387\n",
      "Epoch 459 Batch 30 Loss 0.0374 Accuracy 5.0386\n",
      "Epoch 459 Batch 35 Loss 0.0374 Accuracy 5.0385\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0402\n",
      "Epoch 460 Batch 5 Loss 0.0374 Accuracy 5.0384\n",
      "Epoch 460 Batch 10 Loss 0.0374 Accuracy 5.0383\n",
      "Epoch 460 Batch 15 Loss 0.0374 Accuracy 5.0382\n",
      "Epoch 460 Batch 20 Loss 0.0374 Accuracy 5.0381\n",
      "Epoch 460 Batch 25 Loss 0.0374 Accuracy 5.0380\n",
      "Epoch 460 Batch 30 Loss 0.0374 Accuracy 5.0379\n",
      "Epoch 460 Batch 35 Loss 0.0374 Accuracy 5.0378\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0395\n",
      "Epoch 461 Batch 5 Loss 0.0374 Accuracy 5.0377\n",
      "Epoch 461 Batch 10 Loss 0.0374 Accuracy 5.0376\n",
      "Epoch 461 Batch 15 Loss 0.0374 Accuracy 5.0375\n",
      "Epoch 461 Batch 20 Loss 0.0374 Accuracy 5.0374\n",
      "Epoch 461 Batch 25 Loss 0.0374 Accuracy 5.0373\n",
      "Epoch 461 Batch 30 Loss 0.0374 Accuracy 5.0373\n",
      "Epoch 461 Batch 35 Loss 0.0374 Accuracy 5.0372\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0388\n",
      "Epoch 462 Batch 5 Loss 0.0374 Accuracy 5.0370\n",
      "Epoch 462 Batch 10 Loss 0.0374 Accuracy 5.0369\n",
      "Epoch 462 Batch 15 Loss 0.0374 Accuracy 5.0369\n",
      "Epoch 462 Batch 20 Loss 0.0374 Accuracy 5.0368\n",
      "Epoch 462 Batch 25 Loss 0.0374 Accuracy 5.0367\n",
      "Epoch 462 Batch 30 Loss 0.0374 Accuracy 5.0366\n",
      "Epoch 462 Batch 35 Loss 0.0374 Accuracy 5.0365\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0381\n",
      "Epoch 463 Batch 5 Loss 0.0374 Accuracy 5.0364\n",
      "Epoch 463 Batch 10 Loss 0.0374 Accuracy 5.0363\n",
      "Epoch 463 Batch 15 Loss 0.0374 Accuracy 5.0362\n",
      "Epoch 463 Batch 20 Loss 0.0374 Accuracy 5.0361\n",
      "Epoch 463 Batch 25 Loss 0.0374 Accuracy 5.0360\n",
      "Epoch 463 Batch 30 Loss 0.0374 Accuracy 5.0359\n",
      "Epoch 463 Batch 35 Loss 0.0374 Accuracy 5.0358\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0375\n",
      "Epoch 464 Batch 5 Loss 0.0374 Accuracy 5.0357\n",
      "Epoch 464 Batch 10 Loss 0.0374 Accuracy 5.0356\n",
      "Epoch 464 Batch 15 Loss 0.0374 Accuracy 5.0355\n",
      "Epoch 464 Batch 20 Loss 0.0374 Accuracy 5.0354\n",
      "Epoch 464 Batch 25 Loss 0.0374 Accuracy 5.0353\n",
      "Epoch 464 Batch 30 Loss 0.0374 Accuracy 5.0352\n",
      "Epoch 464 Batch 35 Loss 0.0374 Accuracy 5.0351\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0368\n",
      "Epoch 465 Batch 5 Loss 0.0374 Accuracy 5.0350\n",
      "Epoch 465 Batch 10 Loss 0.0374 Accuracy 5.0349\n",
      "Epoch 465 Batch 15 Loss 0.0374 Accuracy 5.0348\n",
      "Epoch 465 Batch 20 Loss 0.0374 Accuracy 5.0347\n",
      "Epoch 465 Batch 25 Loss 0.0374 Accuracy 5.0347\n",
      "Epoch 465 Batch 30 Loss 0.0374 Accuracy 5.0346\n",
      "Epoch 465 Batch 35 Loss 0.0373 Accuracy 5.0345\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0361\n",
      "Epoch 466 Batch 5 Loss 0.0373 Accuracy 5.0343\n",
      "Epoch 466 Batch 10 Loss 0.0373 Accuracy 5.0343\n",
      "Epoch 466 Batch 15 Loss 0.0373 Accuracy 5.0342\n",
      "Epoch 466 Batch 20 Loss 0.0373 Accuracy 5.0341\n",
      "Epoch 466 Batch 25 Loss 0.0373 Accuracy 5.0340\n",
      "Epoch 466 Batch 30 Loss 0.0373 Accuracy 5.0339\n",
      "Epoch 466 Batch 35 Loss 0.0373 Accuracy 5.0338\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0354\n",
      "Epoch 467 Batch 5 Loss 0.0373 Accuracy 5.0337\n",
      "Epoch 467 Batch 10 Loss 0.0373 Accuracy 5.0336\n",
      "Epoch 467 Batch 15 Loss 0.0373 Accuracy 5.0335\n",
      "Epoch 467 Batch 20 Loss 0.0373 Accuracy 5.0334\n",
      "Epoch 467 Batch 25 Loss 0.0373 Accuracy 5.0333\n",
      "Epoch 467 Batch 30 Loss 0.0373 Accuracy 5.0332\n",
      "Epoch 467 Batch 35 Loss 0.0373 Accuracy 5.0331\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0348\n",
      "Epoch 468 Batch 5 Loss 0.0373 Accuracy 5.0330\n",
      "Epoch 468 Batch 10 Loss 0.0373 Accuracy 5.0329\n",
      "Epoch 468 Batch 15 Loss 0.0373 Accuracy 5.0328\n",
      "Epoch 468 Batch 20 Loss 0.0373 Accuracy 5.0327\n",
      "Epoch 468 Batch 25 Loss 0.0373 Accuracy 5.0326\n",
      "Epoch 468 Batch 30 Loss 0.0373 Accuracy 5.0325\n",
      "Epoch 468 Batch 35 Loss 0.0373 Accuracy 5.0324\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0341\n",
      "Epoch 469 Batch 5 Loss 0.0373 Accuracy 5.0323\n",
      "Epoch 469 Batch 10 Loss 0.0373 Accuracy 5.0322\n",
      "Epoch 469 Batch 15 Loss 0.0373 Accuracy 5.0321\n",
      "Epoch 469 Batch 20 Loss 0.0373 Accuracy 5.0320\n",
      "Epoch 469 Batch 25 Loss 0.0373 Accuracy 5.0320\n",
      "Epoch 469 Batch 30 Loss 0.0373 Accuracy 5.0319\n",
      "Epoch 469 Batch 35 Loss 0.0373 Accuracy 5.0318\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0334\n",
      "Epoch 470 Batch 5 Loss 0.0373 Accuracy 5.0317\n",
      "Epoch 470 Batch 10 Loss 0.0373 Accuracy 5.0316\n",
      "Epoch 470 Batch 15 Loss 0.0373 Accuracy 5.0315\n",
      "Epoch 470 Batch 20 Loss 0.0373 Accuracy 5.0314\n",
      "Epoch 470 Batch 25 Loss 0.0373 Accuracy 5.0313\n",
      "Epoch 470 Batch 30 Loss 0.0373 Accuracy 5.0312\n",
      "Epoch 470 Batch 35 Loss 0.0373 Accuracy 5.0311\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0327\n",
      "Epoch 471 Batch 5 Loss 0.0373 Accuracy 5.0310\n",
      "Epoch 471 Batch 10 Loss 0.0373 Accuracy 5.0309\n",
      "Epoch 471 Batch 15 Loss 0.0373 Accuracy 5.0308\n",
      "Epoch 471 Batch 20 Loss 0.0373 Accuracy 5.0307\n",
      "Epoch 471 Batch 25 Loss 0.0373 Accuracy 5.0306\n",
      "Epoch 471 Batch 30 Loss 0.0373 Accuracy 5.0305\n",
      "Epoch 471 Batch 35 Loss 0.0373 Accuracy 5.0304\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0320\n",
      "Epoch 472 Batch 5 Loss 0.0373 Accuracy 5.0303\n",
      "Epoch 472 Batch 10 Loss 0.0373 Accuracy 5.0302\n",
      "Epoch 472 Batch 15 Loss 0.0373 Accuracy 5.0301\n",
      "Epoch 472 Batch 20 Loss 0.0373 Accuracy 5.0300\n",
      "Epoch 472 Batch 25 Loss 0.0373 Accuracy 5.0299\n",
      "Epoch 472 Batch 30 Loss 0.0373 Accuracy 5.0298\n",
      "Epoch 472 Batch 35 Loss 0.0373 Accuracy 5.0298\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0314\n",
      "Epoch 473 Batch 5 Loss 0.0373 Accuracy 5.0296\n",
      "Epoch 473 Batch 10 Loss 0.0372 Accuracy 5.0295\n",
      "Epoch 473 Batch 15 Loss 0.0372 Accuracy 5.0294\n",
      "Epoch 473 Batch 20 Loss 0.0372 Accuracy 5.0293\n",
      "Epoch 473 Batch 25 Loss 0.0372 Accuracy 5.0293\n",
      "Epoch 473 Batch 30 Loss 0.0372 Accuracy 5.0292\n",
      "Epoch 473 Batch 35 Loss 0.0372 Accuracy 5.0291\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0307\n",
      "Epoch 474 Batch 5 Loss 0.0372 Accuracy 5.0289\n",
      "Epoch 474 Batch 10 Loss 0.0372 Accuracy 5.0289\n",
      "Epoch 474 Batch 15 Loss 0.0372 Accuracy 5.0288\n",
      "Epoch 474 Batch 20 Loss 0.0372 Accuracy 5.0287\n",
      "Epoch 474 Batch 25 Loss 0.0372 Accuracy 5.0286\n",
      "Epoch 474 Batch 30 Loss 0.0372 Accuracy 5.0285\n",
      "Epoch 474 Batch 35 Loss 0.0372 Accuracy 5.0284\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0300\n",
      "Epoch 475 Batch 5 Loss 0.0372 Accuracy 5.0283\n",
      "Epoch 475 Batch 10 Loss 0.0372 Accuracy 5.0282\n",
      "Epoch 475 Batch 15 Loss 0.0372 Accuracy 5.0281\n",
      "Epoch 475 Batch 20 Loss 0.0372 Accuracy 5.0280\n",
      "Epoch 475 Batch 25 Loss 0.0372 Accuracy 5.0279\n",
      "Epoch 475 Batch 30 Loss 0.0372 Accuracy 5.0278\n",
      "Epoch 475 Batch 35 Loss 0.0372 Accuracy 5.0277\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0293\n",
      "Epoch 476 Batch 5 Loss 0.0372 Accuracy 5.0276\n",
      "Epoch 476 Batch 10 Loss 0.0372 Accuracy 5.0275\n",
      "Epoch 476 Batch 15 Loss 0.0372 Accuracy 5.0274\n",
      "Epoch 476 Batch 20 Loss 0.0372 Accuracy 5.0273\n",
      "Epoch 476 Batch 25 Loss 0.0372 Accuracy 5.0272\n",
      "Epoch 476 Batch 30 Loss 0.0372 Accuracy 5.0271\n",
      "Epoch 476 Batch 35 Loss 0.0372 Accuracy 5.0270\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0286\n",
      "Epoch 477 Batch 5 Loss 0.0372 Accuracy 5.0269\n",
      "Epoch 477 Batch 10 Loss 0.0372 Accuracy 5.0268\n",
      "Epoch 477 Batch 15 Loss 0.0372 Accuracy 5.0267\n",
      "Epoch 477 Batch 20 Loss 0.0372 Accuracy 5.0266\n",
      "Epoch 477 Batch 25 Loss 0.0372 Accuracy 5.0266\n",
      "Epoch 477 Batch 30 Loss 0.0372 Accuracy 5.0265\n",
      "Epoch 477 Batch 35 Loss 0.0372 Accuracy 5.0264\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0280\n",
      "Epoch 478 Batch 5 Loss 0.0372 Accuracy 5.0262\n",
      "Epoch 478 Batch 10 Loss 0.0372 Accuracy 5.0261\n",
      "Epoch 478 Batch 15 Loss 0.0372 Accuracy 5.0261\n",
      "Epoch 478 Batch 20 Loss 0.0372 Accuracy 5.0260\n",
      "Epoch 478 Batch 25 Loss 0.0372 Accuracy 5.0259\n",
      "Epoch 478 Batch 30 Loss 0.0372 Accuracy 5.0258\n",
      "Epoch 478 Batch 35 Loss 0.0372 Accuracy 5.0257\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0273\n",
      "Epoch 479 Batch 5 Loss 0.0372 Accuracy 5.0256\n",
      "Epoch 479 Batch 10 Loss 0.0372 Accuracy 5.0255\n",
      "Epoch 479 Batch 15 Loss 0.0372 Accuracy 5.0254\n",
      "Epoch 479 Batch 20 Loss 0.0372 Accuracy 5.0253\n",
      "Epoch 479 Batch 25 Loss 0.0372 Accuracy 5.0252\n",
      "Epoch 479 Batch 30 Loss 0.0372 Accuracy 5.0251\n",
      "Epoch 479 Batch 35 Loss 0.0372 Accuracy 5.0250\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0266\n",
      "Epoch 480 Batch 5 Loss 0.0372 Accuracy 5.0249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480 Batch 10 Loss 0.0372 Accuracy 5.0248\n",
      "Epoch 480 Batch 15 Loss 0.0372 Accuracy 5.0247\n",
      "Epoch 480 Batch 20 Loss 0.0372 Accuracy 5.0246\n",
      "Epoch 480 Batch 25 Loss 0.0372 Accuracy 5.0245\n",
      "Epoch 480 Batch 30 Loss 0.0372 Accuracy 5.0244\n",
      "Epoch 480 Batch 35 Loss 0.0371 Accuracy 5.0243\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0259\n",
      "Epoch 481 Batch 5 Loss 0.0371 Accuracy 5.0242\n",
      "Epoch 481 Batch 10 Loss 0.0371 Accuracy 5.0241\n",
      "Epoch 481 Batch 15 Loss 0.0371 Accuracy 5.0240\n",
      "Epoch 481 Batch 20 Loss 0.0371 Accuracy 5.0239\n",
      "Epoch 481 Batch 25 Loss 0.0371 Accuracy 5.0238\n",
      "Epoch 481 Batch 30 Loss 0.0371 Accuracy 5.0238\n",
      "Epoch 481 Batch 35 Loss 0.0371 Accuracy 5.0237\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0252\n",
      "Epoch 482 Batch 5 Loss 0.0371 Accuracy 5.0235\n",
      "Epoch 482 Batch 10 Loss 0.0371 Accuracy 5.0234\n",
      "Epoch 482 Batch 15 Loss 0.0371 Accuracy 5.0233\n",
      "Epoch 482 Batch 20 Loss 0.0371 Accuracy 5.0233\n",
      "Epoch 482 Batch 25 Loss 0.0371 Accuracy 5.0232\n",
      "Epoch 482 Batch 30 Loss 0.0371 Accuracy 5.0231\n",
      "Epoch 482 Batch 35 Loss 0.0371 Accuracy 5.0230\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0245\n",
      "Epoch 483 Batch 5 Loss 0.0371 Accuracy 5.0228\n",
      "Epoch 483 Batch 10 Loss 0.0371 Accuracy 5.0228\n",
      "Epoch 483 Batch 15 Loss 0.0371 Accuracy 5.0227\n",
      "Epoch 483 Batch 20 Loss 0.0371 Accuracy 5.0226\n",
      "Epoch 483 Batch 25 Loss 0.0371 Accuracy 5.0225\n",
      "Epoch 483 Batch 30 Loss 0.0371 Accuracy 5.0224\n",
      "Epoch 483 Batch 35 Loss 0.0371 Accuracy 5.0223\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0239\n",
      "Epoch 484 Batch 5 Loss 0.0371 Accuracy 5.0222\n",
      "Epoch 484 Batch 10 Loss 0.0371 Accuracy 5.0221\n",
      "Epoch 484 Batch 15 Loss 0.0371 Accuracy 5.0220\n",
      "Epoch 484 Batch 20 Loss 0.0371 Accuracy 5.0219\n",
      "Epoch 484 Batch 25 Loss 0.0371 Accuracy 5.0218\n",
      "Epoch 484 Batch 30 Loss 0.0371 Accuracy 5.0217\n",
      "Epoch 484 Batch 35 Loss 0.0371 Accuracy 5.0216\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0232\n",
      "Epoch 485 Batch 5 Loss 0.0371 Accuracy 5.0215\n",
      "Epoch 485 Batch 10 Loss 0.0371 Accuracy 5.0214\n",
      "Epoch 485 Batch 15 Loss 0.0371 Accuracy 5.0213\n",
      "Epoch 485 Batch 20 Loss 0.0371 Accuracy 5.0212\n",
      "Epoch 485 Batch 25 Loss 0.0371 Accuracy 5.0211\n",
      "Epoch 485 Batch 30 Loss 0.0371 Accuracy 5.0210\n",
      "Epoch 485 Batch 35 Loss 0.0371 Accuracy 5.0209\n",
      "Time taken for 1 epoch: 0.54 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0225\n",
      "Epoch 486 Batch 5 Loss 0.0371 Accuracy 5.0208\n",
      "Epoch 486 Batch 10 Loss 0.0371 Accuracy 5.0207\n",
      "Epoch 486 Batch 15 Loss 0.0371 Accuracy 5.0206\n",
      "Epoch 486 Batch 20 Loss 0.0371 Accuracy 5.0206\n",
      "Epoch 486 Batch 25 Loss 0.0371 Accuracy 5.0205\n",
      "Epoch 486 Batch 30 Loss 0.0371 Accuracy 5.0204\n",
      "Epoch 486 Batch 35 Loss 0.0371 Accuracy 5.0203\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0218\n",
      "Epoch 487 Batch 5 Loss 0.0371 Accuracy 5.0202\n",
      "Epoch 487 Batch 10 Loss 0.0371 Accuracy 5.0201\n",
      "Epoch 487 Batch 15 Loss 0.0371 Accuracy 5.0200\n",
      "Epoch 487 Batch 20 Loss 0.0371 Accuracy 5.0199\n",
      "Epoch 487 Batch 25 Loss 0.0371 Accuracy 5.0198\n",
      "Epoch 487 Batch 30 Loss 0.0371 Accuracy 5.0197\n",
      "Epoch 487 Batch 35 Loss 0.0371 Accuracy 5.0196\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0212\n",
      "Epoch 488 Batch 5 Loss 0.0371 Accuracy 5.0195\n",
      "Epoch 488 Batch 10 Loss 0.0371 Accuracy 5.0194\n",
      "Epoch 488 Batch 15 Loss 0.0371 Accuracy 5.0193\n",
      "Epoch 488 Batch 20 Loss 0.0371 Accuracy 5.0192\n",
      "Epoch 488 Batch 25 Loss 0.0371 Accuracy 5.0191\n",
      "Epoch 488 Batch 30 Loss 0.0371 Accuracy 5.0190\n",
      "Epoch 488 Batch 35 Loss 0.0371 Accuracy 5.0189\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0205\n",
      "Epoch 489 Batch 5 Loss 0.0371 Accuracy 5.0188\n",
      "Epoch 489 Batch 10 Loss 0.0371 Accuracy 5.0187\n",
      "Epoch 489 Batch 15 Loss 0.0371 Accuracy 5.0186\n",
      "Epoch 489 Batch 20 Loss 0.0371 Accuracy 5.0185\n",
      "Epoch 489 Batch 25 Loss 0.0371 Accuracy 5.0185\n",
      "Epoch 489 Batch 30 Loss 0.0371 Accuracy 5.0184\n",
      "Epoch 489 Batch 35 Loss 0.0371 Accuracy 5.0183\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0198\n",
      "Epoch 490 Batch 5 Loss 0.0371 Accuracy 5.0181\n",
      "Epoch 490 Batch 10 Loss 0.0371 Accuracy 5.0181\n",
      "Epoch 490 Batch 15 Loss 0.0371 Accuracy 5.0180\n",
      "Epoch 490 Batch 20 Loss 0.0371 Accuracy 5.0179\n",
      "Epoch 490 Batch 25 Loss 0.0371 Accuracy 5.0178\n",
      "Epoch 490 Batch 30 Loss 0.0371 Accuracy 5.0177\n",
      "Epoch 490 Batch 35 Loss 0.0371 Accuracy 5.0176\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0191\n",
      "Epoch 491 Batch 5 Loss 0.0371 Accuracy 5.0175\n",
      "Epoch 491 Batch 10 Loss 0.0371 Accuracy 5.0174\n",
      "Epoch 491 Batch 15 Loss 0.0371 Accuracy 5.0173\n",
      "Epoch 491 Batch 20 Loss 0.0371 Accuracy 5.0172\n",
      "Epoch 491 Batch 25 Loss 0.0371 Accuracy 5.0171\n",
      "Epoch 491 Batch 30 Loss 0.0371 Accuracy 5.0170\n",
      "Epoch 491 Batch 35 Loss 0.0370 Accuracy 5.0169\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0185\n",
      "Epoch 492 Batch 5 Loss 0.0370 Accuracy 5.0168\n",
      "Epoch 492 Batch 10 Loss 0.0370 Accuracy 5.0167\n",
      "Epoch 492 Batch 15 Loss 0.0370 Accuracy 5.0166\n",
      "Epoch 492 Batch 20 Loss 0.0370 Accuracy 5.0165\n",
      "Epoch 492 Batch 25 Loss 0.0370 Accuracy 5.0164\n",
      "Epoch 492 Batch 30 Loss 0.0370 Accuracy 5.0163\n",
      "Epoch 492 Batch 35 Loss 0.0370 Accuracy 5.0163\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0178\n",
      "Epoch 493 Batch 5 Loss 0.0370 Accuracy 5.0161\n",
      "Epoch 493 Batch 10 Loss 0.0370 Accuracy 5.0160\n",
      "Epoch 493 Batch 15 Loss 0.0370 Accuracy 5.0159\n",
      "Epoch 493 Batch 20 Loss 0.0370 Accuracy 5.0159\n",
      "Epoch 493 Batch 25 Loss 0.0370 Accuracy 5.0158\n",
      "Epoch 493 Batch 30 Loss 0.0370 Accuracy 5.0157\n",
      "Epoch 493 Batch 35 Loss 0.0370 Accuracy 5.0156\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0171\n",
      "Epoch 494 Batch 5 Loss 0.0370 Accuracy 5.0155\n",
      "Epoch 494 Batch 10 Loss 0.0370 Accuracy 5.0154\n",
      "Epoch 494 Batch 15 Loss 0.0370 Accuracy 5.0153\n",
      "Epoch 494 Batch 20 Loss 0.0370 Accuracy 5.0152\n",
      "Epoch 494 Batch 25 Loss 0.0370 Accuracy 5.0151\n",
      "Epoch 494 Batch 30 Loss 0.0370 Accuracy 5.0150\n",
      "Epoch 494 Batch 35 Loss 0.0370 Accuracy 5.0149\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0164\n",
      "Epoch 495 Batch 5 Loss 0.0370 Accuracy 5.0148\n",
      "Epoch 495 Batch 10 Loss 0.0370 Accuracy 5.0147\n",
      "Epoch 495 Batch 15 Loss 0.0370 Accuracy 5.0146\n",
      "Epoch 495 Batch 20 Loss 0.0370 Accuracy 5.0145\n",
      "Epoch 495 Batch 25 Loss 0.0370 Accuracy 5.0144\n",
      "Epoch 495 Batch 30 Loss 0.0370 Accuracy 5.0143\n",
      "Epoch 495 Batch 35 Loss 0.0370 Accuracy 5.0143\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0158\n",
      "Epoch 496 Batch 5 Loss 0.0370 Accuracy 5.0141\n",
      "Epoch 496 Batch 10 Loss 0.0370 Accuracy 5.0140\n",
      "Epoch 496 Batch 15 Loss 0.0370 Accuracy 5.0140\n",
      "Epoch 496 Batch 20 Loss 0.0370 Accuracy 5.0139\n",
      "Epoch 496 Batch 25 Loss 0.0370 Accuracy 5.0138\n",
      "Epoch 496 Batch 30 Loss 0.0370 Accuracy 5.0137\n",
      "Epoch 496 Batch 35 Loss 0.0370 Accuracy 5.0136\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0151\n",
      "Epoch 497 Batch 5 Loss 0.0370 Accuracy 5.0135\n",
      "Epoch 497 Batch 10 Loss 0.0370 Accuracy 5.0134\n",
      "Epoch 497 Batch 15 Loss 0.0370 Accuracy 5.0133\n",
      "Epoch 497 Batch 20 Loss 0.0370 Accuracy 5.0132\n",
      "Epoch 497 Batch 25 Loss 0.0370 Accuracy 5.0131\n",
      "Epoch 497 Batch 30 Loss 0.0370 Accuracy 5.0130\n",
      "Epoch 497 Batch 35 Loss 0.0370 Accuracy 5.0129\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0144\n",
      "Epoch 498 Batch 5 Loss 0.0370 Accuracy 5.0128\n",
      "Epoch 498 Batch 10 Loss 0.0370 Accuracy 5.0127\n",
      "Epoch 498 Batch 15 Loss 0.0370 Accuracy 5.0126\n",
      "Epoch 498 Batch 20 Loss 0.0370 Accuracy 5.0125\n",
      "Epoch 498 Batch 25 Loss 0.0370 Accuracy 5.0124\n",
      "Epoch 498 Batch 30 Loss 0.0370 Accuracy 5.0123\n",
      "Epoch 498 Batch 35 Loss 0.0370 Accuracy 5.0122\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0138\n",
      "Epoch 499 Batch 5 Loss 0.0370 Accuracy 5.0121\n",
      "Epoch 499 Batch 10 Loss 0.0370 Accuracy 5.0120\n",
      "Epoch 499 Batch 15 Loss 0.0370 Accuracy 5.0119\n",
      "Epoch 499 Batch 20 Loss 0.0370 Accuracy 5.0119\n",
      "Epoch 499 Batch 25 Loss 0.0370 Accuracy 5.0118\n",
      "Epoch 499 Batch 30 Loss 0.0370 Accuracy 5.0117\n",
      "Epoch 499 Batch 35 Loss 0.0370 Accuracy 5.0116\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0131\n",
      "Epoch 500 Batch 5 Loss 0.0370 Accuracy 5.0115\n",
      "Epoch 500 Batch 10 Loss 0.0370 Accuracy 5.0114\n",
      "Epoch 500 Batch 15 Loss 0.0370 Accuracy 5.0113\n",
      "Epoch 500 Batch 20 Loss 0.0370 Accuracy 5.0112\n",
      "Epoch 500 Batch 25 Loss 0.0370 Accuracy 5.0111\n",
      "Epoch 500 Batch 30 Loss 0.0370 Accuracy 5.0110\n",
      "Epoch 500 Batch 35 Loss 0.0370 Accuracy 5.0109\n",
      "Time taken for 1 epoch: 0.42 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0124\n",
      "Epoch 501 Batch 5 Loss 0.0370 Accuracy 5.0108\n",
      "Epoch 501 Batch 10 Loss 0.0370 Accuracy 5.0107\n",
      "Epoch 501 Batch 15 Loss 0.0370 Accuracy 5.0106\n",
      "Epoch 501 Batch 20 Loss 0.0370 Accuracy 5.0105\n",
      "Epoch 501 Batch 25 Loss 0.0370 Accuracy 5.0104\n",
      "Epoch 501 Batch 30 Loss 0.0370 Accuracy 5.0103\n",
      "Epoch 501 Batch 35 Loss 0.0370 Accuracy 5.0103\n",
      "Time taken for 1 epoch: 0.42 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0118\n",
      "Epoch 502 Batch 5 Loss 0.0370 Accuracy 5.0101\n",
      "Epoch 502 Batch 10 Loss 0.0370 Accuracy 5.0100\n",
      "Epoch 502 Batch 15 Loss 0.0370 Accuracy 5.0100\n",
      "Epoch 502 Batch 20 Loss 0.0370 Accuracy 5.0099\n",
      "Epoch 502 Batch 25 Loss 0.0370 Accuracy 5.0098\n",
      "Epoch 502 Batch 30 Loss 0.0370 Accuracy 5.0097\n",
      "Epoch 502 Batch 35 Loss 0.0370 Accuracy 5.0096\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0111\n",
      "Epoch 503 Batch 5 Loss 0.0370 Accuracy 5.0095\n",
      "Epoch 503 Batch 10 Loss 0.0370 Accuracy 5.0094\n",
      "Epoch 503 Batch 15 Loss 0.0370 Accuracy 5.0093\n",
      "Epoch 503 Batch 20 Loss 0.0370 Accuracy 5.0092\n",
      "Epoch 503 Batch 25 Loss 0.0370 Accuracy 5.0091\n",
      "Epoch 503 Batch 30 Loss 0.0369 Accuracy 5.0090\n",
      "Epoch 503 Batch 35 Loss 0.0369 Accuracy 5.0089\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0104\n",
      "Epoch 504 Batch 5 Loss 0.0369 Accuracy 5.0088\n",
      "Epoch 504 Batch 10 Loss 0.0369 Accuracy 5.0087\n",
      "Epoch 504 Batch 15 Loss 0.0369 Accuracy 5.0086\n",
      "Epoch 504 Batch 20 Loss 0.0369 Accuracy 5.0086\n",
      "Epoch 504 Batch 25 Loss 0.0369 Accuracy 5.0085\n",
      "Epoch 504 Batch 30 Loss 0.0369 Accuracy 5.0084\n",
      "Epoch 504 Batch 35 Loss 0.0369 Accuracy 5.0083\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0098\n",
      "Epoch 505 Batch 5 Loss 0.0369 Accuracy 5.0082\n",
      "Epoch 505 Batch 10 Loss 0.0369 Accuracy 5.0081\n",
      "Epoch 505 Batch 15 Loss 0.0369 Accuracy 5.0080\n",
      "Epoch 505 Batch 20 Loss 0.0369 Accuracy 5.0079\n",
      "Epoch 505 Batch 25 Loss 0.0369 Accuracy 5.0078\n",
      "Epoch 505 Batch 30 Loss 0.0369 Accuracy 5.0077\n",
      "Epoch 505 Batch 35 Loss 0.0369 Accuracy 5.0076\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0091\n",
      "Epoch 506 Batch 5 Loss 0.0369 Accuracy 5.0075\n",
      "Epoch 506 Batch 10 Loss 0.0369 Accuracy 5.0074\n",
      "Epoch 506 Batch 15 Loss 0.0369 Accuracy 5.0073\n",
      "Epoch 506 Batch 20 Loss 0.0369 Accuracy 5.0072\n",
      "Epoch 506 Batch 25 Loss 0.0369 Accuracy 5.0071\n",
      "Epoch 506 Batch 30 Loss 0.0369 Accuracy 5.0070\n",
      "Epoch 506 Batch 35 Loss 0.0369 Accuracy 5.0070\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0084\n",
      "Epoch 507 Batch 5 Loss 0.0369 Accuracy 5.0068\n",
      "Epoch 507 Batch 10 Loss 0.0369 Accuracy 5.0067\n",
      "Epoch 507 Batch 15 Loss 0.0369 Accuracy 5.0066\n",
      "Epoch 507 Batch 20 Loss 0.0369 Accuracy 5.0066\n",
      "Epoch 507 Batch 25 Loss 0.0369 Accuracy 5.0065\n",
      "Epoch 507 Batch 30 Loss 0.0369 Accuracy 5.0064\n",
      "Epoch 507 Batch 35 Loss 0.0369 Accuracy 5.0063\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0078\n",
      "Epoch 508 Batch 5 Loss 0.0369 Accuracy 5.0062\n",
      "Epoch 508 Batch 10 Loss 0.0369 Accuracy 5.0061\n",
      "Epoch 508 Batch 15 Loss 0.0369 Accuracy 5.0060\n",
      "Epoch 508 Batch 20 Loss 0.0369 Accuracy 5.0059\n",
      "Epoch 508 Batch 25 Loss 0.0369 Accuracy 5.0058\n",
      "Epoch 508 Batch 30 Loss 0.0369 Accuracy 5.0057\n",
      "Epoch 508 Batch 35 Loss 0.0369 Accuracy 5.0056\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0071\n",
      "Epoch 509 Batch 5 Loss 0.0369 Accuracy 5.0055\n",
      "Epoch 509 Batch 10 Loss 0.0369 Accuracy 5.0054\n",
      "Epoch 509 Batch 15 Loss 0.0369 Accuracy 5.0053\n",
      "Epoch 509 Batch 20 Loss 0.0369 Accuracy 5.0052\n",
      "Epoch 509 Batch 25 Loss 0.0369 Accuracy 5.0052\n",
      "Epoch 509 Batch 30 Loss 0.0369 Accuracy 5.0051\n",
      "Epoch 509 Batch 35 Loss 0.0369 Accuracy 5.0050\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0064\n",
      "Epoch 510 Batch 5 Loss 0.0369 Accuracy 5.0049\n",
      "Epoch 510 Batch 10 Loss 0.0369 Accuracy 5.0048\n",
      "Epoch 510 Batch 15 Loss 0.0369 Accuracy 5.0047\n",
      "Epoch 510 Batch 20 Loss 0.0369 Accuracy 5.0046\n",
      "Epoch 510 Batch 25 Loss 0.0369 Accuracy 5.0045\n",
      "Epoch 510 Batch 30 Loss 0.0369 Accuracy 5.0044\n",
      "Epoch 510 Batch 35 Loss 0.0369 Accuracy 5.0043\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0058\n",
      "Epoch 511 Batch 5 Loss 0.0369 Accuracy 5.0042\n",
      "Epoch 511 Batch 10 Loss 0.0369 Accuracy 5.0041\n",
      "Epoch 511 Batch 15 Loss 0.0369 Accuracy 5.0040\n",
      "Epoch 511 Batch 20 Loss 0.0369 Accuracy 5.0039\n",
      "Epoch 511 Batch 25 Loss 0.0369 Accuracy 5.0038\n",
      "Epoch 511 Batch 30 Loss 0.0369 Accuracy 5.0038\n",
      "Epoch 511 Batch 35 Loss 0.0369 Accuracy 5.0037\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0051\n",
      "Epoch 512 Batch 5 Loss 0.0369 Accuracy 5.0035\n",
      "Epoch 512 Batch 10 Loss 0.0369 Accuracy 5.0034\n",
      "Epoch 512 Batch 15 Loss 0.0369 Accuracy 5.0034\n",
      "Epoch 512 Batch 20 Loss 0.0369 Accuracy 5.0033\n",
      "Epoch 512 Batch 25 Loss 0.0369 Accuracy 5.0032\n",
      "Epoch 512 Batch 30 Loss 0.0369 Accuracy 5.0031\n",
      "Epoch 512 Batch 35 Loss 0.0369 Accuracy 5.0030\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0045\n",
      "Epoch 513 Batch 5 Loss 0.0368 Accuracy 5.0029\n",
      "Epoch 513 Batch 10 Loss 0.0368 Accuracy 5.0028\n",
      "Epoch 513 Batch 15 Loss 0.0368 Accuracy 5.0027\n",
      "Epoch 513 Batch 20 Loss 0.0368 Accuracy 5.0026\n",
      "Epoch 513 Batch 25 Loss 0.0368 Accuracy 5.0025\n",
      "Epoch 513 Batch 30 Loss 0.0368 Accuracy 5.0024\n",
      "Epoch 513 Batch 35 Loss 0.0368 Accuracy 5.0023\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0038\n",
      "Epoch 514 Batch 5 Loss 0.0368 Accuracy 5.0022\n",
      "Epoch 514 Batch 10 Loss 0.0368 Accuracy 5.0021\n",
      "Epoch 514 Batch 15 Loss 0.0368 Accuracy 5.0020\n",
      "Epoch 514 Batch 20 Loss 0.0368 Accuracy 5.0019\n",
      "Epoch 514 Batch 25 Loss 0.0368 Accuracy 5.0019\n",
      "Epoch 514 Batch 30 Loss 0.0368 Accuracy 5.0018\n",
      "Epoch 514 Batch 35 Loss 0.0368 Accuracy 5.0017\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0031\n",
      "Epoch 515 Batch 5 Loss 0.0368 Accuracy 5.0016\n",
      "Epoch 515 Batch 10 Loss 0.0368 Accuracy 5.0015\n",
      "Epoch 515 Batch 15 Loss 0.0368 Accuracy 5.0014\n",
      "Epoch 515 Batch 20 Loss 0.0368 Accuracy 5.0013\n",
      "Epoch 515 Batch 25 Loss 0.0368 Accuracy 5.0012\n",
      "Epoch 515 Batch 30 Loss 0.0368 Accuracy 5.0011\n",
      "Epoch 515 Batch 35 Loss 0.0368 Accuracy 5.0010\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0025\n",
      "Epoch 516 Batch 5 Loss 0.0368 Accuracy 5.0009\n",
      "Epoch 516 Batch 10 Loss 0.0368 Accuracy 5.0008\n",
      "Epoch 516 Batch 15 Loss 0.0368 Accuracy 5.0007\n",
      "Epoch 516 Batch 20 Loss 0.0368 Accuracy 5.0006\n",
      "Epoch 516 Batch 25 Loss 0.0368 Accuracy 5.0005\n",
      "Epoch 516 Batch 30 Loss 0.0368 Accuracy 5.0005\n",
      "Epoch 516 Batch 35 Loss 0.0368 Accuracy 5.0004\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0018\n",
      "Epoch 517 Batch 5 Loss 0.0368 Accuracy 5.0002\n",
      "Epoch 517 Batch 10 Loss 0.0368 Accuracy 5.0002\n",
      "Epoch 517 Batch 15 Loss 0.0368 Accuracy 5.0001\n",
      "Epoch 517 Batch 20 Loss 0.0368 Accuracy 5.0000\n",
      "Epoch 517 Batch 25 Loss 0.0368 Accuracy 4.9999\n",
      "Epoch 517 Batch 30 Loss 0.0368 Accuracy 4.9998\n",
      "Epoch 517 Batch 35 Loss 0.0368 Accuracy 4.9997\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0011\n",
      "Epoch 518 Batch 5 Loss 0.0368 Accuracy 4.9996\n",
      "Epoch 518 Batch 10 Loss 0.0368 Accuracy 4.9995\n",
      "Epoch 518 Batch 15 Loss 0.0368 Accuracy 4.9994\n",
      "Epoch 518 Batch 20 Loss 0.0368 Accuracy 4.9993\n",
      "Epoch 518 Batch 25 Loss 0.0368 Accuracy 4.9992\n",
      "Epoch 518 Batch 30 Loss 0.0368 Accuracy 4.9991\n",
      "Epoch 518 Batch 35 Loss 0.0368 Accuracy 4.9990\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 5.0005\n",
      "Epoch 519 Batch 5 Loss 0.0368 Accuracy 4.9989\n",
      "Epoch 519 Batch 10 Loss 0.0368 Accuracy 4.9988\n",
      "Epoch 519 Batch 15 Loss 0.0368 Accuracy 4.9987\n",
      "Epoch 519 Batch 20 Loss 0.0368 Accuracy 4.9986\n",
      "Epoch 519 Batch 25 Loss 0.0368 Accuracy 4.9986\n",
      "Epoch 519 Batch 30 Loss 0.0368 Accuracy 4.9985\n",
      "Epoch 519 Batch 35 Loss 0.0368 Accuracy 4.9984\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9998\n",
      "Epoch 520 Batch 5 Loss 0.0368 Accuracy 4.9983\n",
      "Epoch 520 Batch 10 Loss 0.0368 Accuracy 4.9982\n",
      "Epoch 520 Batch 15 Loss 0.0368 Accuracy 4.9981\n",
      "Epoch 520 Batch 20 Loss 0.0368 Accuracy 4.9980\n",
      "Epoch 520 Batch 25 Loss 0.0368 Accuracy 4.9979\n",
      "Epoch 520 Batch 30 Loss 0.0368 Accuracy 4.9978\n",
      "Epoch 520 Batch 35 Loss 0.0368 Accuracy 4.9977\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9992\n",
      "Epoch 521 Batch 5 Loss 0.0368 Accuracy 4.9976\n",
      "Epoch 521 Batch 10 Loss 0.0368 Accuracy 4.9975\n",
      "Epoch 521 Batch 15 Loss 0.0368 Accuracy 4.9974\n",
      "Epoch 521 Batch 20 Loss 0.0367 Accuracy 4.9973\n",
      "Epoch 521 Batch 25 Loss 0.0367 Accuracy 4.9972\n",
      "Epoch 521 Batch 30 Loss 0.0367 Accuracy 4.9972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 521 Batch 35 Loss 0.0367 Accuracy 4.9971\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9985\n",
      "Epoch 522 Batch 5 Loss 0.0367 Accuracy 4.9969\n",
      "Epoch 522 Batch 10 Loss 0.0367 Accuracy 4.9969\n",
      "Epoch 522 Batch 15 Loss 0.0367 Accuracy 4.9968\n",
      "Epoch 522 Batch 20 Loss 0.0367 Accuracy 4.9967\n",
      "Epoch 522 Batch 25 Loss 0.0367 Accuracy 4.9966\n",
      "Epoch 522 Batch 30 Loss 0.0367 Accuracy 4.9965\n",
      "Epoch 522 Batch 35 Loss 0.0367 Accuracy 4.9964\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9978\n",
      "Epoch 523 Batch 5 Loss 0.0367 Accuracy 4.9963\n",
      "Epoch 523 Batch 10 Loss 0.0367 Accuracy 4.9962\n",
      "Epoch 523 Batch 15 Loss 0.0367 Accuracy 4.9961\n",
      "Epoch 523 Batch 20 Loss 0.0367 Accuracy 4.9960\n",
      "Epoch 523 Batch 25 Loss 0.0367 Accuracy 4.9959\n",
      "Epoch 523 Batch 30 Loss 0.0367 Accuracy 4.9958\n",
      "Epoch 523 Batch 35 Loss 0.0367 Accuracy 4.9958\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9972\n",
      "Epoch 524 Batch 5 Loss 0.0367 Accuracy 4.9956\n",
      "Epoch 524 Batch 10 Loss 0.0367 Accuracy 4.9955\n",
      "Epoch 524 Batch 15 Loss 0.0367 Accuracy 4.9954\n",
      "Epoch 524 Batch 20 Loss 0.0367 Accuracy 4.9954\n",
      "Epoch 524 Batch 25 Loss 0.0367 Accuracy 4.9953\n",
      "Epoch 524 Batch 30 Loss 0.0367 Accuracy 4.9952\n",
      "Epoch 524 Batch 35 Loss 0.0367 Accuracy 4.9951\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9965\n",
      "Epoch 525 Batch 5 Loss 0.0367 Accuracy 4.9950\n",
      "Epoch 525 Batch 10 Loss 0.0367 Accuracy 4.9949\n",
      "Epoch 525 Batch 15 Loss 0.0367 Accuracy 4.9948\n",
      "Epoch 525 Batch 20 Loss 0.0367 Accuracy 4.9947\n",
      "Epoch 525 Batch 25 Loss 0.0367 Accuracy 4.9946\n",
      "Epoch 525 Batch 30 Loss 0.0367 Accuracy 4.9945\n",
      "Epoch 525 Batch 35 Loss 0.0367 Accuracy 4.9944\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9958\n",
      "Epoch 526 Batch 5 Loss 0.0367 Accuracy 4.9943\n",
      "Epoch 526 Batch 10 Loss 0.0367 Accuracy 4.9942\n",
      "Epoch 526 Batch 15 Loss 0.0367 Accuracy 4.9941\n",
      "Epoch 526 Batch 20 Loss 0.0367 Accuracy 4.9940\n",
      "Epoch 526 Batch 25 Loss 0.0367 Accuracy 4.9939\n",
      "Epoch 526 Batch 30 Loss 0.0367 Accuracy 4.9939\n",
      "Epoch 526 Batch 35 Loss 0.0367 Accuracy 4.9938\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9952\n",
      "Epoch 527 Batch 5 Loss 0.0367 Accuracy 4.9936\n",
      "Epoch 527 Batch 10 Loss 0.0367 Accuracy 4.9936\n",
      "Epoch 527 Batch 15 Loss 0.0367 Accuracy 4.9935\n",
      "Epoch 527 Batch 20 Loss 0.0367 Accuracy 4.9934\n",
      "Epoch 527 Batch 25 Loss 0.0367 Accuracy 4.9933\n",
      "Epoch 527 Batch 30 Loss 0.0367 Accuracy 4.9932\n",
      "Epoch 527 Batch 35 Loss 0.0367 Accuracy 4.9931\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9945\n",
      "Epoch 528 Batch 5 Loss 0.0367 Accuracy 4.9930\n",
      "Epoch 528 Batch 10 Loss 0.0367 Accuracy 4.9929\n",
      "Epoch 528 Batch 15 Loss 0.0367 Accuracy 4.9928\n",
      "Epoch 528 Batch 20 Loss 0.0367 Accuracy 4.9927\n",
      "Epoch 528 Batch 25 Loss 0.0367 Accuracy 4.9926\n",
      "Epoch 528 Batch 30 Loss 0.0367 Accuracy 4.9925\n",
      "Epoch 528 Batch 35 Loss 0.0367 Accuracy 4.9925\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9939\n",
      "Epoch 529 Batch 5 Loss 0.0367 Accuracy 4.9923\n",
      "Epoch 529 Batch 10 Loss 0.0367 Accuracy 4.9922\n",
      "Epoch 529 Batch 15 Loss 0.0367 Accuracy 4.9922\n",
      "Epoch 529 Batch 20 Loss 0.0367 Accuracy 4.9921\n",
      "Epoch 529 Batch 25 Loss 0.0367 Accuracy 4.9920\n",
      "Epoch 529 Batch 30 Loss 0.0366 Accuracy 4.9919\n",
      "Epoch 529 Batch 35 Loss 0.0366 Accuracy 4.9918\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9932\n",
      "Epoch 530 Batch 5 Loss 0.0366 Accuracy 4.9917\n",
      "Epoch 530 Batch 10 Loss 0.0366 Accuracy 4.9916\n",
      "Epoch 530 Batch 15 Loss 0.0366 Accuracy 4.9915\n",
      "Epoch 530 Batch 20 Loss 0.0366 Accuracy 4.9914\n",
      "Epoch 530 Batch 25 Loss 0.0366 Accuracy 4.9913\n",
      "Epoch 530 Batch 30 Loss 0.0366 Accuracy 4.9912\n",
      "Epoch 530 Batch 35 Loss 0.0366 Accuracy 4.9911\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9925\n",
      "Epoch 531 Batch 5 Loss 0.0366 Accuracy 4.9910\n",
      "Epoch 531 Batch 10 Loss 0.0366 Accuracy 4.9909\n",
      "Epoch 531 Batch 15 Loss 0.0366 Accuracy 4.9908\n",
      "Epoch 531 Batch 20 Loss 0.0366 Accuracy 4.9907\n",
      "Epoch 531 Batch 25 Loss 0.0366 Accuracy 4.9906\n",
      "Epoch 531 Batch 30 Loss 0.0366 Accuracy 4.9906\n",
      "Epoch 531 Batch 35 Loss 0.0366 Accuracy 4.9905\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9919\n",
      "Epoch 532 Batch 5 Loss 0.0366 Accuracy 4.9903\n",
      "Epoch 532 Batch 10 Loss 0.0366 Accuracy 4.9903\n",
      "Epoch 532 Batch 15 Loss 0.0366 Accuracy 4.9902\n",
      "Epoch 532 Batch 20 Loss 0.0366 Accuracy 4.9901\n",
      "Epoch 532 Batch 25 Loss 0.0366 Accuracy 4.9900\n",
      "Epoch 532 Batch 30 Loss 0.0366 Accuracy 4.9899\n",
      "Epoch 532 Batch 35 Loss 0.0366 Accuracy 4.9898\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9912\n",
      "Epoch 533 Batch 5 Loss 0.0366 Accuracy 4.9897\n",
      "Epoch 533 Batch 10 Loss 0.0366 Accuracy 4.9896\n",
      "Epoch 533 Batch 15 Loss 0.0366 Accuracy 4.9895\n",
      "Epoch 533 Batch 20 Loss 0.0366 Accuracy 4.9894\n",
      "Epoch 533 Batch 25 Loss 0.0366 Accuracy 4.9893\n",
      "Epoch 533 Batch 30 Loss 0.0366 Accuracy 4.9892\n",
      "Epoch 533 Batch 35 Loss 0.0366 Accuracy 4.9892\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9905\n",
      "Epoch 534 Batch 5 Loss 0.0366 Accuracy 4.9890\n",
      "Epoch 534 Batch 10 Loss 0.0366 Accuracy 4.9889\n",
      "Epoch 534 Batch 15 Loss 0.0366 Accuracy 4.9889\n",
      "Epoch 534 Batch 20 Loss 0.0366 Accuracy 4.9888\n",
      "Epoch 534 Batch 25 Loss 0.0366 Accuracy 4.9887\n",
      "Epoch 534 Batch 30 Loss 0.0366 Accuracy 4.9886\n",
      "Epoch 534 Batch 35 Loss 0.0366 Accuracy 4.9885\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9899\n",
      "Epoch 535 Batch 5 Loss 0.0366 Accuracy 4.9884\n",
      "Epoch 535 Batch 10 Loss 0.0366 Accuracy 4.9883\n",
      "Epoch 535 Batch 15 Loss 0.0366 Accuracy 4.9882\n",
      "Epoch 535 Batch 20 Loss 0.0366 Accuracy 4.9881\n",
      "Epoch 535 Batch 25 Loss 0.0366 Accuracy 4.9880\n",
      "Epoch 535 Batch 30 Loss 0.0366 Accuracy 4.9879\n",
      "Epoch 535 Batch 35 Loss 0.0366 Accuracy 4.9878\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9892\n",
      "Epoch 536 Batch 5 Loss 0.0366 Accuracy 4.9877\n",
      "Epoch 536 Batch 10 Loss 0.0366 Accuracy 4.9876\n",
      "Epoch 536 Batch 15 Loss 0.0366 Accuracy 4.9875\n",
      "Epoch 536 Batch 20 Loss 0.0366 Accuracy 4.9874\n",
      "Epoch 536 Batch 25 Loss 0.0366 Accuracy 4.9874\n",
      "Epoch 536 Batch 30 Loss 0.0366 Accuracy 4.9873\n",
      "Epoch 536 Batch 35 Loss 0.0366 Accuracy 4.9872\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9886\n",
      "Epoch 537 Batch 5 Loss 0.0366 Accuracy 4.9870\n",
      "Epoch 537 Batch 10 Loss 0.0366 Accuracy 4.9870\n",
      "Epoch 537 Batch 15 Loss 0.0366 Accuracy 4.9869\n",
      "Epoch 537 Batch 20 Loss 0.0366 Accuracy 4.9868\n",
      "Epoch 537 Batch 25 Loss 0.0366 Accuracy 4.9867\n",
      "Epoch 537 Batch 30 Loss 0.0366 Accuracy 4.9866\n",
      "Epoch 537 Batch 35 Loss 0.0366 Accuracy 4.9865\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9879\n",
      "Epoch 538 Batch 5 Loss 0.0366 Accuracy 4.9864\n",
      "Epoch 538 Batch 10 Loss 0.0366 Accuracy 4.9863\n",
      "Epoch 538 Batch 15 Loss 0.0366 Accuracy 4.9862\n",
      "Epoch 538 Batch 20 Loss 0.0365 Accuracy 4.9861\n",
      "Epoch 538 Batch 25 Loss 0.0365 Accuracy 4.9860\n",
      "Epoch 538 Batch 30 Loss 0.0365 Accuracy 4.9859\n",
      "Epoch 538 Batch 35 Loss 0.0365 Accuracy 4.9859\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9872\n",
      "Epoch 539 Batch 5 Loss 0.0365 Accuracy 4.9857\n",
      "Epoch 539 Batch 10 Loss 0.0365 Accuracy 4.9856\n",
      "Epoch 539 Batch 15 Loss 0.0365 Accuracy 4.9856\n",
      "Epoch 539 Batch 20 Loss 0.0365 Accuracy 4.9855\n",
      "Epoch 539 Batch 25 Loss 0.0365 Accuracy 4.9854\n",
      "Epoch 539 Batch 30 Loss 0.0365 Accuracy 4.9853\n",
      "Epoch 539 Batch 35 Loss 0.0365 Accuracy 4.9852\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9866\n",
      "Epoch 540 Batch 5 Loss 0.0365 Accuracy 4.9851\n",
      "Epoch 540 Batch 10 Loss 0.0365 Accuracy 4.9850\n",
      "Epoch 540 Batch 15 Loss 0.0365 Accuracy 4.9849\n",
      "Epoch 540 Batch 20 Loss 0.0365 Accuracy 4.9848\n",
      "Epoch 540 Batch 25 Loss 0.0365 Accuracy 4.9847\n",
      "Epoch 540 Batch 30 Loss 0.0365 Accuracy 4.9846\n",
      "Epoch 540 Batch 35 Loss 0.0365 Accuracy 4.9845\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9859\n",
      "Epoch 541 Batch 5 Loss 0.0365 Accuracy 4.9844\n",
      "Epoch 541 Batch 10 Loss 0.0365 Accuracy 4.9843\n",
      "Epoch 541 Batch 15 Loss 0.0365 Accuracy 4.9842\n",
      "Epoch 541 Batch 20 Loss 0.0365 Accuracy 4.9842\n",
      "Epoch 541 Batch 25 Loss 0.0365 Accuracy 4.9841\n",
      "Epoch 541 Batch 30 Loss 0.0365 Accuracy 4.9840\n",
      "Epoch 541 Batch 35 Loss 0.0365 Accuracy 4.9839\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9852\n",
      "Epoch 542 Batch 5 Loss 0.0365 Accuracy 4.9838\n",
      "Epoch 542 Batch 10 Loss 0.0365 Accuracy 4.9837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 542 Batch 15 Loss 0.0365 Accuracy 4.9836\n",
      "Epoch 542 Batch 20 Loss 0.0365 Accuracy 4.9835\n",
      "Epoch 542 Batch 25 Loss 0.0365 Accuracy 4.9834\n",
      "Epoch 542 Batch 30 Loss 0.0365 Accuracy 4.9833\n",
      "Epoch 542 Batch 35 Loss 0.0365 Accuracy 4.9832\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9846\n",
      "Epoch 543 Batch 5 Loss 0.0365 Accuracy 4.9831\n",
      "Epoch 543 Batch 10 Loss 0.0365 Accuracy 4.9830\n",
      "Epoch 543 Batch 15 Loss 0.0365 Accuracy 4.9829\n",
      "Epoch 543 Batch 20 Loss 0.0365 Accuracy 4.9828\n",
      "Epoch 543 Batch 25 Loss 0.0365 Accuracy 4.9827\n",
      "Epoch 543 Batch 30 Loss 0.0365 Accuracy 4.9827\n",
      "Epoch 543 Batch 35 Loss 0.0365 Accuracy 4.9826\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9839\n",
      "Epoch 544 Batch 5 Loss 0.0365 Accuracy 4.9824\n",
      "Epoch 544 Batch 10 Loss 0.0365 Accuracy 4.9824\n",
      "Epoch 544 Batch 15 Loss 0.0365 Accuracy 4.9823\n",
      "Epoch 544 Batch 20 Loss 0.0365 Accuracy 4.9822\n",
      "Epoch 544 Batch 25 Loss 0.0365 Accuracy 4.9821\n",
      "Epoch 544 Batch 30 Loss 0.0365 Accuracy 4.9820\n",
      "Epoch 544 Batch 35 Loss 0.0365 Accuracy 4.9819\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9833\n",
      "Epoch 545 Batch 5 Loss 0.0365 Accuracy 4.9818\n",
      "Epoch 545 Batch 10 Loss 0.0365 Accuracy 4.9817\n",
      "Epoch 545 Batch 15 Loss 0.0365 Accuracy 4.9816\n",
      "Epoch 545 Batch 20 Loss 0.0365 Accuracy 4.9815\n",
      "Epoch 545 Batch 25 Loss 0.0365 Accuracy 4.9814\n",
      "Epoch 545 Batch 30 Loss 0.0365 Accuracy 4.9813\n",
      "Epoch 545 Batch 35 Loss 0.0365 Accuracy 4.9813\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9826\n",
      "Epoch 546 Batch 5 Loss 0.0365 Accuracy 4.9811\n",
      "Epoch 546 Batch 10 Loss 0.0365 Accuracy 4.9810\n",
      "Epoch 546 Batch 15 Loss 0.0365 Accuracy 4.9810\n",
      "Epoch 546 Batch 20 Loss 0.0365 Accuracy 4.9809\n",
      "Epoch 546 Batch 25 Loss 0.0365 Accuracy 4.9808\n",
      "Epoch 546 Batch 30 Loss 0.0365 Accuracy 4.9807\n",
      "Epoch 546 Batch 35 Loss 0.0365 Accuracy 4.9806\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9819\n",
      "Epoch 547 Batch 5 Loss 0.0365 Accuracy 4.9805\n",
      "Epoch 547 Batch 10 Loss 0.0365 Accuracy 4.9804\n",
      "Epoch 547 Batch 15 Loss 0.0365 Accuracy 4.9803\n",
      "Epoch 547 Batch 20 Loss 0.0365 Accuracy 4.9802\n",
      "Epoch 547 Batch 25 Loss 0.0365 Accuracy 4.9801\n",
      "Epoch 547 Batch 30 Loss 0.0365 Accuracy 4.9800\n",
      "Epoch 547 Batch 35 Loss 0.0364 Accuracy 4.9799\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9813\n",
      "Epoch 548 Batch 5 Loss 0.0364 Accuracy 4.9798\n",
      "Epoch 548 Batch 10 Loss 0.0364 Accuracy 4.9797\n",
      "Epoch 548 Batch 15 Loss 0.0364 Accuracy 4.9796\n",
      "Epoch 548 Batch 20 Loss 0.0364 Accuracy 4.9796\n",
      "Epoch 548 Batch 25 Loss 0.0364 Accuracy 4.9795\n",
      "Epoch 548 Batch 30 Loss 0.0364 Accuracy 4.9794\n",
      "Epoch 548 Batch 35 Loss 0.0364 Accuracy 4.9793\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9806\n",
      "Epoch 549 Batch 5 Loss 0.0364 Accuracy 4.9792\n",
      "Epoch 549 Batch 10 Loss 0.0364 Accuracy 4.9791\n",
      "Epoch 549 Batch 15 Loss 0.0364 Accuracy 4.9790\n",
      "Epoch 549 Batch 20 Loss 0.0364 Accuracy 4.9789\n",
      "Epoch 549 Batch 25 Loss 0.0364 Accuracy 4.9788\n",
      "Epoch 549 Batch 30 Loss 0.0364 Accuracy 4.9787\n",
      "Epoch 549 Batch 35 Loss 0.0364 Accuracy 4.9786\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9800\n",
      "Epoch 550 Batch 5 Loss 0.0364 Accuracy 4.9785\n",
      "Epoch 550 Batch 10 Loss 0.0364 Accuracy 4.9784\n",
      "Epoch 550 Batch 15 Loss 0.0364 Accuracy 4.9783\n",
      "Epoch 550 Batch 20 Loss 0.0364 Accuracy 4.9782\n",
      "Epoch 550 Batch 25 Loss 0.0364 Accuracy 4.9781\n",
      "Epoch 550 Batch 30 Loss 0.0364 Accuracy 4.9781\n",
      "Epoch 550 Batch 35 Loss 0.0364 Accuracy 4.9780\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9793\n",
      "Epoch 551 Batch 5 Loss 0.0364 Accuracy 4.9778\n",
      "Epoch 551 Batch 10 Loss 0.0364 Accuracy 4.9778\n",
      "Epoch 551 Batch 15 Loss 0.0364 Accuracy 4.9777\n",
      "Epoch 551 Batch 20 Loss 0.0364 Accuracy 4.9776\n",
      "Epoch 551 Batch 25 Loss 0.0364 Accuracy 4.9775\n",
      "Epoch 551 Batch 30 Loss 0.0364 Accuracy 4.9774\n",
      "Epoch 551 Batch 35 Loss 0.0364 Accuracy 4.9773\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9786\n",
      "Epoch 552 Batch 5 Loss 0.0364 Accuracy 4.9772\n",
      "Epoch 552 Batch 10 Loss 0.0364 Accuracy 4.9771\n",
      "Epoch 552 Batch 15 Loss 0.0364 Accuracy 4.9770\n",
      "Epoch 552 Batch 20 Loss 0.0364 Accuracy 4.9769\n",
      "Epoch 552 Batch 25 Loss 0.0364 Accuracy 4.9768\n",
      "Epoch 552 Batch 30 Loss 0.0364 Accuracy 4.9767\n",
      "Epoch 552 Batch 35 Loss 0.0364 Accuracy 4.9767\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9780\n",
      "Epoch 553 Batch 5 Loss 0.0364 Accuracy 4.9765\n",
      "Epoch 553 Batch 10 Loss 0.0364 Accuracy 4.9764\n",
      "Epoch 553 Batch 15 Loss 0.0364 Accuracy 4.9763\n",
      "Epoch 553 Batch 20 Loss 0.0364 Accuracy 4.9763\n",
      "Epoch 553 Batch 25 Loss 0.0364 Accuracy 4.9762\n",
      "Epoch 553 Batch 30 Loss 0.0364 Accuracy 4.9761\n",
      "Epoch 553 Batch 35 Loss 0.0364 Accuracy 4.9760\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9773\n",
      "Epoch 554 Batch 5 Loss 0.0364 Accuracy 4.9759\n",
      "Epoch 554 Batch 10 Loss 0.0364 Accuracy 4.9758\n",
      "Epoch 554 Batch 15 Loss 0.0364 Accuracy 4.9757\n",
      "Epoch 554 Batch 20 Loss 0.0364 Accuracy 4.9756\n",
      "Epoch 554 Batch 25 Loss 0.0364 Accuracy 4.9755\n",
      "Epoch 554 Batch 30 Loss 0.0364 Accuracy 4.9754\n",
      "Epoch 554 Batch 35 Loss 0.0364 Accuracy 4.9753\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9766\n",
      "Epoch 555 Batch 5 Loss 0.0364 Accuracy 4.9752\n",
      "Epoch 555 Batch 10 Loss 0.0364 Accuracy 4.9751\n",
      "Epoch 555 Batch 15 Loss 0.0364 Accuracy 4.9750\n",
      "Epoch 555 Batch 20 Loss 0.0364 Accuracy 4.9749\n",
      "Epoch 555 Batch 25 Loss 0.0364 Accuracy 4.9748\n",
      "Epoch 555 Batch 30 Loss 0.0364 Accuracy 4.9748\n",
      "Epoch 555 Batch 35 Loss 0.0364 Accuracy 4.9747\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9760\n",
      "Epoch 556 Batch 5 Loss 0.0364 Accuracy 4.9745\n",
      "Epoch 556 Batch 10 Loss 0.0364 Accuracy 4.9745\n",
      "Epoch 556 Batch 15 Loss 0.0364 Accuracy 4.9744\n",
      "Epoch 556 Batch 20 Loss 0.0364 Accuracy 4.9743\n",
      "Epoch 556 Batch 25 Loss 0.0363 Accuracy 4.9742\n",
      "Epoch 556 Batch 30 Loss 0.0363 Accuracy 4.9741\n",
      "Epoch 556 Batch 35 Loss 0.0363 Accuracy 4.9740\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9753\n",
      "Epoch 557 Batch 5 Loss 0.0363 Accuracy 4.9739\n",
      "Epoch 557 Batch 10 Loss 0.0363 Accuracy 4.9738\n",
      "Epoch 557 Batch 15 Loss 0.0363 Accuracy 4.9737\n",
      "Epoch 557 Batch 20 Loss 0.0363 Accuracy 4.9736\n",
      "Epoch 557 Batch 25 Loss 0.0363 Accuracy 4.9735\n",
      "Epoch 557 Batch 30 Loss 0.0363 Accuracy 4.9734\n",
      "Epoch 557 Batch 35 Loss 0.0363 Accuracy 4.9734\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9747\n",
      "Epoch 558 Batch 5 Loss 0.0363 Accuracy 4.9732\n",
      "Epoch 558 Batch 10 Loss 0.0363 Accuracy 4.9731\n",
      "Epoch 558 Batch 15 Loss 0.0363 Accuracy 4.9731\n",
      "Epoch 558 Batch 20 Loss 0.0363 Accuracy 4.9730\n",
      "Epoch 558 Batch 25 Loss 0.0363 Accuracy 4.9729\n",
      "Epoch 558 Batch 30 Loss 0.0363 Accuracy 4.9728\n",
      "Epoch 558 Batch 35 Loss 0.0363 Accuracy 4.9727\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9740\n",
      "Epoch 559 Batch 5 Loss 0.0363 Accuracy 4.9726\n",
      "Epoch 559 Batch 10 Loss 0.0363 Accuracy 4.9725\n",
      "Epoch 559 Batch 15 Loss 0.0363 Accuracy 4.9724\n",
      "Epoch 559 Batch 20 Loss 0.0363 Accuracy 4.9723\n",
      "Epoch 559 Batch 25 Loss 0.0363 Accuracy 4.9722\n",
      "Epoch 559 Batch 30 Loss 0.0363 Accuracy 4.9721\n",
      "Epoch 559 Batch 35 Loss 0.0363 Accuracy 4.9721\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9734\n",
      "Epoch 560 Batch 5 Loss 0.0363 Accuracy 4.9719\n",
      "Epoch 560 Batch 10 Loss 0.0363 Accuracy 4.9718\n",
      "Epoch 560 Batch 15 Loss 0.0363 Accuracy 4.9718\n",
      "Epoch 560 Batch 20 Loss 0.0363 Accuracy 4.9717\n",
      "Epoch 560 Batch 25 Loss 0.0363 Accuracy 4.9716\n",
      "Epoch 560 Batch 30 Loss 0.0363 Accuracy 4.9715\n",
      "Epoch 560 Batch 35 Loss 0.0363 Accuracy 4.9714\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9727\n",
      "Epoch 561 Batch 5 Loss 0.0363 Accuracy 4.9713\n",
      "Epoch 561 Batch 10 Loss 0.0363 Accuracy 4.9712\n",
      "Epoch 561 Batch 15 Loss 0.0363 Accuracy 4.9711\n",
      "Epoch 561 Batch 20 Loss 0.0363 Accuracy 4.9710\n",
      "Epoch 561 Batch 25 Loss 0.0363 Accuracy 4.9709\n",
      "Epoch 561 Batch 30 Loss 0.0363 Accuracy 4.9708\n",
      "Epoch 561 Batch 35 Loss 0.0363 Accuracy 4.9707\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9720\n",
      "Epoch 562 Batch 5 Loss 0.0363 Accuracy 4.9706\n",
      "Epoch 562 Batch 10 Loss 0.0363 Accuracy 4.9705\n",
      "Epoch 562 Batch 15 Loss 0.0363 Accuracy 4.9704\n",
      "Epoch 562 Batch 20 Loss 0.0363 Accuracy 4.9704\n",
      "Epoch 562 Batch 25 Loss 0.0363 Accuracy 4.9703\n",
      "Epoch 562 Batch 30 Loss 0.0363 Accuracy 4.9702\n",
      "Epoch 562 Batch 35 Loss 0.0363 Accuracy 4.9701\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 563 Batch 5 Loss 0.0363 Accuracy 4.9700\n",
      "Epoch 563 Batch 10 Loss 0.0363 Accuracy 4.9699\n",
      "Epoch 563 Batch 15 Loss 0.0363 Accuracy 4.9698\n",
      "Epoch 563 Batch 20 Loss 0.0363 Accuracy 4.9697\n",
      "Epoch 563 Batch 25 Loss 0.0363 Accuracy 4.9696\n",
      "Epoch 563 Batch 30 Loss 0.0363 Accuracy 4.9695\n",
      "Epoch 563 Batch 35 Loss 0.0363 Accuracy 4.9694\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9707\n",
      "Epoch 564 Batch 5 Loss 0.0363 Accuracy 4.9693\n",
      "Epoch 564 Batch 10 Loss 0.0363 Accuracy 4.9692\n",
      "Epoch 564 Batch 15 Loss 0.0363 Accuracy 4.9691\n",
      "Epoch 564 Batch 20 Loss 0.0363 Accuracy 4.9690\n",
      "Epoch 564 Batch 25 Loss 0.0363 Accuracy 4.9690\n",
      "Epoch 564 Batch 30 Loss 0.0363 Accuracy 4.9689\n",
      "Epoch 564 Batch 35 Loss 0.0363 Accuracy 4.9688\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9701\n",
      "Epoch 565 Batch 5 Loss 0.0363 Accuracy 4.9687\n",
      "Epoch 565 Batch 10 Loss 0.0363 Accuracy 4.9686\n",
      "Epoch 565 Batch 15 Loss 0.0363 Accuracy 4.9685\n",
      "Epoch 565 Batch 20 Loss 0.0363 Accuracy 4.9684\n",
      "Epoch 565 Batch 25 Loss 0.0363 Accuracy 4.9683\n",
      "Epoch 565 Batch 30 Loss 0.0363 Accuracy 4.9682\n",
      "Epoch 565 Batch 35 Loss 0.0363 Accuracy 4.9681\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9694\n",
      "Epoch 566 Batch 5 Loss 0.0363 Accuracy 4.9680\n",
      "Epoch 566 Batch 10 Loss 0.0363 Accuracy 4.9679\n",
      "Epoch 566 Batch 15 Loss 0.0363 Accuracy 4.9678\n",
      "Epoch 566 Batch 20 Loss 0.0363 Accuracy 4.9678\n",
      "Epoch 566 Batch 25 Loss 0.0363 Accuracy 4.9677\n",
      "Epoch 566 Batch 30 Loss 0.0363 Accuracy 4.9676\n",
      "Epoch 566 Batch 35 Loss 0.0363 Accuracy 4.9675\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9688\n",
      "Epoch 567 Batch 5 Loss 0.0363 Accuracy 4.9674\n",
      "Epoch 567 Batch 10 Loss 0.0363 Accuracy 4.9673\n",
      "Epoch 567 Batch 15 Loss 0.0363 Accuracy 4.9672\n",
      "Epoch 567 Batch 20 Loss 0.0363 Accuracy 4.9671\n",
      "Epoch 567 Batch 25 Loss 0.0363 Accuracy 4.9670\n",
      "Epoch 567 Batch 30 Loss 0.0363 Accuracy 4.9669\n",
      "Epoch 567 Batch 35 Loss 0.0363 Accuracy 4.9668\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9681\n",
      "Epoch 568 Batch 5 Loss 0.0363 Accuracy 4.9667\n",
      "Epoch 568 Batch 10 Loss 0.0363 Accuracy 4.9666\n",
      "Epoch 568 Batch 15 Loss 0.0363 Accuracy 4.9665\n",
      "Epoch 568 Batch 20 Loss 0.0363 Accuracy 4.9665\n",
      "Epoch 568 Batch 25 Loss 0.0362 Accuracy 4.9664\n",
      "Epoch 568 Batch 30 Loss 0.0362 Accuracy 4.9663\n",
      "Epoch 568 Batch 35 Loss 0.0362 Accuracy 4.9662\n",
      "Time taken for 1 epoch: 0.55 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9675\n",
      "Epoch 569 Batch 5 Loss 0.0362 Accuracy 4.9661\n",
      "Epoch 569 Batch 10 Loss 0.0362 Accuracy 4.9660\n",
      "Epoch 569 Batch 15 Loss 0.0362 Accuracy 4.9659\n",
      "Epoch 569 Batch 20 Loss 0.0362 Accuracy 4.9658\n",
      "Epoch 569 Batch 25 Loss 0.0362 Accuracy 4.9657\n",
      "Epoch 569 Batch 30 Loss 0.0362 Accuracy 4.9656\n",
      "Epoch 569 Batch 35 Loss 0.0362 Accuracy 4.9655\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9668\n",
      "Epoch 570 Batch 5 Loss 0.0362 Accuracy 4.9654\n",
      "Epoch 570 Batch 10 Loss 0.0362 Accuracy 4.9653\n",
      "Epoch 570 Batch 15 Loss 0.0362 Accuracy 4.9652\n",
      "Epoch 570 Batch 20 Loss 0.0362 Accuracy 4.9652\n",
      "Epoch 570 Batch 25 Loss 0.0362 Accuracy 4.9651\n",
      "Epoch 570 Batch 30 Loss 0.0362 Accuracy 4.9650\n",
      "Epoch 570 Batch 35 Loss 0.0362 Accuracy 4.9649\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9662\n",
      "Epoch 571 Batch 5 Loss 0.0362 Accuracy 4.9648\n",
      "Epoch 571 Batch 10 Loss 0.0362 Accuracy 4.9647\n",
      "Epoch 571 Batch 15 Loss 0.0362 Accuracy 4.9646\n",
      "Epoch 571 Batch 20 Loss 0.0362 Accuracy 4.9645\n",
      "Epoch 571 Batch 25 Loss 0.0362 Accuracy 4.9644\n",
      "Epoch 571 Batch 30 Loss 0.0362 Accuracy 4.9643\n",
      "Epoch 571 Batch 35 Loss 0.0362 Accuracy 4.9642\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9655\n",
      "Epoch 572 Batch 5 Loss 0.0362 Accuracy 4.9641\n",
      "Epoch 572 Batch 10 Loss 0.0362 Accuracy 4.9640\n",
      "Epoch 572 Batch 15 Loss 0.0362 Accuracy 4.9639\n",
      "Epoch 572 Batch 20 Loss 0.0362 Accuracy 4.9639\n",
      "Epoch 572 Batch 25 Loss 0.0362 Accuracy 4.9638\n",
      "Epoch 572 Batch 30 Loss 0.0362 Accuracy 4.9637\n",
      "Epoch 572 Batch 35 Loss 0.0362 Accuracy 4.9636\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9649\n",
      "Epoch 573 Batch 5 Loss 0.0362 Accuracy 4.9635\n",
      "Epoch 573 Batch 10 Loss 0.0362 Accuracy 4.9634\n",
      "Epoch 573 Batch 15 Loss 0.0362 Accuracy 4.9633\n",
      "Epoch 573 Batch 20 Loss 0.0362 Accuracy 4.9632\n",
      "Epoch 573 Batch 25 Loss 0.0362 Accuracy 4.9631\n",
      "Epoch 573 Batch 30 Loss 0.0362 Accuracy 4.9630\n",
      "Epoch 573 Batch 35 Loss 0.0362 Accuracy 4.9629\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9642\n",
      "Epoch 574 Batch 5 Loss 0.0362 Accuracy 4.9628\n",
      "Epoch 574 Batch 10 Loss 0.0362 Accuracy 4.9627\n",
      "Epoch 574 Batch 15 Loss 0.0362 Accuracy 4.9627\n",
      "Epoch 574 Batch 20 Loss 0.0362 Accuracy 4.9626\n",
      "Epoch 574 Batch 25 Loss 0.0362 Accuracy 4.9625\n",
      "Epoch 574 Batch 30 Loss 0.0362 Accuracy 4.9624\n",
      "Epoch 574 Batch 35 Loss 0.0362 Accuracy 4.9623\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9636\n",
      "Epoch 575 Batch 5 Loss 0.0362 Accuracy 4.9622\n",
      "Epoch 575 Batch 10 Loss 0.0362 Accuracy 4.9621\n",
      "Epoch 575 Batch 15 Loss 0.0362 Accuracy 4.9620\n",
      "Epoch 575 Batch 20 Loss 0.0362 Accuracy 4.9619\n",
      "Epoch 575 Batch 25 Loss 0.0362 Accuracy 4.9618\n",
      "Epoch 575 Batch 30 Loss 0.0362 Accuracy 4.9617\n",
      "Epoch 575 Batch 35 Loss 0.0362 Accuracy 4.9617\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9629\n",
      "Epoch 576 Batch 5 Loss 0.0362 Accuracy 4.9615\n",
      "Epoch 576 Batch 10 Loss 0.0362 Accuracy 4.9614\n",
      "Epoch 576 Batch 15 Loss 0.0362 Accuracy 4.9614\n",
      "Epoch 576 Batch 20 Loss 0.0362 Accuracy 4.9613\n",
      "Epoch 576 Batch 25 Loss 0.0362 Accuracy 4.9612\n",
      "Epoch 576 Batch 30 Loss 0.0362 Accuracy 4.9611\n",
      "Epoch 576 Batch 35 Loss 0.0362 Accuracy 4.9610\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9623\n",
      "Epoch 577 Batch 5 Loss 0.0362 Accuracy 4.9609\n",
      "Epoch 577 Batch 10 Loss 0.0362 Accuracy 4.9608\n",
      "Epoch 577 Batch 15 Loss 0.0362 Accuracy 4.9607\n",
      "Epoch 577 Batch 20 Loss 0.0362 Accuracy 4.9606\n",
      "Epoch 577 Batch 25 Loss 0.0362 Accuracy 4.9605\n",
      "Epoch 577 Batch 30 Loss 0.0362 Accuracy 4.9604\n",
      "Epoch 577 Batch 35 Loss 0.0362 Accuracy 4.9603\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9616\n",
      "Epoch 578 Batch 5 Loss 0.0362 Accuracy 4.9602\n",
      "Epoch 578 Batch 10 Loss 0.0362 Accuracy 4.9601\n",
      "Epoch 578 Batch 15 Loss 0.0362 Accuracy 4.9601\n",
      "Epoch 578 Batch 20 Loss 0.0362 Accuracy 4.9600\n",
      "Epoch 578 Batch 25 Loss 0.0362 Accuracy 4.9599\n",
      "Epoch 578 Batch 30 Loss 0.0361 Accuracy 4.9598\n",
      "Epoch 578 Batch 35 Loss 0.0361 Accuracy 4.9597\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9610\n",
      "Epoch 579 Batch 5 Loss 0.0362 Accuracy 4.9596\n",
      "Epoch 579 Batch 10 Loss 0.0362 Accuracy 4.9595\n",
      "Epoch 579 Batch 15 Loss 0.0362 Accuracy 4.9594\n",
      "Epoch 579 Batch 20 Loss 0.0362 Accuracy 4.9593\n",
      "Epoch 579 Batch 25 Loss 0.0362 Accuracy 4.9592\n",
      "Epoch 579 Batch 30 Loss 0.0361 Accuracy 4.9591\n",
      "Epoch 579 Batch 35 Loss 0.0361 Accuracy 4.9591\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9603\n",
      "Epoch 580 Batch 5 Loss 0.0362 Accuracy 4.9589\n",
      "Epoch 580 Batch 10 Loss 0.0362 Accuracy 4.9588\n",
      "Epoch 580 Batch 15 Loss 0.0362 Accuracy 4.9588\n",
      "Epoch 580 Batch 20 Loss 0.0362 Accuracy 4.9587\n",
      "Epoch 580 Batch 25 Loss 0.0361 Accuracy 4.9586\n",
      "Epoch 580 Batch 30 Loss 0.0361 Accuracy 4.9585\n",
      "Epoch 580 Batch 35 Loss 0.0361 Accuracy 4.9584\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9597\n",
      "Epoch 581 Batch 5 Loss 0.0361 Accuracy 4.9583\n",
      "Epoch 581 Batch 10 Loss 0.0361 Accuracy 4.9582\n",
      "Epoch 581 Batch 15 Loss 0.0361 Accuracy 4.9581\n",
      "Epoch 581 Batch 20 Loss 0.0361 Accuracy 4.9580\n",
      "Epoch 581 Batch 25 Loss 0.0361 Accuracy 4.9579\n",
      "Epoch 581 Batch 30 Loss 0.0361 Accuracy 4.9579\n",
      "Epoch 581 Batch 35 Loss 0.0361 Accuracy 4.9578\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9590\n",
      "Epoch 582 Batch 5 Loss 0.0361 Accuracy 4.9576\n",
      "Epoch 582 Batch 10 Loss 0.0361 Accuracy 4.9576\n",
      "Epoch 582 Batch 15 Loss 0.0361 Accuracy 4.9575\n",
      "Epoch 582 Batch 20 Loss 0.0361 Accuracy 4.9574\n",
      "Epoch 582 Batch 25 Loss 0.0361 Accuracy 4.9573\n",
      "Epoch 582 Batch 30 Loss 0.0361 Accuracy 4.9572\n",
      "Epoch 582 Batch 35 Loss 0.0361 Accuracy 4.9571\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9584\n",
      "Epoch 583 Batch 5 Loss 0.0361 Accuracy 4.9570\n",
      "Epoch 583 Batch 10 Loss 0.0361 Accuracy 4.9569\n",
      "Epoch 583 Batch 15 Loss 0.0361 Accuracy 4.9568\n",
      "Epoch 583 Batch 20 Loss 0.0361 Accuracy 4.9568\n",
      "Epoch 583 Batch 25 Loss 0.0361 Accuracy 4.9567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 583 Batch 30 Loss 0.0361 Accuracy 4.9566\n",
      "Epoch 583 Batch 35 Loss 0.0361 Accuracy 4.9565\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9577\n",
      "Epoch 584 Batch 5 Loss 0.0361 Accuracy 4.9564\n",
      "Epoch 584 Batch 10 Loss 0.0361 Accuracy 4.9563\n",
      "Epoch 584 Batch 15 Loss 0.0361 Accuracy 4.9562\n",
      "Epoch 584 Batch 20 Loss 0.0361 Accuracy 4.9561\n",
      "Epoch 584 Batch 25 Loss 0.0361 Accuracy 4.9560\n",
      "Epoch 584 Batch 30 Loss 0.0361 Accuracy 4.9559\n",
      "Epoch 584 Batch 35 Loss 0.0361 Accuracy 4.9559\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9571\n",
      "Epoch 585 Batch 5 Loss 0.0361 Accuracy 4.9557\n",
      "Epoch 585 Batch 10 Loss 0.0361 Accuracy 4.9557\n",
      "Epoch 585 Batch 15 Loss 0.0361 Accuracy 4.9556\n",
      "Epoch 585 Batch 20 Loss 0.0361 Accuracy 4.9555\n",
      "Epoch 585 Batch 25 Loss 0.0361 Accuracy 4.9554\n",
      "Epoch 585 Batch 30 Loss 0.0361 Accuracy 4.9553\n",
      "Epoch 585 Batch 35 Loss 0.0361 Accuracy 4.9552\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9565\n",
      "Epoch 586 Batch 5 Loss 0.0361 Accuracy 4.9551\n",
      "Epoch 586 Batch 10 Loss 0.0361 Accuracy 4.9550\n",
      "Epoch 586 Batch 15 Loss 0.0361 Accuracy 4.9549\n",
      "Epoch 586 Batch 20 Loss 0.0361 Accuracy 4.9549\n",
      "Epoch 586 Batch 25 Loss 0.0361 Accuracy 4.9548\n",
      "Epoch 586 Batch 30 Loss 0.0361 Accuracy 4.9547\n",
      "Epoch 586 Batch 35 Loss 0.0361 Accuracy 4.9546\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9558\n",
      "Epoch 587 Batch 5 Loss 0.0361 Accuracy 4.9545\n",
      "Epoch 587 Batch 10 Loss 0.0361 Accuracy 4.9544\n",
      "Epoch 587 Batch 15 Loss 0.0361 Accuracy 4.9543\n",
      "Epoch 587 Batch 20 Loss 0.0361 Accuracy 4.9542\n",
      "Epoch 587 Batch 25 Loss 0.0361 Accuracy 4.9541\n",
      "Epoch 587 Batch 30 Loss 0.0361 Accuracy 4.9540\n",
      "Epoch 587 Batch 35 Loss 0.0361 Accuracy 4.9540\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9552\n",
      "Epoch 588 Batch 5 Loss 0.0361 Accuracy 4.9538\n",
      "Epoch 588 Batch 10 Loss 0.0361 Accuracy 4.9537\n",
      "Epoch 588 Batch 15 Loss 0.0361 Accuracy 4.9537\n",
      "Epoch 588 Batch 20 Loss 0.0361 Accuracy 4.9536\n",
      "Epoch 588 Batch 25 Loss 0.0361 Accuracy 4.9535\n",
      "Epoch 588 Batch 30 Loss 0.0361 Accuracy 4.9534\n",
      "Epoch 588 Batch 35 Loss 0.0361 Accuracy 4.9533\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9546\n",
      "Epoch 589 Batch 5 Loss 0.0361 Accuracy 4.9532\n",
      "Epoch 589 Batch 10 Loss 0.0361 Accuracy 4.9531\n",
      "Epoch 589 Batch 15 Loss 0.0361 Accuracy 4.9530\n",
      "Epoch 589 Batch 20 Loss 0.0361 Accuracy 4.9529\n",
      "Epoch 589 Batch 25 Loss 0.0361 Accuracy 4.9529\n",
      "Epoch 589 Batch 30 Loss 0.0361 Accuracy 4.9528\n",
      "Epoch 589 Batch 35 Loss 0.0361 Accuracy 4.9527\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9539\n",
      "Epoch 590 Batch 5 Loss 0.0361 Accuracy 4.9526\n",
      "Epoch 590 Batch 10 Loss 0.0361 Accuracy 4.9525\n",
      "Epoch 590 Batch 15 Loss 0.0361 Accuracy 4.9524\n",
      "Epoch 590 Batch 20 Loss 0.0361 Accuracy 4.9523\n",
      "Epoch 590 Batch 25 Loss 0.0361 Accuracy 4.9522\n",
      "Epoch 590 Batch 30 Loss 0.0361 Accuracy 4.9521\n",
      "Epoch 590 Batch 35 Loss 0.0361 Accuracy 4.9520\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9533\n",
      "Epoch 591 Batch 5 Loss 0.0361 Accuracy 4.9519\n",
      "Epoch 591 Batch 10 Loss 0.0361 Accuracy 4.9518\n",
      "Epoch 591 Batch 15 Loss 0.0361 Accuracy 4.9518\n",
      "Epoch 591 Batch 20 Loss 0.0361 Accuracy 4.9517\n",
      "Epoch 591 Batch 25 Loss 0.0361 Accuracy 4.9516\n",
      "Epoch 591 Batch 30 Loss 0.0361 Accuracy 4.9515\n",
      "Epoch 591 Batch 35 Loss 0.0361 Accuracy 4.9514\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9526\n",
      "Epoch 592 Batch 5 Loss 0.0361 Accuracy 4.9513\n",
      "Epoch 592 Batch 10 Loss 0.0361 Accuracy 4.9512\n",
      "Epoch 592 Batch 15 Loss 0.0361 Accuracy 4.9511\n",
      "Epoch 592 Batch 20 Loss 0.0361 Accuracy 4.9510\n",
      "Epoch 592 Batch 25 Loss 0.0361 Accuracy 4.9510\n",
      "Epoch 592 Batch 30 Loss 0.0361 Accuracy 4.9509\n",
      "Epoch 592 Batch 35 Loss 0.0361 Accuracy 4.9508\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9520\n",
      "Epoch 593 Batch 5 Loss 0.0361 Accuracy 4.9507\n",
      "Epoch 593 Batch 10 Loss 0.0361 Accuracy 4.9506\n",
      "Epoch 593 Batch 15 Loss 0.0361 Accuracy 4.9505\n",
      "Epoch 593 Batch 20 Loss 0.0361 Accuracy 4.9504\n",
      "Epoch 593 Batch 25 Loss 0.0361 Accuracy 4.9503\n",
      "Epoch 593 Batch 30 Loss 0.0360 Accuracy 4.9502\n",
      "Epoch 593 Batch 35 Loss 0.0360 Accuracy 4.9502\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9514\n",
      "Epoch 594 Batch 5 Loss 0.0360 Accuracy 4.9500\n",
      "Epoch 594 Batch 10 Loss 0.0360 Accuracy 4.9499\n",
      "Epoch 594 Batch 15 Loss 0.0360 Accuracy 4.9499\n",
      "Epoch 594 Batch 20 Loss 0.0360 Accuracy 4.9498\n",
      "Epoch 594 Batch 25 Loss 0.0360 Accuracy 4.9497\n",
      "Epoch 594 Batch 30 Loss 0.0360 Accuracy 4.9496\n",
      "Epoch 594 Batch 35 Loss 0.0360 Accuracy 4.9495\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9507\n",
      "Epoch 595 Batch 5 Loss 0.0360 Accuracy 4.9494\n",
      "Epoch 595 Batch 10 Loss 0.0360 Accuracy 4.9493\n",
      "Epoch 595 Batch 15 Loss 0.0360 Accuracy 4.9492\n",
      "Epoch 595 Batch 20 Loss 0.0360 Accuracy 4.9492\n",
      "Epoch 595 Batch 25 Loss 0.0360 Accuracy 4.9491\n",
      "Epoch 595 Batch 30 Loss 0.0360 Accuracy 4.9490\n",
      "Epoch 595 Batch 35 Loss 0.0360 Accuracy 4.9489\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9501\n",
      "Epoch 596 Batch 5 Loss 0.0360 Accuracy 4.9488\n",
      "Epoch 596 Batch 10 Loss 0.0360 Accuracy 4.9487\n",
      "Epoch 596 Batch 15 Loss 0.0360 Accuracy 4.9486\n",
      "Epoch 596 Batch 20 Loss 0.0360 Accuracy 4.9485\n",
      "Epoch 596 Batch 25 Loss 0.0360 Accuracy 4.9484\n",
      "Epoch 596 Batch 30 Loss 0.0360 Accuracy 4.9483\n",
      "Epoch 596 Batch 35 Loss 0.0360 Accuracy 4.9483\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9495\n",
      "Epoch 597 Batch 5 Loss 0.0360 Accuracy 4.9481\n",
      "Epoch 597 Batch 10 Loss 0.0360 Accuracy 4.9481\n",
      "Epoch 597 Batch 15 Loss 0.0360 Accuracy 4.9480\n",
      "Epoch 597 Batch 20 Loss 0.0360 Accuracy 4.9479\n",
      "Epoch 597 Batch 25 Loss 0.0360 Accuracy 4.9478\n",
      "Epoch 597 Batch 30 Loss 0.0360 Accuracy 4.9477\n",
      "Epoch 597 Batch 35 Loss 0.0360 Accuracy 4.9476\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9488\n",
      "Epoch 598 Batch 5 Loss 0.0360 Accuracy 4.9475\n",
      "Epoch 598 Batch 10 Loss 0.0360 Accuracy 4.9474\n",
      "Epoch 598 Batch 15 Loss 0.0360 Accuracy 4.9473\n",
      "Epoch 598 Batch 20 Loss 0.0360 Accuracy 4.9473\n",
      "Epoch 598 Batch 25 Loss 0.0360 Accuracy 4.9472\n",
      "Epoch 598 Batch 30 Loss 0.0360 Accuracy 4.9471\n",
      "Epoch 598 Batch 35 Loss 0.0360 Accuracy 4.9470\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9482\n",
      "Epoch 599 Batch 5 Loss 0.0360 Accuracy 4.9469\n",
      "Epoch 599 Batch 10 Loss 0.0360 Accuracy 4.9468\n",
      "Epoch 599 Batch 15 Loss 0.0360 Accuracy 4.9467\n",
      "Epoch 599 Batch 20 Loss 0.0360 Accuracy 4.9466\n",
      "Epoch 599 Batch 25 Loss 0.0360 Accuracy 4.9465\n",
      "Epoch 599 Batch 30 Loss 0.0360 Accuracy 4.9465\n",
      "Epoch 599 Batch 35 Loss 0.0360 Accuracy 4.9464\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9476\n",
      "Epoch 600 Batch 5 Loss 0.0360 Accuracy 4.9462\n",
      "Epoch 600 Batch 10 Loss 0.0360 Accuracy 4.9462\n",
      "Epoch 600 Batch 15 Loss 0.0360 Accuracy 4.9461\n",
      "Epoch 600 Batch 20 Loss 0.0360 Accuracy 4.9460\n",
      "Epoch 600 Batch 25 Loss 0.0360 Accuracy 4.9459\n",
      "Epoch 600 Batch 30 Loss 0.0360 Accuracy 4.9458\n",
      "Epoch 600 Batch 35 Loss 0.0360 Accuracy 4.9457\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9470\n",
      "Epoch 601 Batch 5 Loss 0.0360 Accuracy 4.9456\n",
      "Epoch 601 Batch 10 Loss 0.0360 Accuracy 4.9455\n",
      "Epoch 601 Batch 15 Loss 0.0360 Accuracy 4.9455\n",
      "Epoch 601 Batch 20 Loss 0.0360 Accuracy 4.9454\n",
      "Epoch 601 Batch 25 Loss 0.0360 Accuracy 4.9453\n",
      "Epoch 601 Batch 30 Loss 0.0360 Accuracy 4.9452\n",
      "Epoch 601 Batch 35 Loss 0.0360 Accuracy 4.9451\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9463\n",
      "Epoch 602 Batch 5 Loss 0.0360 Accuracy 4.9450\n",
      "Epoch 602 Batch 10 Loss 0.0360 Accuracy 4.9449\n",
      "Epoch 602 Batch 15 Loss 0.0360 Accuracy 4.9448\n",
      "Epoch 602 Batch 20 Loss 0.0360 Accuracy 4.9447\n",
      "Epoch 602 Batch 25 Loss 0.0360 Accuracy 4.9447\n",
      "Epoch 602 Batch 30 Loss 0.0360 Accuracy 4.9446\n",
      "Epoch 602 Batch 35 Loss 0.0360 Accuracy 4.9445\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9457\n",
      "Epoch 603 Batch 5 Loss 0.0360 Accuracy 4.9444\n",
      "Epoch 603 Batch 10 Loss 0.0360 Accuracy 4.9443\n",
      "Epoch 603 Batch 15 Loss 0.0360 Accuracy 4.9442\n",
      "Epoch 603 Batch 20 Loss 0.0360 Accuracy 4.9441\n",
      "Epoch 603 Batch 25 Loss 0.0360 Accuracy 4.9440\n",
      "Epoch 603 Batch 30 Loss 0.0360 Accuracy 4.9440\n",
      "Epoch 603 Batch 35 Loss 0.0360 Accuracy 4.9439\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9451\n",
      "Epoch 604 Batch 5 Loss 0.0360 Accuracy 4.9438\n",
      "Epoch 604 Batch 10 Loss 0.0360 Accuracy 4.9437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 604 Batch 15 Loss 0.0360 Accuracy 4.9436\n",
      "Epoch 604 Batch 20 Loss 0.0360 Accuracy 4.9435\n",
      "Epoch 604 Batch 25 Loss 0.0360 Accuracy 4.9434\n",
      "Epoch 604 Batch 30 Loss 0.0360 Accuracy 4.9433\n",
      "Epoch 604 Batch 35 Loss 0.0360 Accuracy 4.9432\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9444\n",
      "Epoch 605 Batch 5 Loss 0.0360 Accuracy 4.9431\n",
      "Epoch 605 Batch 10 Loss 0.0360 Accuracy 4.9430\n",
      "Epoch 605 Batch 15 Loss 0.0360 Accuracy 4.9430\n",
      "Epoch 605 Batch 20 Loss 0.0360 Accuracy 4.9429\n",
      "Epoch 605 Batch 25 Loss 0.0360 Accuracy 4.9428\n",
      "Epoch 605 Batch 30 Loss 0.0360 Accuracy 4.9427\n",
      "Epoch 605 Batch 35 Loss 0.0360 Accuracy 4.9426\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9438\n",
      "Epoch 606 Batch 5 Loss 0.0360 Accuracy 4.9425\n",
      "Epoch 606 Batch 10 Loss 0.0360 Accuracy 4.9424\n",
      "Epoch 606 Batch 15 Loss 0.0360 Accuracy 4.9423\n",
      "Epoch 606 Batch 20 Loss 0.0360 Accuracy 4.9422\n",
      "Epoch 606 Batch 25 Loss 0.0359 Accuracy 4.9422\n",
      "Epoch 606 Batch 30 Loss 0.0359 Accuracy 4.9421\n",
      "Epoch 606 Batch 35 Loss 0.0359 Accuracy 4.9420\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9432\n",
      "Epoch 607 Batch 5 Loss 0.0359 Accuracy 4.9419\n",
      "Epoch 607 Batch 10 Loss 0.0359 Accuracy 4.9418\n",
      "Epoch 607 Batch 15 Loss 0.0359 Accuracy 4.9417\n",
      "Epoch 607 Batch 20 Loss 0.0359 Accuracy 4.9416\n",
      "Epoch 607 Batch 25 Loss 0.0359 Accuracy 4.9415\n",
      "Epoch 607 Batch 30 Loss 0.0359 Accuracy 4.9415\n",
      "Epoch 607 Batch 35 Loss 0.0359 Accuracy 4.9414\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9426\n",
      "Epoch 608 Batch 5 Loss 0.0359 Accuracy 4.9412\n",
      "Epoch 608 Batch 10 Loss 0.0359 Accuracy 4.9412\n",
      "Epoch 608 Batch 15 Loss 0.0359 Accuracy 4.9411\n",
      "Epoch 608 Batch 20 Loss 0.0359 Accuracy 4.9410\n",
      "Epoch 608 Batch 25 Loss 0.0359 Accuracy 4.9409\n",
      "Epoch 608 Batch 30 Loss 0.0359 Accuracy 4.9408\n",
      "Epoch 608 Batch 35 Loss 0.0359 Accuracy 4.9407\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9419\n",
      "Epoch 609 Batch 5 Loss 0.0359 Accuracy 4.9406\n",
      "Epoch 609 Batch 10 Loss 0.0359 Accuracy 4.9405\n",
      "Epoch 609 Batch 15 Loss 0.0359 Accuracy 4.9405\n",
      "Epoch 609 Batch 20 Loss 0.0359 Accuracy 4.9404\n",
      "Epoch 609 Batch 25 Loss 0.0359 Accuracy 4.9403\n",
      "Epoch 609 Batch 30 Loss 0.0359 Accuracy 4.9402\n",
      "Epoch 609 Batch 35 Loss 0.0359 Accuracy 4.9401\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9413\n",
      "Epoch 610 Batch 5 Loss 0.0359 Accuracy 4.9400\n",
      "Epoch 610 Batch 10 Loss 0.0359 Accuracy 4.9399\n",
      "Epoch 610 Batch 15 Loss 0.0359 Accuracy 4.9398\n",
      "Epoch 610 Batch 20 Loss 0.0359 Accuracy 4.9398\n",
      "Epoch 610 Batch 25 Loss 0.0359 Accuracy 4.9397\n",
      "Epoch 610 Batch 30 Loss 0.0359 Accuracy 4.9396\n",
      "Epoch 610 Batch 35 Loss 0.0359 Accuracy 4.9395\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9407\n",
      "Epoch 611 Batch 5 Loss 0.0359 Accuracy 4.9394\n",
      "Epoch 611 Batch 10 Loss 0.0359 Accuracy 4.9393\n",
      "Epoch 611 Batch 15 Loss 0.0359 Accuracy 4.9392\n",
      "Epoch 611 Batch 20 Loss 0.0359 Accuracy 4.9391\n",
      "Epoch 611 Batch 25 Loss 0.0359 Accuracy 4.9391\n",
      "Epoch 611 Batch 30 Loss 0.0359 Accuracy 4.9390\n",
      "Epoch 611 Batch 35 Loss 0.0359 Accuracy 4.9389\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9401\n",
      "Epoch 612 Batch 5 Loss 0.0359 Accuracy 4.9388\n",
      "Epoch 612 Batch 10 Loss 0.0359 Accuracy 4.9387\n",
      "Epoch 612 Batch 15 Loss 0.0359 Accuracy 4.9386\n",
      "Epoch 612 Batch 20 Loss 0.0359 Accuracy 4.9385\n",
      "Epoch 612 Batch 25 Loss 0.0359 Accuracy 4.9384\n",
      "Epoch 612 Batch 30 Loss 0.0359 Accuracy 4.9384\n",
      "Epoch 612 Batch 35 Loss 0.0359 Accuracy 4.9383\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9395\n",
      "Epoch 613 Batch 5 Loss 0.0359 Accuracy 4.9382\n",
      "Epoch 613 Batch 10 Loss 0.0359 Accuracy 4.9381\n",
      "Epoch 613 Batch 15 Loss 0.0359 Accuracy 4.9380\n",
      "Epoch 613 Batch 20 Loss 0.0359 Accuracy 4.9379\n",
      "Epoch 613 Batch 25 Loss 0.0359 Accuracy 4.9378\n",
      "Epoch 613 Batch 30 Loss 0.0359 Accuracy 4.9377\n",
      "Epoch 613 Batch 35 Loss 0.0359 Accuracy 4.9377\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9388\n",
      "Epoch 614 Batch 5 Loss 0.0359 Accuracy 4.9375\n",
      "Epoch 614 Batch 10 Loss 0.0359 Accuracy 4.9375\n",
      "Epoch 614 Batch 15 Loss 0.0359 Accuracy 4.9374\n",
      "Epoch 614 Batch 20 Loss 0.0359 Accuracy 4.9373\n",
      "Epoch 614 Batch 25 Loss 0.0359 Accuracy 4.9372\n",
      "Epoch 614 Batch 30 Loss 0.0359 Accuracy 4.9371\n",
      "Epoch 614 Batch 35 Loss 0.0359 Accuracy 4.9370\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9382\n",
      "Epoch 615 Batch 5 Loss 0.0359 Accuracy 4.9369\n",
      "Epoch 615 Batch 10 Loss 0.0359 Accuracy 4.9368\n",
      "Epoch 615 Batch 15 Loss 0.0359 Accuracy 4.9368\n",
      "Epoch 615 Batch 20 Loss 0.0359 Accuracy 4.9367\n",
      "Epoch 615 Batch 25 Loss 0.0359 Accuracy 4.9366\n",
      "Epoch 615 Batch 30 Loss 0.0359 Accuracy 4.9365\n",
      "Epoch 615 Batch 35 Loss 0.0359 Accuracy 4.9364\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9376\n",
      "Epoch 616 Batch 5 Loss 0.0359 Accuracy 4.9363\n",
      "Epoch 616 Batch 10 Loss 0.0359 Accuracy 4.9362\n",
      "Epoch 616 Batch 15 Loss 0.0359 Accuracy 4.9361\n",
      "Epoch 616 Batch 20 Loss 0.0359 Accuracy 4.9360\n",
      "Epoch 616 Batch 25 Loss 0.0359 Accuracy 4.9360\n",
      "Epoch 616 Batch 30 Loss 0.0359 Accuracy 4.9359\n",
      "Epoch 616 Batch 35 Loss 0.0359 Accuracy 4.9358\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9370\n",
      "Epoch 617 Batch 5 Loss 0.0359 Accuracy 4.9357\n",
      "Epoch 617 Batch 10 Loss 0.0359 Accuracy 4.9356\n",
      "Epoch 617 Batch 15 Loss 0.0359 Accuracy 4.9355\n",
      "Epoch 617 Batch 20 Loss 0.0359 Accuracy 4.9354\n",
      "Epoch 617 Batch 25 Loss 0.0359 Accuracy 4.9353\n",
      "Epoch 617 Batch 30 Loss 0.0359 Accuracy 4.9353\n",
      "Epoch 617 Batch 35 Loss 0.0359 Accuracy 4.9352\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9363\n",
      "Epoch 618 Batch 5 Loss 0.0359 Accuracy 4.9351\n",
      "Epoch 618 Batch 10 Loss 0.0359 Accuracy 4.9350\n",
      "Epoch 618 Batch 15 Loss 0.0359 Accuracy 4.9349\n",
      "Epoch 618 Batch 20 Loss 0.0359 Accuracy 4.9348\n",
      "Epoch 618 Batch 25 Loss 0.0358 Accuracy 4.9347\n",
      "Epoch 618 Batch 30 Loss 0.0358 Accuracy 4.9346\n",
      "Epoch 618 Batch 35 Loss 0.0358 Accuracy 4.9346\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9357\n",
      "Epoch 619 Batch 5 Loss 0.0358 Accuracy 4.9344\n",
      "Epoch 619 Batch 10 Loss 0.0358 Accuracy 4.9344\n",
      "Epoch 619 Batch 15 Loss 0.0358 Accuracy 4.9343\n",
      "Epoch 619 Batch 20 Loss 0.0358 Accuracy 4.9342\n",
      "Epoch 619 Batch 25 Loss 0.0358 Accuracy 4.9341\n",
      "Epoch 619 Batch 30 Loss 0.0358 Accuracy 4.9340\n",
      "Epoch 619 Batch 35 Loss 0.0358 Accuracy 4.9339\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9351\n",
      "Epoch 620 Batch 5 Loss 0.0358 Accuracy 4.9338\n",
      "Epoch 620 Batch 10 Loss 0.0358 Accuracy 4.9338\n",
      "Epoch 620 Batch 15 Loss 0.0358 Accuracy 4.9337\n",
      "Epoch 620 Batch 20 Loss 0.0358 Accuracy 4.9336\n",
      "Epoch 620 Batch 25 Loss 0.0358 Accuracy 4.9335\n",
      "Epoch 620 Batch 30 Loss 0.0358 Accuracy 4.9334\n",
      "Epoch 620 Batch 35 Loss 0.0358 Accuracy 4.9333\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9345\n",
      "Epoch 621 Batch 5 Loss 0.0358 Accuracy 4.9332\n",
      "Epoch 621 Batch 10 Loss 0.0358 Accuracy 4.9331\n",
      "Epoch 621 Batch 15 Loss 0.0358 Accuracy 4.9330\n",
      "Epoch 621 Batch 20 Loss 0.0358 Accuracy 4.9330\n",
      "Epoch 621 Batch 25 Loss 0.0358 Accuracy 4.9329\n",
      "Epoch 621 Batch 30 Loss 0.0358 Accuracy 4.9328\n",
      "Epoch 621 Batch 35 Loss 0.0358 Accuracy 4.9327\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9339\n",
      "Epoch 622 Batch 5 Loss 0.0358 Accuracy 4.9326\n",
      "Epoch 622 Batch 10 Loss 0.0358 Accuracy 4.9325\n",
      "Epoch 622 Batch 15 Loss 0.0358 Accuracy 4.9324\n",
      "Epoch 622 Batch 20 Loss 0.0358 Accuracy 4.9323\n",
      "Epoch 622 Batch 25 Loss 0.0358 Accuracy 4.9323\n",
      "Epoch 622 Batch 30 Loss 0.0358 Accuracy 4.9322\n",
      "Epoch 622 Batch 35 Loss 0.0358 Accuracy 4.9321\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9333\n",
      "Epoch 623 Batch 5 Loss 0.0358 Accuracy 4.9320\n",
      "Epoch 623 Batch 10 Loss 0.0358 Accuracy 4.9319\n",
      "Epoch 623 Batch 15 Loss 0.0358 Accuracy 4.9318\n",
      "Epoch 623 Batch 20 Loss 0.0358 Accuracy 4.9317\n",
      "Epoch 623 Batch 25 Loss 0.0358 Accuracy 4.9316\n",
      "Epoch 623 Batch 30 Loss 0.0358 Accuracy 4.9316\n",
      "Epoch 623 Batch 35 Loss 0.0358 Accuracy 4.9315\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9326\n",
      "Epoch 624 Batch 5 Loss 0.0358 Accuracy 4.9314\n",
      "Epoch 624 Batch 10 Loss 0.0358 Accuracy 4.9313\n",
      "Epoch 624 Batch 15 Loss 0.0358 Accuracy 4.9312\n",
      "Epoch 624 Batch 20 Loss 0.0358 Accuracy 4.9311\n",
      "Epoch 624 Batch 25 Loss 0.0358 Accuracy 4.9310\n",
      "Epoch 624 Batch 30 Loss 0.0358 Accuracy 4.9309\n",
      "Epoch 624 Batch 35 Loss 0.0358 Accuracy 4.9309\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9320\n",
      "Epoch 625 Batch 5 Loss 0.0358 Accuracy 4.9307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 625 Batch 10 Loss 0.0358 Accuracy 4.9307\n",
      "Epoch 625 Batch 15 Loss 0.0358 Accuracy 4.9306\n",
      "Epoch 625 Batch 20 Loss 0.0358 Accuracy 4.9305\n",
      "Epoch 625 Batch 25 Loss 0.0358 Accuracy 4.9304\n",
      "Epoch 625 Batch 30 Loss 0.0358 Accuracy 4.9303\n",
      "Epoch 625 Batch 35 Loss 0.0358 Accuracy 4.9302\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9314\n",
      "Epoch 626 Batch 5 Loss 0.0358 Accuracy 4.9301\n",
      "Epoch 626 Batch 10 Loss 0.0358 Accuracy 4.9300\n",
      "Epoch 626 Batch 15 Loss 0.0358 Accuracy 4.9300\n",
      "Epoch 626 Batch 20 Loss 0.0358 Accuracy 4.9299\n",
      "Epoch 626 Batch 25 Loss 0.0358 Accuracy 4.9298\n",
      "Epoch 626 Batch 30 Loss 0.0358 Accuracy 4.9297\n",
      "Epoch 626 Batch 35 Loss 0.0358 Accuracy 4.9296\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9308\n",
      "Epoch 627 Batch 5 Loss 0.0358 Accuracy 4.9295\n",
      "Epoch 627 Batch 10 Loss 0.0358 Accuracy 4.9294\n",
      "Epoch 627 Batch 15 Loss 0.0358 Accuracy 4.9293\n",
      "Epoch 627 Batch 20 Loss 0.0358 Accuracy 4.9293\n",
      "Epoch 627 Batch 25 Loss 0.0358 Accuracy 4.9292\n",
      "Epoch 627 Batch 30 Loss 0.0358 Accuracy 4.9291\n",
      "Epoch 627 Batch 35 Loss 0.0358 Accuracy 4.9290\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9302\n",
      "Epoch 628 Batch 5 Loss 0.0358 Accuracy 4.9289\n",
      "Epoch 628 Batch 10 Loss 0.0358 Accuracy 4.9288\n",
      "Epoch 628 Batch 15 Loss 0.0358 Accuracy 4.9287\n",
      "Epoch 628 Batch 20 Loss 0.0358 Accuracy 4.9287\n",
      "Epoch 628 Batch 25 Loss 0.0358 Accuracy 4.9286\n",
      "Epoch 628 Batch 30 Loss 0.0358 Accuracy 4.9285\n",
      "Epoch 628 Batch 35 Loss 0.0358 Accuracy 4.9284\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9296\n",
      "Epoch 629 Batch 5 Loss 0.0358 Accuracy 4.9283\n",
      "Epoch 629 Batch 10 Loss 0.0358 Accuracy 4.9282\n",
      "Epoch 629 Batch 15 Loss 0.0358 Accuracy 4.9281\n",
      "Epoch 629 Batch 20 Loss 0.0358 Accuracy 4.9280\n",
      "Epoch 629 Batch 25 Loss 0.0358 Accuracy 4.9280\n",
      "Epoch 629 Batch 30 Loss 0.0358 Accuracy 4.9279\n",
      "Epoch 629 Batch 35 Loss 0.0358 Accuracy 4.9278\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9289\n",
      "Epoch 630 Batch 5 Loss 0.0358 Accuracy 4.9277\n",
      "Epoch 630 Batch 10 Loss 0.0358 Accuracy 4.9276\n",
      "Epoch 630 Batch 15 Loss 0.0358 Accuracy 4.9275\n",
      "Epoch 630 Batch 20 Loss 0.0358 Accuracy 4.9274\n",
      "Epoch 630 Batch 25 Loss 0.0358 Accuracy 4.9274\n",
      "Epoch 630 Batch 30 Loss 0.0358 Accuracy 4.9273\n",
      "Epoch 630 Batch 35 Loss 0.0358 Accuracy 4.9272\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9283\n",
      "Epoch 631 Batch 5 Loss 0.0358 Accuracy 4.9271\n",
      "Epoch 631 Batch 10 Loss 0.0358 Accuracy 4.9270\n",
      "Epoch 631 Batch 15 Loss 0.0358 Accuracy 4.9269\n",
      "Epoch 631 Batch 20 Loss 0.0358 Accuracy 4.9268\n",
      "Epoch 631 Batch 25 Loss 0.0358 Accuracy 4.9267\n",
      "Epoch 631 Batch 30 Loss 0.0358 Accuracy 4.9267\n",
      "Epoch 631 Batch 35 Loss 0.0358 Accuracy 4.9266\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9277\n",
      "Epoch 632 Batch 5 Loss 0.0358 Accuracy 4.9265\n",
      "Epoch 632 Batch 10 Loss 0.0358 Accuracy 4.9264\n",
      "Epoch 632 Batch 15 Loss 0.0358 Accuracy 4.9263\n",
      "Epoch 632 Batch 20 Loss 0.0358 Accuracy 4.9262\n",
      "Epoch 632 Batch 25 Loss 0.0358 Accuracy 4.9261\n",
      "Epoch 632 Batch 30 Loss 0.0358 Accuracy 4.9261\n",
      "Epoch 632 Batch 35 Loss 0.0357 Accuracy 4.9260\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9271\n",
      "Epoch 633 Batch 5 Loss 0.0358 Accuracy 4.9259\n",
      "Epoch 633 Batch 10 Loss 0.0357 Accuracy 4.9258\n",
      "Epoch 633 Batch 15 Loss 0.0357 Accuracy 4.9257\n",
      "Epoch 633 Batch 20 Loss 0.0357 Accuracy 4.9256\n",
      "Epoch 633 Batch 25 Loss 0.0357 Accuracy 4.9255\n",
      "Epoch 633 Batch 30 Loss 0.0357 Accuracy 4.9254\n",
      "Epoch 633 Batch 35 Loss 0.0357 Accuracy 4.9254\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9265\n",
      "Epoch 634 Batch 5 Loss 0.0357 Accuracy 4.9252\n",
      "Epoch 634 Batch 10 Loss 0.0357 Accuracy 4.9252\n",
      "Epoch 634 Batch 15 Loss 0.0357 Accuracy 4.9251\n",
      "Epoch 634 Batch 20 Loss 0.0357 Accuracy 4.9250\n",
      "Epoch 634 Batch 25 Loss 0.0357 Accuracy 4.9249\n",
      "Epoch 634 Batch 30 Loss 0.0357 Accuracy 4.9248\n",
      "Epoch 634 Batch 35 Loss 0.0357 Accuracy 4.9247\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9259\n",
      "Epoch 635 Batch 5 Loss 0.0357 Accuracy 4.9246\n",
      "Epoch 635 Batch 10 Loss 0.0357 Accuracy 4.9246\n",
      "Epoch 635 Batch 15 Loss 0.0357 Accuracy 4.9245\n",
      "Epoch 635 Batch 20 Loss 0.0357 Accuracy 4.9244\n",
      "Epoch 635 Batch 25 Loss 0.0357 Accuracy 4.9243\n",
      "Epoch 635 Batch 30 Loss 0.0357 Accuracy 4.9242\n",
      "Epoch 635 Batch 35 Loss 0.0357 Accuracy 4.9241\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9253\n",
      "Epoch 636 Batch 5 Loss 0.0357 Accuracy 4.9240\n",
      "Epoch 636 Batch 10 Loss 0.0357 Accuracy 4.9239\n",
      "Epoch 636 Batch 15 Loss 0.0357 Accuracy 4.9239\n",
      "Epoch 636 Batch 20 Loss 0.0357 Accuracy 4.9238\n",
      "Epoch 636 Batch 25 Loss 0.0357 Accuracy 4.9237\n",
      "Epoch 636 Batch 30 Loss 0.0357 Accuracy 4.9236\n",
      "Epoch 636 Batch 35 Loss 0.0357 Accuracy 4.9235\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9247\n",
      "Epoch 637 Batch 5 Loss 0.0357 Accuracy 4.9234\n",
      "Epoch 637 Batch 10 Loss 0.0357 Accuracy 4.9233\n",
      "Epoch 637 Batch 15 Loss 0.0357 Accuracy 4.9233\n",
      "Epoch 637 Batch 20 Loss 0.0357 Accuracy 4.9232\n",
      "Epoch 637 Batch 25 Loss 0.0357 Accuracy 4.9231\n",
      "Epoch 637 Batch 30 Loss 0.0357 Accuracy 4.9230\n",
      "Epoch 637 Batch 35 Loss 0.0357 Accuracy 4.9229\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9241\n",
      "Epoch 638 Batch 5 Loss 0.0357 Accuracy 4.9228\n",
      "Epoch 638 Batch 10 Loss 0.0357 Accuracy 4.9227\n",
      "Epoch 638 Batch 15 Loss 0.0357 Accuracy 4.9227\n",
      "Epoch 638 Batch 20 Loss 0.0357 Accuracy 4.9226\n",
      "Epoch 638 Batch 25 Loss 0.0357 Accuracy 4.9225\n",
      "Epoch 638 Batch 30 Loss 0.0357 Accuracy 4.9224\n",
      "Epoch 638 Batch 35 Loss 0.0357 Accuracy 4.9223\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9235\n",
      "Epoch 639 Batch 5 Loss 0.0357 Accuracy 4.9222\n",
      "Epoch 639 Batch 10 Loss 0.0357 Accuracy 4.9221\n",
      "Epoch 639 Batch 15 Loss 0.0357 Accuracy 4.9221\n",
      "Epoch 639 Batch 20 Loss 0.0357 Accuracy 4.9220\n",
      "Epoch 639 Batch 25 Loss 0.0357 Accuracy 4.9219\n",
      "Epoch 639 Batch 30 Loss 0.0357 Accuracy 4.9218\n",
      "Epoch 639 Batch 35 Loss 0.0357 Accuracy 4.9217\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9229\n",
      "Epoch 640 Batch 5 Loss 0.0357 Accuracy 4.9216\n",
      "Epoch 640 Batch 10 Loss 0.0357 Accuracy 4.9215\n",
      "Epoch 640 Batch 15 Loss 0.0357 Accuracy 4.9215\n",
      "Epoch 640 Batch 20 Loss 0.0357 Accuracy 4.9214\n",
      "Epoch 640 Batch 25 Loss 0.0357 Accuracy 4.9213\n",
      "Epoch 640 Batch 30 Loss 0.0357 Accuracy 4.9212\n",
      "Epoch 640 Batch 35 Loss 0.0357 Accuracy 4.9211\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9222\n",
      "Epoch 641 Batch 5 Loss 0.0357 Accuracy 4.9210\n",
      "Epoch 641 Batch 10 Loss 0.0357 Accuracy 4.9209\n",
      "Epoch 641 Batch 15 Loss 0.0357 Accuracy 4.9209\n",
      "Epoch 641 Batch 20 Loss 0.0357 Accuracy 4.9208\n",
      "Epoch 641 Batch 25 Loss 0.0357 Accuracy 4.9207\n",
      "Epoch 641 Batch 30 Loss 0.0357 Accuracy 4.9206\n",
      "Epoch 641 Batch 35 Loss 0.0357 Accuracy 4.9205\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9216\n",
      "Epoch 642 Batch 5 Loss 0.0357 Accuracy 4.9204\n",
      "Epoch 642 Batch 10 Loss 0.0357 Accuracy 4.9203\n",
      "Epoch 642 Batch 15 Loss 0.0357 Accuracy 4.9202\n",
      "Epoch 642 Batch 20 Loss 0.0357 Accuracy 4.9202\n",
      "Epoch 642 Batch 25 Loss 0.0357 Accuracy 4.9201\n",
      "Epoch 642 Batch 30 Loss 0.0357 Accuracy 4.9200\n",
      "Epoch 642 Batch 35 Loss 0.0357 Accuracy 4.9199\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9210\n",
      "Epoch 643 Batch 5 Loss 0.0357 Accuracy 4.9198\n",
      "Epoch 643 Batch 10 Loss 0.0357 Accuracy 4.9197\n",
      "Epoch 643 Batch 15 Loss 0.0357 Accuracy 4.9196\n",
      "Epoch 643 Batch 20 Loss 0.0357 Accuracy 4.9196\n",
      "Epoch 643 Batch 25 Loss 0.0357 Accuracy 4.9195\n",
      "Epoch 643 Batch 30 Loss 0.0357 Accuracy 4.9194\n",
      "Epoch 643 Batch 35 Loss 0.0357 Accuracy 4.9193\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9204\n",
      "Epoch 644 Batch 5 Loss 0.0357 Accuracy 4.9192\n",
      "Epoch 644 Batch 10 Loss 0.0357 Accuracy 4.9191\n",
      "Epoch 644 Batch 15 Loss 0.0357 Accuracy 4.9190\n",
      "Epoch 644 Batch 20 Loss 0.0357 Accuracy 4.9190\n",
      "Epoch 644 Batch 25 Loss 0.0357 Accuracy 4.9189\n",
      "Epoch 644 Batch 30 Loss 0.0357 Accuracy 4.9188\n",
      "Epoch 644 Batch 35 Loss 0.0357 Accuracy 4.9187\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9198\n",
      "Epoch 645 Batch 5 Loss 0.0357 Accuracy 4.9186\n",
      "Epoch 645 Batch 10 Loss 0.0357 Accuracy 4.9185\n",
      "Epoch 645 Batch 15 Loss 0.0356 Accuracy 4.9184\n",
      "Epoch 645 Batch 20 Loss 0.0356 Accuracy 4.9184\n",
      "Epoch 645 Batch 25 Loss 0.0356 Accuracy 4.9183\n",
      "Epoch 645 Batch 30 Loss 0.0356 Accuracy 4.9182\n",
      "Epoch 645 Batch 35 Loss 0.0356 Accuracy 4.9181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9192\n",
      "Epoch 646 Batch 5 Loss 0.0356 Accuracy 4.9180\n",
      "Epoch 646 Batch 10 Loss 0.0356 Accuracy 4.9179\n",
      "Epoch 646 Batch 15 Loss 0.0356 Accuracy 4.9178\n",
      "Epoch 646 Batch 20 Loss 0.0356 Accuracy 4.9178\n",
      "Epoch 646 Batch 25 Loss 0.0356 Accuracy 4.9177\n",
      "Epoch 646 Batch 30 Loss 0.0356 Accuracy 4.9176\n",
      "Epoch 646 Batch 35 Loss 0.0356 Accuracy 4.9175\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9186\n",
      "Epoch 647 Batch 5 Loss 0.0356 Accuracy 4.9174\n",
      "Epoch 647 Batch 10 Loss 0.0356 Accuracy 4.9173\n",
      "Epoch 647 Batch 15 Loss 0.0356 Accuracy 4.9172\n",
      "Epoch 647 Batch 20 Loss 0.0356 Accuracy 4.9172\n",
      "Epoch 647 Batch 25 Loss 0.0356 Accuracy 4.9171\n",
      "Epoch 647 Batch 30 Loss 0.0356 Accuracy 4.9170\n",
      "Epoch 647 Batch 35 Loss 0.0356 Accuracy 4.9169\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9180\n",
      "Epoch 648 Batch 5 Loss 0.0356 Accuracy 4.9168\n",
      "Epoch 648 Batch 10 Loss 0.0356 Accuracy 4.9167\n",
      "Epoch 648 Batch 15 Loss 0.0356 Accuracy 4.9166\n",
      "Epoch 648 Batch 20 Loss 0.0356 Accuracy 4.9166\n",
      "Epoch 648 Batch 25 Loss 0.0356 Accuracy 4.9165\n",
      "Epoch 648 Batch 30 Loss 0.0356 Accuracy 4.9164\n",
      "Epoch 648 Batch 35 Loss 0.0356 Accuracy 4.9163\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9174\n",
      "Epoch 649 Batch 5 Loss 0.0356 Accuracy 4.9162\n",
      "Epoch 649 Batch 10 Loss 0.0356 Accuracy 4.9161\n",
      "Epoch 649 Batch 15 Loss 0.0356 Accuracy 4.9160\n",
      "Epoch 649 Batch 20 Loss 0.0356 Accuracy 4.9160\n",
      "Epoch 649 Batch 25 Loss 0.0356 Accuracy 4.9159\n",
      "Epoch 649 Batch 30 Loss 0.0356 Accuracy 4.9158\n",
      "Epoch 649 Batch 35 Loss 0.0356 Accuracy 4.9157\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9168\n",
      "Epoch 650 Batch 5 Loss 0.0356 Accuracy 4.9156\n",
      "Epoch 650 Batch 10 Loss 0.0356 Accuracy 4.9155\n",
      "Epoch 650 Batch 15 Loss 0.0356 Accuracy 4.9154\n",
      "Epoch 650 Batch 20 Loss 0.0356 Accuracy 4.9154\n",
      "Epoch 650 Batch 25 Loss 0.0356 Accuracy 4.9153\n",
      "Epoch 650 Batch 30 Loss 0.0356 Accuracy 4.9152\n",
      "Epoch 650 Batch 35 Loss 0.0356 Accuracy 4.9151\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9162\n",
      "Epoch 651 Batch 5 Loss 0.0356 Accuracy 4.9150\n",
      "Epoch 651 Batch 10 Loss 0.0356 Accuracy 4.9149\n",
      "Epoch 651 Batch 15 Loss 0.0356 Accuracy 4.9148\n",
      "Epoch 651 Batch 20 Loss 0.0356 Accuracy 4.9148\n",
      "Epoch 651 Batch 25 Loss 0.0356 Accuracy 4.9147\n",
      "Epoch 651 Batch 30 Loss 0.0356 Accuracy 4.9146\n",
      "Epoch 651 Batch 35 Loss 0.0356 Accuracy 4.9145\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9156\n",
      "Epoch 652 Batch 5 Loss 0.0356 Accuracy 4.9144\n",
      "Epoch 652 Batch 10 Loss 0.0356 Accuracy 4.9143\n",
      "Epoch 652 Batch 15 Loss 0.0356 Accuracy 4.9142\n",
      "Epoch 652 Batch 20 Loss 0.0356 Accuracy 4.9142\n",
      "Epoch 652 Batch 25 Loss 0.0356 Accuracy 4.9141\n",
      "Epoch 652 Batch 30 Loss 0.0356 Accuracy 4.9140\n",
      "Epoch 652 Batch 35 Loss 0.0356 Accuracy 4.9139\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9150\n",
      "Epoch 653 Batch 5 Loss 0.0356 Accuracy 4.9138\n",
      "Epoch 653 Batch 10 Loss 0.0356 Accuracy 4.9137\n",
      "Epoch 653 Batch 15 Loss 0.0356 Accuracy 4.9136\n",
      "Epoch 653 Batch 20 Loss 0.0356 Accuracy 4.9136\n",
      "Epoch 653 Batch 25 Loss 0.0356 Accuracy 4.9135\n",
      "Epoch 653 Batch 30 Loss 0.0356 Accuracy 4.9134\n",
      "Epoch 653 Batch 35 Loss 0.0356 Accuracy 4.9133\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9144\n",
      "Epoch 654 Batch 5 Loss 0.0356 Accuracy 4.9132\n",
      "Epoch 654 Batch 10 Loss 0.0356 Accuracy 4.9131\n",
      "Epoch 654 Batch 15 Loss 0.0356 Accuracy 4.9130\n",
      "Epoch 654 Batch 20 Loss 0.0356 Accuracy 4.9130\n",
      "Epoch 654 Batch 25 Loss 0.0356 Accuracy 4.9129\n",
      "Epoch 654 Batch 30 Loss 0.0356 Accuracy 4.9128\n",
      "Epoch 654 Batch 35 Loss 0.0356 Accuracy 4.9127\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9138\n",
      "Epoch 655 Batch 5 Loss 0.0356 Accuracy 4.9126\n",
      "Epoch 655 Batch 10 Loss 0.0356 Accuracy 4.9125\n",
      "Epoch 655 Batch 15 Loss 0.0355 Accuracy 4.9124\n",
      "Epoch 655 Batch 20 Loss 0.0355 Accuracy 4.9124\n",
      "Epoch 655 Batch 25 Loss 0.0355 Accuracy 4.9123\n",
      "Epoch 655 Batch 30 Loss 0.0355 Accuracy 4.9122\n",
      "Epoch 655 Batch 35 Loss 0.0355 Accuracy 4.9121\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9132\n",
      "Epoch 656 Batch 5 Loss 0.0355 Accuracy 4.9120\n",
      "Epoch 656 Batch 10 Loss 0.0355 Accuracy 4.9119\n",
      "Epoch 656 Batch 15 Loss 0.0355 Accuracy 4.9118\n",
      "Epoch 656 Batch 20 Loss 0.0355 Accuracy 4.9118\n",
      "Epoch 656 Batch 25 Loss 0.0355 Accuracy 4.9117\n",
      "Epoch 656 Batch 30 Loss 0.0355 Accuracy 4.9116\n",
      "Epoch 656 Batch 35 Loss 0.0355 Accuracy 4.9115\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9126\n",
      "Epoch 657 Batch 5 Loss 0.0355 Accuracy 4.9114\n",
      "Epoch 657 Batch 10 Loss 0.0355 Accuracy 4.9113\n",
      "Epoch 657 Batch 15 Loss 0.0355 Accuracy 4.9112\n",
      "Epoch 657 Batch 20 Loss 0.0355 Accuracy 4.9112\n",
      "Epoch 657 Batch 25 Loss 0.0355 Accuracy 4.9111\n",
      "Epoch 657 Batch 30 Loss 0.0355 Accuracy 4.9110\n",
      "Epoch 657 Batch 35 Loss 0.0355 Accuracy 4.9109\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9120\n",
      "Epoch 658 Batch 5 Loss 0.0355 Accuracy 4.9108\n",
      "Epoch 658 Batch 10 Loss 0.0355 Accuracy 4.9107\n",
      "Epoch 658 Batch 15 Loss 0.0355 Accuracy 4.9106\n",
      "Epoch 658 Batch 20 Loss 0.0355 Accuracy 4.9106\n",
      "Epoch 658 Batch 25 Loss 0.0355 Accuracy 4.9105\n",
      "Epoch 658 Batch 30 Loss 0.0355 Accuracy 4.9104\n",
      "Epoch 658 Batch 35 Loss 0.0355 Accuracy 4.9103\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9114\n",
      "Epoch 659 Batch 5 Loss 0.0355 Accuracy 4.9102\n",
      "Epoch 659 Batch 10 Loss 0.0355 Accuracy 4.9101\n",
      "Epoch 659 Batch 15 Loss 0.0355 Accuracy 4.9100\n",
      "Epoch 659 Batch 20 Loss 0.0355 Accuracy 4.9100\n",
      "Epoch 659 Batch 25 Loss 0.0355 Accuracy 4.9099\n",
      "Epoch 659 Batch 30 Loss 0.0355 Accuracy 4.9098\n",
      "Epoch 659 Batch 35 Loss 0.0355 Accuracy 4.9097\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9108\n",
      "Epoch 660 Batch 5 Loss 0.0355 Accuracy 4.9096\n",
      "Epoch 660 Batch 10 Loss 0.0355 Accuracy 4.9095\n",
      "Epoch 660 Batch 15 Loss 0.0355 Accuracy 4.9094\n",
      "Epoch 660 Batch 20 Loss 0.0355 Accuracy 4.9094\n",
      "Epoch 660 Batch 25 Loss 0.0355 Accuracy 4.9093\n",
      "Epoch 660 Batch 30 Loss 0.0355 Accuracy 4.9092\n",
      "Epoch 660 Batch 35 Loss 0.0355 Accuracy 4.9091\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9102\n",
      "Epoch 661 Batch 5 Loss 0.0355 Accuracy 4.9090\n",
      "Epoch 661 Batch 10 Loss 0.0355 Accuracy 4.9089\n",
      "Epoch 661 Batch 15 Loss 0.0355 Accuracy 4.9088\n",
      "Epoch 661 Batch 20 Loss 0.0355 Accuracy 4.9088\n",
      "Epoch 661 Batch 25 Loss 0.0355 Accuracy 4.9087\n",
      "Epoch 661 Batch 30 Loss 0.0355 Accuracy 4.9086\n",
      "Epoch 661 Batch 35 Loss 0.0355 Accuracy 4.9085\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9096\n",
      "Epoch 662 Batch 5 Loss 0.0355 Accuracy 4.9084\n",
      "Epoch 662 Batch 10 Loss 0.0355 Accuracy 4.9083\n",
      "Epoch 662 Batch 15 Loss 0.0355 Accuracy 4.9082\n",
      "Epoch 662 Batch 20 Loss 0.0355 Accuracy 4.9082\n",
      "Epoch 662 Batch 25 Loss 0.0355 Accuracy 4.9081\n",
      "Epoch 662 Batch 30 Loss 0.0355 Accuracy 4.9080\n",
      "Epoch 662 Batch 35 Loss 0.0355 Accuracy 4.9079\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9090\n",
      "Epoch 663 Batch 5 Loss 0.0355 Accuracy 4.9078\n",
      "Epoch 663 Batch 10 Loss 0.0355 Accuracy 4.9077\n",
      "Epoch 663 Batch 15 Loss 0.0355 Accuracy 4.9076\n",
      "Epoch 663 Batch 20 Loss 0.0355 Accuracy 4.9075\n",
      "Epoch 663 Batch 25 Loss 0.0355 Accuracy 4.9075\n",
      "Epoch 663 Batch 30 Loss 0.0355 Accuracy 4.9074\n",
      "Epoch 663 Batch 35 Loss 0.0355 Accuracy 4.9073\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9084\n",
      "Epoch 664 Batch 5 Loss 0.0355 Accuracy 4.9072\n",
      "Epoch 664 Batch 10 Loss 0.0355 Accuracy 4.9071\n",
      "Epoch 664 Batch 15 Loss 0.0355 Accuracy 4.9070\n",
      "Epoch 664 Batch 20 Loss 0.0355 Accuracy 4.9069\n",
      "Epoch 664 Batch 25 Loss 0.0355 Accuracy 4.9069\n",
      "Epoch 664 Batch 30 Loss 0.0355 Accuracy 4.9068\n",
      "Epoch 664 Batch 35 Loss 0.0355 Accuracy 4.9067\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9078\n",
      "Epoch 665 Batch 5 Loss 0.0355 Accuracy 4.9066\n",
      "Epoch 665 Batch 10 Loss 0.0355 Accuracy 4.9065\n",
      "Epoch 665 Batch 15 Loss 0.0355 Accuracy 4.9064\n",
      "Epoch 665 Batch 20 Loss 0.0355 Accuracy 4.9063\n",
      "Epoch 665 Batch 25 Loss 0.0355 Accuracy 4.9063\n",
      "Epoch 665 Batch 30 Loss 0.0355 Accuracy 4.9062\n",
      "Epoch 665 Batch 35 Loss 0.0354 Accuracy 4.9061\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9072\n",
      "Epoch 666 Batch 5 Loss 0.0354 Accuracy 4.9060\n",
      "Epoch 666 Batch 10 Loss 0.0354 Accuracy 4.9059\n",
      "Epoch 666 Batch 15 Loss 0.0354 Accuracy 4.9058\n",
      "Epoch 666 Batch 20 Loss 0.0354 Accuracy 4.9057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 666 Batch 25 Loss 0.0354 Accuracy 4.9057\n",
      "Epoch 666 Batch 30 Loss 0.0354 Accuracy 4.9056\n",
      "Epoch 666 Batch 35 Loss 0.0354 Accuracy 4.9055\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9066\n",
      "Epoch 667 Batch 5 Loss 0.0354 Accuracy 4.9054\n",
      "Epoch 667 Batch 10 Loss 0.0354 Accuracy 4.9053\n",
      "Epoch 667 Batch 15 Loss 0.0354 Accuracy 4.9052\n",
      "Epoch 667 Batch 20 Loss 0.0354 Accuracy 4.9051\n",
      "Epoch 667 Batch 25 Loss 0.0354 Accuracy 4.9051\n",
      "Epoch 667 Batch 30 Loss 0.0354 Accuracy 4.9050\n",
      "Epoch 667 Batch 35 Loss 0.0354 Accuracy 4.9049\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9060\n",
      "Epoch 668 Batch 5 Loss 0.0354 Accuracy 4.9048\n",
      "Epoch 668 Batch 10 Loss 0.0354 Accuracy 4.9047\n",
      "Epoch 668 Batch 15 Loss 0.0354 Accuracy 4.9046\n",
      "Epoch 668 Batch 20 Loss 0.0354 Accuracy 4.9046\n",
      "Epoch 668 Batch 25 Loss 0.0354 Accuracy 4.9045\n",
      "Epoch 668 Batch 30 Loss 0.0354 Accuracy 4.9044\n",
      "Epoch 668 Batch 35 Loss 0.0354 Accuracy 4.9043\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9054\n",
      "Epoch 669 Batch 5 Loss 0.0354 Accuracy 4.9042\n",
      "Epoch 669 Batch 10 Loss 0.0354 Accuracy 4.9041\n",
      "Epoch 669 Batch 15 Loss 0.0354 Accuracy 4.9040\n",
      "Epoch 669 Batch 20 Loss 0.0354 Accuracy 4.9040\n",
      "Epoch 669 Batch 25 Loss 0.0354 Accuracy 4.9039\n",
      "Epoch 669 Batch 30 Loss 0.0354 Accuracy 4.9038\n",
      "Epoch 669 Batch 35 Loss 0.0354 Accuracy 4.9037\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9048\n",
      "Epoch 670 Batch 5 Loss 0.0354 Accuracy 4.9036\n",
      "Epoch 670 Batch 10 Loss 0.0354 Accuracy 4.9035\n",
      "Epoch 670 Batch 15 Loss 0.0354 Accuracy 4.9034\n",
      "Epoch 670 Batch 20 Loss 0.0354 Accuracy 4.9034\n",
      "Epoch 670 Batch 25 Loss 0.0354 Accuracy 4.9033\n",
      "Epoch 670 Batch 30 Loss 0.0354 Accuracy 4.9032\n",
      "Epoch 670 Batch 35 Loss 0.0354 Accuracy 4.9031\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9042\n",
      "Epoch 671 Batch 5 Loss 0.0354 Accuracy 4.9030\n",
      "Epoch 671 Batch 10 Loss 0.0354 Accuracy 4.9029\n",
      "Epoch 671 Batch 15 Loss 0.0354 Accuracy 4.9029\n",
      "Epoch 671 Batch 20 Loss 0.0354 Accuracy 4.9028\n",
      "Epoch 671 Batch 25 Loss 0.0354 Accuracy 4.9027\n",
      "Epoch 671 Batch 30 Loss 0.0354 Accuracy 4.9026\n",
      "Epoch 671 Batch 35 Loss 0.0354 Accuracy 4.9025\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9036\n",
      "Epoch 672 Batch 5 Loss 0.0354 Accuracy 4.9024\n",
      "Epoch 672 Batch 10 Loss 0.0354 Accuracy 4.9023\n",
      "Epoch 672 Batch 15 Loss 0.0354 Accuracy 4.9023\n",
      "Epoch 672 Batch 20 Loss 0.0354 Accuracy 4.9022\n",
      "Epoch 672 Batch 25 Loss 0.0354 Accuracy 4.9021\n",
      "Epoch 672 Batch 30 Loss 0.0354 Accuracy 4.9020\n",
      "Epoch 672 Batch 35 Loss 0.0354 Accuracy 4.9019\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9030\n",
      "Epoch 673 Batch 5 Loss 0.0354 Accuracy 4.9018\n",
      "Epoch 673 Batch 10 Loss 0.0354 Accuracy 4.9017\n",
      "Epoch 673 Batch 15 Loss 0.0354 Accuracy 4.9017\n",
      "Epoch 673 Batch 20 Loss 0.0354 Accuracy 4.9016\n",
      "Epoch 673 Batch 25 Loss 0.0354 Accuracy 4.9015\n",
      "Epoch 673 Batch 30 Loss 0.0354 Accuracy 4.9014\n",
      "Epoch 673 Batch 35 Loss 0.0354 Accuracy 4.9013\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9024\n",
      "Epoch 674 Batch 5 Loss 0.0354 Accuracy 4.9012\n",
      "Epoch 674 Batch 10 Loss 0.0354 Accuracy 4.9011\n",
      "Epoch 674 Batch 15 Loss 0.0354 Accuracy 4.9011\n",
      "Epoch 674 Batch 20 Loss 0.0354 Accuracy 4.9010\n",
      "Epoch 674 Batch 25 Loss 0.0354 Accuracy 4.9009\n",
      "Epoch 674 Batch 30 Loss 0.0354 Accuracy 4.9008\n",
      "Epoch 674 Batch 35 Loss 0.0354 Accuracy 4.9007\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9018\n",
      "Epoch 675 Batch 5 Loss 0.0354 Accuracy 4.9006\n",
      "Epoch 675 Batch 10 Loss 0.0354 Accuracy 4.9005\n",
      "Epoch 675 Batch 15 Loss 0.0354 Accuracy 4.9005\n",
      "Epoch 675 Batch 20 Loss 0.0354 Accuracy 4.9004\n",
      "Epoch 675 Batch 25 Loss 0.0354 Accuracy 4.9003\n",
      "Epoch 675 Batch 30 Loss 0.0354 Accuracy 4.9002\n",
      "Epoch 675 Batch 35 Loss 0.0354 Accuracy 4.9001\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9012\n",
      "Epoch 676 Batch 5 Loss 0.0354 Accuracy 4.9000\n",
      "Epoch 676 Batch 10 Loss 0.0354 Accuracy 4.8999\n",
      "Epoch 676 Batch 15 Loss 0.0354 Accuracy 4.8999\n",
      "Epoch 676 Batch 20 Loss 0.0354 Accuracy 4.8998\n",
      "Epoch 676 Batch 25 Loss 0.0354 Accuracy 4.8997\n",
      "Epoch 676 Batch 30 Loss 0.0354 Accuracy 4.8996\n",
      "Epoch 676 Batch 35 Loss 0.0354 Accuracy 4.8995\n",
      "Time taken for 1 epoch: 0.54 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9006\n",
      "Epoch 677 Batch 5 Loss 0.0354 Accuracy 4.8994\n",
      "Epoch 677 Batch 10 Loss 0.0354 Accuracy 4.8994\n",
      "Epoch 677 Batch 15 Loss 0.0354 Accuracy 4.8993\n",
      "Epoch 677 Batch 20 Loss 0.0354 Accuracy 4.8992\n",
      "Epoch 677 Batch 25 Loss 0.0354 Accuracy 4.8991\n",
      "Epoch 677 Batch 30 Loss 0.0354 Accuracy 4.8990\n",
      "Epoch 677 Batch 35 Loss 0.0354 Accuracy 4.8990\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.9000\n",
      "Epoch 678 Batch 5 Loss 0.0354 Accuracy 4.8988\n",
      "Epoch 678 Batch 10 Loss 0.0354 Accuracy 4.8988\n",
      "Epoch 678 Batch 15 Loss 0.0354 Accuracy 4.8987\n",
      "Epoch 678 Batch 20 Loss 0.0354 Accuracy 4.8986\n",
      "Epoch 678 Batch 25 Loss 0.0354 Accuracy 4.8985\n",
      "Epoch 678 Batch 30 Loss 0.0354 Accuracy 4.8984\n",
      "Epoch 678 Batch 35 Loss 0.0354 Accuracy 4.8984\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8994\n",
      "Epoch 679 Batch 5 Loss 0.0354 Accuracy 4.8983\n",
      "Epoch 679 Batch 10 Loss 0.0354 Accuracy 4.8982\n",
      "Epoch 679 Batch 15 Loss 0.0353 Accuracy 4.8981\n",
      "Epoch 679 Batch 20 Loss 0.0353 Accuracy 4.8980\n",
      "Epoch 679 Batch 25 Loss 0.0353 Accuracy 4.8979\n",
      "Epoch 679 Batch 30 Loss 0.0353 Accuracy 4.8979\n",
      "Epoch 679 Batch 35 Loss 0.0353 Accuracy 4.8978\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8988\n",
      "Epoch 680 Batch 5 Loss 0.0353 Accuracy 4.8977\n",
      "Epoch 680 Batch 10 Loss 0.0353 Accuracy 4.8976\n",
      "Epoch 680 Batch 15 Loss 0.0353 Accuracy 4.8975\n",
      "Epoch 680 Batch 20 Loss 0.0353 Accuracy 4.8974\n",
      "Epoch 680 Batch 25 Loss 0.0353 Accuracy 4.8973\n",
      "Epoch 680 Batch 30 Loss 0.0353 Accuracy 4.8973\n",
      "Epoch 680 Batch 35 Loss 0.0353 Accuracy 4.8972\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8982\n",
      "Epoch 681 Batch 5 Loss 0.0353 Accuracy 4.8971\n",
      "Epoch 681 Batch 10 Loss 0.0353 Accuracy 4.8970\n",
      "Epoch 681 Batch 15 Loss 0.0353 Accuracy 4.8969\n",
      "Epoch 681 Batch 20 Loss 0.0353 Accuracy 4.8968\n",
      "Epoch 681 Batch 25 Loss 0.0353 Accuracy 4.8968\n",
      "Epoch 681 Batch 30 Loss 0.0353 Accuracy 4.8967\n",
      "Epoch 681 Batch 35 Loss 0.0353 Accuracy 4.8966\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8976\n",
      "Epoch 682 Batch 5 Loss 0.0353 Accuracy 4.8965\n",
      "Epoch 682 Batch 10 Loss 0.0353 Accuracy 4.8964\n",
      "Epoch 682 Batch 15 Loss 0.0353 Accuracy 4.8963\n",
      "Epoch 682 Batch 20 Loss 0.0353 Accuracy 4.8962\n",
      "Epoch 682 Batch 25 Loss 0.0353 Accuracy 4.8962\n",
      "Epoch 682 Batch 30 Loss 0.0353 Accuracy 4.8961\n",
      "Epoch 682 Batch 35 Loss 0.0353 Accuracy 4.8960\n",
      "Time taken for 1 epoch: 0.43 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8970\n",
      "Epoch 683 Batch 5 Loss 0.0353 Accuracy 4.8959\n",
      "Epoch 683 Batch 10 Loss 0.0353 Accuracy 4.8958\n",
      "Epoch 683 Batch 15 Loss 0.0353 Accuracy 4.8957\n",
      "Epoch 683 Batch 20 Loss 0.0353 Accuracy 4.8956\n",
      "Epoch 683 Batch 25 Loss 0.0353 Accuracy 4.8956\n",
      "Epoch 683 Batch 30 Loss 0.0353 Accuracy 4.8955\n",
      "Epoch 683 Batch 35 Loss 0.0353 Accuracy 4.8954\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8964\n",
      "Epoch 684 Batch 5 Loss 0.0353 Accuracy 4.8953\n",
      "Epoch 684 Batch 10 Loss 0.0353 Accuracy 4.8952\n",
      "Epoch 684 Batch 15 Loss 0.0353 Accuracy 4.8951\n",
      "Epoch 684 Batch 20 Loss 0.0353 Accuracy 4.8951\n",
      "Epoch 684 Batch 25 Loss 0.0353 Accuracy 4.8950\n",
      "Epoch 684 Batch 30 Loss 0.0353 Accuracy 4.8949\n",
      "Epoch 684 Batch 35 Loss 0.0353 Accuracy 4.8948\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8959\n",
      "Epoch 685 Batch 5 Loss 0.0353 Accuracy 4.8947\n",
      "Epoch 685 Batch 10 Loss 0.0353 Accuracy 4.8946\n",
      "Epoch 685 Batch 15 Loss 0.0353 Accuracy 4.8945\n",
      "Epoch 685 Batch 20 Loss 0.0353 Accuracy 4.8945\n",
      "Epoch 685 Batch 25 Loss 0.0353 Accuracy 4.8944\n",
      "Epoch 685 Batch 30 Loss 0.0353 Accuracy 4.8943\n",
      "Epoch 685 Batch 35 Loss 0.0353 Accuracy 4.8942\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8953\n",
      "Epoch 686 Batch 5 Loss 0.0353 Accuracy 4.8941\n",
      "Epoch 686 Batch 10 Loss 0.0353 Accuracy 4.8940\n",
      "Epoch 686 Batch 15 Loss 0.0353 Accuracy 4.8940\n",
      "Epoch 686 Batch 20 Loss 0.0353 Accuracy 4.8939\n",
      "Epoch 686 Batch 25 Loss 0.0353 Accuracy 4.8938\n",
      "Epoch 686 Batch 30 Loss 0.0353 Accuracy 4.8937\n",
      "Epoch 686 Batch 35 Loss 0.0353 Accuracy 4.8936\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8947\n",
      "Epoch 687 Batch 5 Loss 0.0353 Accuracy 4.8935\n",
      "Epoch 687 Batch 10 Loss 0.0353 Accuracy 4.8935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 687 Batch 15 Loss 0.0353 Accuracy 4.8934\n",
      "Epoch 687 Batch 20 Loss 0.0353 Accuracy 4.8933\n",
      "Epoch 687 Batch 25 Loss 0.0353 Accuracy 4.8932\n",
      "Epoch 687 Batch 30 Loss 0.0353 Accuracy 4.8931\n",
      "Epoch 687 Batch 35 Loss 0.0353 Accuracy 4.8931\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8941\n",
      "Epoch 688 Batch 5 Loss 0.0353 Accuracy 4.8929\n",
      "Epoch 688 Batch 10 Loss 0.0353 Accuracy 4.8929\n",
      "Epoch 688 Batch 15 Loss 0.0353 Accuracy 4.8928\n",
      "Epoch 688 Batch 20 Loss 0.0353 Accuracy 4.8927\n",
      "Epoch 688 Batch 25 Loss 0.0353 Accuracy 4.8926\n",
      "Epoch 688 Batch 30 Loss 0.0353 Accuracy 4.8925\n",
      "Epoch 688 Batch 35 Loss 0.0353 Accuracy 4.8925\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8935\n",
      "Epoch 689 Batch 5 Loss 0.0353 Accuracy 4.8924\n",
      "Epoch 689 Batch 10 Loss 0.0353 Accuracy 4.8923\n",
      "Epoch 689 Batch 15 Loss 0.0353 Accuracy 4.8922\n",
      "Epoch 689 Batch 20 Loss 0.0353 Accuracy 4.8921\n",
      "Epoch 689 Batch 25 Loss 0.0353 Accuracy 4.8920\n",
      "Epoch 689 Batch 30 Loss 0.0353 Accuracy 4.8920\n",
      "Epoch 689 Batch 35 Loss 0.0352 Accuracy 4.8919\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8929\n",
      "Epoch 690 Batch 5 Loss 0.0352 Accuracy 4.8918\n",
      "Epoch 690 Batch 10 Loss 0.0352 Accuracy 4.8917\n",
      "Epoch 690 Batch 15 Loss 0.0352 Accuracy 4.8916\n",
      "Epoch 690 Batch 20 Loss 0.0352 Accuracy 4.8915\n",
      "Epoch 690 Batch 25 Loss 0.0352 Accuracy 4.8914\n",
      "Epoch 690 Batch 30 Loss 0.0352 Accuracy 4.8914\n",
      "Epoch 690 Batch 35 Loss 0.0352 Accuracy 4.8913\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8923\n",
      "Epoch 691 Batch 5 Loss 0.0352 Accuracy 4.8912\n",
      "Epoch 691 Batch 10 Loss 0.0352 Accuracy 4.8911\n",
      "Epoch 691 Batch 15 Loss 0.0352 Accuracy 4.8910\n",
      "Epoch 691 Batch 20 Loss 0.0352 Accuracy 4.8909\n",
      "Epoch 691 Batch 25 Loss 0.0352 Accuracy 4.8909\n",
      "Epoch 691 Batch 30 Loss 0.0352 Accuracy 4.8908\n",
      "Epoch 691 Batch 35 Loss 0.0352 Accuracy 4.8907\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8917\n",
      "Epoch 692 Batch 5 Loss 0.0352 Accuracy 4.8906\n",
      "Epoch 692 Batch 10 Loss 0.0352 Accuracy 4.8905\n",
      "Epoch 692 Batch 15 Loss 0.0352 Accuracy 4.8904\n",
      "Epoch 692 Batch 20 Loss 0.0352 Accuracy 4.8903\n",
      "Epoch 692 Batch 25 Loss 0.0352 Accuracy 4.8903\n",
      "Epoch 692 Batch 30 Loss 0.0352 Accuracy 4.8902\n",
      "Epoch 692 Batch 35 Loss 0.0352 Accuracy 4.8901\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8911\n",
      "Epoch 693 Batch 5 Loss 0.0352 Accuracy 4.8900\n",
      "Epoch 693 Batch 10 Loss 0.0352 Accuracy 4.8899\n",
      "Epoch 693 Batch 15 Loss 0.0352 Accuracy 4.8898\n",
      "Epoch 693 Batch 20 Loss 0.0352 Accuracy 4.8898\n",
      "Epoch 693 Batch 25 Loss 0.0352 Accuracy 4.8897\n",
      "Epoch 693 Batch 30 Loss 0.0352 Accuracy 4.8896\n",
      "Epoch 693 Batch 35 Loss 0.0352 Accuracy 4.8895\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8905\n",
      "Epoch 694 Batch 5 Loss 0.0352 Accuracy 4.8894\n",
      "Epoch 694 Batch 10 Loss 0.0352 Accuracy 4.8893\n",
      "Epoch 694 Batch 15 Loss 0.0352 Accuracy 4.8892\n",
      "Epoch 694 Batch 20 Loss 0.0352 Accuracy 4.8892\n",
      "Epoch 694 Batch 25 Loss 0.0352 Accuracy 4.8891\n",
      "Epoch 694 Batch 30 Loss 0.0352 Accuracy 4.8890\n",
      "Epoch 694 Batch 35 Loss 0.0352 Accuracy 4.8889\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8899\n",
      "Epoch 695 Batch 5 Loss 0.0352 Accuracy 4.8888\n",
      "Epoch 695 Batch 10 Loss 0.0352 Accuracy 4.8887\n",
      "Epoch 695 Batch 15 Loss 0.0352 Accuracy 4.8887\n",
      "Epoch 695 Batch 20 Loss 0.0352 Accuracy 4.8886\n",
      "Epoch 695 Batch 25 Loss 0.0352 Accuracy 4.8885\n",
      "Epoch 695 Batch 30 Loss 0.0352 Accuracy 4.8884\n",
      "Epoch 695 Batch 35 Loss 0.0352 Accuracy 4.8883\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8893\n",
      "Epoch 696 Batch 5 Loss 0.0352 Accuracy 4.8882\n",
      "Epoch 696 Batch 10 Loss 0.0352 Accuracy 4.8881\n",
      "Epoch 696 Batch 15 Loss 0.0352 Accuracy 4.8881\n",
      "Epoch 696 Batch 20 Loss 0.0352 Accuracy 4.8880\n",
      "Epoch 696 Batch 25 Loss 0.0352 Accuracy 4.8879\n",
      "Epoch 696 Batch 30 Loss 0.0352 Accuracy 4.8878\n",
      "Epoch 696 Batch 35 Loss 0.0352 Accuracy 4.8877\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8888\n",
      "Epoch 697 Batch 5 Loss 0.0352 Accuracy 4.8876\n",
      "Epoch 697 Batch 10 Loss 0.0352 Accuracy 4.8876\n",
      "Epoch 697 Batch 15 Loss 0.0352 Accuracy 4.8875\n",
      "Epoch 697 Batch 20 Loss 0.0352 Accuracy 4.8874\n",
      "Epoch 697 Batch 25 Loss 0.0352 Accuracy 4.8873\n",
      "Epoch 697 Batch 30 Loss 0.0352 Accuracy 4.8872\n",
      "Epoch 697 Batch 35 Loss 0.0352 Accuracy 4.8872\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8882\n",
      "Epoch 698 Batch 5 Loss 0.0352 Accuracy 4.8870\n",
      "Epoch 698 Batch 10 Loss 0.0352 Accuracy 4.8870\n",
      "Epoch 698 Batch 15 Loss 0.0352 Accuracy 4.8869\n",
      "Epoch 698 Batch 20 Loss 0.0352 Accuracy 4.8868\n",
      "Epoch 698 Batch 25 Loss 0.0352 Accuracy 4.8867\n",
      "Epoch 698 Batch 30 Loss 0.0352 Accuracy 4.8866\n",
      "Epoch 698 Batch 35 Loss 0.0352 Accuracy 4.8866\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8876\n",
      "Epoch 699 Batch 5 Loss 0.0352 Accuracy 4.8865\n",
      "Epoch 699 Batch 10 Loss 0.0352 Accuracy 4.8864\n",
      "Epoch 699 Batch 15 Loss 0.0352 Accuracy 4.8863\n",
      "Epoch 699 Batch 20 Loss 0.0351 Accuracy 4.8862\n",
      "Epoch 699 Batch 25 Loss 0.0351 Accuracy 4.8861\n",
      "Epoch 699 Batch 30 Loss 0.0351 Accuracy 4.8861\n",
      "Epoch 699 Batch 35 Loss 0.0351 Accuracy 4.8860\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8870\n",
      "Epoch 700 Batch 5 Loss 0.0351 Accuracy 4.8859\n",
      "Epoch 700 Batch 10 Loss 0.0351 Accuracy 4.8858\n",
      "Epoch 700 Batch 15 Loss 0.0351 Accuracy 4.8857\n",
      "Epoch 700 Batch 20 Loss 0.0351 Accuracy 4.8856\n",
      "Epoch 700 Batch 25 Loss 0.0351 Accuracy 4.8856\n",
      "Epoch 700 Batch 30 Loss 0.0351 Accuracy 4.8855\n",
      "Epoch 700 Batch 35 Loss 0.0351 Accuracy 4.8854\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8864\n",
      "Epoch 701 Batch 5 Loss 0.0351 Accuracy 4.8853\n",
      "Epoch 701 Batch 10 Loss 0.0351 Accuracy 4.8852\n",
      "Epoch 701 Batch 15 Loss 0.0351 Accuracy 4.8851\n",
      "Epoch 701 Batch 20 Loss 0.0351 Accuracy 4.8850\n",
      "Epoch 701 Batch 25 Loss 0.0351 Accuracy 4.8850\n",
      "Epoch 701 Batch 30 Loss 0.0351 Accuracy 4.8849\n",
      "Epoch 701 Batch 35 Loss 0.0351 Accuracy 4.8848\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8858\n",
      "Epoch 702 Batch 5 Loss 0.0351 Accuracy 4.8847\n",
      "Epoch 702 Batch 10 Loss 0.0351 Accuracy 4.8846\n",
      "Epoch 702 Batch 15 Loss 0.0351 Accuracy 4.8845\n",
      "Epoch 702 Batch 20 Loss 0.0351 Accuracy 4.8844\n",
      "Epoch 702 Batch 25 Loss 0.0351 Accuracy 4.8844\n",
      "Epoch 702 Batch 30 Loss 0.0351 Accuracy 4.8843\n",
      "Epoch 702 Batch 35 Loss 0.0351 Accuracy 4.8842\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8852\n",
      "Epoch 703 Batch 5 Loss 0.0351 Accuracy 4.8841\n",
      "Epoch 703 Batch 10 Loss 0.0351 Accuracy 4.8840\n",
      "Epoch 703 Batch 15 Loss 0.0351 Accuracy 4.8839\n",
      "Epoch 703 Batch 20 Loss 0.0351 Accuracy 4.8839\n",
      "Epoch 703 Batch 25 Loss 0.0351 Accuracy 4.8838\n",
      "Epoch 703 Batch 30 Loss 0.0351 Accuracy 4.8837\n",
      "Epoch 703 Batch 35 Loss 0.0351 Accuracy 4.8836\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8846\n",
      "Epoch 704 Batch 5 Loss 0.0351 Accuracy 4.8835\n",
      "Epoch 704 Batch 10 Loss 0.0351 Accuracy 4.8834\n",
      "Epoch 704 Batch 15 Loss 0.0351 Accuracy 4.8833\n",
      "Epoch 704 Batch 20 Loss 0.0351 Accuracy 4.8833\n",
      "Epoch 704 Batch 25 Loss 0.0351 Accuracy 4.8832\n",
      "Epoch 704 Batch 30 Loss 0.0351 Accuracy 4.8831\n",
      "Epoch 704 Batch 35 Loss 0.0351 Accuracy 4.8830\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8840\n",
      "Epoch 705 Batch 5 Loss 0.0351 Accuracy 4.8829\n",
      "Epoch 705 Batch 10 Loss 0.0351 Accuracy 4.8828\n",
      "Epoch 705 Batch 15 Loss 0.0351 Accuracy 4.8828\n",
      "Epoch 705 Batch 20 Loss 0.0351 Accuracy 4.8827\n",
      "Epoch 705 Batch 25 Loss 0.0351 Accuracy 4.8826\n",
      "Epoch 705 Batch 30 Loss 0.0351 Accuracy 4.8825\n",
      "Epoch 705 Batch 35 Loss 0.0351 Accuracy 4.8824\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8834\n",
      "Epoch 706 Batch 5 Loss 0.0351 Accuracy 4.8823\n",
      "Epoch 706 Batch 10 Loss 0.0351 Accuracy 4.8822\n",
      "Epoch 706 Batch 15 Loss 0.0351 Accuracy 4.8822\n",
      "Epoch 706 Batch 20 Loss 0.0351 Accuracy 4.8821\n",
      "Epoch 706 Batch 25 Loss 0.0351 Accuracy 4.8820\n",
      "Epoch 706 Batch 30 Loss 0.0351 Accuracy 4.8819\n",
      "Epoch 706 Batch 35 Loss 0.0351 Accuracy 4.8819\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8828\n",
      "Epoch 707 Batch 5 Loss 0.0351 Accuracy 4.8817\n",
      "Epoch 707 Batch 10 Loss 0.0351 Accuracy 4.8817\n",
      "Epoch 707 Batch 15 Loss 0.0351 Accuracy 4.8816\n",
      "Epoch 707 Batch 20 Loss 0.0351 Accuracy 4.8815\n",
      "Epoch 707 Batch 25 Loss 0.0351 Accuracy 4.8814\n",
      "Epoch 707 Batch 30 Loss 0.0351 Accuracy 4.8813\n",
      "Epoch 707 Batch 35 Loss 0.0351 Accuracy 4.8813\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 708 Batch 5 Loss 0.0351 Accuracy 4.8812\n",
      "Epoch 708 Batch 10 Loss 0.0351 Accuracy 4.8811\n",
      "Epoch 708 Batch 15 Loss 0.0351 Accuracy 4.8810\n",
      "Epoch 708 Batch 20 Loss 0.0351 Accuracy 4.8809\n",
      "Epoch 708 Batch 25 Loss 0.0351 Accuracy 4.8808\n",
      "Epoch 708 Batch 30 Loss 0.0351 Accuracy 4.8808\n",
      "Epoch 708 Batch 35 Loss 0.0351 Accuracy 4.8807\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8817\n",
      "Epoch 709 Batch 5 Loss 0.0351 Accuracy 4.8806\n",
      "Epoch 709 Batch 10 Loss 0.0351 Accuracy 4.8805\n",
      "Epoch 709 Batch 15 Loss 0.0351 Accuracy 4.8804\n",
      "Epoch 709 Batch 20 Loss 0.0350 Accuracy 4.8803\n",
      "Epoch 709 Batch 25 Loss 0.0350 Accuracy 4.8802\n",
      "Epoch 709 Batch 30 Loss 0.0350 Accuracy 4.8802\n",
      "Epoch 709 Batch 35 Loss 0.0350 Accuracy 4.8801\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8811\n",
      "Epoch 710 Batch 5 Loss 0.0350 Accuracy 4.8800\n",
      "Epoch 710 Batch 10 Loss 0.0350 Accuracy 4.8799\n",
      "Epoch 710 Batch 15 Loss 0.0350 Accuracy 4.8798\n",
      "Epoch 710 Batch 20 Loss 0.0350 Accuracy 4.8797\n",
      "Epoch 710 Batch 25 Loss 0.0350 Accuracy 4.8797\n",
      "Epoch 710 Batch 30 Loss 0.0350 Accuracy 4.8796\n",
      "Epoch 710 Batch 35 Loss 0.0350 Accuracy 4.8795\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8805\n",
      "Epoch 711 Batch 5 Loss 0.0350 Accuracy 4.8794\n",
      "Epoch 711 Batch 10 Loss 0.0350 Accuracy 4.8793\n",
      "Epoch 711 Batch 15 Loss 0.0350 Accuracy 4.8792\n",
      "Epoch 711 Batch 20 Loss 0.0350 Accuracy 4.8791\n",
      "Epoch 711 Batch 25 Loss 0.0350 Accuracy 4.8791\n",
      "Epoch 711 Batch 30 Loss 0.0350 Accuracy 4.8790\n",
      "Epoch 711 Batch 35 Loss 0.0350 Accuracy 4.8789\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8799\n",
      "Epoch 712 Batch 5 Loss 0.0350 Accuracy 4.8788\n",
      "Epoch 712 Batch 10 Loss 0.0350 Accuracy 4.8787\n",
      "Epoch 712 Batch 15 Loss 0.0350 Accuracy 4.8786\n",
      "Epoch 712 Batch 20 Loss 0.0350 Accuracy 4.8786\n",
      "Epoch 712 Batch 25 Loss 0.0350 Accuracy 4.8785\n",
      "Epoch 712 Batch 30 Loss 0.0350 Accuracy 4.8784\n",
      "Epoch 712 Batch 35 Loss 0.0350 Accuracy 4.8783\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8793\n",
      "Epoch 713 Batch 5 Loss 0.0350 Accuracy 4.8782\n",
      "Epoch 713 Batch 10 Loss 0.0350 Accuracy 4.8781\n",
      "Epoch 713 Batch 15 Loss 0.0350 Accuracy 4.8781\n",
      "Epoch 713 Batch 20 Loss 0.0350 Accuracy 4.8780\n",
      "Epoch 713 Batch 25 Loss 0.0350 Accuracy 4.8779\n",
      "Epoch 713 Batch 30 Loss 0.0350 Accuracy 4.8778\n",
      "Epoch 713 Batch 35 Loss 0.0350 Accuracy 4.8777\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8787\n",
      "Epoch 714 Batch 5 Loss 0.0350 Accuracy 4.8776\n",
      "Epoch 714 Batch 10 Loss 0.0350 Accuracy 4.8775\n",
      "Epoch 714 Batch 15 Loss 0.0350 Accuracy 4.8775\n",
      "Epoch 714 Batch 20 Loss 0.0350 Accuracy 4.8774\n",
      "Epoch 714 Batch 25 Loss 0.0350 Accuracy 4.8773\n",
      "Epoch 714 Batch 30 Loss 0.0350 Accuracy 4.8772\n",
      "Epoch 714 Batch 35 Loss 0.0350 Accuracy 4.8772\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8781\n",
      "Epoch 715 Batch 5 Loss 0.0350 Accuracy 4.8770\n",
      "Epoch 715 Batch 10 Loss 0.0350 Accuracy 4.8770\n",
      "Epoch 715 Batch 15 Loss 0.0350 Accuracy 4.8769\n",
      "Epoch 715 Batch 20 Loss 0.0350 Accuracy 4.8768\n",
      "Epoch 715 Batch 25 Loss 0.0350 Accuracy 4.8767\n",
      "Epoch 715 Batch 30 Loss 0.0350 Accuracy 4.8766\n",
      "Epoch 715 Batch 35 Loss 0.0350 Accuracy 4.8766\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8775\n",
      "Epoch 716 Batch 5 Loss 0.0350 Accuracy 4.8765\n",
      "Epoch 716 Batch 10 Loss 0.0350 Accuracy 4.8764\n",
      "Epoch 716 Batch 15 Loss 0.0350 Accuracy 4.8763\n",
      "Epoch 716 Batch 20 Loss 0.0350 Accuracy 4.8762\n",
      "Epoch 716 Batch 25 Loss 0.0350 Accuracy 4.8761\n",
      "Epoch 716 Batch 30 Loss 0.0350 Accuracy 4.8761\n",
      "Epoch 716 Batch 35 Loss 0.0350 Accuracy 4.8760\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8769\n",
      "Epoch 717 Batch 5 Loss 0.0350 Accuracy 4.8759\n",
      "Epoch 717 Batch 10 Loss 0.0350 Accuracy 4.8758\n",
      "Epoch 717 Batch 15 Loss 0.0350 Accuracy 4.8757\n",
      "Epoch 717 Batch 20 Loss 0.0350 Accuracy 4.8756\n",
      "Epoch 717 Batch 25 Loss 0.0350 Accuracy 4.8755\n",
      "Epoch 717 Batch 30 Loss 0.0350 Accuracy 4.8755\n",
      "Epoch 717 Batch 35 Loss 0.0350 Accuracy 4.8754\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8764\n",
      "Epoch 718 Batch 5 Loss 0.0350 Accuracy 4.8753\n",
      "Epoch 718 Batch 10 Loss 0.0350 Accuracy 4.8752\n",
      "Epoch 718 Batch 15 Loss 0.0350 Accuracy 4.8751\n",
      "Epoch 718 Batch 20 Loss 0.0350 Accuracy 4.8750\n",
      "Epoch 718 Batch 25 Loss 0.0350 Accuracy 4.8750\n",
      "Epoch 718 Batch 30 Loss 0.0350 Accuracy 4.8749\n",
      "Epoch 718 Batch 35 Loss 0.0350 Accuracy 4.8748\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8758\n",
      "Epoch 719 Batch 5 Loss 0.0350 Accuracy 4.8747\n",
      "Epoch 719 Batch 10 Loss 0.0350 Accuracy 4.8746\n",
      "Epoch 719 Batch 15 Loss 0.0350 Accuracy 4.8745\n",
      "Epoch 719 Batch 20 Loss 0.0350 Accuracy 4.8745\n",
      "Epoch 719 Batch 25 Loss 0.0349 Accuracy 4.8744\n",
      "Epoch 719 Batch 30 Loss 0.0349 Accuracy 4.8743\n",
      "Epoch 719 Batch 35 Loss 0.0349 Accuracy 4.8742\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8752\n",
      "Epoch 720 Batch 5 Loss 0.0349 Accuracy 4.8741\n",
      "Epoch 720 Batch 10 Loss 0.0349 Accuracy 4.8740\n",
      "Epoch 720 Batch 15 Loss 0.0349 Accuracy 4.8739\n",
      "Epoch 720 Batch 20 Loss 0.0349 Accuracy 4.8739\n",
      "Epoch 720 Batch 25 Loss 0.0349 Accuracy 4.8738\n",
      "Epoch 720 Batch 30 Loss 0.0349 Accuracy 4.8737\n",
      "Epoch 720 Batch 35 Loss 0.0349 Accuracy 4.8736\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8746\n",
      "Epoch 721 Batch 5 Loss 0.0349 Accuracy 4.8735\n",
      "Epoch 721 Batch 10 Loss 0.0349 Accuracy 4.8734\n",
      "Epoch 721 Batch 15 Loss 0.0349 Accuracy 4.8734\n",
      "Epoch 721 Batch 20 Loss 0.0349 Accuracy 4.8733\n",
      "Epoch 721 Batch 25 Loss 0.0349 Accuracy 4.8732\n",
      "Epoch 721 Batch 30 Loss 0.0349 Accuracy 4.8731\n",
      "Epoch 721 Batch 35 Loss 0.0349 Accuracy 4.8730\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8740\n",
      "Epoch 722 Batch 5 Loss 0.0349 Accuracy 4.8729\n",
      "Epoch 722 Batch 10 Loss 0.0349 Accuracy 4.8728\n",
      "Epoch 722 Batch 15 Loss 0.0349 Accuracy 4.8728\n",
      "Epoch 722 Batch 20 Loss 0.0349 Accuracy 4.8727\n",
      "Epoch 722 Batch 25 Loss 0.0349 Accuracy 4.8726\n",
      "Epoch 722 Batch 30 Loss 0.0349 Accuracy 4.8725\n",
      "Epoch 722 Batch 35 Loss 0.0349 Accuracy 4.8724\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8734\n",
      "Epoch 723 Batch 5 Loss 0.0349 Accuracy 4.8723\n",
      "Epoch 723 Batch 10 Loss 0.0349 Accuracy 4.8723\n",
      "Epoch 723 Batch 15 Loss 0.0349 Accuracy 4.8722\n",
      "Epoch 723 Batch 20 Loss 0.0349 Accuracy 4.8721\n",
      "Epoch 723 Batch 25 Loss 0.0349 Accuracy 4.8720\n",
      "Epoch 723 Batch 30 Loss 0.0349 Accuracy 4.8719\n",
      "Epoch 723 Batch 35 Loss 0.0349 Accuracy 4.8719\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8728\n",
      "Epoch 724 Batch 5 Loss 0.0349 Accuracy 4.8717\n",
      "Epoch 724 Batch 10 Loss 0.0349 Accuracy 4.8717\n",
      "Epoch 724 Batch 15 Loss 0.0349 Accuracy 4.8716\n",
      "Epoch 724 Batch 20 Loss 0.0349 Accuracy 4.8715\n",
      "Epoch 724 Batch 25 Loss 0.0349 Accuracy 4.8714\n",
      "Epoch 724 Batch 30 Loss 0.0349 Accuracy 4.8713\n",
      "Epoch 724 Batch 35 Loss 0.0349 Accuracy 4.8713\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8722\n",
      "Epoch 725 Batch 5 Loss 0.0349 Accuracy 4.8712\n",
      "Epoch 725 Batch 10 Loss 0.0349 Accuracy 4.8711\n",
      "Epoch 725 Batch 15 Loss 0.0349 Accuracy 4.8710\n",
      "Epoch 725 Batch 20 Loss 0.0349 Accuracy 4.8709\n",
      "Epoch 725 Batch 25 Loss 0.0349 Accuracy 4.8708\n",
      "Epoch 725 Batch 30 Loss 0.0349 Accuracy 4.8708\n",
      "Epoch 725 Batch 35 Loss 0.0349 Accuracy 4.8707\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8716\n",
      "Epoch 726 Batch 5 Loss 0.0349 Accuracy 4.8706\n",
      "Epoch 726 Batch 10 Loss 0.0349 Accuracy 4.8705\n",
      "Epoch 726 Batch 15 Loss 0.0349 Accuracy 4.8704\n",
      "Epoch 726 Batch 20 Loss 0.0349 Accuracy 4.8703\n",
      "Epoch 726 Batch 25 Loss 0.0349 Accuracy 4.8703\n",
      "Epoch 726 Batch 30 Loss 0.0349 Accuracy 4.8702\n",
      "Epoch 726 Batch 35 Loss 0.0349 Accuracy 4.8701\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8710\n",
      "Epoch 727 Batch 5 Loss 0.0349 Accuracy 4.8700\n",
      "Epoch 727 Batch 10 Loss 0.0349 Accuracy 4.8699\n",
      "Epoch 727 Batch 15 Loss 0.0349 Accuracy 4.8698\n",
      "Epoch 727 Batch 20 Loss 0.0349 Accuracy 4.8697\n",
      "Epoch 727 Batch 25 Loss 0.0349 Accuracy 4.8697\n",
      "Epoch 727 Batch 30 Loss 0.0349 Accuracy 4.8696\n",
      "Epoch 727 Batch 35 Loss 0.0349 Accuracy 4.8695\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8705\n",
      "Epoch 728 Batch 5 Loss 0.0349 Accuracy 4.8694\n",
      "Epoch 728 Batch 10 Loss 0.0349 Accuracy 4.8693\n",
      "Epoch 728 Batch 15 Loss 0.0349 Accuracy 4.8692\n",
      "Epoch 728 Batch 20 Loss 0.0349 Accuracy 4.8692\n",
      "Epoch 728 Batch 25 Loss 0.0348 Accuracy 4.8691\n",
      "Epoch 728 Batch 30 Loss 0.0348 Accuracy 4.8690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 728 Batch 35 Loss 0.0348 Accuracy 4.8689\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8699\n",
      "Epoch 729 Batch 5 Loss 0.0348 Accuracy 4.8688\n",
      "Epoch 729 Batch 10 Loss 0.0348 Accuracy 4.8687\n",
      "Epoch 729 Batch 15 Loss 0.0348 Accuracy 4.8687\n",
      "Epoch 729 Batch 20 Loss 0.0348 Accuracy 4.8686\n",
      "Epoch 729 Batch 25 Loss 0.0348 Accuracy 4.8685\n",
      "Epoch 729 Batch 30 Loss 0.0348 Accuracy 4.8684\n",
      "Epoch 729 Batch 35 Loss 0.0348 Accuracy 4.8683\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8693\n",
      "Epoch 730 Batch 5 Loss 0.0348 Accuracy 4.8682\n",
      "Epoch 730 Batch 10 Loss 0.0348 Accuracy 4.8681\n",
      "Epoch 730 Batch 15 Loss 0.0348 Accuracy 4.8681\n",
      "Epoch 730 Batch 20 Loss 0.0348 Accuracy 4.8680\n",
      "Epoch 730 Batch 25 Loss 0.0348 Accuracy 4.8679\n",
      "Epoch 730 Batch 30 Loss 0.0348 Accuracy 4.8678\n",
      "Epoch 730 Batch 35 Loss 0.0348 Accuracy 4.8677\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8687\n",
      "Epoch 731 Batch 5 Loss 0.0348 Accuracy 4.8676\n",
      "Epoch 731 Batch 10 Loss 0.0348 Accuracy 4.8676\n",
      "Epoch 731 Batch 15 Loss 0.0348 Accuracy 4.8675\n",
      "Epoch 731 Batch 20 Loss 0.0348 Accuracy 4.8674\n",
      "Epoch 731 Batch 25 Loss 0.0348 Accuracy 4.8673\n",
      "Epoch 731 Batch 30 Loss 0.0348 Accuracy 4.8672\n",
      "Epoch 731 Batch 35 Loss 0.0348 Accuracy 4.8672\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8681\n",
      "Epoch 732 Batch 5 Loss 0.0348 Accuracy 4.8670\n",
      "Epoch 732 Batch 10 Loss 0.0348 Accuracy 4.8670\n",
      "Epoch 732 Batch 15 Loss 0.0348 Accuracy 4.8669\n",
      "Epoch 732 Batch 20 Loss 0.0348 Accuracy 4.8668\n",
      "Epoch 732 Batch 25 Loss 0.0348 Accuracy 4.8667\n",
      "Epoch 732 Batch 30 Loss 0.0348 Accuracy 4.8666\n",
      "Epoch 732 Batch 35 Loss 0.0348 Accuracy 4.8666\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8675\n",
      "Epoch 733 Batch 5 Loss 0.0348 Accuracy 4.8665\n",
      "Epoch 733 Batch 10 Loss 0.0348 Accuracy 4.8664\n",
      "Epoch 733 Batch 15 Loss 0.0348 Accuracy 4.8663\n",
      "Epoch 733 Batch 20 Loss 0.0348 Accuracy 4.8662\n",
      "Epoch 733 Batch 25 Loss 0.0348 Accuracy 4.8661\n",
      "Epoch 733 Batch 30 Loss 0.0348 Accuracy 4.8661\n",
      "Epoch 733 Batch 35 Loss 0.0348 Accuracy 4.8660\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8669\n",
      "Epoch 734 Batch 5 Loss 0.0348 Accuracy 4.8659\n",
      "Epoch 734 Batch 10 Loss 0.0348 Accuracy 4.8658\n",
      "Epoch 734 Batch 15 Loss 0.0348 Accuracy 4.8657\n",
      "Epoch 734 Batch 20 Loss 0.0348 Accuracy 4.8656\n",
      "Epoch 734 Batch 25 Loss 0.0348 Accuracy 4.8656\n",
      "Epoch 734 Batch 30 Loss 0.0348 Accuracy 4.8655\n",
      "Epoch 734 Batch 35 Loss 0.0348 Accuracy 4.8654\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8663\n",
      "Epoch 735 Batch 5 Loss 0.0348 Accuracy 4.8653\n",
      "Epoch 735 Batch 10 Loss 0.0348 Accuracy 4.8652\n",
      "Epoch 735 Batch 15 Loss 0.0348 Accuracy 4.8651\n",
      "Epoch 735 Batch 20 Loss 0.0348 Accuracy 4.8651\n",
      "Epoch 735 Batch 25 Loss 0.0348 Accuracy 4.8650\n",
      "Epoch 735 Batch 30 Loss 0.0348 Accuracy 4.8649\n",
      "Epoch 735 Batch 35 Loss 0.0348 Accuracy 4.8648\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8657\n",
      "Epoch 736 Batch 5 Loss 0.0348 Accuracy 4.8647\n",
      "Epoch 736 Batch 10 Loss 0.0348 Accuracy 4.8646\n",
      "Epoch 736 Batch 15 Loss 0.0348 Accuracy 4.8645\n",
      "Epoch 736 Batch 20 Loss 0.0348 Accuracy 4.8645\n",
      "Epoch 736 Batch 25 Loss 0.0348 Accuracy 4.8644\n",
      "Epoch 736 Batch 30 Loss 0.0348 Accuracy 4.8643\n",
      "Epoch 736 Batch 35 Loss 0.0348 Accuracy 4.8642\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8651\n",
      "Epoch 737 Batch 5 Loss 0.0348 Accuracy 4.8641\n",
      "Epoch 737 Batch 10 Loss 0.0348 Accuracy 4.8640\n",
      "Epoch 737 Batch 15 Loss 0.0348 Accuracy 4.8640\n",
      "Epoch 737 Batch 20 Loss 0.0347 Accuracy 4.8639\n",
      "Epoch 737 Batch 25 Loss 0.0347 Accuracy 4.8638\n",
      "Epoch 737 Batch 30 Loss 0.0347 Accuracy 4.8637\n",
      "Epoch 737 Batch 35 Loss 0.0347 Accuracy 4.8636\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8645\n",
      "Epoch 738 Batch 5 Loss 0.0347 Accuracy 4.8635\n",
      "Epoch 738 Batch 10 Loss 0.0347 Accuracy 4.8635\n",
      "Epoch 738 Batch 15 Loss 0.0347 Accuracy 4.8634\n",
      "Epoch 738 Batch 20 Loss 0.0347 Accuracy 4.8633\n",
      "Epoch 738 Batch 25 Loss 0.0347 Accuracy 4.8632\n",
      "Epoch 738 Batch 30 Loss 0.0347 Accuracy 4.8631\n",
      "Epoch 738 Batch 35 Loss 0.0347 Accuracy 4.8630\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8640\n",
      "Epoch 739 Batch 5 Loss 0.0347 Accuracy 4.8629\n",
      "Epoch 739 Batch 10 Loss 0.0347 Accuracy 4.8629\n",
      "Epoch 739 Batch 15 Loss 0.0347 Accuracy 4.8628\n",
      "Epoch 739 Batch 20 Loss 0.0347 Accuracy 4.8627\n",
      "Epoch 739 Batch 25 Loss 0.0347 Accuracy 4.8626\n",
      "Epoch 739 Batch 30 Loss 0.0347 Accuracy 4.8625\n",
      "Epoch 739 Batch 35 Loss 0.0347 Accuracy 4.8625\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8634\n",
      "Epoch 740 Batch 5 Loss 0.0347 Accuracy 4.8623\n",
      "Epoch 740 Batch 10 Loss 0.0347 Accuracy 4.8623\n",
      "Epoch 740 Batch 15 Loss 0.0347 Accuracy 4.8622\n",
      "Epoch 740 Batch 20 Loss 0.0347 Accuracy 4.8621\n",
      "Epoch 740 Batch 25 Loss 0.0347 Accuracy 4.8620\n",
      "Epoch 740 Batch 30 Loss 0.0347 Accuracy 4.8619\n",
      "Epoch 740 Batch 35 Loss 0.0347 Accuracy 4.8619\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8628\n",
      "Epoch 741 Batch 5 Loss 0.0347 Accuracy 4.8617\n",
      "Epoch 741 Batch 10 Loss 0.0347 Accuracy 4.8617\n",
      "Epoch 741 Batch 15 Loss 0.0347 Accuracy 4.8616\n",
      "Epoch 741 Batch 20 Loss 0.0347 Accuracy 4.8615\n",
      "Epoch 741 Batch 25 Loss 0.0347 Accuracy 4.8614\n",
      "Epoch 741 Batch 30 Loss 0.0347 Accuracy 4.8613\n",
      "Epoch 741 Batch 35 Loss 0.0347 Accuracy 4.8613\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8622\n",
      "Epoch 742 Batch 5 Loss 0.0347 Accuracy 4.8612\n",
      "Epoch 742 Batch 10 Loss 0.0347 Accuracy 4.8611\n",
      "Epoch 742 Batch 15 Loss 0.0347 Accuracy 4.8610\n",
      "Epoch 742 Batch 20 Loss 0.0347 Accuracy 4.8609\n",
      "Epoch 742 Batch 25 Loss 0.0347 Accuracy 4.8608\n",
      "Epoch 742 Batch 30 Loss 0.0347 Accuracy 4.8608\n",
      "Epoch 742 Batch 35 Loss 0.0347 Accuracy 4.8607\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8616\n",
      "Epoch 743 Batch 5 Loss 0.0347 Accuracy 4.8606\n",
      "Epoch 743 Batch 10 Loss 0.0347 Accuracy 4.8605\n",
      "Epoch 743 Batch 15 Loss 0.0347 Accuracy 4.8604\n",
      "Epoch 743 Batch 20 Loss 0.0347 Accuracy 4.8603\n",
      "Epoch 743 Batch 25 Loss 0.0347 Accuracy 4.8602\n",
      "Epoch 743 Batch 30 Loss 0.0347 Accuracy 4.8602\n",
      "Epoch 743 Batch 35 Loss 0.0347 Accuracy 4.8601\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8610\n",
      "Epoch 744 Batch 5 Loss 0.0347 Accuracy 4.8600\n",
      "Epoch 744 Batch 10 Loss 0.0347 Accuracy 4.8599\n",
      "Epoch 744 Batch 15 Loss 0.0347 Accuracy 4.8598\n",
      "Epoch 744 Batch 20 Loss 0.0347 Accuracy 4.8597\n",
      "Epoch 744 Batch 25 Loss 0.0347 Accuracy 4.8596\n",
      "Epoch 744 Batch 30 Loss 0.0347 Accuracy 4.8596\n",
      "Epoch 744 Batch 35 Loss 0.0347 Accuracy 4.8595\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8604\n",
      "Epoch 745 Batch 5 Loss 0.0347 Accuracy 4.8594\n",
      "Epoch 745 Batch 10 Loss 0.0347 Accuracy 4.8593\n",
      "Epoch 745 Batch 15 Loss 0.0347 Accuracy 4.8592\n",
      "Epoch 745 Batch 20 Loss 0.0347 Accuracy 4.8591\n",
      "Epoch 745 Batch 25 Loss 0.0347 Accuracy 4.8591\n",
      "Epoch 745 Batch 30 Loss 0.0347 Accuracy 4.8590\n",
      "Epoch 745 Batch 35 Loss 0.0347 Accuracy 4.8589\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8598\n",
      "Epoch 746 Batch 5 Loss 0.0347 Accuracy 4.8588\n",
      "Epoch 746 Batch 10 Loss 0.0347 Accuracy 4.8587\n",
      "Epoch 746 Batch 15 Loss 0.0347 Accuracy 4.8586\n",
      "Epoch 746 Batch 20 Loss 0.0347 Accuracy 4.8586\n",
      "Epoch 746 Batch 25 Loss 0.0347 Accuracy 4.8585\n",
      "Epoch 746 Batch 30 Loss 0.0347 Accuracy 4.8584\n",
      "Epoch 746 Batch 35 Loss 0.0347 Accuracy 4.8583\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8592\n",
      "Epoch 747 Batch 5 Loss 0.0347 Accuracy 4.8582\n",
      "Epoch 747 Batch 10 Loss 0.0346 Accuracy 4.8581\n",
      "Epoch 747 Batch 15 Loss 0.0346 Accuracy 4.8580\n",
      "Epoch 747 Batch 20 Loss 0.0346 Accuracy 4.8580\n",
      "Epoch 747 Batch 25 Loss 0.0346 Accuracy 4.8579\n",
      "Epoch 747 Batch 30 Loss 0.0346 Accuracy 4.8578\n",
      "Epoch 747 Batch 35 Loss 0.0346 Accuracy 4.8577\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8586\n",
      "Epoch 748 Batch 5 Loss 0.0346 Accuracy 4.8576\n",
      "Epoch 748 Batch 10 Loss 0.0346 Accuracy 4.8575\n",
      "Epoch 748 Batch 15 Loss 0.0346 Accuracy 4.8575\n",
      "Epoch 748 Batch 20 Loss 0.0346 Accuracy 4.8574\n",
      "Epoch 748 Batch 25 Loss 0.0346 Accuracy 4.8573\n",
      "Epoch 748 Batch 30 Loss 0.0346 Accuracy 4.8572\n",
      "Epoch 748 Batch 35 Loss 0.0346 Accuracy 4.8572\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8580\n",
      "Epoch 749 Batch 5 Loss 0.0346 Accuracy 4.8570\n",
      "Epoch 749 Batch 10 Loss 0.0346 Accuracy 4.8570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 749 Batch 15 Loss 0.0346 Accuracy 4.8569\n",
      "Epoch 749 Batch 20 Loss 0.0346 Accuracy 4.8568\n",
      "Epoch 749 Batch 25 Loss 0.0346 Accuracy 4.8567\n",
      "Epoch 749 Batch 30 Loss 0.0346 Accuracy 4.8566\n",
      "Epoch 749 Batch 35 Loss 0.0346 Accuracy 4.8566\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8574\n",
      "Epoch 750 Batch 5 Loss 0.0346 Accuracy 4.8565\n",
      "Epoch 750 Batch 10 Loss 0.0346 Accuracy 4.8564\n",
      "Epoch 750 Batch 15 Loss 0.0346 Accuracy 4.8563\n",
      "Epoch 750 Batch 20 Loss 0.0346 Accuracy 4.8562\n",
      "Epoch 750 Batch 25 Loss 0.0346 Accuracy 4.8561\n",
      "Epoch 750 Batch 30 Loss 0.0346 Accuracy 4.8561\n",
      "Epoch 750 Batch 35 Loss 0.0346 Accuracy 4.8560\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8569\n",
      "Epoch 751 Batch 5 Loss 0.0346 Accuracy 4.8559\n",
      "Epoch 751 Batch 10 Loss 0.0346 Accuracy 4.8558\n",
      "Epoch 751 Batch 15 Loss 0.0346 Accuracy 4.8557\n",
      "Epoch 751 Batch 20 Loss 0.0346 Accuracy 4.8556\n",
      "Epoch 751 Batch 25 Loss 0.0346 Accuracy 4.8556\n",
      "Epoch 751 Batch 30 Loss 0.0346 Accuracy 4.8555\n",
      "Epoch 751 Batch 35 Loss 0.0346 Accuracy 4.8554\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8563\n",
      "Epoch 752 Batch 5 Loss 0.0346 Accuracy 4.8553\n",
      "Epoch 752 Batch 10 Loss 0.0346 Accuracy 4.8552\n",
      "Epoch 752 Batch 15 Loss 0.0346 Accuracy 4.8551\n",
      "Epoch 752 Batch 20 Loss 0.0346 Accuracy 4.8550\n",
      "Epoch 752 Batch 25 Loss 0.0346 Accuracy 4.8550\n",
      "Epoch 752 Batch 30 Loss 0.0346 Accuracy 4.8549\n",
      "Epoch 752 Batch 35 Loss 0.0346 Accuracy 4.8548\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8557\n",
      "Epoch 753 Batch 5 Loss 0.0346 Accuracy 4.8547\n",
      "Epoch 753 Batch 10 Loss 0.0346 Accuracy 4.8546\n",
      "Epoch 753 Batch 15 Loss 0.0346 Accuracy 4.8545\n",
      "Epoch 753 Batch 20 Loss 0.0346 Accuracy 4.8544\n",
      "Epoch 753 Batch 25 Loss 0.0346 Accuracy 4.8544\n",
      "Epoch 753 Batch 30 Loss 0.0346 Accuracy 4.8543\n",
      "Epoch 753 Batch 35 Loss 0.0346 Accuracy 4.8542\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8551\n",
      "Epoch 754 Batch 5 Loss 0.0346 Accuracy 4.8541\n",
      "Epoch 754 Batch 10 Loss 0.0346 Accuracy 4.8540\n",
      "Epoch 754 Batch 15 Loss 0.0346 Accuracy 4.8539\n",
      "Epoch 754 Batch 20 Loss 0.0346 Accuracy 4.8538\n",
      "Epoch 754 Batch 25 Loss 0.0346 Accuracy 4.8538\n",
      "Epoch 754 Batch 30 Loss 0.0346 Accuracy 4.8537\n",
      "Epoch 754 Batch 35 Loss 0.0346 Accuracy 4.8536\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8545\n",
      "Epoch 755 Batch 5 Loss 0.0346 Accuracy 4.8535\n",
      "Epoch 755 Batch 10 Loss 0.0346 Accuracy 4.8534\n",
      "Epoch 755 Batch 15 Loss 0.0346 Accuracy 4.8533\n",
      "Epoch 755 Batch 20 Loss 0.0346 Accuracy 4.8533\n",
      "Epoch 755 Batch 25 Loss 0.0346 Accuracy 4.8532\n",
      "Epoch 755 Batch 30 Loss 0.0346 Accuracy 4.8531\n",
      "Epoch 755 Batch 35 Loss 0.0346 Accuracy 4.8530\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8539\n",
      "Epoch 756 Batch 5 Loss 0.0346 Accuracy 4.8529\n",
      "Epoch 756 Batch 10 Loss 0.0346 Accuracy 4.8528\n",
      "Epoch 756 Batch 15 Loss 0.0346 Accuracy 4.8527\n",
      "Epoch 756 Batch 20 Loss 0.0346 Accuracy 4.8527\n",
      "Epoch 756 Batch 25 Loss 0.0346 Accuracy 4.8526\n",
      "Epoch 756 Batch 30 Loss 0.0346 Accuracy 4.8525\n",
      "Epoch 756 Batch 35 Loss 0.0346 Accuracy 4.8524\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8533\n",
      "Epoch 757 Batch 5 Loss 0.0346 Accuracy 4.8523\n",
      "Epoch 757 Batch 10 Loss 0.0346 Accuracy 4.8522\n",
      "Epoch 757 Batch 15 Loss 0.0346 Accuracy 4.8522\n",
      "Epoch 757 Batch 20 Loss 0.0346 Accuracy 4.8521\n",
      "Epoch 757 Batch 25 Loss 0.0346 Accuracy 4.8520\n",
      "Epoch 757 Batch 30 Loss 0.0346 Accuracy 4.8519\n",
      "Epoch 757 Batch 35 Loss 0.0346 Accuracy 4.8518\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8527\n",
      "Epoch 758 Batch 5 Loss 0.0346 Accuracy 4.8517\n",
      "Epoch 758 Batch 10 Loss 0.0346 Accuracy 4.8516\n",
      "Epoch 758 Batch 15 Loss 0.0346 Accuracy 4.8516\n",
      "Epoch 758 Batch 20 Loss 0.0346 Accuracy 4.8515\n",
      "Epoch 758 Batch 25 Loss 0.0346 Accuracy 4.8514\n",
      "Epoch 758 Batch 30 Loss 0.0346 Accuracy 4.8513\n",
      "Epoch 758 Batch 35 Loss 0.0346 Accuracy 4.8512\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8522\n",
      "Epoch 759 Batch 5 Loss 0.0346 Accuracy 4.8511\n",
      "Epoch 759 Batch 10 Loss 0.0346 Accuracy 4.8511\n",
      "Epoch 759 Batch 15 Loss 0.0346 Accuracy 4.8510\n",
      "Epoch 759 Batch 20 Loss 0.0346 Accuracy 4.8509\n",
      "Epoch 759 Batch 25 Loss 0.0345 Accuracy 4.8508\n",
      "Epoch 759 Batch 30 Loss 0.0345 Accuracy 4.8507\n",
      "Epoch 759 Batch 35 Loss 0.0345 Accuracy 4.8507\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8516\n",
      "Epoch 760 Batch 5 Loss 0.0345 Accuracy 4.8505\n",
      "Epoch 760 Batch 10 Loss 0.0345 Accuracy 4.8505\n",
      "Epoch 760 Batch 15 Loss 0.0345 Accuracy 4.8504\n",
      "Epoch 760 Batch 20 Loss 0.0345 Accuracy 4.8503\n",
      "Epoch 760 Batch 25 Loss 0.0345 Accuracy 4.8502\n",
      "Epoch 760 Batch 30 Loss 0.0345 Accuracy 4.8502\n",
      "Epoch 760 Batch 35 Loss 0.0345 Accuracy 4.8501\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8510\n",
      "Epoch 761 Batch 5 Loss 0.0345 Accuracy 4.8500\n",
      "Epoch 761 Batch 10 Loss 0.0345 Accuracy 4.8499\n",
      "Epoch 761 Batch 15 Loss 0.0345 Accuracy 4.8498\n",
      "Epoch 761 Batch 20 Loss 0.0345 Accuracy 4.8497\n",
      "Epoch 761 Batch 25 Loss 0.0345 Accuracy 4.8496\n",
      "Epoch 761 Batch 30 Loss 0.0345 Accuracy 4.8496\n",
      "Epoch 761 Batch 35 Loss 0.0345 Accuracy 4.8495\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8504\n",
      "Epoch 762 Batch 5 Loss 0.0345 Accuracy 4.8494\n",
      "Epoch 762 Batch 10 Loss 0.0345 Accuracy 4.8493\n",
      "Epoch 762 Batch 15 Loss 0.0345 Accuracy 4.8492\n",
      "Epoch 762 Batch 20 Loss 0.0345 Accuracy 4.8491\n",
      "Epoch 762 Batch 25 Loss 0.0345 Accuracy 4.8491\n",
      "Epoch 762 Batch 30 Loss 0.0345 Accuracy 4.8490\n",
      "Epoch 762 Batch 35 Loss 0.0345 Accuracy 4.8489\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8498\n",
      "Epoch 763 Batch 5 Loss 0.0345 Accuracy 4.8488\n",
      "Epoch 763 Batch 10 Loss 0.0345 Accuracy 4.8487\n",
      "Epoch 763 Batch 15 Loss 0.0345 Accuracy 4.8486\n",
      "Epoch 763 Batch 20 Loss 0.0345 Accuracy 4.8486\n",
      "Epoch 763 Batch 25 Loss 0.0345 Accuracy 4.8485\n",
      "Epoch 763 Batch 30 Loss 0.0345 Accuracy 4.8484\n",
      "Epoch 763 Batch 35 Loss 0.0345 Accuracy 4.8483\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8492\n",
      "Epoch 764 Batch 5 Loss 0.0345 Accuracy 4.8482\n",
      "Epoch 764 Batch 10 Loss 0.0345 Accuracy 4.8481\n",
      "Epoch 764 Batch 15 Loss 0.0345 Accuracy 4.8481\n",
      "Epoch 764 Batch 20 Loss 0.0345 Accuracy 4.8480\n",
      "Epoch 764 Batch 25 Loss 0.0345 Accuracy 4.8479\n",
      "Epoch 764 Batch 30 Loss 0.0345 Accuracy 4.8478\n",
      "Epoch 764 Batch 35 Loss 0.0345 Accuracy 4.8478\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8486\n",
      "Epoch 765 Batch 5 Loss 0.0345 Accuracy 4.8476\n",
      "Epoch 765 Batch 10 Loss 0.0345 Accuracy 4.8476\n",
      "Epoch 765 Batch 15 Loss 0.0345 Accuracy 4.8475\n",
      "Epoch 765 Batch 20 Loss 0.0345 Accuracy 4.8474\n",
      "Epoch 765 Batch 25 Loss 0.0345 Accuracy 4.8473\n",
      "Epoch 765 Batch 30 Loss 0.0345 Accuracy 4.8473\n",
      "Epoch 765 Batch 35 Loss 0.0345 Accuracy 4.8472\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8481\n",
      "Epoch 766 Batch 5 Loss 0.0345 Accuracy 4.8471\n",
      "Epoch 766 Batch 10 Loss 0.0345 Accuracy 4.8470\n",
      "Epoch 766 Batch 15 Loss 0.0345 Accuracy 4.8469\n",
      "Epoch 766 Batch 20 Loss 0.0345 Accuracy 4.8468\n",
      "Epoch 766 Batch 25 Loss 0.0345 Accuracy 4.8468\n",
      "Epoch 766 Batch 30 Loss 0.0345 Accuracy 4.8467\n",
      "Epoch 766 Batch 35 Loss 0.0345 Accuracy 4.8466\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8475\n",
      "Epoch 767 Batch 5 Loss 0.0345 Accuracy 4.8465\n",
      "Epoch 767 Batch 10 Loss 0.0345 Accuracy 4.8464\n",
      "Epoch 767 Batch 15 Loss 0.0345 Accuracy 4.8463\n",
      "Epoch 767 Batch 20 Loss 0.0345 Accuracy 4.8463\n",
      "Epoch 767 Batch 25 Loss 0.0345 Accuracy 4.8462\n",
      "Epoch 767 Batch 30 Loss 0.0345 Accuracy 4.8461\n",
      "Epoch 767 Batch 35 Loss 0.0345 Accuracy 4.8460\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8469\n",
      "Epoch 768 Batch 5 Loss 0.0345 Accuracy 4.8459\n",
      "Epoch 768 Batch 10 Loss 0.0345 Accuracy 4.8458\n",
      "Epoch 768 Batch 15 Loss 0.0345 Accuracy 4.8458\n",
      "Epoch 768 Batch 20 Loss 0.0345 Accuracy 4.8457\n",
      "Epoch 768 Batch 25 Loss 0.0345 Accuracy 4.8456\n",
      "Epoch 768 Batch 30 Loss 0.0345 Accuracy 4.8455\n",
      "Epoch 768 Batch 35 Loss 0.0345 Accuracy 4.8455\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8463\n",
      "Epoch 769 Batch 5 Loss 0.0345 Accuracy 4.8453\n",
      "Epoch 769 Batch 10 Loss 0.0345 Accuracy 4.8453\n",
      "Epoch 769 Batch 15 Loss 0.0345 Accuracy 4.8452\n",
      "Epoch 769 Batch 20 Loss 0.0345 Accuracy 4.8451\n",
      "Epoch 769 Batch 25 Loss 0.0345 Accuracy 4.8450\n",
      "Epoch 769 Batch 30 Loss 0.0345 Accuracy 4.8450\n",
      "Epoch 769 Batch 35 Loss 0.0345 Accuracy 4.8449\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8457\n",
      "Epoch 770 Batch 5 Loss 0.0345 Accuracy 4.8448\n",
      "Epoch 770 Batch 10 Loss 0.0345 Accuracy 4.8447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 770 Batch 15 Loss 0.0345 Accuracy 4.8446\n",
      "Epoch 770 Batch 20 Loss 0.0345 Accuracy 4.8445\n",
      "Epoch 770 Batch 25 Loss 0.0345 Accuracy 4.8445\n",
      "Epoch 770 Batch 30 Loss 0.0345 Accuracy 4.8444\n",
      "Epoch 770 Batch 35 Loss 0.0345 Accuracy 4.8443\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8451\n",
      "Epoch 771 Batch 5 Loss 0.0345 Accuracy 4.8442\n",
      "Epoch 771 Batch 10 Loss 0.0345 Accuracy 4.8441\n",
      "Epoch 771 Batch 15 Loss 0.0345 Accuracy 4.8440\n",
      "Epoch 771 Batch 20 Loss 0.0345 Accuracy 4.8440\n",
      "Epoch 771 Batch 25 Loss 0.0345 Accuracy 4.8439\n",
      "Epoch 771 Batch 30 Loss 0.0345 Accuracy 4.8438\n",
      "Epoch 771 Batch 35 Loss 0.0345 Accuracy 4.8437\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8446\n",
      "Epoch 772 Batch 5 Loss 0.0345 Accuracy 4.8436\n",
      "Epoch 772 Batch 10 Loss 0.0345 Accuracy 4.8435\n",
      "Epoch 772 Batch 15 Loss 0.0345 Accuracy 4.8434\n",
      "Epoch 772 Batch 20 Loss 0.0345 Accuracy 4.8434\n",
      "Epoch 772 Batch 25 Loss 0.0345 Accuracy 4.8433\n",
      "Epoch 772 Batch 30 Loss 0.0345 Accuracy 4.8432\n",
      "Epoch 772 Batch 35 Loss 0.0345 Accuracy 4.8431\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8440\n",
      "Epoch 773 Batch 5 Loss 0.0345 Accuracy 4.8430\n",
      "Epoch 773 Batch 10 Loss 0.0344 Accuracy 4.8429\n",
      "Epoch 773 Batch 15 Loss 0.0344 Accuracy 4.8429\n",
      "Epoch 773 Batch 20 Loss 0.0344 Accuracy 4.8428\n",
      "Epoch 773 Batch 25 Loss 0.0344 Accuracy 4.8427\n",
      "Epoch 773 Batch 30 Loss 0.0344 Accuracy 4.8426\n",
      "Epoch 773 Batch 35 Loss 0.0344 Accuracy 4.8425\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8434\n",
      "Epoch 774 Batch 5 Loss 0.0344 Accuracy 4.8424\n",
      "Epoch 774 Batch 10 Loss 0.0344 Accuracy 4.8423\n",
      "Epoch 774 Batch 15 Loss 0.0344 Accuracy 4.8423\n",
      "Epoch 774 Batch 20 Loss 0.0344 Accuracy 4.8422\n",
      "Epoch 774 Batch 25 Loss 0.0344 Accuracy 4.8421\n",
      "Epoch 774 Batch 30 Loss 0.0344 Accuracy 4.8420\n",
      "Epoch 774 Batch 35 Loss 0.0344 Accuracy 4.8420\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8428\n",
      "Epoch 775 Batch 5 Loss 0.0344 Accuracy 4.8418\n",
      "Epoch 775 Batch 10 Loss 0.0344 Accuracy 4.8418\n",
      "Epoch 775 Batch 15 Loss 0.0344 Accuracy 4.8417\n",
      "Epoch 775 Batch 20 Loss 0.0344 Accuracy 4.8416\n",
      "Epoch 775 Batch 25 Loss 0.0344 Accuracy 4.8415\n",
      "Epoch 775 Batch 30 Loss 0.0344 Accuracy 4.8415\n",
      "Epoch 775 Batch 35 Loss 0.0344 Accuracy 4.8414\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8422\n",
      "Epoch 776 Batch 5 Loss 0.0344 Accuracy 4.8413\n",
      "Epoch 776 Batch 10 Loss 0.0344 Accuracy 4.8412\n",
      "Epoch 776 Batch 15 Loss 0.0344 Accuracy 4.8411\n",
      "Epoch 776 Batch 20 Loss 0.0344 Accuracy 4.8410\n",
      "Epoch 776 Batch 25 Loss 0.0344 Accuracy 4.8409\n",
      "Epoch 776 Batch 30 Loss 0.0344 Accuracy 4.8409\n",
      "Epoch 776 Batch 35 Loss 0.0344 Accuracy 4.8408\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8417\n",
      "Epoch 777 Batch 5 Loss 0.0344 Accuracy 4.8407\n",
      "Epoch 777 Batch 10 Loss 0.0344 Accuracy 4.8406\n",
      "Epoch 777 Batch 15 Loss 0.0344 Accuracy 4.8405\n",
      "Epoch 777 Batch 20 Loss 0.0344 Accuracy 4.8404\n",
      "Epoch 777 Batch 25 Loss 0.0344 Accuracy 4.8404\n",
      "Epoch 777 Batch 30 Loss 0.0344 Accuracy 4.8403\n",
      "Epoch 777 Batch 35 Loss 0.0344 Accuracy 4.8402\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8411\n",
      "Epoch 778 Batch 5 Loss 0.0344 Accuracy 4.8401\n",
      "Epoch 778 Batch 10 Loss 0.0344 Accuracy 4.8400\n",
      "Epoch 778 Batch 15 Loss 0.0344 Accuracy 4.8399\n",
      "Epoch 778 Batch 20 Loss 0.0344 Accuracy 4.8399\n",
      "Epoch 778 Batch 25 Loss 0.0344 Accuracy 4.8398\n",
      "Epoch 778 Batch 30 Loss 0.0344 Accuracy 4.8397\n",
      "Epoch 778 Batch 35 Loss 0.0344 Accuracy 4.8396\n",
      "Time taken for 1 epoch: 0.63 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8405\n",
      "Epoch 779 Batch 5 Loss 0.0344 Accuracy 4.8395\n",
      "Epoch 779 Batch 10 Loss 0.0344 Accuracy 4.8394\n",
      "Epoch 779 Batch 15 Loss 0.0344 Accuracy 4.8394\n",
      "Epoch 779 Batch 20 Loss 0.0344 Accuracy 4.8393\n",
      "Epoch 779 Batch 25 Loss 0.0344 Accuracy 4.8392\n",
      "Epoch 779 Batch 30 Loss 0.0344 Accuracy 4.8391\n",
      "Epoch 779 Batch 35 Loss 0.0344 Accuracy 4.8391\n",
      "Time taken for 1 epoch: 0.58 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8399\n",
      "Epoch 780 Batch 5 Loss 0.0344 Accuracy 4.8389\n",
      "Epoch 780 Batch 10 Loss 0.0344 Accuracy 4.8389\n",
      "Epoch 780 Batch 15 Loss 0.0344 Accuracy 4.8388\n",
      "Epoch 780 Batch 20 Loss 0.0344 Accuracy 4.8387\n",
      "Epoch 780 Batch 25 Loss 0.0344 Accuracy 4.8386\n",
      "Epoch 780 Batch 30 Loss 0.0344 Accuracy 4.8386\n",
      "Epoch 780 Batch 35 Loss 0.0344 Accuracy 4.8385\n",
      "Time taken for 1 epoch: 0.58 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8393\n",
      "Epoch 781 Batch 5 Loss 0.0344 Accuracy 4.8384\n",
      "Epoch 781 Batch 10 Loss 0.0344 Accuracy 4.8383\n",
      "Epoch 781 Batch 15 Loss 0.0344 Accuracy 4.8382\n",
      "Epoch 781 Batch 20 Loss 0.0344 Accuracy 4.8381\n",
      "Epoch 781 Batch 25 Loss 0.0344 Accuracy 4.8381\n",
      "Epoch 781 Batch 30 Loss 0.0344 Accuracy 4.8380\n",
      "Epoch 781 Batch 35 Loss 0.0344 Accuracy 4.8379\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8388\n",
      "Epoch 782 Batch 5 Loss 0.0344 Accuracy 4.8378\n",
      "Epoch 782 Batch 10 Loss 0.0344 Accuracy 4.8377\n",
      "Epoch 782 Batch 15 Loss 0.0344 Accuracy 4.8376\n",
      "Epoch 782 Batch 20 Loss 0.0344 Accuracy 4.8376\n",
      "Epoch 782 Batch 25 Loss 0.0344 Accuracy 4.8375\n",
      "Epoch 782 Batch 30 Loss 0.0344 Accuracy 4.8374\n",
      "Epoch 782 Batch 35 Loss 0.0344 Accuracy 4.8373\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8382\n",
      "Epoch 783 Batch 5 Loss 0.0344 Accuracy 4.8372\n",
      "Epoch 783 Batch 10 Loss 0.0344 Accuracy 4.8372\n",
      "Epoch 783 Batch 15 Loss 0.0344 Accuracy 4.8371\n",
      "Epoch 783 Batch 20 Loss 0.0344 Accuracy 4.8370\n",
      "Epoch 783 Batch 25 Loss 0.0344 Accuracy 4.8369\n",
      "Epoch 783 Batch 30 Loss 0.0344 Accuracy 4.8368\n",
      "Epoch 783 Batch 35 Loss 0.0344 Accuracy 4.8368\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8376\n",
      "Epoch 784 Batch 5 Loss 0.0344 Accuracy 4.8367\n",
      "Epoch 784 Batch 10 Loss 0.0344 Accuracy 4.8366\n",
      "Epoch 784 Batch 15 Loss 0.0344 Accuracy 4.8365\n",
      "Epoch 784 Batch 20 Loss 0.0344 Accuracy 4.8364\n",
      "Epoch 784 Batch 25 Loss 0.0343 Accuracy 4.8364\n",
      "Epoch 784 Batch 30 Loss 0.0343 Accuracy 4.8363\n",
      "Epoch 784 Batch 35 Loss 0.0343 Accuracy 4.8362\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8370\n",
      "Epoch 785 Batch 5 Loss 0.0343 Accuracy 4.8361\n",
      "Epoch 785 Batch 10 Loss 0.0343 Accuracy 4.8360\n",
      "Epoch 785 Batch 15 Loss 0.0343 Accuracy 4.8359\n",
      "Epoch 785 Batch 20 Loss 0.0343 Accuracy 4.8359\n",
      "Epoch 785 Batch 25 Loss 0.0343 Accuracy 4.8358\n",
      "Epoch 785 Batch 30 Loss 0.0343 Accuracy 4.8357\n",
      "Epoch 785 Batch 35 Loss 0.0343 Accuracy 4.8356\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8365\n",
      "Epoch 786 Batch 5 Loss 0.0343 Accuracy 4.8355\n",
      "Epoch 786 Batch 10 Loss 0.0343 Accuracy 4.8354\n",
      "Epoch 786 Batch 15 Loss 0.0343 Accuracy 4.8354\n",
      "Epoch 786 Batch 20 Loss 0.0343 Accuracy 4.8353\n",
      "Epoch 786 Batch 25 Loss 0.0343 Accuracy 4.8352\n",
      "Epoch 786 Batch 30 Loss 0.0343 Accuracy 4.8351\n",
      "Epoch 786 Batch 35 Loss 0.0343 Accuracy 4.8351\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8359\n",
      "Epoch 787 Batch 5 Loss 0.0343 Accuracy 4.8350\n",
      "Epoch 787 Batch 10 Loss 0.0343 Accuracy 4.8349\n",
      "Epoch 787 Batch 15 Loss 0.0343 Accuracy 4.8348\n",
      "Epoch 787 Batch 20 Loss 0.0343 Accuracy 4.8347\n",
      "Epoch 787 Batch 25 Loss 0.0343 Accuracy 4.8347\n",
      "Epoch 787 Batch 30 Loss 0.0343 Accuracy 4.8346\n",
      "Epoch 787 Batch 35 Loss 0.0343 Accuracy 4.8345\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8353\n",
      "Epoch 788 Batch 5 Loss 0.0343 Accuracy 4.8344\n",
      "Epoch 788 Batch 10 Loss 0.0343 Accuracy 4.8343\n",
      "Epoch 788 Batch 15 Loss 0.0343 Accuracy 4.8342\n",
      "Epoch 788 Batch 20 Loss 0.0343 Accuracy 4.8342\n",
      "Epoch 788 Batch 25 Loss 0.0343 Accuracy 4.8341\n",
      "Epoch 788 Batch 30 Loss 0.0343 Accuracy 4.8340\n",
      "Epoch 788 Batch 35 Loss 0.0343 Accuracy 4.8339\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8347\n",
      "Epoch 789 Batch 5 Loss 0.0343 Accuracy 4.8338\n",
      "Epoch 789 Batch 10 Loss 0.0343 Accuracy 4.8337\n",
      "Epoch 789 Batch 15 Loss 0.0343 Accuracy 4.8336\n",
      "Epoch 789 Batch 20 Loss 0.0343 Accuracy 4.8336\n",
      "Epoch 789 Batch 25 Loss 0.0343 Accuracy 4.8335\n",
      "Epoch 789 Batch 30 Loss 0.0343 Accuracy 4.8334\n",
      "Epoch 789 Batch 35 Loss 0.0343 Accuracy 4.8333\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8342\n",
      "Epoch 790 Batch 5 Loss 0.0343 Accuracy 4.8332\n",
      "Epoch 790 Batch 10 Loss 0.0343 Accuracy 4.8331\n",
      "Epoch 790 Batch 15 Loss 0.0343 Accuracy 4.8331\n",
      "Epoch 790 Batch 20 Loss 0.0343 Accuracy 4.8330\n",
      "Epoch 790 Batch 25 Loss 0.0343 Accuracy 4.8329\n",
      "Epoch 790 Batch 30 Loss 0.0343 Accuracy 4.8328\n",
      "Epoch 790 Batch 35 Loss 0.0343 Accuracy 4.8328\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8336\n",
      "Epoch 791 Batch 5 Loss 0.0343 Accuracy 4.8326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 791 Batch 10 Loss 0.0343 Accuracy 4.8326\n",
      "Epoch 791 Batch 15 Loss 0.0343 Accuracy 4.8325\n",
      "Epoch 791 Batch 20 Loss 0.0343 Accuracy 4.8324\n",
      "Epoch 791 Batch 25 Loss 0.0343 Accuracy 4.8323\n",
      "Epoch 791 Batch 30 Loss 0.0343 Accuracy 4.8323\n",
      "Epoch 791 Batch 35 Loss 0.0343 Accuracy 4.8322\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8330\n",
      "Epoch 792 Batch 5 Loss 0.0343 Accuracy 4.8321\n",
      "Epoch 792 Batch 10 Loss 0.0343 Accuracy 4.8320\n",
      "Epoch 792 Batch 15 Loss 0.0343 Accuracy 4.8319\n",
      "Epoch 792 Batch 20 Loss 0.0343 Accuracy 4.8318\n",
      "Epoch 792 Batch 25 Loss 0.0343 Accuracy 4.8318\n",
      "Epoch 792 Batch 30 Loss 0.0343 Accuracy 4.8317\n",
      "Epoch 792 Batch 35 Loss 0.0343 Accuracy 4.8316\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8324\n",
      "Epoch 793 Batch 5 Loss 0.0343 Accuracy 4.8315\n",
      "Epoch 793 Batch 10 Loss 0.0343 Accuracy 4.8314\n",
      "Epoch 793 Batch 15 Loss 0.0343 Accuracy 4.8313\n",
      "Epoch 793 Batch 20 Loss 0.0343 Accuracy 4.8313\n",
      "Epoch 793 Batch 25 Loss 0.0343 Accuracy 4.8312\n",
      "Epoch 793 Batch 30 Loss 0.0343 Accuracy 4.8311\n",
      "Epoch 793 Batch 35 Loss 0.0343 Accuracy 4.8310\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8319\n",
      "Epoch 794 Batch 5 Loss 0.0343 Accuracy 4.8309\n",
      "Epoch 794 Batch 10 Loss 0.0343 Accuracy 4.8308\n",
      "Epoch 794 Batch 15 Loss 0.0343 Accuracy 4.8308\n",
      "Epoch 794 Batch 20 Loss 0.0343 Accuracy 4.8307\n",
      "Epoch 794 Batch 25 Loss 0.0343 Accuracy 4.8306\n",
      "Epoch 794 Batch 30 Loss 0.0343 Accuracy 4.8305\n",
      "Epoch 794 Batch 35 Loss 0.0343 Accuracy 4.8304\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8313\n",
      "Epoch 795 Batch 5 Loss 0.0343 Accuracy 4.8303\n",
      "Epoch 795 Batch 10 Loss 0.0343 Accuracy 4.8303\n",
      "Epoch 795 Batch 15 Loss 0.0343 Accuracy 4.8302\n",
      "Epoch 795 Batch 20 Loss 0.0343 Accuracy 4.8301\n",
      "Epoch 795 Batch 25 Loss 0.0343 Accuracy 4.8300\n",
      "Epoch 795 Batch 30 Loss 0.0343 Accuracy 4.8300\n",
      "Epoch 795 Batch 35 Loss 0.0343 Accuracy 4.8299\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8307\n",
      "Epoch 796 Batch 5 Loss 0.0343 Accuracy 4.8298\n",
      "Epoch 796 Batch 10 Loss 0.0343 Accuracy 4.8297\n",
      "Epoch 796 Batch 15 Loss 0.0343 Accuracy 4.8296\n",
      "Epoch 796 Batch 20 Loss 0.0343 Accuracy 4.8295\n",
      "Epoch 796 Batch 25 Loss 0.0343 Accuracy 4.8295\n",
      "Epoch 796 Batch 30 Loss 0.0343 Accuracy 4.8294\n",
      "Epoch 796 Batch 35 Loss 0.0343 Accuracy 4.8293\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8302\n",
      "Epoch 797 Batch 5 Loss 0.0343 Accuracy 4.8292\n",
      "Epoch 797 Batch 10 Loss 0.0343 Accuracy 4.8291\n",
      "Epoch 797 Batch 15 Loss 0.0343 Accuracy 4.8290\n",
      "Epoch 797 Batch 20 Loss 0.0343 Accuracy 4.8290\n",
      "Epoch 797 Batch 25 Loss 0.0343 Accuracy 4.8289\n",
      "Epoch 797 Batch 30 Loss 0.0343 Accuracy 4.8288\n",
      "Epoch 797 Batch 35 Loss 0.0343 Accuracy 4.8287\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8296\n",
      "Epoch 798 Batch 5 Loss 0.0342 Accuracy 4.8286\n",
      "Epoch 798 Batch 10 Loss 0.0342 Accuracy 4.8285\n",
      "Epoch 798 Batch 15 Loss 0.0342 Accuracy 4.8285\n",
      "Epoch 798 Batch 20 Loss 0.0342 Accuracy 4.8284\n",
      "Epoch 798 Batch 25 Loss 0.0342 Accuracy 4.8283\n",
      "Epoch 798 Batch 30 Loss 0.0342 Accuracy 4.8282\n",
      "Epoch 798 Batch 35 Loss 0.0342 Accuracy 4.8282\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8290\n",
      "Epoch 799 Batch 5 Loss 0.0342 Accuracy 4.8281\n",
      "Epoch 799 Batch 10 Loss 0.0342 Accuracy 4.8280\n",
      "Epoch 799 Batch 15 Loss 0.0342 Accuracy 4.8279\n",
      "Epoch 799 Batch 20 Loss 0.0342 Accuracy 4.8278\n",
      "Epoch 799 Batch 25 Loss 0.0342 Accuracy 4.8277\n",
      "Epoch 799 Batch 30 Loss 0.0342 Accuracy 4.8277\n",
      "Epoch 799 Batch 35 Loss 0.0342 Accuracy 4.8276\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8284\n",
      "Epoch 800 Batch 5 Loss 0.0342 Accuracy 4.8275\n",
      "Epoch 800 Batch 10 Loss 0.0342 Accuracy 4.8274\n",
      "Epoch 800 Batch 15 Loss 0.0342 Accuracy 4.8273\n",
      "Epoch 800 Batch 20 Loss 0.0342 Accuracy 4.8273\n",
      "Epoch 800 Batch 25 Loss 0.0342 Accuracy 4.8272\n",
      "Epoch 800 Batch 30 Loss 0.0342 Accuracy 4.8271\n",
      "Epoch 800 Batch 35 Loss 0.0342 Accuracy 4.8270\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8279\n",
      "Epoch 801 Batch 5 Loss 0.0342 Accuracy 4.8269\n",
      "Epoch 801 Batch 10 Loss 0.0342 Accuracy 4.8268\n",
      "Epoch 801 Batch 15 Loss 0.0342 Accuracy 4.8268\n",
      "Epoch 801 Batch 20 Loss 0.0342 Accuracy 4.8267\n",
      "Epoch 801 Batch 25 Loss 0.0342 Accuracy 4.8266\n",
      "Epoch 801 Batch 30 Loss 0.0342 Accuracy 4.8265\n",
      "Epoch 801 Batch 35 Loss 0.0342 Accuracy 4.8265\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8273\n",
      "Epoch 802 Batch 5 Loss 0.0342 Accuracy 4.8264\n",
      "Epoch 802 Batch 10 Loss 0.0342 Accuracy 4.8263\n",
      "Epoch 802 Batch 15 Loss 0.0342 Accuracy 4.8262\n",
      "Epoch 802 Batch 20 Loss 0.0342 Accuracy 4.8261\n",
      "Epoch 802 Batch 25 Loss 0.0342 Accuracy 4.8261\n",
      "Epoch 802 Batch 30 Loss 0.0342 Accuracy 4.8260\n",
      "Epoch 802 Batch 35 Loss 0.0342 Accuracy 4.8259\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8267\n",
      "Epoch 803 Batch 5 Loss 0.0342 Accuracy 4.8258\n",
      "Epoch 803 Batch 10 Loss 0.0342 Accuracy 4.8257\n",
      "Epoch 803 Batch 15 Loss 0.0342 Accuracy 4.8256\n",
      "Epoch 803 Batch 20 Loss 0.0342 Accuracy 4.8256\n",
      "Epoch 803 Batch 25 Loss 0.0342 Accuracy 4.8255\n",
      "Epoch 803 Batch 30 Loss 0.0342 Accuracy 4.8254\n",
      "Epoch 803 Batch 35 Loss 0.0342 Accuracy 4.8253\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8261\n",
      "Epoch 804 Batch 5 Loss 0.0342 Accuracy 4.8252\n",
      "Epoch 804 Batch 10 Loss 0.0342 Accuracy 4.8251\n",
      "Epoch 804 Batch 15 Loss 0.0342 Accuracy 4.8251\n",
      "Epoch 804 Batch 20 Loss 0.0342 Accuracy 4.8250\n",
      "Epoch 804 Batch 25 Loss 0.0342 Accuracy 4.8249\n",
      "Epoch 804 Batch 30 Loss 0.0342 Accuracy 4.8248\n",
      "Epoch 804 Batch 35 Loss 0.0342 Accuracy 4.8248\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8256\n",
      "Epoch 805 Batch 5 Loss 0.0342 Accuracy 4.8246\n",
      "Epoch 805 Batch 10 Loss 0.0342 Accuracy 4.8246\n",
      "Epoch 805 Batch 15 Loss 0.0342 Accuracy 4.8245\n",
      "Epoch 805 Batch 20 Loss 0.0342 Accuracy 4.8244\n",
      "Epoch 805 Batch 25 Loss 0.0342 Accuracy 4.8243\n",
      "Epoch 805 Batch 30 Loss 0.0342 Accuracy 4.8243\n",
      "Epoch 805 Batch 35 Loss 0.0342 Accuracy 4.8242\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8250\n",
      "Epoch 806 Batch 5 Loss 0.0342 Accuracy 4.8241\n",
      "Epoch 806 Batch 10 Loss 0.0342 Accuracy 4.8240\n",
      "Epoch 806 Batch 15 Loss 0.0342 Accuracy 4.8239\n",
      "Epoch 806 Batch 20 Loss 0.0342 Accuracy 4.8238\n",
      "Epoch 806 Batch 25 Loss 0.0342 Accuracy 4.8238\n",
      "Epoch 806 Batch 30 Loss 0.0342 Accuracy 4.8237\n",
      "Epoch 806 Batch 35 Loss 0.0342 Accuracy 4.8236\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8244\n",
      "Epoch 807 Batch 5 Loss 0.0342 Accuracy 4.8235\n",
      "Epoch 807 Batch 10 Loss 0.0342 Accuracy 4.8234\n",
      "Epoch 807 Batch 15 Loss 0.0342 Accuracy 4.8233\n",
      "Epoch 807 Batch 20 Loss 0.0342 Accuracy 4.8233\n",
      "Epoch 807 Batch 25 Loss 0.0342 Accuracy 4.8232\n",
      "Epoch 807 Batch 30 Loss 0.0342 Accuracy 4.8231\n",
      "Epoch 807 Batch 35 Loss 0.0342 Accuracy 4.8230\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8239\n",
      "Epoch 808 Batch 5 Loss 0.0342 Accuracy 4.8229\n",
      "Epoch 808 Batch 10 Loss 0.0342 Accuracy 4.8228\n",
      "Epoch 808 Batch 15 Loss 0.0342 Accuracy 4.8228\n",
      "Epoch 808 Batch 20 Loss 0.0342 Accuracy 4.8227\n",
      "Epoch 808 Batch 25 Loss 0.0342 Accuracy 4.8226\n",
      "Epoch 808 Batch 30 Loss 0.0342 Accuracy 4.8225\n",
      "Epoch 808 Batch 35 Loss 0.0342 Accuracy 4.8225\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8233\n",
      "Epoch 809 Batch 5 Loss 0.0342 Accuracy 4.8223\n",
      "Epoch 809 Batch 10 Loss 0.0342 Accuracy 4.8223\n",
      "Epoch 809 Batch 15 Loss 0.0342 Accuracy 4.8222\n",
      "Epoch 809 Batch 20 Loss 0.0342 Accuracy 4.8221\n",
      "Epoch 809 Batch 25 Loss 0.0342 Accuracy 4.8220\n",
      "Epoch 809 Batch 30 Loss 0.0342 Accuracy 4.8220\n",
      "Epoch 809 Batch 35 Loss 0.0342 Accuracy 4.8219\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8227\n",
      "Epoch 810 Batch 5 Loss 0.0342 Accuracy 4.8218\n",
      "Epoch 810 Batch 10 Loss 0.0342 Accuracy 4.8217\n",
      "Epoch 810 Batch 15 Loss 0.0342 Accuracy 4.8216\n",
      "Epoch 810 Batch 20 Loss 0.0341 Accuracy 4.8215\n",
      "Epoch 810 Batch 25 Loss 0.0341 Accuracy 4.8215\n",
      "Epoch 810 Batch 30 Loss 0.0341 Accuracy 4.8214\n",
      "Epoch 810 Batch 35 Loss 0.0341 Accuracy 4.8213\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8222\n",
      "Epoch 811 Batch 5 Loss 0.0341 Accuracy 4.8212\n",
      "Epoch 811 Batch 10 Loss 0.0341 Accuracy 4.8211\n",
      "Epoch 811 Batch 15 Loss 0.0341 Accuracy 4.8210\n",
      "Epoch 811 Batch 20 Loss 0.0341 Accuracy 4.8210\n",
      "Epoch 811 Batch 25 Loss 0.0341 Accuracy 4.8209\n",
      "Epoch 811 Batch 30 Loss 0.0341 Accuracy 4.8208\n",
      "Epoch 811 Batch 35 Loss 0.0341 Accuracy 4.8207\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8216\n",
      "Epoch 812 Batch 5 Loss 0.0341 Accuracy 4.8206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 812 Batch 10 Loss 0.0341 Accuracy 4.8206\n",
      "Epoch 812 Batch 15 Loss 0.0341 Accuracy 4.8205\n",
      "Epoch 812 Batch 20 Loss 0.0341 Accuracy 4.8204\n",
      "Epoch 812 Batch 25 Loss 0.0341 Accuracy 4.8203\n",
      "Epoch 812 Batch 30 Loss 0.0341 Accuracy 4.8202\n",
      "Epoch 812 Batch 35 Loss 0.0341 Accuracy 4.8202\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8210\n",
      "Epoch 813 Batch 5 Loss 0.0341 Accuracy 4.8201\n",
      "Epoch 813 Batch 10 Loss 0.0341 Accuracy 4.8200\n",
      "Epoch 813 Batch 15 Loss 0.0341 Accuracy 4.8199\n",
      "Epoch 813 Batch 20 Loss 0.0341 Accuracy 4.8198\n",
      "Epoch 813 Batch 25 Loss 0.0341 Accuracy 4.8198\n",
      "Epoch 813 Batch 30 Loss 0.0341 Accuracy 4.8197\n",
      "Epoch 813 Batch 35 Loss 0.0341 Accuracy 4.8196\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8204\n",
      "Epoch 814 Batch 5 Loss 0.0341 Accuracy 4.8195\n",
      "Epoch 814 Batch 10 Loss 0.0341 Accuracy 4.8194\n",
      "Epoch 814 Batch 15 Loss 0.0341 Accuracy 4.8193\n",
      "Epoch 814 Batch 20 Loss 0.0341 Accuracy 4.8193\n",
      "Epoch 814 Batch 25 Loss 0.0341 Accuracy 4.8192\n",
      "Epoch 814 Batch 30 Loss 0.0341 Accuracy 4.8191\n",
      "Epoch 814 Batch 35 Loss 0.0341 Accuracy 4.8190\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8199\n",
      "Epoch 815 Batch 5 Loss 0.0341 Accuracy 4.8189\n",
      "Epoch 815 Batch 10 Loss 0.0341 Accuracy 4.8189\n",
      "Epoch 815 Batch 15 Loss 0.0341 Accuracy 4.8188\n",
      "Epoch 815 Batch 20 Loss 0.0341 Accuracy 4.8187\n",
      "Epoch 815 Batch 25 Loss 0.0341 Accuracy 4.8186\n",
      "Epoch 815 Batch 30 Loss 0.0341 Accuracy 4.8186\n",
      "Epoch 815 Batch 35 Loss 0.0341 Accuracy 4.8185\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8193\n",
      "Epoch 816 Batch 5 Loss 0.0341 Accuracy 4.8184\n",
      "Epoch 816 Batch 10 Loss 0.0341 Accuracy 4.8183\n",
      "Epoch 816 Batch 15 Loss 0.0341 Accuracy 4.8182\n",
      "Epoch 816 Batch 20 Loss 0.0341 Accuracy 4.8181\n",
      "Epoch 816 Batch 25 Loss 0.0341 Accuracy 4.8181\n",
      "Epoch 816 Batch 30 Loss 0.0341 Accuracy 4.8180\n",
      "Epoch 816 Batch 35 Loss 0.0341 Accuracy 4.8179\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8187\n",
      "Epoch 817 Batch 5 Loss 0.0341 Accuracy 4.8178\n",
      "Epoch 817 Batch 10 Loss 0.0341 Accuracy 4.8177\n",
      "Epoch 817 Batch 15 Loss 0.0341 Accuracy 4.8177\n",
      "Epoch 817 Batch 20 Loss 0.0341 Accuracy 4.8176\n",
      "Epoch 817 Batch 25 Loss 0.0341 Accuracy 4.8175\n",
      "Epoch 817 Batch 30 Loss 0.0341 Accuracy 4.8174\n",
      "Epoch 817 Batch 35 Loss 0.0341 Accuracy 4.8174\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8182\n",
      "Epoch 818 Batch 5 Loss 0.0341 Accuracy 4.8172\n",
      "Epoch 818 Batch 10 Loss 0.0341 Accuracy 4.8172\n",
      "Epoch 818 Batch 15 Loss 0.0341 Accuracy 4.8171\n",
      "Epoch 818 Batch 20 Loss 0.0341 Accuracy 4.8170\n",
      "Epoch 818 Batch 25 Loss 0.0341 Accuracy 4.8169\n",
      "Epoch 818 Batch 30 Loss 0.0341 Accuracy 4.8169\n",
      "Epoch 818 Batch 35 Loss 0.0341 Accuracy 4.8168\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8176\n",
      "Epoch 819 Batch 5 Loss 0.0341 Accuracy 4.8167\n",
      "Epoch 819 Batch 10 Loss 0.0341 Accuracy 4.8166\n",
      "Epoch 819 Batch 15 Loss 0.0341 Accuracy 4.8165\n",
      "Epoch 819 Batch 20 Loss 0.0341 Accuracy 4.8165\n",
      "Epoch 819 Batch 25 Loss 0.0341 Accuracy 4.8164\n",
      "Epoch 819 Batch 30 Loss 0.0341 Accuracy 4.8163\n",
      "Epoch 819 Batch 35 Loss 0.0341 Accuracy 4.8162\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8170\n",
      "Epoch 820 Batch 5 Loss 0.0341 Accuracy 4.8161\n",
      "Epoch 820 Batch 10 Loss 0.0341 Accuracy 4.8161\n",
      "Epoch 820 Batch 15 Loss 0.0340 Accuracy 4.8160\n",
      "Epoch 820 Batch 20 Loss 0.0340 Accuracy 4.8159\n",
      "Epoch 820 Batch 25 Loss 0.0340 Accuracy 4.8158\n",
      "Epoch 820 Batch 30 Loss 0.0340 Accuracy 4.8157\n",
      "Epoch 820 Batch 35 Loss 0.0340 Accuracy 4.8157\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8165\n",
      "Epoch 821 Batch 5 Loss 0.0340 Accuracy 4.8156\n",
      "Epoch 821 Batch 10 Loss 0.0340 Accuracy 4.8155\n",
      "Epoch 821 Batch 15 Loss 0.0340 Accuracy 4.8154\n",
      "Epoch 821 Batch 20 Loss 0.0340 Accuracy 4.8153\n",
      "Epoch 821 Batch 25 Loss 0.0340 Accuracy 4.8152\n",
      "Epoch 821 Batch 30 Loss 0.0340 Accuracy 4.8152\n",
      "Epoch 821 Batch 35 Loss 0.0340 Accuracy 4.8151\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8159\n",
      "Epoch 822 Batch 5 Loss 0.0340 Accuracy 4.8150\n",
      "Epoch 822 Batch 10 Loss 0.0340 Accuracy 4.8149\n",
      "Epoch 822 Batch 15 Loss 0.0340 Accuracy 4.8148\n",
      "Epoch 822 Batch 20 Loss 0.0340 Accuracy 4.8147\n",
      "Epoch 822 Batch 25 Loss 0.0340 Accuracy 4.8147\n",
      "Epoch 822 Batch 30 Loss 0.0340 Accuracy 4.8146\n",
      "Epoch 822 Batch 35 Loss 0.0340 Accuracy 4.8145\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8153\n",
      "Epoch 823 Batch 5 Loss 0.0340 Accuracy 4.8144\n",
      "Epoch 823 Batch 10 Loss 0.0340 Accuracy 4.8143\n",
      "Epoch 823 Batch 15 Loss 0.0340 Accuracy 4.8143\n",
      "Epoch 823 Batch 20 Loss 0.0340 Accuracy 4.8142\n",
      "Epoch 823 Batch 25 Loss 0.0340 Accuracy 4.8141\n",
      "Epoch 823 Batch 30 Loss 0.0340 Accuracy 4.8140\n",
      "Epoch 823 Batch 35 Loss 0.0340 Accuracy 4.8139\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8148\n",
      "Epoch 824 Batch 5 Loss 0.0340 Accuracy 4.8138\n",
      "Epoch 824 Batch 10 Loss 0.0340 Accuracy 4.8138\n",
      "Epoch 824 Batch 15 Loss 0.0340 Accuracy 4.8137\n",
      "Epoch 824 Batch 20 Loss 0.0340 Accuracy 4.8136\n",
      "Epoch 824 Batch 25 Loss 0.0340 Accuracy 4.8135\n",
      "Epoch 824 Batch 30 Loss 0.0340 Accuracy 4.8134\n",
      "Epoch 824 Batch 35 Loss 0.0340 Accuracy 4.8134\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8142\n",
      "Epoch 825 Batch 5 Loss 0.0340 Accuracy 4.8133\n",
      "Epoch 825 Batch 10 Loss 0.0340 Accuracy 4.8132\n",
      "Epoch 825 Batch 15 Loss 0.0340 Accuracy 4.8131\n",
      "Epoch 825 Batch 20 Loss 0.0340 Accuracy 4.8130\n",
      "Epoch 825 Batch 25 Loss 0.0340 Accuracy 4.8130\n",
      "Epoch 825 Batch 30 Loss 0.0340 Accuracy 4.8129\n",
      "Epoch 825 Batch 35 Loss 0.0340 Accuracy 4.8128\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8136\n",
      "Epoch 826 Batch 5 Loss 0.0340 Accuracy 4.8127\n",
      "Epoch 826 Batch 10 Loss 0.0340 Accuracy 4.8126\n",
      "Epoch 826 Batch 15 Loss 0.0340 Accuracy 4.8125\n",
      "Epoch 826 Batch 20 Loss 0.0340 Accuracy 4.8125\n",
      "Epoch 826 Batch 25 Loss 0.0340 Accuracy 4.8124\n",
      "Epoch 826 Batch 30 Loss 0.0340 Accuracy 4.8123\n",
      "Epoch 826 Batch 35 Loss 0.0340 Accuracy 4.8122\n",
      "Time taken for 1 epoch: 0.48 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8131\n",
      "Epoch 827 Batch 5 Loss 0.0340 Accuracy 4.8121\n",
      "Epoch 827 Batch 10 Loss 0.0340 Accuracy 4.8121\n",
      "Epoch 827 Batch 15 Loss 0.0340 Accuracy 4.8120\n",
      "Epoch 827 Batch 20 Loss 0.0340 Accuracy 4.8119\n",
      "Epoch 827 Batch 25 Loss 0.0340 Accuracy 4.8118\n",
      "Epoch 827 Batch 30 Loss 0.0340 Accuracy 4.8117\n",
      "Epoch 827 Batch 35 Loss 0.0340 Accuracy 4.8117\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8125\n",
      "Epoch 828 Batch 5 Loss 0.0340 Accuracy 4.8116\n",
      "Epoch 828 Batch 10 Loss 0.0340 Accuracy 4.8115\n",
      "Epoch 828 Batch 15 Loss 0.0340 Accuracy 4.8114\n",
      "Epoch 828 Batch 20 Loss 0.0340 Accuracy 4.8113\n",
      "Epoch 828 Batch 25 Loss 0.0340 Accuracy 4.8113\n",
      "Epoch 828 Batch 30 Loss 0.0340 Accuracy 4.8112\n",
      "Epoch 828 Batch 35 Loss 0.0340 Accuracy 4.8111\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8119\n",
      "Epoch 829 Batch 5 Loss 0.0340 Accuracy 4.8110\n",
      "Epoch 829 Batch 10 Loss 0.0340 Accuracy 4.8109\n",
      "Epoch 829 Batch 15 Loss 0.0340 Accuracy 4.8108\n",
      "Epoch 829 Batch 20 Loss 0.0340 Accuracy 4.8108\n",
      "Epoch 829 Batch 25 Loss 0.0340 Accuracy 4.8107\n",
      "Epoch 829 Batch 30 Loss 0.0340 Accuracy 4.8106\n",
      "Epoch 829 Batch 35 Loss 0.0340 Accuracy 4.8105\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8114\n",
      "Epoch 830 Batch 5 Loss 0.0340 Accuracy 4.8104\n",
      "Epoch 830 Batch 10 Loss 0.0340 Accuracy 4.8104\n",
      "Epoch 830 Batch 15 Loss 0.0340 Accuracy 4.8103\n",
      "Epoch 830 Batch 20 Loss 0.0340 Accuracy 4.8102\n",
      "Epoch 830 Batch 25 Loss 0.0340 Accuracy 4.8101\n",
      "Epoch 830 Batch 30 Loss 0.0340 Accuracy 4.8101\n",
      "Epoch 830 Batch 35 Loss 0.0339 Accuracy 4.8100\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8108\n",
      "Epoch 831 Batch 5 Loss 0.0339 Accuracy 4.8099\n",
      "Epoch 831 Batch 10 Loss 0.0339 Accuracy 4.8098\n",
      "Epoch 831 Batch 15 Loss 0.0339 Accuracy 4.8097\n",
      "Epoch 831 Batch 20 Loss 0.0339 Accuracy 4.8096\n",
      "Epoch 831 Batch 25 Loss 0.0339 Accuracy 4.8096\n",
      "Epoch 831 Batch 30 Loss 0.0339 Accuracy 4.8095\n",
      "Epoch 831 Batch 35 Loss 0.0339 Accuracy 4.8094\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8102\n",
      "Epoch 832 Batch 5 Loss 0.0339 Accuracy 4.8093\n",
      "Epoch 832 Batch 10 Loss 0.0339 Accuracy 4.8092\n",
      "Epoch 832 Batch 15 Loss 0.0339 Accuracy 4.8092\n",
      "Epoch 832 Batch 20 Loss 0.0339 Accuracy 4.8091\n",
      "Epoch 832 Batch 25 Loss 0.0339 Accuracy 4.8090\n",
      "Epoch 832 Batch 30 Loss 0.0339 Accuracy 4.8089\n",
      "Epoch 832 Batch 35 Loss 0.0339 Accuracy 4.8089\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 833 Batch 5 Loss 0.0339 Accuracy 4.8087\n",
      "Epoch 833 Batch 10 Loss 0.0339 Accuracy 4.8087\n",
      "Epoch 833 Batch 15 Loss 0.0339 Accuracy 4.8086\n",
      "Epoch 833 Batch 20 Loss 0.0339 Accuracy 4.8085\n",
      "Epoch 833 Batch 25 Loss 0.0339 Accuracy 4.8084\n",
      "Epoch 833 Batch 30 Loss 0.0339 Accuracy 4.8084\n",
      "Epoch 833 Batch 35 Loss 0.0339 Accuracy 4.8083\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8091\n",
      "Epoch 834 Batch 5 Loss 0.0339 Accuracy 4.8082\n",
      "Epoch 834 Batch 10 Loss 0.0339 Accuracy 4.8081\n",
      "Epoch 834 Batch 15 Loss 0.0339 Accuracy 4.8080\n",
      "Epoch 834 Batch 20 Loss 0.0339 Accuracy 4.8080\n",
      "Epoch 834 Batch 25 Loss 0.0339 Accuracy 4.8079\n",
      "Epoch 834 Batch 30 Loss 0.0339 Accuracy 4.8078\n",
      "Epoch 834 Batch 35 Loss 0.0339 Accuracy 4.8077\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8085\n",
      "Epoch 835 Batch 5 Loss 0.0339 Accuracy 4.8076\n",
      "Epoch 835 Batch 10 Loss 0.0339 Accuracy 4.8076\n",
      "Epoch 835 Batch 15 Loss 0.0339 Accuracy 4.8075\n",
      "Epoch 835 Batch 20 Loss 0.0339 Accuracy 4.8074\n",
      "Epoch 835 Batch 25 Loss 0.0339 Accuracy 4.8073\n",
      "Epoch 835 Batch 30 Loss 0.0339 Accuracy 4.8072\n",
      "Epoch 835 Batch 35 Loss 0.0339 Accuracy 4.8072\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8080\n",
      "Epoch 836 Batch 5 Loss 0.0339 Accuracy 4.8071\n",
      "Epoch 836 Batch 10 Loss 0.0339 Accuracy 4.8070\n",
      "Epoch 836 Batch 15 Loss 0.0339 Accuracy 4.8069\n",
      "Epoch 836 Batch 20 Loss 0.0339 Accuracy 4.8068\n",
      "Epoch 836 Batch 25 Loss 0.0339 Accuracy 4.8067\n",
      "Epoch 836 Batch 30 Loss 0.0339 Accuracy 4.8067\n",
      "Epoch 836 Batch 35 Loss 0.0339 Accuracy 4.8066\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8074\n",
      "Epoch 837 Batch 5 Loss 0.0339 Accuracy 4.8065\n",
      "Epoch 837 Batch 10 Loss 0.0339 Accuracy 4.8064\n",
      "Epoch 837 Batch 15 Loss 0.0339 Accuracy 4.8063\n",
      "Epoch 837 Batch 20 Loss 0.0339 Accuracy 4.8063\n",
      "Epoch 837 Batch 25 Loss 0.0339 Accuracy 4.8062\n",
      "Epoch 837 Batch 30 Loss 0.0339 Accuracy 4.8061\n",
      "Epoch 837 Batch 35 Loss 0.0339 Accuracy 4.8060\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8068\n",
      "Epoch 838 Batch 5 Loss 0.0339 Accuracy 4.8059\n",
      "Epoch 838 Batch 10 Loss 0.0339 Accuracy 4.8058\n",
      "Epoch 838 Batch 15 Loss 0.0339 Accuracy 4.8058\n",
      "Epoch 838 Batch 20 Loss 0.0339 Accuracy 4.8057\n",
      "Epoch 838 Batch 25 Loss 0.0339 Accuracy 4.8056\n",
      "Epoch 838 Batch 30 Loss 0.0339 Accuracy 4.8055\n",
      "Epoch 838 Batch 35 Loss 0.0339 Accuracy 4.8054\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8063\n",
      "Epoch 839 Batch 5 Loss 0.0339 Accuracy 4.8053\n",
      "Epoch 839 Batch 10 Loss 0.0339 Accuracy 4.8053\n",
      "Epoch 839 Batch 15 Loss 0.0339 Accuracy 4.8052\n",
      "Epoch 839 Batch 20 Loss 0.0339 Accuracy 4.8051\n",
      "Epoch 839 Batch 25 Loss 0.0339 Accuracy 4.8050\n",
      "Epoch 839 Batch 30 Loss 0.0339 Accuracy 4.8050\n",
      "Epoch 839 Batch 35 Loss 0.0339 Accuracy 4.8049\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8057\n",
      "Epoch 840 Batch 5 Loss 0.0339 Accuracy 4.8048\n",
      "Epoch 840 Batch 10 Loss 0.0339 Accuracy 4.8047\n",
      "Epoch 840 Batch 15 Loss 0.0339 Accuracy 4.8046\n",
      "Epoch 840 Batch 20 Loss 0.0339 Accuracy 4.8045\n",
      "Epoch 840 Batch 25 Loss 0.0339 Accuracy 4.8045\n",
      "Epoch 840 Batch 30 Loss 0.0339 Accuracy 4.8044\n",
      "Epoch 840 Batch 35 Loss 0.0339 Accuracy 4.8043\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8051\n",
      "Epoch 841 Batch 5 Loss 0.0339 Accuracy 4.8042\n",
      "Epoch 841 Batch 10 Loss 0.0339 Accuracy 4.8041\n",
      "Epoch 841 Batch 15 Loss 0.0339 Accuracy 4.8041\n",
      "Epoch 841 Batch 20 Loss 0.0339 Accuracy 4.8040\n",
      "Epoch 841 Batch 25 Loss 0.0339 Accuracy 4.8039\n",
      "Epoch 841 Batch 30 Loss 0.0339 Accuracy 4.8038\n",
      "Epoch 841 Batch 35 Loss 0.0339 Accuracy 4.8037\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8046\n",
      "Epoch 842 Batch 5 Loss 0.0339 Accuracy 4.8036\n",
      "Epoch 842 Batch 10 Loss 0.0339 Accuracy 4.8036\n",
      "Epoch 842 Batch 15 Loss 0.0339 Accuracy 4.8035\n",
      "Epoch 842 Batch 20 Loss 0.0339 Accuracy 4.8034\n",
      "Epoch 842 Batch 25 Loss 0.0339 Accuracy 4.8033\n",
      "Epoch 842 Batch 30 Loss 0.0339 Accuracy 4.8033\n",
      "Epoch 842 Batch 35 Loss 0.0338 Accuracy 4.8032\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8040\n",
      "Epoch 843 Batch 5 Loss 0.0338 Accuracy 4.8031\n",
      "Epoch 843 Batch 10 Loss 0.0338 Accuracy 4.8030\n",
      "Epoch 843 Batch 15 Loss 0.0338 Accuracy 4.8029\n",
      "Epoch 843 Batch 20 Loss 0.0338 Accuracy 4.8028\n",
      "Epoch 843 Batch 25 Loss 0.0338 Accuracy 4.8028\n",
      "Epoch 843 Batch 30 Loss 0.0338 Accuracy 4.8027\n",
      "Epoch 843 Batch 35 Loss 0.0338 Accuracy 4.8026\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8034\n",
      "Epoch 844 Batch 5 Loss 0.0338 Accuracy 4.8025\n",
      "Epoch 844 Batch 10 Loss 0.0338 Accuracy 4.8024\n",
      "Epoch 844 Batch 15 Loss 0.0338 Accuracy 4.8024\n",
      "Epoch 844 Batch 20 Loss 0.0338 Accuracy 4.8023\n",
      "Epoch 844 Batch 25 Loss 0.0338 Accuracy 4.8022\n",
      "Epoch 844 Batch 30 Loss 0.0338 Accuracy 4.8021\n",
      "Epoch 844 Batch 35 Loss 0.0338 Accuracy 4.8021\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8029\n",
      "Epoch 845 Batch 5 Loss 0.0338 Accuracy 4.8019\n",
      "Epoch 845 Batch 10 Loss 0.0338 Accuracy 4.8019\n",
      "Epoch 845 Batch 15 Loss 0.0338 Accuracy 4.8018\n",
      "Epoch 845 Batch 20 Loss 0.0338 Accuracy 4.8017\n",
      "Epoch 845 Batch 25 Loss 0.0338 Accuracy 4.8016\n",
      "Epoch 845 Batch 30 Loss 0.0338 Accuracy 4.8016\n",
      "Epoch 845 Batch 35 Loss 0.0338 Accuracy 4.8015\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8023\n",
      "Epoch 846 Batch 5 Loss 0.0338 Accuracy 4.8014\n",
      "Epoch 846 Batch 10 Loss 0.0338 Accuracy 4.8013\n",
      "Epoch 846 Batch 15 Loss 0.0338 Accuracy 4.8012\n",
      "Epoch 846 Batch 20 Loss 0.0338 Accuracy 4.8012\n",
      "Epoch 846 Batch 25 Loss 0.0338 Accuracy 4.8011\n",
      "Epoch 846 Batch 30 Loss 0.0338 Accuracy 4.8010\n",
      "Epoch 846 Batch 35 Loss 0.0338 Accuracy 4.8009\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8017\n",
      "Epoch 847 Batch 5 Loss 0.0338 Accuracy 4.8008\n",
      "Epoch 847 Batch 10 Loss 0.0338 Accuracy 4.8008\n",
      "Epoch 847 Batch 15 Loss 0.0338 Accuracy 4.8007\n",
      "Epoch 847 Batch 20 Loss 0.0338 Accuracy 4.8006\n",
      "Epoch 847 Batch 25 Loss 0.0338 Accuracy 4.8005\n",
      "Epoch 847 Batch 30 Loss 0.0338 Accuracy 4.8005\n",
      "Epoch 847 Batch 35 Loss 0.0338 Accuracy 4.8004\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8012\n",
      "Epoch 848 Batch 5 Loss 0.0338 Accuracy 4.8003\n",
      "Epoch 848 Batch 10 Loss 0.0338 Accuracy 4.8002\n",
      "Epoch 848 Batch 15 Loss 0.0338 Accuracy 4.8001\n",
      "Epoch 848 Batch 20 Loss 0.0338 Accuracy 4.8000\n",
      "Epoch 848 Batch 25 Loss 0.0338 Accuracy 4.8000\n",
      "Epoch 848 Batch 30 Loss 0.0338 Accuracy 4.7999\n",
      "Epoch 848 Batch 35 Loss 0.0338 Accuracy 4.7998\n",
      "Time taken for 1 epoch: 0.54 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8006\n",
      "Epoch 849 Batch 5 Loss 0.0338 Accuracy 4.7997\n",
      "Epoch 849 Batch 10 Loss 0.0338 Accuracy 4.7996\n",
      "Epoch 849 Batch 15 Loss 0.0338 Accuracy 4.7996\n",
      "Epoch 849 Batch 20 Loss 0.0338 Accuracy 4.7995\n",
      "Epoch 849 Batch 25 Loss 0.0338 Accuracy 4.7994\n",
      "Epoch 849 Batch 30 Loss 0.0338 Accuracy 4.7993\n",
      "Epoch 849 Batch 35 Loss 0.0338 Accuracy 4.7993\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.8000\n",
      "Epoch 850 Batch 5 Loss 0.0338 Accuracy 4.7992\n",
      "Epoch 850 Batch 10 Loss 0.0338 Accuracy 4.7991\n",
      "Epoch 850 Batch 15 Loss 0.0338 Accuracy 4.7990\n",
      "Epoch 850 Batch 20 Loss 0.0338 Accuracy 4.7989\n",
      "Epoch 850 Batch 25 Loss 0.0338 Accuracy 4.7989\n",
      "Epoch 850 Batch 30 Loss 0.0338 Accuracy 4.7988\n",
      "Epoch 850 Batch 35 Loss 0.0338 Accuracy 4.7987\n",
      "Time taken for 1 epoch: 0.54 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7995\n",
      "Epoch 851 Batch 5 Loss 0.0338 Accuracy 4.7986\n",
      "Epoch 851 Batch 10 Loss 0.0338 Accuracy 4.7985\n",
      "Epoch 851 Batch 15 Loss 0.0338 Accuracy 4.7984\n",
      "Epoch 851 Batch 20 Loss 0.0338 Accuracy 4.7984\n",
      "Epoch 851 Batch 25 Loss 0.0338 Accuracy 4.7983\n",
      "Epoch 851 Batch 30 Loss 0.0338 Accuracy 4.7982\n",
      "Epoch 851 Batch 35 Loss 0.0338 Accuracy 4.7981\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7989\n",
      "Epoch 852 Batch 5 Loss 0.0338 Accuracy 4.7980\n",
      "Epoch 852 Batch 10 Loss 0.0338 Accuracy 4.7979\n",
      "Epoch 852 Batch 15 Loss 0.0338 Accuracy 4.7979\n",
      "Epoch 852 Batch 20 Loss 0.0338 Accuracy 4.7978\n",
      "Epoch 852 Batch 25 Loss 0.0338 Accuracy 4.7977\n",
      "Epoch 852 Batch 30 Loss 0.0338 Accuracy 4.7976\n",
      "Epoch 852 Batch 35 Loss 0.0338 Accuracy 4.7976\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7983\n",
      "Epoch 853 Batch 5 Loss 0.0338 Accuracy 4.7975\n",
      "Epoch 853 Batch 10 Loss 0.0338 Accuracy 4.7974\n",
      "Epoch 853 Batch 15 Loss 0.0338 Accuracy 4.7973\n",
      "Epoch 853 Batch 20 Loss 0.0338 Accuracy 4.7972\n",
      "Epoch 853 Batch 25 Loss 0.0337 Accuracy 4.7971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 853 Batch 30 Loss 0.0337 Accuracy 4.7971\n",
      "Epoch 853 Batch 35 Loss 0.0337 Accuracy 4.7970\n",
      "Time taken for 1 epoch: 0.55 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7978\n",
      "Epoch 854 Batch 5 Loss 0.0337 Accuracy 4.7969\n",
      "Epoch 854 Batch 10 Loss 0.0337 Accuracy 4.7968\n",
      "Epoch 854 Batch 15 Loss 0.0337 Accuracy 4.7967\n",
      "Epoch 854 Batch 20 Loss 0.0337 Accuracy 4.7967\n",
      "Epoch 854 Batch 25 Loss 0.0337 Accuracy 4.7966\n",
      "Epoch 854 Batch 30 Loss 0.0337 Accuracy 4.7965\n",
      "Epoch 854 Batch 35 Loss 0.0337 Accuracy 4.7964\n",
      "Time taken for 1 epoch: 0.55 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7972\n",
      "Epoch 855 Batch 5 Loss 0.0337 Accuracy 4.7963\n",
      "Epoch 855 Batch 10 Loss 0.0337 Accuracy 4.7962\n",
      "Epoch 855 Batch 15 Loss 0.0337 Accuracy 4.7962\n",
      "Epoch 855 Batch 20 Loss 0.0337 Accuracy 4.7961\n",
      "Epoch 855 Batch 25 Loss 0.0337 Accuracy 4.7960\n",
      "Epoch 855 Batch 30 Loss 0.0337 Accuracy 4.7959\n",
      "Epoch 855 Batch 35 Loss 0.0337 Accuracy 4.7959\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7967\n",
      "Epoch 856 Batch 5 Loss 0.0337 Accuracy 4.7958\n",
      "Epoch 856 Batch 10 Loss 0.0337 Accuracy 4.7957\n",
      "Epoch 856 Batch 15 Loss 0.0337 Accuracy 4.7956\n",
      "Epoch 856 Batch 20 Loss 0.0337 Accuracy 4.7955\n",
      "Epoch 856 Batch 25 Loss 0.0337 Accuracy 4.7954\n",
      "Epoch 856 Batch 30 Loss 0.0337 Accuracy 4.7954\n",
      "Epoch 856 Batch 35 Loss 0.0337 Accuracy 4.7953\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7961\n",
      "Epoch 857 Batch 5 Loss 0.0337 Accuracy 4.7952\n",
      "Epoch 857 Batch 10 Loss 0.0337 Accuracy 4.7951\n",
      "Epoch 857 Batch 15 Loss 0.0337 Accuracy 4.7950\n",
      "Epoch 857 Batch 20 Loss 0.0337 Accuracy 4.7950\n",
      "Epoch 857 Batch 25 Loss 0.0337 Accuracy 4.7949\n",
      "Epoch 857 Batch 30 Loss 0.0337 Accuracy 4.7948\n",
      "Epoch 857 Batch 35 Loss 0.0337 Accuracy 4.7947\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7955\n",
      "Epoch 858 Batch 5 Loss 0.0337 Accuracy 4.7946\n",
      "Epoch 858 Batch 10 Loss 0.0337 Accuracy 4.7946\n",
      "Epoch 858 Batch 15 Loss 0.0337 Accuracy 4.7945\n",
      "Epoch 858 Batch 20 Loss 0.0337 Accuracy 4.7944\n",
      "Epoch 858 Batch 25 Loss 0.0337 Accuracy 4.7943\n",
      "Epoch 858 Batch 30 Loss 0.0337 Accuracy 4.7942\n",
      "Epoch 858 Batch 35 Loss 0.0337 Accuracy 4.7942\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7950\n",
      "Epoch 859 Batch 5 Loss 0.0337 Accuracy 4.7941\n",
      "Epoch 859 Batch 10 Loss 0.0337 Accuracy 4.7940\n",
      "Epoch 859 Batch 15 Loss 0.0337 Accuracy 4.7939\n",
      "Epoch 859 Batch 20 Loss 0.0337 Accuracy 4.7938\n",
      "Epoch 859 Batch 25 Loss 0.0337 Accuracy 4.7938\n",
      "Epoch 859 Batch 30 Loss 0.0337 Accuracy 4.7937\n",
      "Epoch 859 Batch 35 Loss 0.0337 Accuracy 4.7936\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7944\n",
      "Epoch 860 Batch 5 Loss 0.0337 Accuracy 4.7935\n",
      "Epoch 860 Batch 10 Loss 0.0337 Accuracy 4.7934\n",
      "Epoch 860 Batch 15 Loss 0.0337 Accuracy 4.7934\n",
      "Epoch 860 Batch 20 Loss 0.0337 Accuracy 4.7933\n",
      "Epoch 860 Batch 25 Loss 0.0337 Accuracy 4.7932\n",
      "Epoch 860 Batch 30 Loss 0.0337 Accuracy 4.7931\n",
      "Epoch 860 Batch 35 Loss 0.0337 Accuracy 4.7931\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7938\n",
      "Epoch 861 Batch 5 Loss 0.0337 Accuracy 4.7929\n",
      "Epoch 861 Batch 10 Loss 0.0337 Accuracy 4.7929\n",
      "Epoch 861 Batch 15 Loss 0.0337 Accuracy 4.7928\n",
      "Epoch 861 Batch 20 Loss 0.0337 Accuracy 4.7927\n",
      "Epoch 861 Batch 25 Loss 0.0337 Accuracy 4.7926\n",
      "Epoch 861 Batch 30 Loss 0.0337 Accuracy 4.7926\n",
      "Epoch 861 Batch 35 Loss 0.0337 Accuracy 4.7925\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7933\n",
      "Epoch 862 Batch 5 Loss 0.0337 Accuracy 4.7924\n",
      "Epoch 862 Batch 10 Loss 0.0337 Accuracy 4.7923\n",
      "Epoch 862 Batch 15 Loss 0.0337 Accuracy 4.7922\n",
      "Epoch 862 Batch 20 Loss 0.0337 Accuracy 4.7922\n",
      "Epoch 862 Batch 25 Loss 0.0337 Accuracy 4.7921\n",
      "Epoch 862 Batch 30 Loss 0.0337 Accuracy 4.7920\n",
      "Epoch 862 Batch 35 Loss 0.0337 Accuracy 4.7919\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7927\n",
      "Epoch 863 Batch 5 Loss 0.0337 Accuracy 4.7918\n",
      "Epoch 863 Batch 10 Loss 0.0337 Accuracy 4.7918\n",
      "Epoch 863 Batch 15 Loss 0.0337 Accuracy 4.7917\n",
      "Epoch 863 Batch 20 Loss 0.0337 Accuracy 4.7916\n",
      "Epoch 863 Batch 25 Loss 0.0337 Accuracy 4.7915\n",
      "Epoch 863 Batch 30 Loss 0.0337 Accuracy 4.7915\n",
      "Epoch 863 Batch 35 Loss 0.0337 Accuracy 4.7914\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7922\n",
      "Epoch 864 Batch 5 Loss 0.0337 Accuracy 4.7913\n",
      "Epoch 864 Batch 10 Loss 0.0337 Accuracy 4.7912\n",
      "Epoch 864 Batch 15 Loss 0.0336 Accuracy 4.7911\n",
      "Epoch 864 Batch 20 Loss 0.0336 Accuracy 4.7910\n",
      "Epoch 864 Batch 25 Loss 0.0336 Accuracy 4.7910\n",
      "Epoch 864 Batch 30 Loss 0.0336 Accuracy 4.7909\n",
      "Epoch 864 Batch 35 Loss 0.0336 Accuracy 4.7908\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7916\n",
      "Epoch 865 Batch 5 Loss 0.0336 Accuracy 4.7907\n",
      "Epoch 865 Batch 10 Loss 0.0336 Accuracy 4.7906\n",
      "Epoch 865 Batch 15 Loss 0.0336 Accuracy 4.7906\n",
      "Epoch 865 Batch 20 Loss 0.0336 Accuracy 4.7905\n",
      "Epoch 865 Batch 25 Loss 0.0336 Accuracy 4.7904\n",
      "Epoch 865 Batch 30 Loss 0.0336 Accuracy 4.7903\n",
      "Epoch 865 Batch 35 Loss 0.0336 Accuracy 4.7903\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7910\n",
      "Epoch 866 Batch 5 Loss 0.0336 Accuracy 4.7902\n",
      "Epoch 866 Batch 10 Loss 0.0336 Accuracy 4.7901\n",
      "Epoch 866 Batch 15 Loss 0.0336 Accuracy 4.7900\n",
      "Epoch 866 Batch 20 Loss 0.0336 Accuracy 4.7899\n",
      "Epoch 866 Batch 25 Loss 0.0336 Accuracy 4.7899\n",
      "Epoch 866 Batch 30 Loss 0.0336 Accuracy 4.7898\n",
      "Epoch 866 Batch 35 Loss 0.0336 Accuracy 4.7897\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7905\n",
      "Epoch 867 Batch 5 Loss 0.0336 Accuracy 4.7896\n",
      "Epoch 867 Batch 10 Loss 0.0336 Accuracy 4.7895\n",
      "Epoch 867 Batch 15 Loss 0.0336 Accuracy 4.7894\n",
      "Epoch 867 Batch 20 Loss 0.0336 Accuracy 4.7894\n",
      "Epoch 867 Batch 25 Loss 0.0336 Accuracy 4.7893\n",
      "Epoch 867 Batch 30 Loss 0.0336 Accuracy 4.7892\n",
      "Epoch 867 Batch 35 Loss 0.0336 Accuracy 4.7891\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7899\n",
      "Epoch 868 Batch 5 Loss 0.0336 Accuracy 4.7890\n",
      "Epoch 868 Batch 10 Loss 0.0336 Accuracy 4.7890\n",
      "Epoch 868 Batch 15 Loss 0.0336 Accuracy 4.7889\n",
      "Epoch 868 Batch 20 Loss 0.0336 Accuracy 4.7888\n",
      "Epoch 868 Batch 25 Loss 0.0336 Accuracy 4.7887\n",
      "Epoch 868 Batch 30 Loss 0.0336 Accuracy 4.7886\n",
      "Epoch 868 Batch 35 Loss 0.0336 Accuracy 4.7886\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7893\n",
      "Epoch 869 Batch 5 Loss 0.0336 Accuracy 4.7885\n",
      "Epoch 869 Batch 10 Loss 0.0336 Accuracy 4.7884\n",
      "Epoch 869 Batch 15 Loss 0.0336 Accuracy 4.7883\n",
      "Epoch 869 Batch 20 Loss 0.0336 Accuracy 4.7882\n",
      "Epoch 869 Batch 25 Loss 0.0336 Accuracy 4.7882\n",
      "Epoch 869 Batch 30 Loss 0.0336 Accuracy 4.7881\n",
      "Epoch 869 Batch 35 Loss 0.0336 Accuracy 4.7880\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7888\n",
      "Epoch 870 Batch 5 Loss 0.0336 Accuracy 4.7879\n",
      "Epoch 870 Batch 10 Loss 0.0336 Accuracy 4.7878\n",
      "Epoch 870 Batch 15 Loss 0.0336 Accuracy 4.7877\n",
      "Epoch 870 Batch 20 Loss 0.0336 Accuracy 4.7877\n",
      "Epoch 870 Batch 25 Loss 0.0336 Accuracy 4.7876\n",
      "Epoch 870 Batch 30 Loss 0.0336 Accuracy 4.7875\n",
      "Epoch 870 Batch 35 Loss 0.0336 Accuracy 4.7874\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7882\n",
      "Epoch 871 Batch 5 Loss 0.0336 Accuracy 4.7873\n",
      "Epoch 871 Batch 10 Loss 0.0336 Accuracy 4.7873\n",
      "Epoch 871 Batch 15 Loss 0.0336 Accuracy 4.7872\n",
      "Epoch 871 Batch 20 Loss 0.0336 Accuracy 4.7871\n",
      "Epoch 871 Batch 25 Loss 0.0336 Accuracy 4.7870\n",
      "Epoch 871 Batch 30 Loss 0.0336 Accuracy 4.7870\n",
      "Epoch 871 Batch 35 Loss 0.0336 Accuracy 4.7869\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7877\n",
      "Epoch 872 Batch 5 Loss 0.0336 Accuracy 4.7868\n",
      "Epoch 872 Batch 10 Loss 0.0336 Accuracy 4.7867\n",
      "Epoch 872 Batch 15 Loss 0.0336 Accuracy 4.7866\n",
      "Epoch 872 Batch 20 Loss 0.0336 Accuracy 4.7865\n",
      "Epoch 872 Batch 25 Loss 0.0336 Accuracy 4.7865\n",
      "Epoch 872 Batch 30 Loss 0.0336 Accuracy 4.7864\n",
      "Epoch 872 Batch 35 Loss 0.0336 Accuracy 4.7863\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7871\n",
      "Epoch 873 Batch 5 Loss 0.0336 Accuracy 4.7862\n",
      "Epoch 873 Batch 10 Loss 0.0336 Accuracy 4.7861\n",
      "Epoch 873 Batch 15 Loss 0.0336 Accuracy 4.7861\n",
      "Epoch 873 Batch 20 Loss 0.0336 Accuracy 4.7860\n",
      "Epoch 873 Batch 25 Loss 0.0336 Accuracy 4.7859\n",
      "Epoch 873 Batch 30 Loss 0.0336 Accuracy 4.7858\n",
      "Epoch 873 Batch 35 Loss 0.0336 Accuracy 4.7858\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7865\n",
      "Epoch 874 Batch 5 Loss 0.0336 Accuracy 4.7856\n",
      "Epoch 874 Batch 10 Loss 0.0336 Accuracy 4.7856\n",
      "Epoch 874 Batch 15 Loss 0.0336 Accuracy 4.7855\n",
      "Epoch 874 Batch 20 Loss 0.0336 Accuracy 4.7854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 874 Batch 25 Loss 0.0336 Accuracy 4.7853\n",
      "Epoch 874 Batch 30 Loss 0.0336 Accuracy 4.7853\n",
      "Epoch 874 Batch 35 Loss 0.0336 Accuracy 4.7852\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7860\n",
      "Epoch 875 Batch 5 Loss 0.0335 Accuracy 4.7851\n",
      "Epoch 875 Batch 10 Loss 0.0335 Accuracy 4.7850\n",
      "Epoch 875 Batch 15 Loss 0.0335 Accuracy 4.7849\n",
      "Epoch 875 Batch 20 Loss 0.0335 Accuracy 4.7849\n",
      "Epoch 875 Batch 25 Loss 0.0335 Accuracy 4.7848\n",
      "Epoch 875 Batch 30 Loss 0.0335 Accuracy 4.7847\n",
      "Epoch 875 Batch 35 Loss 0.0335 Accuracy 4.7846\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7854\n",
      "Epoch 876 Batch 5 Loss 0.0335 Accuracy 4.7845\n",
      "Epoch 876 Batch 10 Loss 0.0335 Accuracy 4.7845\n",
      "Epoch 876 Batch 15 Loss 0.0335 Accuracy 4.7844\n",
      "Epoch 876 Batch 20 Loss 0.0335 Accuracy 4.7843\n",
      "Epoch 876 Batch 25 Loss 0.0335 Accuracy 4.7842\n",
      "Epoch 876 Batch 30 Loss 0.0335 Accuracy 4.7842\n",
      "Epoch 876 Batch 35 Loss 0.0335 Accuracy 4.7841\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7848\n",
      "Epoch 877 Batch 5 Loss 0.0335 Accuracy 4.7840\n",
      "Epoch 877 Batch 10 Loss 0.0335 Accuracy 4.7839\n",
      "Epoch 877 Batch 15 Loss 0.0335 Accuracy 4.7838\n",
      "Epoch 877 Batch 20 Loss 0.0335 Accuracy 4.7838\n",
      "Epoch 877 Batch 25 Loss 0.0335 Accuracy 4.7837\n",
      "Epoch 877 Batch 30 Loss 0.0335 Accuracy 4.7836\n",
      "Epoch 877 Batch 35 Loss 0.0335 Accuracy 4.7835\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7843\n",
      "Epoch 878 Batch 5 Loss 0.0335 Accuracy 4.7834\n",
      "Epoch 878 Batch 10 Loss 0.0335 Accuracy 4.7833\n",
      "Epoch 878 Batch 15 Loss 0.0335 Accuracy 4.7833\n",
      "Epoch 878 Batch 20 Loss 0.0335 Accuracy 4.7832\n",
      "Epoch 878 Batch 25 Loss 0.0335 Accuracy 4.7831\n",
      "Epoch 878 Batch 30 Loss 0.0335 Accuracy 4.7830\n",
      "Epoch 878 Batch 35 Loss 0.0335 Accuracy 4.7830\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7837\n",
      "Epoch 879 Batch 5 Loss 0.0335 Accuracy 4.7829\n",
      "Epoch 879 Batch 10 Loss 0.0335 Accuracy 4.7828\n",
      "Epoch 879 Batch 15 Loss 0.0335 Accuracy 4.7827\n",
      "Epoch 879 Batch 20 Loss 0.0335 Accuracy 4.7826\n",
      "Epoch 879 Batch 25 Loss 0.0335 Accuracy 4.7826\n",
      "Epoch 879 Batch 30 Loss 0.0335 Accuracy 4.7825\n",
      "Epoch 879 Batch 35 Loss 0.0335 Accuracy 4.7824\n",
      "Time taken for 1 epoch: 0.54 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7832\n",
      "Epoch 880 Batch 5 Loss 0.0335 Accuracy 4.7823\n",
      "Epoch 880 Batch 10 Loss 0.0335 Accuracy 4.7822\n",
      "Epoch 880 Batch 15 Loss 0.0335 Accuracy 4.7822\n",
      "Epoch 880 Batch 20 Loss 0.0335 Accuracy 4.7821\n",
      "Epoch 880 Batch 25 Loss 0.0335 Accuracy 4.7820\n",
      "Epoch 880 Batch 30 Loss 0.0335 Accuracy 4.7819\n",
      "Epoch 880 Batch 35 Loss 0.0335 Accuracy 4.7819\n",
      "Time taken for 1 epoch: 0.63 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7826\n",
      "Epoch 881 Batch 5 Loss 0.0335 Accuracy 4.7818\n",
      "Epoch 881 Batch 10 Loss 0.0335 Accuracy 4.7817\n",
      "Epoch 881 Batch 15 Loss 0.0335 Accuracy 4.7816\n",
      "Epoch 881 Batch 20 Loss 0.0335 Accuracy 4.7815\n",
      "Epoch 881 Batch 25 Loss 0.0335 Accuracy 4.7815\n",
      "Epoch 881 Batch 30 Loss 0.0335 Accuracy 4.7814\n",
      "Epoch 881 Batch 35 Loss 0.0335 Accuracy 4.7813\n",
      "Time taken for 1 epoch: 0.54 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7820\n",
      "Epoch 882 Batch 5 Loss 0.0335 Accuracy 4.7812\n",
      "Epoch 882 Batch 10 Loss 0.0335 Accuracy 4.7811\n",
      "Epoch 882 Batch 15 Loss 0.0335 Accuracy 4.7810\n",
      "Epoch 882 Batch 20 Loss 0.0335 Accuracy 4.7810\n",
      "Epoch 882 Batch 25 Loss 0.0335 Accuracy 4.7809\n",
      "Epoch 882 Batch 30 Loss 0.0335 Accuracy 4.7808\n",
      "Epoch 882 Batch 35 Loss 0.0335 Accuracy 4.7807\n",
      "Time taken for 1 epoch: 0.54 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7815\n",
      "Epoch 883 Batch 5 Loss 0.0335 Accuracy 4.7806\n",
      "Epoch 883 Batch 10 Loss 0.0335 Accuracy 4.7806\n",
      "Epoch 883 Batch 15 Loss 0.0335 Accuracy 4.7805\n",
      "Epoch 883 Batch 20 Loss 0.0335 Accuracy 4.7804\n",
      "Epoch 883 Batch 25 Loss 0.0335 Accuracy 4.7803\n",
      "Epoch 883 Batch 30 Loss 0.0335 Accuracy 4.7803\n",
      "Epoch 883 Batch 35 Loss 0.0335 Accuracy 4.7802\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7809\n",
      "Epoch 884 Batch 5 Loss 0.0335 Accuracy 4.7801\n",
      "Epoch 884 Batch 10 Loss 0.0335 Accuracy 4.7800\n",
      "Epoch 884 Batch 15 Loss 0.0335 Accuracy 4.7799\n",
      "Epoch 884 Batch 20 Loss 0.0335 Accuracy 4.7798\n",
      "Epoch 884 Batch 25 Loss 0.0335 Accuracy 4.7798\n",
      "Epoch 884 Batch 30 Loss 0.0335 Accuracy 4.7797\n",
      "Epoch 884 Batch 35 Loss 0.0335 Accuracy 4.7796\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7804\n",
      "Epoch 885 Batch 5 Loss 0.0335 Accuracy 4.7795\n",
      "Epoch 885 Batch 10 Loss 0.0335 Accuracy 4.7794\n",
      "Epoch 885 Batch 15 Loss 0.0335 Accuracy 4.7794\n",
      "Epoch 885 Batch 20 Loss 0.0335 Accuracy 4.7793\n",
      "Epoch 885 Batch 25 Loss 0.0335 Accuracy 4.7792\n",
      "Epoch 885 Batch 30 Loss 0.0335 Accuracy 4.7791\n",
      "Epoch 885 Batch 35 Loss 0.0335 Accuracy 4.7790\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7798\n",
      "Epoch 886 Batch 5 Loss 0.0335 Accuracy 4.7789\n",
      "Epoch 886 Batch 10 Loss 0.0335 Accuracy 4.7789\n",
      "Epoch 886 Batch 15 Loss 0.0335 Accuracy 4.7788\n",
      "Epoch 886 Batch 20 Loss 0.0335 Accuracy 4.7787\n",
      "Epoch 886 Batch 25 Loss 0.0334 Accuracy 4.7786\n",
      "Epoch 886 Batch 30 Loss 0.0334 Accuracy 4.7786\n",
      "Epoch 886 Batch 35 Loss 0.0334 Accuracy 4.7785\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7792\n",
      "Epoch 887 Batch 5 Loss 0.0334 Accuracy 4.7784\n",
      "Epoch 887 Batch 10 Loss 0.0334 Accuracy 4.7783\n",
      "Epoch 887 Batch 15 Loss 0.0334 Accuracy 4.7782\n",
      "Epoch 887 Batch 20 Loss 0.0334 Accuracy 4.7782\n",
      "Epoch 887 Batch 25 Loss 0.0334 Accuracy 4.7781\n",
      "Epoch 887 Batch 30 Loss 0.0334 Accuracy 4.7780\n",
      "Epoch 887 Batch 35 Loss 0.0334 Accuracy 4.7779\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7787\n",
      "Epoch 888 Batch 5 Loss 0.0334 Accuracy 4.7778\n",
      "Epoch 888 Batch 10 Loss 0.0334 Accuracy 4.7777\n",
      "Epoch 888 Batch 15 Loss 0.0334 Accuracy 4.7777\n",
      "Epoch 888 Batch 20 Loss 0.0334 Accuracy 4.7776\n",
      "Epoch 888 Batch 25 Loss 0.0334 Accuracy 4.7775\n",
      "Epoch 888 Batch 30 Loss 0.0334 Accuracy 4.7774\n",
      "Epoch 888 Batch 35 Loss 0.0334 Accuracy 4.7774\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7781\n",
      "Epoch 889 Batch 5 Loss 0.0334 Accuracy 4.7773\n",
      "Epoch 889 Batch 10 Loss 0.0334 Accuracy 4.7772\n",
      "Epoch 889 Batch 15 Loss 0.0334 Accuracy 4.7771\n",
      "Epoch 889 Batch 20 Loss 0.0334 Accuracy 4.7770\n",
      "Epoch 889 Batch 25 Loss 0.0334 Accuracy 4.7770\n",
      "Epoch 889 Batch 30 Loss 0.0334 Accuracy 4.7769\n",
      "Epoch 889 Batch 35 Loss 0.0334 Accuracy 4.7768\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7776\n",
      "Epoch 890 Batch 5 Loss 0.0334 Accuracy 4.7767\n",
      "Epoch 890 Batch 10 Loss 0.0334 Accuracy 4.7766\n",
      "Epoch 890 Batch 15 Loss 0.0334 Accuracy 4.7766\n",
      "Epoch 890 Batch 20 Loss 0.0334 Accuracy 4.7765\n",
      "Epoch 890 Batch 25 Loss 0.0334 Accuracy 4.7764\n",
      "Epoch 890 Batch 30 Loss 0.0334 Accuracy 4.7763\n",
      "Epoch 890 Batch 35 Loss 0.0334 Accuracy 4.7763\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7770\n",
      "Epoch 891 Batch 5 Loss 0.0334 Accuracy 4.7761\n",
      "Epoch 891 Batch 10 Loss 0.0334 Accuracy 4.7761\n",
      "Epoch 891 Batch 15 Loss 0.0334 Accuracy 4.7760\n",
      "Epoch 891 Batch 20 Loss 0.0334 Accuracy 4.7759\n",
      "Epoch 891 Batch 25 Loss 0.0334 Accuracy 4.7758\n",
      "Epoch 891 Batch 30 Loss 0.0334 Accuracy 4.7758\n",
      "Epoch 891 Batch 35 Loss 0.0334 Accuracy 4.7757\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7764\n",
      "Epoch 892 Batch 5 Loss 0.0334 Accuracy 4.7756\n",
      "Epoch 892 Batch 10 Loss 0.0334 Accuracy 4.7755\n",
      "Epoch 892 Batch 15 Loss 0.0334 Accuracy 4.7754\n",
      "Epoch 892 Batch 20 Loss 0.0334 Accuracy 4.7754\n",
      "Epoch 892 Batch 25 Loss 0.0334 Accuracy 4.7753\n",
      "Epoch 892 Batch 30 Loss 0.0334 Accuracy 4.7752\n",
      "Epoch 892 Batch 35 Loss 0.0334 Accuracy 4.7751\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7759\n",
      "Epoch 893 Batch 5 Loss 0.0334 Accuracy 4.7750\n",
      "Epoch 893 Batch 10 Loss 0.0334 Accuracy 4.7750\n",
      "Epoch 893 Batch 15 Loss 0.0334 Accuracy 4.7749\n",
      "Epoch 893 Batch 20 Loss 0.0334 Accuracy 4.7748\n",
      "Epoch 893 Batch 25 Loss 0.0334 Accuracy 4.7747\n",
      "Epoch 893 Batch 30 Loss 0.0334 Accuracy 4.7747\n",
      "Epoch 893 Batch 35 Loss 0.0334 Accuracy 4.7746\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7753\n",
      "Epoch 894 Batch 5 Loss 0.0334 Accuracy 4.7745\n",
      "Epoch 894 Batch 10 Loss 0.0334 Accuracy 4.7744\n",
      "Epoch 894 Batch 15 Loss 0.0334 Accuracy 4.7743\n",
      "Epoch 894 Batch 20 Loss 0.0334 Accuracy 4.7743\n",
      "Epoch 894 Batch 25 Loss 0.0334 Accuracy 4.7742\n",
      "Epoch 894 Batch 30 Loss 0.0334 Accuracy 4.7741\n",
      "Epoch 894 Batch 35 Loss 0.0334 Accuracy 4.7740\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7748\n",
      "Epoch 895 Batch 5 Loss 0.0334 Accuracy 4.7739\n",
      "Epoch 895 Batch 10 Loss 0.0334 Accuracy 4.7739\n",
      "Epoch 895 Batch 15 Loss 0.0334 Accuracy 4.7738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 895 Batch 20 Loss 0.0334 Accuracy 4.7737\n",
      "Epoch 895 Batch 25 Loss 0.0334 Accuracy 4.7736\n",
      "Epoch 895 Batch 30 Loss 0.0334 Accuracy 4.7736\n",
      "Epoch 895 Batch 35 Loss 0.0334 Accuracy 4.7735\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7742\n",
      "Epoch 896 Batch 5 Loss 0.0334 Accuracy 4.7734\n",
      "Epoch 896 Batch 10 Loss 0.0334 Accuracy 4.7733\n",
      "Epoch 896 Batch 15 Loss 0.0334 Accuracy 4.7732\n",
      "Epoch 896 Batch 20 Loss 0.0334 Accuracy 4.7732\n",
      "Epoch 896 Batch 25 Loss 0.0334 Accuracy 4.7731\n",
      "Epoch 896 Batch 30 Loss 0.0334 Accuracy 4.7730\n",
      "Epoch 896 Batch 35 Loss 0.0334 Accuracy 4.7729\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7737\n",
      "Epoch 897 Batch 5 Loss 0.0334 Accuracy 4.7728\n",
      "Epoch 897 Batch 10 Loss 0.0334 Accuracy 4.7728\n",
      "Epoch 897 Batch 15 Loss 0.0334 Accuracy 4.7727\n",
      "Epoch 897 Batch 20 Loss 0.0334 Accuracy 4.7726\n",
      "Epoch 897 Batch 25 Loss 0.0334 Accuracy 4.7725\n",
      "Epoch 897 Batch 30 Loss 0.0334 Accuracy 4.7725\n",
      "Epoch 897 Batch 35 Loss 0.0334 Accuracy 4.7724\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7731\n",
      "Epoch 898 Batch 5 Loss 0.0334 Accuracy 4.7723\n",
      "Epoch 898 Batch 10 Loss 0.0333 Accuracy 4.7722\n",
      "Epoch 898 Batch 15 Loss 0.0333 Accuracy 4.7721\n",
      "Epoch 898 Batch 20 Loss 0.0333 Accuracy 4.7720\n",
      "Epoch 898 Batch 25 Loss 0.0333 Accuracy 4.7720\n",
      "Epoch 898 Batch 30 Loss 0.0333 Accuracy 4.7719\n",
      "Epoch 898 Batch 35 Loss 0.0333 Accuracy 4.7718\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7725\n",
      "Epoch 899 Batch 5 Loss 0.0333 Accuracy 4.7717\n",
      "Epoch 899 Batch 10 Loss 0.0333 Accuracy 4.7716\n",
      "Epoch 899 Batch 15 Loss 0.0333 Accuracy 4.7716\n",
      "Epoch 899 Batch 20 Loss 0.0333 Accuracy 4.7715\n",
      "Epoch 899 Batch 25 Loss 0.0333 Accuracy 4.7714\n",
      "Epoch 899 Batch 30 Loss 0.0333 Accuracy 4.7713\n",
      "Epoch 899 Batch 35 Loss 0.0333 Accuracy 4.7713\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7720\n",
      "Epoch 900 Batch 5 Loss 0.0333 Accuracy 4.7711\n",
      "Epoch 900 Batch 10 Loss 0.0333 Accuracy 4.7711\n",
      "Epoch 900 Batch 15 Loss 0.0333 Accuracy 4.7710\n",
      "Epoch 900 Batch 20 Loss 0.0333 Accuracy 4.7709\n",
      "Epoch 900 Batch 25 Loss 0.0333 Accuracy 4.7708\n",
      "Epoch 900 Batch 30 Loss 0.0333 Accuracy 4.7708\n",
      "Epoch 900 Batch 35 Loss 0.0333 Accuracy 4.7707\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7714\n",
      "Epoch 901 Batch 5 Loss 0.0333 Accuracy 4.7706\n",
      "Epoch 901 Batch 10 Loss 0.0333 Accuracy 4.7705\n",
      "Epoch 901 Batch 15 Loss 0.0333 Accuracy 4.7704\n",
      "Epoch 901 Batch 20 Loss 0.0333 Accuracy 4.7704\n",
      "Epoch 901 Batch 25 Loss 0.0333 Accuracy 4.7703\n",
      "Epoch 901 Batch 30 Loss 0.0333 Accuracy 4.7702\n",
      "Epoch 901 Batch 35 Loss 0.0333 Accuracy 4.7701\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7709\n",
      "Epoch 902 Batch 5 Loss 0.0333 Accuracy 4.7700\n",
      "Epoch 902 Batch 10 Loss 0.0333 Accuracy 4.7700\n",
      "Epoch 902 Batch 15 Loss 0.0333 Accuracy 4.7699\n",
      "Epoch 902 Batch 20 Loss 0.0333 Accuracy 4.7698\n",
      "Epoch 902 Batch 25 Loss 0.0333 Accuracy 4.7697\n",
      "Epoch 902 Batch 30 Loss 0.0333 Accuracy 4.7696\n",
      "Epoch 902 Batch 35 Loss 0.0333 Accuracy 4.7696\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7703\n",
      "Epoch 903 Batch 5 Loss 0.0333 Accuracy 4.7695\n",
      "Epoch 903 Batch 10 Loss 0.0333 Accuracy 4.7694\n",
      "Epoch 903 Batch 15 Loss 0.0333 Accuracy 4.7693\n",
      "Epoch 903 Batch 20 Loss 0.0333 Accuracy 4.7692\n",
      "Epoch 903 Batch 25 Loss 0.0333 Accuracy 4.7692\n",
      "Epoch 903 Batch 30 Loss 0.0333 Accuracy 4.7691\n",
      "Epoch 903 Batch 35 Loss 0.0333 Accuracy 4.7690\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7698\n",
      "Epoch 904 Batch 5 Loss 0.0333 Accuracy 4.7689\n",
      "Epoch 904 Batch 10 Loss 0.0333 Accuracy 4.7688\n",
      "Epoch 904 Batch 15 Loss 0.0333 Accuracy 4.7688\n",
      "Epoch 904 Batch 20 Loss 0.0333 Accuracy 4.7687\n",
      "Epoch 904 Batch 25 Loss 0.0333 Accuracy 4.7686\n",
      "Epoch 904 Batch 30 Loss 0.0333 Accuracy 4.7685\n",
      "Epoch 904 Batch 35 Loss 0.0333 Accuracy 4.7685\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7692\n",
      "Epoch 905 Batch 5 Loss 0.0333 Accuracy 4.7684\n",
      "Epoch 905 Batch 10 Loss 0.0333 Accuracy 4.7683\n",
      "Epoch 905 Batch 15 Loss 0.0333 Accuracy 4.7682\n",
      "Epoch 905 Batch 20 Loss 0.0333 Accuracy 4.7681\n",
      "Epoch 905 Batch 25 Loss 0.0333 Accuracy 4.7681\n",
      "Epoch 905 Batch 30 Loss 0.0333 Accuracy 4.7680\n",
      "Epoch 905 Batch 35 Loss 0.0333 Accuracy 4.7679\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7686\n",
      "Epoch 906 Batch 5 Loss 0.0333 Accuracy 4.7678\n",
      "Epoch 906 Batch 10 Loss 0.0333 Accuracy 4.7677\n",
      "Epoch 906 Batch 15 Loss 0.0333 Accuracy 4.7676\n",
      "Epoch 906 Batch 20 Loss 0.0333 Accuracy 4.7676\n",
      "Epoch 906 Batch 25 Loss 0.0333 Accuracy 4.7675\n",
      "Epoch 906 Batch 30 Loss 0.0333 Accuracy 4.7674\n",
      "Epoch 906 Batch 35 Loss 0.0333 Accuracy 4.7673\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7681\n",
      "Epoch 907 Batch 5 Loss 0.0333 Accuracy 4.7672\n",
      "Epoch 907 Batch 10 Loss 0.0333 Accuracy 4.7672\n",
      "Epoch 907 Batch 15 Loss 0.0333 Accuracy 4.7671\n",
      "Epoch 907 Batch 20 Loss 0.0333 Accuracy 4.7670\n",
      "Epoch 907 Batch 25 Loss 0.0333 Accuracy 4.7669\n",
      "Epoch 907 Batch 30 Loss 0.0333 Accuracy 4.7669\n",
      "Epoch 907 Batch 35 Loss 0.0333 Accuracy 4.7668\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7675\n",
      "Epoch 908 Batch 5 Loss 0.0333 Accuracy 4.7667\n",
      "Epoch 908 Batch 10 Loss 0.0333 Accuracy 4.7666\n",
      "Epoch 908 Batch 15 Loss 0.0333 Accuracy 4.7665\n",
      "Epoch 908 Batch 20 Loss 0.0332 Accuracy 4.7665\n",
      "Epoch 908 Batch 25 Loss 0.0332 Accuracy 4.7664\n",
      "Epoch 908 Batch 30 Loss 0.0332 Accuracy 4.7663\n",
      "Epoch 908 Batch 35 Loss 0.0332 Accuracy 4.7662\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7670\n",
      "Epoch 909 Batch 5 Loss 0.0332 Accuracy 4.7661\n",
      "Epoch 909 Batch 10 Loss 0.0332 Accuracy 4.7661\n",
      "Epoch 909 Batch 15 Loss 0.0332 Accuracy 4.7660\n",
      "Epoch 909 Batch 20 Loss 0.0332 Accuracy 4.7659\n",
      "Epoch 909 Batch 25 Loss 0.0332 Accuracy 4.7658\n",
      "Epoch 909 Batch 30 Loss 0.0332 Accuracy 4.7658\n",
      "Epoch 909 Batch 35 Loss 0.0332 Accuracy 4.7657\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7664\n",
      "Epoch 910 Batch 5 Loss 0.0332 Accuracy 4.7656\n",
      "Epoch 910 Batch 10 Loss 0.0332 Accuracy 4.7655\n",
      "Epoch 910 Batch 15 Loss 0.0332 Accuracy 4.7654\n",
      "Epoch 910 Batch 20 Loss 0.0332 Accuracy 4.7654\n",
      "Epoch 910 Batch 25 Loss 0.0332 Accuracy 4.7653\n",
      "Epoch 910 Batch 30 Loss 0.0332 Accuracy 4.7652\n",
      "Epoch 910 Batch 35 Loss 0.0332 Accuracy 4.7651\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7659\n",
      "Epoch 911 Batch 5 Loss 0.0332 Accuracy 4.7650\n",
      "Epoch 911 Batch 10 Loss 0.0332 Accuracy 4.7650\n",
      "Epoch 911 Batch 15 Loss 0.0332 Accuracy 4.7649\n",
      "Epoch 911 Batch 20 Loss 0.0332 Accuracy 4.7648\n",
      "Epoch 911 Batch 25 Loss 0.0332 Accuracy 4.7647\n",
      "Epoch 911 Batch 30 Loss 0.0332 Accuracy 4.7647\n",
      "Epoch 911 Batch 35 Loss 0.0332 Accuracy 4.7646\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7653\n",
      "Epoch 912 Batch 5 Loss 0.0332 Accuracy 4.7645\n",
      "Epoch 912 Batch 10 Loss 0.0332 Accuracy 4.7644\n",
      "Epoch 912 Batch 15 Loss 0.0332 Accuracy 4.7643\n",
      "Epoch 912 Batch 20 Loss 0.0332 Accuracy 4.7643\n",
      "Epoch 912 Batch 25 Loss 0.0332 Accuracy 4.7642\n",
      "Epoch 912 Batch 30 Loss 0.0332 Accuracy 4.7641\n",
      "Epoch 912 Batch 35 Loss 0.0332 Accuracy 4.7640\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7647\n",
      "Epoch 913 Batch 5 Loss 0.0332 Accuracy 4.7639\n",
      "Epoch 913 Batch 10 Loss 0.0332 Accuracy 4.7639\n",
      "Epoch 913 Batch 15 Loss 0.0332 Accuracy 4.7638\n",
      "Epoch 913 Batch 20 Loss 0.0332 Accuracy 4.7637\n",
      "Epoch 913 Batch 25 Loss 0.0332 Accuracy 4.7636\n",
      "Epoch 913 Batch 30 Loss 0.0332 Accuracy 4.7636\n",
      "Epoch 913 Batch 35 Loss 0.0332 Accuracy 4.7635\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7642\n",
      "Epoch 914 Batch 5 Loss 0.0332 Accuracy 4.7634\n",
      "Epoch 914 Batch 10 Loss 0.0332 Accuracy 4.7633\n",
      "Epoch 914 Batch 15 Loss 0.0332 Accuracy 4.7632\n",
      "Epoch 914 Batch 20 Loss 0.0332 Accuracy 4.7631\n",
      "Epoch 914 Batch 25 Loss 0.0332 Accuracy 4.7631\n",
      "Epoch 914 Batch 30 Loss 0.0332 Accuracy 4.7630\n",
      "Epoch 914 Batch 35 Loss 0.0332 Accuracy 4.7629\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7636\n",
      "Epoch 915 Batch 5 Loss 0.0332 Accuracy 4.7628\n",
      "Epoch 915 Batch 10 Loss 0.0332 Accuracy 4.7627\n",
      "Epoch 915 Batch 15 Loss 0.0332 Accuracy 4.7627\n",
      "Epoch 915 Batch 20 Loss 0.0332 Accuracy 4.7626\n",
      "Epoch 915 Batch 25 Loss 0.0332 Accuracy 4.7625\n",
      "Epoch 915 Batch 30 Loss 0.0332 Accuracy 4.7624\n",
      "Epoch 915 Batch 35 Loss 0.0332 Accuracy 4.7624\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestLoss 0.0000 TestAccuracy 4.7631\n",
      "Epoch 916 Batch 5 Loss 0.0332 Accuracy 4.7622\n",
      "Epoch 916 Batch 10 Loss 0.0332 Accuracy 4.7622\n",
      "Epoch 916 Batch 15 Loss 0.0332 Accuracy 4.7621\n",
      "Epoch 916 Batch 20 Loss 0.0332 Accuracy 4.7620\n",
      "Epoch 916 Batch 25 Loss 0.0332 Accuracy 4.7619\n",
      "Epoch 916 Batch 30 Loss 0.0332 Accuracy 4.7619\n",
      "Epoch 916 Batch 35 Loss 0.0332 Accuracy 4.7618\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7625\n",
      "Epoch 917 Batch 5 Loss 0.0332 Accuracy 4.7617\n",
      "Epoch 917 Batch 10 Loss 0.0332 Accuracy 4.7616\n",
      "Epoch 917 Batch 15 Loss 0.0332 Accuracy 4.7615\n",
      "Epoch 917 Batch 20 Loss 0.0332 Accuracy 4.7615\n",
      "Epoch 917 Batch 25 Loss 0.0332 Accuracy 4.7614\n",
      "Epoch 917 Batch 30 Loss 0.0332 Accuracy 4.7613\n",
      "Epoch 917 Batch 35 Loss 0.0332 Accuracy 4.7612\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7620\n",
      "Epoch 918 Batch 5 Loss 0.0332 Accuracy 4.7611\n",
      "Epoch 918 Batch 10 Loss 0.0332 Accuracy 4.7611\n",
      "Epoch 918 Batch 15 Loss 0.0332 Accuracy 4.7610\n",
      "Epoch 918 Batch 20 Loss 0.0332 Accuracy 4.7609\n",
      "Epoch 918 Batch 25 Loss 0.0332 Accuracy 4.7608\n",
      "Epoch 918 Batch 30 Loss 0.0332 Accuracy 4.7608\n",
      "Epoch 918 Batch 35 Loss 0.0332 Accuracy 4.7607\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7614\n",
      "Epoch 919 Batch 5 Loss 0.0332 Accuracy 4.7606\n",
      "Epoch 919 Batch 10 Loss 0.0332 Accuracy 4.7605\n",
      "Epoch 919 Batch 15 Loss 0.0332 Accuracy 4.7604\n",
      "Epoch 919 Batch 20 Loss 0.0332 Accuracy 4.7603\n",
      "Epoch 919 Batch 25 Loss 0.0332 Accuracy 4.7603\n",
      "Epoch 919 Batch 30 Loss 0.0332 Accuracy 4.7602\n",
      "Epoch 919 Batch 35 Loss 0.0332 Accuracy 4.7601\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7608\n",
      "Epoch 920 Batch 5 Loss 0.0332 Accuracy 4.7600\n",
      "Epoch 920 Batch 10 Loss 0.0332 Accuracy 4.7599\n",
      "Epoch 920 Batch 15 Loss 0.0332 Accuracy 4.7599\n",
      "Epoch 920 Batch 20 Loss 0.0332 Accuracy 4.7598\n",
      "Epoch 920 Batch 25 Loss 0.0332 Accuracy 4.7597\n",
      "Epoch 920 Batch 30 Loss 0.0331 Accuracy 4.7596\n",
      "Epoch 920 Batch 35 Loss 0.0331 Accuracy 4.7596\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7603\n",
      "Epoch 921 Batch 5 Loss 0.0331 Accuracy 4.7595\n",
      "Epoch 921 Batch 10 Loss 0.0331 Accuracy 4.7594\n",
      "Epoch 921 Batch 15 Loss 0.0331 Accuracy 4.7593\n",
      "Epoch 921 Batch 20 Loss 0.0331 Accuracy 4.7592\n",
      "Epoch 921 Batch 25 Loss 0.0331 Accuracy 4.7592\n",
      "Epoch 921 Batch 30 Loss 0.0331 Accuracy 4.7591\n",
      "Epoch 921 Batch 35 Loss 0.0331 Accuracy 4.7590\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7597\n",
      "Epoch 922 Batch 5 Loss 0.0331 Accuracy 4.7589\n",
      "Epoch 922 Batch 10 Loss 0.0331 Accuracy 4.7588\n",
      "Epoch 922 Batch 15 Loss 0.0331 Accuracy 4.7588\n",
      "Epoch 922 Batch 20 Loss 0.0331 Accuracy 4.7587\n",
      "Epoch 922 Batch 25 Loss 0.0331 Accuracy 4.7586\n",
      "Epoch 922 Batch 30 Loss 0.0331 Accuracy 4.7585\n",
      "Epoch 922 Batch 35 Loss 0.0331 Accuracy 4.7585\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7592\n",
      "Epoch 923 Batch 5 Loss 0.0331 Accuracy 4.7584\n",
      "Epoch 923 Batch 10 Loss 0.0331 Accuracy 4.7583\n",
      "Epoch 923 Batch 15 Loss 0.0331 Accuracy 4.7582\n",
      "Epoch 923 Batch 20 Loss 0.0331 Accuracy 4.7581\n",
      "Epoch 923 Batch 25 Loss 0.0331 Accuracy 4.7581\n",
      "Epoch 923 Batch 30 Loss 0.0331 Accuracy 4.7580\n",
      "Epoch 923 Batch 35 Loss 0.0331 Accuracy 4.7579\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7586\n",
      "Epoch 924 Batch 5 Loss 0.0331 Accuracy 4.7578\n",
      "Epoch 924 Batch 10 Loss 0.0331 Accuracy 4.7577\n",
      "Epoch 924 Batch 15 Loss 0.0331 Accuracy 4.7577\n",
      "Epoch 924 Batch 20 Loss 0.0331 Accuracy 4.7576\n",
      "Epoch 924 Batch 25 Loss 0.0331 Accuracy 4.7575\n",
      "Epoch 924 Batch 30 Loss 0.0331 Accuracy 4.7574\n",
      "Epoch 924 Batch 35 Loss 0.0331 Accuracy 4.7574\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7581\n",
      "Epoch 925 Batch 5 Loss 0.0331 Accuracy 4.7573\n",
      "Epoch 925 Batch 10 Loss 0.0331 Accuracy 4.7572\n",
      "Epoch 925 Batch 15 Loss 0.0331 Accuracy 4.7571\n",
      "Epoch 925 Batch 20 Loss 0.0331 Accuracy 4.7570\n",
      "Epoch 925 Batch 25 Loss 0.0331 Accuracy 4.7570\n",
      "Epoch 925 Batch 30 Loss 0.0331 Accuracy 4.7569\n",
      "Epoch 925 Batch 35 Loss 0.0331 Accuracy 4.7568\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7575\n",
      "Epoch 926 Batch 5 Loss 0.0331 Accuracy 4.7567\n",
      "Epoch 926 Batch 10 Loss 0.0331 Accuracy 4.7566\n",
      "Epoch 926 Batch 15 Loss 0.0331 Accuracy 4.7566\n",
      "Epoch 926 Batch 20 Loss 0.0331 Accuracy 4.7565\n",
      "Epoch 926 Batch 25 Loss 0.0331 Accuracy 4.7564\n",
      "Epoch 926 Batch 30 Loss 0.0331 Accuracy 4.7563\n",
      "Epoch 926 Batch 35 Loss 0.0331 Accuracy 4.7563\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7570\n",
      "Epoch 927 Batch 5 Loss 0.0331 Accuracy 4.7562\n",
      "Epoch 927 Batch 10 Loss 0.0331 Accuracy 4.7561\n",
      "Epoch 927 Batch 15 Loss 0.0331 Accuracy 4.7560\n",
      "Epoch 927 Batch 20 Loss 0.0331 Accuracy 4.7559\n",
      "Epoch 927 Batch 25 Loss 0.0331 Accuracy 4.7559\n",
      "Epoch 927 Batch 30 Loss 0.0331 Accuracy 4.7558\n",
      "Epoch 927 Batch 35 Loss 0.0331 Accuracy 4.7557\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7564\n",
      "Epoch 928 Batch 5 Loss 0.0331 Accuracy 4.7556\n",
      "Epoch 928 Batch 10 Loss 0.0331 Accuracy 4.7555\n",
      "Epoch 928 Batch 15 Loss 0.0331 Accuracy 4.7555\n",
      "Epoch 928 Batch 20 Loss 0.0331 Accuracy 4.7554\n",
      "Epoch 928 Batch 25 Loss 0.0331 Accuracy 4.7553\n",
      "Epoch 928 Batch 30 Loss 0.0331 Accuracy 4.7552\n",
      "Epoch 928 Batch 35 Loss 0.0331 Accuracy 4.7552\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7559\n",
      "Epoch 929 Batch 5 Loss 0.0331 Accuracy 4.7551\n",
      "Epoch 929 Batch 10 Loss 0.0331 Accuracy 4.7550\n",
      "Epoch 929 Batch 15 Loss 0.0331 Accuracy 4.7549\n",
      "Epoch 929 Batch 20 Loss 0.0331 Accuracy 4.7549\n",
      "Epoch 929 Batch 25 Loss 0.0331 Accuracy 4.7548\n",
      "Epoch 929 Batch 30 Loss 0.0331 Accuracy 4.7547\n",
      "Epoch 929 Batch 35 Loss 0.0331 Accuracy 4.7546\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7553\n",
      "Epoch 930 Batch 5 Loss 0.0331 Accuracy 4.7545\n",
      "Epoch 930 Batch 10 Loss 0.0331 Accuracy 4.7545\n",
      "Epoch 930 Batch 15 Loss 0.0331 Accuracy 4.7544\n",
      "Epoch 930 Batch 20 Loss 0.0331 Accuracy 4.7543\n",
      "Epoch 930 Batch 25 Loss 0.0331 Accuracy 4.7542\n",
      "Epoch 930 Batch 30 Loss 0.0331 Accuracy 4.7542\n",
      "Epoch 930 Batch 35 Loss 0.0331 Accuracy 4.7541\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7548\n",
      "Epoch 931 Batch 5 Loss 0.0331 Accuracy 4.7540\n",
      "Epoch 931 Batch 10 Loss 0.0331 Accuracy 4.7539\n",
      "Epoch 931 Batch 15 Loss 0.0331 Accuracy 4.7538\n",
      "Epoch 931 Batch 20 Loss 0.0331 Accuracy 4.7538\n",
      "Epoch 931 Batch 25 Loss 0.0331 Accuracy 4.7537\n",
      "Epoch 931 Batch 30 Loss 0.0331 Accuracy 4.7536\n",
      "Epoch 931 Batch 35 Loss 0.0331 Accuracy 4.7535\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7542\n",
      "Epoch 932 Batch 5 Loss 0.0331 Accuracy 4.7534\n",
      "Epoch 932 Batch 10 Loss 0.0331 Accuracy 4.7534\n",
      "Epoch 932 Batch 15 Loss 0.0331 Accuracy 4.7533\n",
      "Epoch 932 Batch 20 Loss 0.0331 Accuracy 4.7532\n",
      "Epoch 932 Batch 25 Loss 0.0331 Accuracy 4.7532\n",
      "Epoch 932 Batch 30 Loss 0.0331 Accuracy 4.7531\n",
      "Epoch 932 Batch 35 Loss 0.0331 Accuracy 4.7530\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7537\n",
      "Epoch 933 Batch 5 Loss 0.0331 Accuracy 4.7529\n",
      "Epoch 933 Batch 10 Loss 0.0331 Accuracy 4.7528\n",
      "Epoch 933 Batch 15 Loss 0.0331 Accuracy 4.7528\n",
      "Epoch 933 Batch 20 Loss 0.0331 Accuracy 4.7527\n",
      "Epoch 933 Batch 25 Loss 0.0331 Accuracy 4.7526\n",
      "Epoch 933 Batch 30 Loss 0.0331 Accuracy 4.7525\n",
      "Epoch 933 Batch 35 Loss 0.0331 Accuracy 4.7525\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7531\n",
      "Epoch 934 Batch 5 Loss 0.0331 Accuracy 4.7524\n",
      "Epoch 934 Batch 10 Loss 0.0331 Accuracy 4.7523\n",
      "Epoch 934 Batch 15 Loss 0.0331 Accuracy 4.7522\n",
      "Epoch 934 Batch 20 Loss 0.0331 Accuracy 4.7521\n",
      "Epoch 934 Batch 25 Loss 0.0331 Accuracy 4.7521\n",
      "Epoch 934 Batch 30 Loss 0.0331 Accuracy 4.7520\n",
      "Epoch 934 Batch 35 Loss 0.0331 Accuracy 4.7519\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7526\n",
      "Epoch 935 Batch 5 Loss 0.0331 Accuracy 4.7518\n",
      "Epoch 935 Batch 10 Loss 0.0331 Accuracy 4.7517\n",
      "Epoch 935 Batch 15 Loss 0.0331 Accuracy 4.7517\n",
      "Epoch 935 Batch 20 Loss 0.0331 Accuracy 4.7516\n",
      "Epoch 935 Batch 25 Loss 0.0331 Accuracy 4.7515\n",
      "Epoch 935 Batch 30 Loss 0.0331 Accuracy 4.7514\n",
      "Epoch 935 Batch 35 Loss 0.0331 Accuracy 4.7514\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7520\n",
      "Epoch 936 Batch 5 Loss 0.0331 Accuracy 4.7513\n",
      "Epoch 936 Batch 10 Loss 0.0331 Accuracy 4.7512\n",
      "Epoch 936 Batch 15 Loss 0.0331 Accuracy 4.7511\n",
      "Epoch 936 Batch 20 Loss 0.0331 Accuracy 4.7510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 936 Batch 25 Loss 0.0331 Accuracy 4.7510\n",
      "Epoch 936 Batch 30 Loss 0.0331 Accuracy 4.7509\n",
      "Epoch 936 Batch 35 Loss 0.0331 Accuracy 4.7508\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7515\n",
      "Epoch 937 Batch 5 Loss 0.0331 Accuracy 4.7507\n",
      "Epoch 937 Batch 10 Loss 0.0331 Accuracy 4.7506\n",
      "Epoch 937 Batch 15 Loss 0.0331 Accuracy 4.7506\n",
      "Epoch 937 Batch 20 Loss 0.0331 Accuracy 4.7505\n",
      "Epoch 937 Batch 25 Loss 0.0331 Accuracy 4.7504\n",
      "Epoch 937 Batch 30 Loss 0.0331 Accuracy 4.7503\n",
      "Epoch 937 Batch 35 Loss 0.0331 Accuracy 4.7503\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7509\n",
      "Epoch 938 Batch 5 Loss 0.0331 Accuracy 4.7502\n",
      "Epoch 938 Batch 10 Loss 0.0331 Accuracy 4.7501\n",
      "Epoch 938 Batch 15 Loss 0.0330 Accuracy 4.7500\n",
      "Epoch 938 Batch 20 Loss 0.0330 Accuracy 4.7499\n",
      "Epoch 938 Batch 25 Loss 0.0330 Accuracy 4.7499\n",
      "Epoch 938 Batch 30 Loss 0.0330 Accuracy 4.7498\n",
      "Epoch 938 Batch 35 Loss 0.0330 Accuracy 4.7497\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7504\n",
      "Epoch 939 Batch 5 Loss 0.0330 Accuracy 4.7496\n",
      "Epoch 939 Batch 10 Loss 0.0330 Accuracy 4.7495\n",
      "Epoch 939 Batch 15 Loss 0.0330 Accuracy 4.7495\n",
      "Epoch 939 Batch 20 Loss 0.0330 Accuracy 4.7494\n",
      "Epoch 939 Batch 25 Loss 0.0330 Accuracy 4.7493\n",
      "Epoch 939 Batch 30 Loss 0.0330 Accuracy 4.7492\n",
      "Epoch 939 Batch 35 Loss 0.0330 Accuracy 4.7492\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7499\n",
      "Epoch 940 Batch 5 Loss 0.0330 Accuracy 4.7491\n",
      "Epoch 940 Batch 10 Loss 0.0330 Accuracy 4.7490\n",
      "Epoch 940 Batch 15 Loss 0.0330 Accuracy 4.7489\n",
      "Epoch 940 Batch 20 Loss 0.0330 Accuracy 4.7488\n",
      "Epoch 940 Batch 25 Loss 0.0330 Accuracy 4.7488\n",
      "Epoch 940 Batch 30 Loss 0.0330 Accuracy 4.7487\n",
      "Epoch 940 Batch 35 Loss 0.0330 Accuracy 4.7486\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7493\n",
      "Epoch 941 Batch 5 Loss 0.0330 Accuracy 4.7485\n",
      "Epoch 941 Batch 10 Loss 0.0330 Accuracy 4.7484\n",
      "Epoch 941 Batch 15 Loss 0.0330 Accuracy 4.7484\n",
      "Epoch 941 Batch 20 Loss 0.0330 Accuracy 4.7483\n",
      "Epoch 941 Batch 25 Loss 0.0330 Accuracy 4.7482\n",
      "Epoch 941 Batch 30 Loss 0.0330 Accuracy 4.7481\n",
      "Epoch 941 Batch 35 Loss 0.0330 Accuracy 4.7481\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7488\n",
      "Epoch 942 Batch 5 Loss 0.0330 Accuracy 4.7480\n",
      "Epoch 942 Batch 10 Loss 0.0330 Accuracy 4.7479\n",
      "Epoch 942 Batch 15 Loss 0.0330 Accuracy 4.7478\n",
      "Epoch 942 Batch 20 Loss 0.0330 Accuracy 4.7477\n",
      "Epoch 942 Batch 25 Loss 0.0330 Accuracy 4.7477\n",
      "Epoch 942 Batch 30 Loss 0.0330 Accuracy 4.7476\n",
      "Epoch 942 Batch 35 Loss 0.0330 Accuracy 4.7475\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7482\n",
      "Epoch 943 Batch 5 Loss 0.0330 Accuracy 4.7474\n",
      "Epoch 943 Batch 10 Loss 0.0330 Accuracy 4.7473\n",
      "Epoch 943 Batch 15 Loss 0.0330 Accuracy 4.7473\n",
      "Epoch 943 Batch 20 Loss 0.0330 Accuracy 4.7472\n",
      "Epoch 943 Batch 25 Loss 0.0330 Accuracy 4.7471\n",
      "Epoch 943 Batch 30 Loss 0.0330 Accuracy 4.7471\n",
      "Epoch 943 Batch 35 Loss 0.0330 Accuracy 4.7470\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7477\n",
      "Epoch 944 Batch 5 Loss 0.0330 Accuracy 4.7469\n",
      "Epoch 944 Batch 10 Loss 0.0330 Accuracy 4.7468\n",
      "Epoch 944 Batch 15 Loss 0.0330 Accuracy 4.7467\n",
      "Epoch 944 Batch 20 Loss 0.0330 Accuracy 4.7467\n",
      "Epoch 944 Batch 25 Loss 0.0330 Accuracy 4.7466\n",
      "Epoch 944 Batch 30 Loss 0.0330 Accuracy 4.7465\n",
      "Epoch 944 Batch 35 Loss 0.0330 Accuracy 4.7464\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7471\n",
      "Epoch 945 Batch 5 Loss 0.0330 Accuracy 4.7463\n",
      "Epoch 945 Batch 10 Loss 0.0330 Accuracy 4.7463\n",
      "Epoch 945 Batch 15 Loss 0.0330 Accuracy 4.7462\n",
      "Epoch 945 Batch 20 Loss 0.0330 Accuracy 4.7461\n",
      "Epoch 945 Batch 25 Loss 0.0330 Accuracy 4.7460\n",
      "Epoch 945 Batch 30 Loss 0.0330 Accuracy 4.7460\n",
      "Epoch 945 Batch 35 Loss 0.0330 Accuracy 4.7459\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7466\n",
      "Epoch 946 Batch 5 Loss 0.0330 Accuracy 4.7458\n",
      "Epoch 946 Batch 10 Loss 0.0330 Accuracy 4.7457\n",
      "Epoch 946 Batch 15 Loss 0.0330 Accuracy 4.7456\n",
      "Epoch 946 Batch 20 Loss 0.0330 Accuracy 4.7456\n",
      "Epoch 946 Batch 25 Loss 0.0330 Accuracy 4.7455\n",
      "Epoch 946 Batch 30 Loss 0.0330 Accuracy 4.7454\n",
      "Epoch 946 Batch 35 Loss 0.0330 Accuracy 4.7454\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7460\n",
      "Epoch 947 Batch 5 Loss 0.0330 Accuracy 4.7453\n",
      "Epoch 947 Batch 10 Loss 0.0330 Accuracy 4.7452\n",
      "Epoch 947 Batch 15 Loss 0.0330 Accuracy 4.7451\n",
      "Epoch 947 Batch 20 Loss 0.0330 Accuracy 4.7450\n",
      "Epoch 947 Batch 25 Loss 0.0330 Accuracy 4.7450\n",
      "Epoch 947 Batch 30 Loss 0.0330 Accuracy 4.7449\n",
      "Epoch 947 Batch 35 Loss 0.0330 Accuracy 4.7448\n",
      "Time taken for 1 epoch: 0.53 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7455\n",
      "Epoch 948 Batch 5 Loss 0.0330 Accuracy 4.7447\n",
      "Epoch 948 Batch 10 Loss 0.0330 Accuracy 4.7446\n",
      "Epoch 948 Batch 15 Loss 0.0330 Accuracy 4.7446\n",
      "Epoch 948 Batch 20 Loss 0.0330 Accuracy 4.7445\n",
      "Epoch 948 Batch 25 Loss 0.0330 Accuracy 4.7444\n",
      "Epoch 948 Batch 30 Loss 0.0330 Accuracy 4.7444\n",
      "Epoch 948 Batch 35 Loss 0.0330 Accuracy 4.7443\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7449\n",
      "Epoch 949 Batch 5 Loss 0.0330 Accuracy 4.7442\n",
      "Epoch 949 Batch 10 Loss 0.0330 Accuracy 4.7441\n",
      "Epoch 949 Batch 15 Loss 0.0330 Accuracy 4.7440\n",
      "Epoch 949 Batch 20 Loss 0.0330 Accuracy 4.7440\n",
      "Epoch 949 Batch 25 Loss 0.0330 Accuracy 4.7439\n",
      "Epoch 949 Batch 30 Loss 0.0330 Accuracy 4.7438\n",
      "Epoch 949 Batch 35 Loss 0.0330 Accuracy 4.7437\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7444\n",
      "Epoch 950 Batch 5 Loss 0.0329 Accuracy 4.7436\n",
      "Epoch 950 Batch 10 Loss 0.0329 Accuracy 4.7436\n",
      "Epoch 950 Batch 15 Loss 0.0329 Accuracy 4.7435\n",
      "Epoch 950 Batch 20 Loss 0.0329 Accuracy 4.7434\n",
      "Epoch 950 Batch 25 Loss 0.0329 Accuracy 4.7433\n",
      "Epoch 950 Batch 30 Loss 0.0329 Accuracy 4.7433\n",
      "Epoch 950 Batch 35 Loss 0.0329 Accuracy 4.7432\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7439\n",
      "Epoch 951 Batch 5 Loss 0.0329 Accuracy 4.7431\n",
      "Epoch 951 Batch 10 Loss 0.0329 Accuracy 4.7430\n",
      "Epoch 951 Batch 15 Loss 0.0329 Accuracy 4.7430\n",
      "Epoch 951 Batch 20 Loss 0.0329 Accuracy 4.7429\n",
      "Epoch 951 Batch 25 Loss 0.0329 Accuracy 4.7428\n",
      "Epoch 951 Batch 30 Loss 0.0329 Accuracy 4.7427\n",
      "Epoch 951 Batch 35 Loss 0.0329 Accuracy 4.7427\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7433\n",
      "Epoch 952 Batch 5 Loss 0.0329 Accuracy 4.7426\n",
      "Epoch 952 Batch 10 Loss 0.0329 Accuracy 4.7425\n",
      "Epoch 952 Batch 15 Loss 0.0329 Accuracy 4.7424\n",
      "Epoch 952 Batch 20 Loss 0.0329 Accuracy 4.7423\n",
      "Epoch 952 Batch 25 Loss 0.0329 Accuracy 4.7423\n",
      "Epoch 952 Batch 30 Loss 0.0329 Accuracy 4.7422\n",
      "Epoch 952 Batch 35 Loss 0.0329 Accuracy 4.7421\n",
      "Time taken for 1 epoch: 0.52 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7428\n",
      "Epoch 953 Batch 5 Loss 0.0329 Accuracy 4.7420\n",
      "Epoch 953 Batch 10 Loss 0.0329 Accuracy 4.7419\n",
      "Epoch 953 Batch 15 Loss 0.0329 Accuracy 4.7419\n",
      "Epoch 953 Batch 20 Loss 0.0329 Accuracy 4.7418\n",
      "Epoch 953 Batch 25 Loss 0.0329 Accuracy 4.7417\n",
      "Epoch 953 Batch 30 Loss 0.0329 Accuracy 4.7416\n",
      "Epoch 953 Batch 35 Loss 0.0329 Accuracy 4.7416\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7422\n",
      "Epoch 954 Batch 5 Loss 0.0329 Accuracy 4.7415\n",
      "Epoch 954 Batch 10 Loss 0.0329 Accuracy 4.7414\n",
      "Epoch 954 Batch 15 Loss 0.0329 Accuracy 4.7413\n",
      "Epoch 954 Batch 20 Loss 0.0329 Accuracy 4.7412\n",
      "Epoch 954 Batch 25 Loss 0.0329 Accuracy 4.7412\n",
      "Epoch 954 Batch 30 Loss 0.0329 Accuracy 4.7411\n",
      "Epoch 954 Batch 35 Loss 0.0329 Accuracy 4.7410\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7417\n",
      "Epoch 955 Batch 5 Loss 0.0329 Accuracy 4.7409\n",
      "Epoch 955 Batch 10 Loss 0.0329 Accuracy 4.7408\n",
      "Epoch 955 Batch 15 Loss 0.0329 Accuracy 4.7408\n",
      "Epoch 955 Batch 20 Loss 0.0329 Accuracy 4.7407\n",
      "Epoch 955 Batch 25 Loss 0.0329 Accuracy 4.7406\n",
      "Epoch 955 Batch 30 Loss 0.0329 Accuracy 4.7405\n",
      "Epoch 955 Batch 35 Loss 0.0329 Accuracy 4.7405\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7411\n",
      "Epoch 956 Batch 5 Loss 0.0329 Accuracy 4.7404\n",
      "Epoch 956 Batch 10 Loss 0.0329 Accuracy 4.7403\n",
      "Epoch 956 Batch 15 Loss 0.0329 Accuracy 4.7402\n",
      "Epoch 956 Batch 20 Loss 0.0329 Accuracy 4.7401\n",
      "Epoch 956 Batch 25 Loss 0.0329 Accuracy 4.7401\n",
      "Epoch 956 Batch 30 Loss 0.0329 Accuracy 4.7400\n",
      "Epoch 956 Batch 35 Loss 0.0329 Accuracy 4.7399\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7406\n",
      "Epoch 957 Batch 5 Loss 0.0329 Accuracy 4.7398\n",
      "Epoch 957 Batch 10 Loss 0.0329 Accuracy 4.7397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 957 Batch 15 Loss 0.0329 Accuracy 4.7397\n",
      "Epoch 957 Batch 20 Loss 0.0329 Accuracy 4.7396\n",
      "Epoch 957 Batch 25 Loss 0.0329 Accuracy 4.7395\n",
      "Epoch 957 Batch 30 Loss 0.0329 Accuracy 4.7395\n",
      "Epoch 957 Batch 35 Loss 0.0329 Accuracy 4.7394\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7401\n",
      "Epoch 958 Batch 5 Loss 0.0329 Accuracy 4.7393\n",
      "Epoch 958 Batch 10 Loss 0.0329 Accuracy 4.7392\n",
      "Epoch 958 Batch 15 Loss 0.0329 Accuracy 4.7391\n",
      "Epoch 958 Batch 20 Loss 0.0329 Accuracy 4.7391\n",
      "Epoch 958 Batch 25 Loss 0.0329 Accuracy 4.7390\n",
      "Epoch 958 Batch 30 Loss 0.0329 Accuracy 4.7389\n",
      "Epoch 958 Batch 35 Loss 0.0329 Accuracy 4.7388\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7395\n",
      "Epoch 959 Batch 5 Loss 0.0329 Accuracy 4.7387\n",
      "Epoch 959 Batch 10 Loss 0.0329 Accuracy 4.7387\n",
      "Epoch 959 Batch 15 Loss 0.0329 Accuracy 4.7386\n",
      "Epoch 959 Batch 20 Loss 0.0329 Accuracy 4.7385\n",
      "Epoch 959 Batch 25 Loss 0.0329 Accuracy 4.7384\n",
      "Epoch 959 Batch 30 Loss 0.0329 Accuracy 4.7384\n",
      "Epoch 959 Batch 35 Loss 0.0329 Accuracy 4.7383\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7390\n",
      "Epoch 960 Batch 5 Loss 0.0329 Accuracy 4.7382\n",
      "Epoch 960 Batch 10 Loss 0.0329 Accuracy 4.7381\n",
      "Epoch 960 Batch 15 Loss 0.0329 Accuracy 4.7380\n",
      "Epoch 960 Batch 20 Loss 0.0329 Accuracy 4.7380\n",
      "Epoch 960 Batch 25 Loss 0.0329 Accuracy 4.7379\n",
      "Epoch 960 Batch 30 Loss 0.0329 Accuracy 4.7378\n",
      "Epoch 960 Batch 35 Loss 0.0329 Accuracy 4.7378\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7384\n",
      "Epoch 961 Batch 5 Loss 0.0329 Accuracy 4.7376\n",
      "Epoch 961 Batch 10 Loss 0.0329 Accuracy 4.7376\n",
      "Epoch 961 Batch 15 Loss 0.0329 Accuracy 4.7375\n",
      "Epoch 961 Batch 20 Loss 0.0329 Accuracy 4.7374\n",
      "Epoch 961 Batch 25 Loss 0.0329 Accuracy 4.7374\n",
      "Epoch 961 Batch 30 Loss 0.0329 Accuracy 4.7373\n",
      "Epoch 961 Batch 35 Loss 0.0329 Accuracy 4.7372\n",
      "Time taken for 1 epoch: 0.49 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7379\n",
      "Epoch 962 Batch 5 Loss 0.0329 Accuracy 4.7371\n",
      "Epoch 962 Batch 10 Loss 0.0329 Accuracy 4.7370\n",
      "Epoch 962 Batch 15 Loss 0.0329 Accuracy 4.7370\n",
      "Epoch 962 Batch 20 Loss 0.0329 Accuracy 4.7369\n",
      "Epoch 962 Batch 25 Loss 0.0329 Accuracy 4.7368\n",
      "Epoch 962 Batch 30 Loss 0.0329 Accuracy 4.7367\n",
      "Epoch 962 Batch 35 Loss 0.0329 Accuracy 4.7367\n",
      "Time taken for 1 epoch: 0.44 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7374\n",
      "Epoch 963 Batch 5 Loss 0.0329 Accuracy 4.7366\n",
      "Epoch 963 Batch 10 Loss 0.0329 Accuracy 4.7365\n",
      "Epoch 963 Batch 15 Loss 0.0329 Accuracy 4.7364\n",
      "Epoch 963 Batch 20 Loss 0.0329 Accuracy 4.7364\n",
      "Epoch 963 Batch 25 Loss 0.0329 Accuracy 4.7363\n",
      "Epoch 963 Batch 30 Loss 0.0329 Accuracy 4.7362\n",
      "Epoch 963 Batch 35 Loss 0.0329 Accuracy 4.7361\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7368\n",
      "Epoch 964 Batch 5 Loss 0.0328 Accuracy 4.7360\n",
      "Epoch 964 Batch 10 Loss 0.0328 Accuracy 4.7360\n",
      "Epoch 964 Batch 15 Loss 0.0328 Accuracy 4.7359\n",
      "Epoch 964 Batch 20 Loss 0.0328 Accuracy 4.7358\n",
      "Epoch 964 Batch 25 Loss 0.0328 Accuracy 4.7357\n",
      "Epoch 964 Batch 30 Loss 0.0328 Accuracy 4.7357\n",
      "Epoch 964 Batch 35 Loss 0.0328 Accuracy 4.7356\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7363\n",
      "Epoch 965 Batch 5 Loss 0.0328 Accuracy 4.7355\n",
      "Epoch 965 Batch 10 Loss 0.0328 Accuracy 4.7354\n",
      "Epoch 965 Batch 15 Loss 0.0328 Accuracy 4.7354\n",
      "Epoch 965 Batch 20 Loss 0.0328 Accuracy 4.7353\n",
      "Epoch 965 Batch 25 Loss 0.0328 Accuracy 4.7352\n",
      "Epoch 965 Batch 30 Loss 0.0328 Accuracy 4.7351\n",
      "Epoch 965 Batch 35 Loss 0.0328 Accuracy 4.7351\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7357\n",
      "Epoch 966 Batch 5 Loss 0.0328 Accuracy 4.7350\n",
      "Epoch 966 Batch 10 Loss 0.0328 Accuracy 4.7349\n",
      "Epoch 966 Batch 15 Loss 0.0328 Accuracy 4.7348\n",
      "Epoch 966 Batch 20 Loss 0.0328 Accuracy 4.7347\n",
      "Epoch 966 Batch 25 Loss 0.0328 Accuracy 4.7347\n",
      "Epoch 966 Batch 30 Loss 0.0328 Accuracy 4.7346\n",
      "Epoch 966 Batch 35 Loss 0.0328 Accuracy 4.7345\n",
      "Time taken for 1 epoch: 0.46 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7352\n",
      "Epoch 967 Batch 5 Loss 0.0328 Accuracy 4.7344\n",
      "Epoch 967 Batch 10 Loss 0.0328 Accuracy 4.7344\n",
      "Epoch 967 Batch 15 Loss 0.0328 Accuracy 4.7343\n",
      "Epoch 967 Batch 20 Loss 0.0328 Accuracy 4.7342\n",
      "Epoch 967 Batch 25 Loss 0.0328 Accuracy 4.7341\n",
      "Epoch 967 Batch 30 Loss 0.0328 Accuracy 4.7341\n",
      "Epoch 967 Batch 35 Loss 0.0328 Accuracy 4.7340\n",
      "Time taken for 1 epoch: 0.45 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7347\n",
      "Epoch 968 Batch 5 Loss 0.0328 Accuracy 4.7339\n",
      "Epoch 968 Batch 10 Loss 0.0328 Accuracy 4.7338\n",
      "Epoch 968 Batch 15 Loss 0.0328 Accuracy 4.7338\n",
      "Epoch 968 Batch 20 Loss 0.0328 Accuracy 4.7337\n",
      "Epoch 968 Batch 25 Loss 0.0328 Accuracy 4.7336\n",
      "Epoch 968 Batch 30 Loss 0.0328 Accuracy 4.7335\n",
      "Epoch 968 Batch 35 Loss 0.0328 Accuracy 4.7335\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7341\n",
      "Epoch 969 Batch 5 Loss 0.0328 Accuracy 4.7334\n",
      "Epoch 969 Batch 10 Loss 0.0328 Accuracy 4.7333\n",
      "Epoch 969 Batch 15 Loss 0.0328 Accuracy 4.7332\n",
      "Epoch 969 Batch 20 Loss 0.0328 Accuracy 4.7331\n",
      "Epoch 969 Batch 25 Loss 0.0328 Accuracy 4.7331\n",
      "Epoch 969 Batch 30 Loss 0.0328 Accuracy 4.7330\n",
      "Epoch 969 Batch 35 Loss 0.0328 Accuracy 4.7329\n",
      "Time taken for 1 epoch: 0.47 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7336\n",
      "Epoch 970 Batch 5 Loss 0.0328 Accuracy 4.7328\n",
      "Epoch 970 Batch 10 Loss 0.0328 Accuracy 4.7328\n",
      "Epoch 970 Batch 15 Loss 0.0328 Accuracy 4.7327\n",
      "Epoch 970 Batch 20 Loss 0.0328 Accuracy 4.7326\n",
      "Epoch 970 Batch 25 Loss 0.0328 Accuracy 4.7325\n",
      "Epoch 970 Batch 30 Loss 0.0328 Accuracy 4.7325\n",
      "Epoch 970 Batch 35 Loss 0.0328 Accuracy 4.7324\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7330\n",
      "Epoch 971 Batch 5 Loss 0.0328 Accuracy 4.7323\n",
      "Epoch 971 Batch 10 Loss 0.0328 Accuracy 4.7322\n",
      "Epoch 971 Batch 15 Loss 0.0328 Accuracy 4.7322\n",
      "Epoch 971 Batch 20 Loss 0.0328 Accuracy 4.7321\n",
      "Epoch 971 Batch 25 Loss 0.0328 Accuracy 4.7320\n",
      "Epoch 971 Batch 30 Loss 0.0328 Accuracy 4.7319\n",
      "Epoch 971 Batch 35 Loss 0.0328 Accuracy 4.7319\n",
      "Time taken for 1 epoch: 0.51 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7325\n",
      "Epoch 972 Batch 5 Loss 0.0328 Accuracy 4.7318\n",
      "Epoch 972 Batch 10 Loss 0.0328 Accuracy 4.7317\n",
      "Epoch 972 Batch 15 Loss 0.0328 Accuracy 4.7316\n",
      "Epoch 972 Batch 20 Loss 0.0328 Accuracy 4.7315\n",
      "Epoch 972 Batch 25 Loss 0.0328 Accuracy 4.7315\n",
      "Epoch 972 Batch 30 Loss 0.0328 Accuracy 4.7314\n",
      "Epoch 972 Batch 35 Loss 0.0328 Accuracy 4.7313\n",
      "Time taken for 1 epoch: 0.50 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7320\n",
      "Epoch 973 Batch 5 Loss 0.0328 Accuracy 4.7312\n",
      "Epoch 973 Batch 10 Loss 0.0328 Accuracy 4.7311\n",
      "Epoch 973 Batch 15 Loss 0.0328 Accuracy 4.7311\n",
      "Epoch 973 Batch 20 Loss 0.0328 Accuracy 4.7310\n",
      "Epoch 973 Batch 25 Loss 0.0328 Accuracy 4.7309\n",
      "Epoch 973 Batch 30 Loss 0.0328 Accuracy 4.7308\n",
      "Epoch 973 Batch 35 Loss 0.0328 Accuracy 4.7308\n",
      "Time taken for 1 epoch: 0.67 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7314\n",
      "Epoch 974 Batch 5 Loss 0.0328 Accuracy 4.7307\n",
      "Epoch 974 Batch 10 Loss 0.0328 Accuracy 4.7306\n",
      "Epoch 974 Batch 15 Loss 0.0328 Accuracy 4.7305\n",
      "Epoch 974 Batch 20 Loss 0.0328 Accuracy 4.7305\n",
      "Epoch 974 Batch 25 Loss 0.0328 Accuracy 4.7304\n",
      "Epoch 974 Batch 30 Loss 0.0328 Accuracy 4.7303\n",
      "Epoch 974 Batch 35 Loss 0.0328 Accuracy 4.7302\n",
      "Time taken for 1 epoch: 0.69 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7309\n",
      "Epoch 975 Batch 5 Loss 0.0328 Accuracy 4.7301\n",
      "Epoch 975 Batch 10 Loss 0.0328 Accuracy 4.7301\n",
      "Epoch 975 Batch 15 Loss 0.0328 Accuracy 4.7300\n",
      "Epoch 975 Batch 20 Loss 0.0328 Accuracy 4.7299\n",
      "Epoch 975 Batch 25 Loss 0.0328 Accuracy 4.7298\n",
      "Epoch 975 Batch 30 Loss 0.0328 Accuracy 4.7298\n",
      "Epoch 975 Batch 35 Loss 0.0328 Accuracy 4.7297\n",
      "Time taken for 1 epoch: 0.55 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7304\n",
      "Epoch 976 Batch 5 Loss 0.0328 Accuracy 4.7296\n",
      "Epoch 976 Batch 10 Loss 0.0328 Accuracy 4.7295\n",
      "Epoch 976 Batch 15 Loss 0.0328 Accuracy 4.7294\n",
      "Epoch 976 Batch 20 Loss 0.0328 Accuracy 4.7294\n",
      "Epoch 976 Batch 25 Loss 0.0328 Accuracy 4.7293\n",
      "Epoch 976 Batch 30 Loss 0.0328 Accuracy 4.7292\n",
      "Epoch 976 Batch 35 Loss 0.0328 Accuracy 4.7292\n",
      "Time taken for 1 epoch: 0.56 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7298\n",
      "Epoch 977 Batch 5 Loss 0.0328 Accuracy 4.7291\n",
      "Epoch 977 Batch 10 Loss 0.0328 Accuracy 4.7290\n",
      "Epoch 977 Batch 15 Loss 0.0328 Accuracy 4.7289\n",
      "Epoch 977 Batch 20 Loss 0.0328 Accuracy 4.7288\n",
      "Epoch 977 Batch 25 Loss 0.0328 Accuracy 4.7288\n",
      "Epoch 977 Batch 30 Loss 0.0328 Accuracy 4.7287\n",
      "Epoch 977 Batch 35 Loss 0.0328 Accuracy 4.7286\n",
      "Time taken for 1 epoch: 0.54 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7293\n",
      "Epoch 978 Batch 5 Loss 0.0328 Accuracy 4.7285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 978 Batch 10 Loss 0.0328 Accuracy 4.7284\n",
      "Epoch 978 Batch 15 Loss 0.0328 Accuracy 4.7284\n",
      "Epoch 978 Batch 20 Loss 0.0328 Accuracy 4.7283\n",
      "Epoch 978 Batch 25 Loss 0.0328 Accuracy 4.7282\n",
      "Epoch 978 Batch 30 Loss 0.0328 Accuracy 4.7281\n",
      "Epoch 978 Batch 35 Loss 0.0328 Accuracy 4.7281\n",
      "Time taken for 1 epoch: 0.61 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7288\n",
      "Epoch 979 Batch 5 Loss 0.0328 Accuracy 4.7280\n",
      "Epoch 979 Batch 10 Loss 0.0328 Accuracy 4.7279\n",
      "Epoch 979 Batch 15 Loss 0.0328 Accuracy 4.7278\n",
      "Epoch 979 Batch 20 Loss 0.0328 Accuracy 4.7278\n",
      "Epoch 979 Batch 25 Loss 0.0328 Accuracy 4.7277\n",
      "Epoch 979 Batch 30 Loss 0.0328 Accuracy 4.7276\n",
      "Epoch 979 Batch 35 Loss 0.0328 Accuracy 4.7275\n",
      "Time taken for 1 epoch: 1.17 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7282\n",
      "Epoch 980 Batch 5 Loss 0.0328 Accuracy 4.7274\n",
      "Epoch 980 Batch 10 Loss 0.0328 Accuracy 4.7274\n",
      "Epoch 980 Batch 15 Loss 0.0327 Accuracy 4.7273\n",
      "Epoch 980 Batch 20 Loss 0.0327 Accuracy 4.7272\n",
      "Epoch 980 Batch 25 Loss 0.0327 Accuracy 4.7271\n",
      "Epoch 980 Batch 30 Loss 0.0327 Accuracy 4.7271\n",
      "Epoch 980 Batch 35 Loss 0.0327 Accuracy 4.7270\n",
      "Time taken for 1 epoch: 0.89 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7277\n",
      "Epoch 981 Batch 5 Loss 0.0327 Accuracy 4.7269\n",
      "Epoch 981 Batch 10 Loss 0.0327 Accuracy 4.7268\n",
      "Epoch 981 Batch 15 Loss 0.0327 Accuracy 4.7268\n",
      "Epoch 981 Batch 20 Loss 0.0327 Accuracy 4.7267\n",
      "Epoch 981 Batch 25 Loss 0.0327 Accuracy 4.7266\n",
      "Epoch 981 Batch 30 Loss 0.0327 Accuracy 4.7265\n",
      "Epoch 981 Batch 35 Loss 0.0327 Accuracy 4.7265\n",
      "Time taken for 1 epoch: 0.84 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7272\n",
      "Epoch 982 Batch 5 Loss 0.0327 Accuracy 4.7264\n",
      "Epoch 982 Batch 10 Loss 0.0327 Accuracy 4.7263\n",
      "Epoch 982 Batch 15 Loss 0.0327 Accuracy 4.7262\n",
      "Epoch 982 Batch 20 Loss 0.0327 Accuracy 4.7262\n",
      "Epoch 982 Batch 25 Loss 0.0327 Accuracy 4.7261\n",
      "Epoch 982 Batch 30 Loss 0.0327 Accuracy 4.7260\n",
      "Epoch 982 Batch 35 Loss 0.0327 Accuracy 4.7259\n",
      "Time taken for 1 epoch: 0.82 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7266\n",
      "Epoch 983 Batch 5 Loss 0.0327 Accuracy 4.7258\n",
      "Epoch 983 Batch 10 Loss 0.0327 Accuracy 4.7258\n",
      "Epoch 983 Batch 15 Loss 0.0327 Accuracy 4.7257\n",
      "Epoch 983 Batch 20 Loss 0.0327 Accuracy 4.7256\n",
      "Epoch 983 Batch 25 Loss 0.0327 Accuracy 4.7256\n",
      "Epoch 983 Batch 30 Loss 0.0327 Accuracy 4.7255\n",
      "Epoch 983 Batch 35 Loss 0.0327 Accuracy 4.7254\n",
      "Time taken for 1 epoch: 0.76 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7261\n",
      "Epoch 984 Batch 5 Loss 0.0327 Accuracy 4.7253\n",
      "Epoch 984 Batch 10 Loss 0.0327 Accuracy 4.7252\n",
      "Epoch 984 Batch 15 Loss 0.0327 Accuracy 4.7252\n",
      "Epoch 984 Batch 20 Loss 0.0327 Accuracy 4.7251\n",
      "Epoch 984 Batch 25 Loss 0.0327 Accuracy 4.7250\n",
      "Epoch 984 Batch 30 Loss 0.0327 Accuracy 4.7249\n",
      "Epoch 984 Batch 35 Loss 0.0327 Accuracy 4.7249\n",
      "Time taken for 1 epoch: 0.76 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7256\n",
      "Epoch 985 Batch 5 Loss 0.0327 Accuracy 4.7248\n",
      "Epoch 985 Batch 10 Loss 0.0327 Accuracy 4.7247\n",
      "Epoch 985 Batch 15 Loss 0.0327 Accuracy 4.7246\n",
      "Epoch 985 Batch 20 Loss 0.0327 Accuracy 4.7246\n",
      "Epoch 985 Batch 25 Loss 0.0327 Accuracy 4.7245\n",
      "Epoch 985 Batch 30 Loss 0.0327 Accuracy 4.7244\n",
      "Epoch 985 Batch 35 Loss 0.0327 Accuracy 4.7243\n",
      "Time taken for 1 epoch: 0.77 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7250\n",
      "Epoch 986 Batch 5 Loss 0.0327 Accuracy 4.7242\n",
      "Epoch 986 Batch 10 Loss 0.0327 Accuracy 4.7242\n",
      "Epoch 986 Batch 15 Loss 0.0327 Accuracy 4.7241\n",
      "Epoch 986 Batch 20 Loss 0.0327 Accuracy 4.7240\n",
      "Epoch 986 Batch 25 Loss 0.0327 Accuracy 4.7240\n",
      "Epoch 986 Batch 30 Loss 0.0327 Accuracy 4.7239\n",
      "Epoch 986 Batch 35 Loss 0.0327 Accuracy 4.7238\n",
      "Time taken for 1 epoch: 0.77 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7245\n",
      "Epoch 987 Batch 5 Loss 0.0327 Accuracy 4.7237\n",
      "Epoch 987 Batch 10 Loss 0.0327 Accuracy 4.7236\n",
      "Epoch 987 Batch 15 Loss 0.0327 Accuracy 4.7236\n",
      "Epoch 987 Batch 20 Loss 0.0327 Accuracy 4.7235\n",
      "Epoch 987 Batch 25 Loss 0.0327 Accuracy 4.7234\n",
      "Epoch 987 Batch 30 Loss 0.0327 Accuracy 4.7234\n",
      "Epoch 987 Batch 35 Loss 0.0327 Accuracy 4.7233\n",
      "Time taken for 1 epoch: 0.74 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7240\n",
      "Epoch 988 Batch 5 Loss 0.0327 Accuracy 4.7232\n",
      "Epoch 988 Batch 10 Loss 0.0327 Accuracy 4.7231\n",
      "Epoch 988 Batch 15 Loss 0.0327 Accuracy 4.7230\n",
      "Epoch 988 Batch 20 Loss 0.0327 Accuracy 4.7230\n",
      "Epoch 988 Batch 25 Loss 0.0327 Accuracy 4.7229\n",
      "Epoch 988 Batch 30 Loss 0.0327 Accuracy 4.7228\n",
      "Epoch 988 Batch 35 Loss 0.0327 Accuracy 4.7228\n",
      "Time taken for 1 epoch: 0.78 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7234\n",
      "Epoch 989 Batch 5 Loss 0.0327 Accuracy 4.7227\n",
      "Epoch 989 Batch 10 Loss 0.0327 Accuracy 4.7226\n",
      "Epoch 989 Batch 15 Loss 0.0327 Accuracy 4.7225\n",
      "Epoch 989 Batch 20 Loss 0.0327 Accuracy 4.7225\n",
      "Epoch 989 Batch 25 Loss 0.0327 Accuracy 4.7224\n",
      "Epoch 989 Batch 30 Loss 0.0327 Accuracy 4.7223\n",
      "Epoch 989 Batch 35 Loss 0.0327 Accuracy 4.7222\n",
      "Time taken for 1 epoch: 0.78 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7229\n",
      "Epoch 990 Batch 5 Loss 0.0327 Accuracy 4.7221\n",
      "Epoch 990 Batch 10 Loss 0.0327 Accuracy 4.7221\n",
      "Epoch 990 Batch 15 Loss 0.0327 Accuracy 4.7220\n",
      "Epoch 990 Batch 20 Loss 0.0327 Accuracy 4.7219\n",
      "Epoch 990 Batch 25 Loss 0.0327 Accuracy 4.7219\n",
      "Epoch 990 Batch 30 Loss 0.0327 Accuracy 4.7218\n",
      "Epoch 990 Batch 35 Loss 0.0327 Accuracy 4.7217\n",
      "Time taken for 1 epoch: 0.68 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7224\n",
      "Epoch 991 Batch 5 Loss 0.0327 Accuracy 4.7216\n",
      "Epoch 991 Batch 10 Loss 0.0327 Accuracy 4.7215\n",
      "Epoch 991 Batch 15 Loss 0.0327 Accuracy 4.7215\n",
      "Epoch 991 Batch 20 Loss 0.0327 Accuracy 4.7214\n",
      "Epoch 991 Batch 25 Loss 0.0327 Accuracy 4.7213\n",
      "Epoch 991 Batch 30 Loss 0.0327 Accuracy 4.7213\n",
      "Epoch 991 Batch 35 Loss 0.0327 Accuracy 4.7212\n",
      "Time taken for 1 epoch: 0.76 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7219\n",
      "Epoch 992 Batch 5 Loss 0.0327 Accuracy 4.7211\n",
      "Epoch 992 Batch 10 Loss 0.0327 Accuracy 4.7210\n",
      "Epoch 992 Batch 15 Loss 0.0327 Accuracy 4.7209\n",
      "Epoch 992 Batch 20 Loss 0.0327 Accuracy 4.7209\n",
      "Epoch 992 Batch 25 Loss 0.0327 Accuracy 4.7208\n",
      "Epoch 992 Batch 30 Loss 0.0327 Accuracy 4.7207\n",
      "Epoch 992 Batch 35 Loss 0.0327 Accuracy 4.7207\n",
      "Time taken for 1 epoch: 0.76 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7213\n",
      "Epoch 993 Batch 5 Loss 0.0327 Accuracy 4.7206\n",
      "Epoch 993 Batch 10 Loss 0.0327 Accuracy 4.7205\n",
      "Epoch 993 Batch 15 Loss 0.0327 Accuracy 4.7204\n",
      "Epoch 993 Batch 20 Loss 0.0327 Accuracy 4.7204\n",
      "Epoch 993 Batch 25 Loss 0.0327 Accuracy 4.7203\n",
      "Epoch 993 Batch 30 Loss 0.0327 Accuracy 4.7202\n",
      "Epoch 993 Batch 35 Loss 0.0327 Accuracy 4.7201\n",
      "Time taken for 1 epoch: 0.73 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7208\n",
      "Epoch 994 Batch 5 Loss 0.0327 Accuracy 4.7200\n",
      "Epoch 994 Batch 10 Loss 0.0327 Accuracy 4.7200\n",
      "Epoch 994 Batch 15 Loss 0.0327 Accuracy 4.7199\n",
      "Epoch 994 Batch 20 Loss 0.0327 Accuracy 4.7198\n",
      "Epoch 994 Batch 25 Loss 0.0327 Accuracy 4.7198\n",
      "Epoch 994 Batch 30 Loss 0.0327 Accuracy 4.7197\n",
      "Epoch 994 Batch 35 Loss 0.0327 Accuracy 4.7196\n",
      "Time taken for 1 epoch: 0.75 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7203\n",
      "Epoch 995 Batch 5 Loss 0.0327 Accuracy 4.7195\n",
      "Epoch 995 Batch 10 Loss 0.0327 Accuracy 4.7195\n",
      "Epoch 995 Batch 15 Loss 0.0327 Accuracy 4.7194\n",
      "Epoch 995 Batch 20 Loss 0.0327 Accuracy 4.7193\n",
      "Epoch 995 Batch 25 Loss 0.0327 Accuracy 4.7192\n",
      "Epoch 995 Batch 30 Loss 0.0327 Accuracy 4.7192\n",
      "Epoch 995 Batch 35 Loss 0.0327 Accuracy 4.7191\n",
      "Time taken for 1 epoch: 0.79 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7197\n",
      "Epoch 996 Batch 5 Loss 0.0327 Accuracy 4.7190\n",
      "Epoch 996 Batch 10 Loss 0.0327 Accuracy 4.7189\n",
      "Epoch 996 Batch 15 Loss 0.0327 Accuracy 4.7189\n",
      "Epoch 996 Batch 20 Loss 0.0327 Accuracy 4.7188\n",
      "Epoch 996 Batch 25 Loss 0.0327 Accuracy 4.7187\n",
      "Epoch 996 Batch 30 Loss 0.0327 Accuracy 4.7187\n",
      "Epoch 996 Batch 35 Loss 0.0327 Accuracy 4.7186\n",
      "Time taken for 1 epoch: 0.78 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7192\n",
      "Epoch 997 Batch 5 Loss 0.0327 Accuracy 4.7185\n",
      "Epoch 997 Batch 10 Loss 0.0327 Accuracy 4.7184\n",
      "Epoch 997 Batch 15 Loss 0.0327 Accuracy 4.7184\n",
      "Epoch 997 Batch 20 Loss 0.0327 Accuracy 4.7183\n",
      "Epoch 997 Batch 25 Loss 0.0327 Accuracy 4.7182\n",
      "Epoch 997 Batch 30 Loss 0.0327 Accuracy 4.7181\n",
      "Epoch 997 Batch 35 Loss 0.0327 Accuracy 4.7181\n",
      "Time taken for 1 epoch: 0.79 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7187\n",
      "Epoch 998 Batch 5 Loss 0.0327 Accuracy 4.7180\n",
      "Epoch 998 Batch 10 Loss 0.0327 Accuracy 4.7179\n",
      "Epoch 998 Batch 15 Loss 0.0327 Accuracy 4.7178\n",
      "Epoch 998 Batch 20 Loss 0.0327 Accuracy 4.7178\n",
      "Epoch 998 Batch 25 Loss 0.0327 Accuracy 4.7177\n",
      "Epoch 998 Batch 30 Loss 0.0327 Accuracy 4.7176\n",
      "Epoch 998 Batch 35 Loss 0.0327 Accuracy 4.7175\n",
      "Time taken for 1 epoch: 0.79 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 999 Batch 5 Loss 0.0327 Accuracy 4.7174\n",
      "Epoch 999 Batch 10 Loss 0.0326 Accuracy 4.7174\n",
      "Epoch 999 Batch 15 Loss 0.0326 Accuracy 4.7173\n",
      "Epoch 999 Batch 20 Loss 0.0326 Accuracy 4.7172\n",
      "Epoch 999 Batch 25 Loss 0.0326 Accuracy 4.7172\n",
      "Epoch 999 Batch 30 Loss 0.0326 Accuracy 4.7171\n",
      "Epoch 999 Batch 35 Loss 0.0326 Accuracy 4.7170\n",
      "Time taken for 1 epoch: 0.80 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7176\n",
      "Epoch 1000 Batch 5 Loss 0.0326 Accuracy 4.7169\n",
      "Epoch 1000 Batch 10 Loss 0.0326 Accuracy 4.7168\n",
      "Epoch 1000 Batch 15 Loss 0.0326 Accuracy 4.7168\n",
      "Epoch 1000 Batch 20 Loss 0.0326 Accuracy 4.7167\n",
      "Epoch 1000 Batch 25 Loss 0.0326 Accuracy 4.7166\n",
      "Epoch 1000 Batch 30 Loss 0.0326 Accuracy 4.7166\n",
      "Epoch 1000 Batch 35 Loss 0.0326 Accuracy 4.7165\n",
      "Time taken for 1 epoch: 0.78 secs\n",
      "\n",
      "TestLoss 0.0000 TestAccuracy 4.7171\n"
     ]
    }
   ],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name = \"test_loss\")\n",
    "test_accuracy = tf.keras.metrics.Mean(name = \"test_accuracy\")\n",
    " \n",
    "loss_function = tf.keras.losses.MeanAbsoluteError(reduction = tf.keras.losses.Reduction.NONE)\n",
    "accuracy_function = tf.keras.metrics.MeanAbsoluteError()\n",
    " \n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    i = 1\n",
    "\n",
    "    while True:\n",
    "\n",
    "        inp = train_x_scaled[(i - 1) * batch_size : (i * batch_size)].copy()\n",
    "        inp = tf.Variable(inp, dtype = tf.float32)\n",
    "        \n",
    "        tar = tf.Variable(train_y_scaled[(i - 1) * batch_size : (i * batch_size)], dtype = tf.float32)\n",
    "        tar = tf.expand_dims(tar, -1)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        training_LSTM(inp, tar)\n",
    "\n",
    "        if i % 5 == 0:\n",
    "            print(f'Epoch {epoch + 1} Batch {i} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "\n",
    "        if i > int(len(train_x_scaled) / batch_size) :\n",
    "            print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')\n",
    "            val_accuracy(val_x_scaled, val_y)\n",
    "            print(f'TestLoss {test_loss.result():.4f} TestAccuracy {test_accuracy.result():.4f}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = AE.predict(val_x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = fine_dust_dangjin_model.predict(np.reshape(val_x, [30 * 24, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23.575901 , 20.134405 , 15.555787 , 14.88469  , 18.783464 ,\n",
       "        25.811096 , 32.842857 , 29.321783 , 23.716692 , 20.18959  ,\n",
       "        20.14732  , 24.413511 , 29.675474 , 38.376736 , 41.023335 ,\n",
       "        41.692856 , 41.9752   , 40.598427 , 37.842003 , 40.577713 ,\n",
       "        38.705162 , 32.244225 , 22.393919 , 18.317968 ],\n",
       "       [16.194712 , 20.4598   , 47.739204 , 60.426254 , 64.16274  ,\n",
       "        41.722435 , 23.294966 , 20.962763 , 16.15448  , 18.938229 ,\n",
       "        18.60642  , 16.55279  , 17.242512 , 20.279787 , 24.520754 ,\n",
       "        25.66197  , 29.34688  , 34.906673 , 32.954906 , 29.552185 ,\n",
       "        29.601063 , 27.40419  , 21.822926 , 21.908388 ],\n",
       "       [25.510742 , 27.272272 , 38.06314  , 33.463913 , 35.23822  ,\n",
       "        27.170006 , 25.237244 , 25.835554 , 31.400068 , 27.220484 ,\n",
       "        20.984346 , 17.434004 , 15.833205 , 21.168768 , 27.606272 ,\n",
       "        32.365135 , 37.80561  , 38.438522 , 41.37767  , 33.29882  ,\n",
       "        23.69405  , 20.285866 , 21.258572 , 20.684908 ],\n",
       "       [22.242369 , 14.459969 , 19.586304 , 20.91229  , 26.910183 ,\n",
       "        32.232067 , 36.429447 , 38.2561   , 38.608467 , 38.74147  ,\n",
       "        42.93854  , 42.48899  , 40.586548 , 40.54676  , 36.23587  ,\n",
       "        41.01791  , 44.939    , 55.379463 , 53.816883 , 47.7195   ,\n",
       "        40.591595 , 35.444557 , 35.50863  , 34.749756 ],\n",
       "       [22.611855 , 16.568386 , 24.627329 , 25.324274 , 29.954195 ,\n",
       "        31.196543 , 35.63896  , 29.662848 , 30.572874 , 29.536955 ,\n",
       "        28.179144 , 31.30707  , 30.57467  , 40.664925 , 49.03004  ,\n",
       "        52.25265  , 53.913254 , 52.544765 , 45.969112 , 42.65787  ,\n",
       "        42.971607 , 41.622948 , 39.790436 , 37.658165 ],\n",
       "       [21.668264 , 23.790257 , 30.084421 , 19.99055  , 17.782158 ,\n",
       "        17.047182 , 25.11552  , 20.881098 , 23.118746 , 21.358109 ,\n",
       "        18.567345 , 15.28836  , 22.183477 , 25.269026 , 24.380133 ,\n",
       "        24.76619  , 28.998047 , 31.997652 , 33.985733 , 32.943066 ,\n",
       "        32.776608 , 31.946081 , 32.85608  , 31.739107 ],\n",
       "       [21.797852 , 20.25192  , 32.35548  , 48.413918 , 38.505882 ,\n",
       "        30.055271 , 27.495852 , 29.27636  , 30.33973  , 28.468111 ,\n",
       "        27.417242 , 30.878542 , 32.43511  , 32.503124 , 31.498833 ,\n",
       "        32.49295  , 31.362524 , 28.531355 , 27.022871 , 27.343801 ,\n",
       "        25.76853  , 19.939175 , 14.7816   , 13.70765  ],\n",
       "       [12.8284025, 20.222872 , 24.725332 , 24.124863 , 19.745193 ,\n",
       "        17.97102  , 19.080496 , 20.97419  , 24.504375 , 27.232477 ,\n",
       "        31.395994 , 33.61532  , 47.867844 , 49.9286   , 48.8572   ,\n",
       "        47.436073 , 40.695408 , 33.486416 , 31.91979  , 24.251348 ,\n",
       "        18.702515 , 15.490335 , 14.151506 , 13.149426 ],\n",
       "       [18.523916 ,  9.245751 , 20.142107 , 20.41484  , 24.468342 ,\n",
       "        20.583363 , 17.960716 , 17.477314 , 26.356749 , 29.655134 ,\n",
       "        31.732464 , 38.03992  , 47.186607 , 47.210938 , 42.93563  ,\n",
       "        38.7214   , 41.83792  , 43.899395 , 38.222397 , 38.401947 ,\n",
       "        39.787216 , 46.88191  , 56.296715 , 59.17025  ],\n",
       "       [43.43285  , 42.51915  , 71.36272  , 64.46641  , 41.650043 ,\n",
       "        44.526257 , 44.06583  , 45.24074  , 45.96566  , 47.379307 ,\n",
       "        46.803154 , 61.05842  , 65.63958  , 62.089943 , 52.327602 ,\n",
       "        42.845505 , 39.585274 , 40.621216 , 51.255062 , 49.595177 ,\n",
       "        36.42344  , 24.48841  , 29.692375 , 28.096098 ],\n",
       "       [39.744667 , 40.796352 , 48.784523 , 26.153522 , 15.736259 ,\n",
       "        13.014204 , 12.208404 , 13.1186   , 12.017308 , 13.346942 ,\n",
       "        22.831154 , 32.500595 , 32.429016 , 28.808174 , 24.156971 ,\n",
       "        22.300276 , 18.480606 , 18.63337  , 19.870665 , 19.741646 ,\n",
       "        18.023645 , 16.402956 , 15.441293 , 11.515834 ],\n",
       "       [24.57798  , 13.152958 , 28.74795  , 27.456703 , 34.823936 ,\n",
       "        26.497732 , 16.995445 , 16.383268 , 28.545147 , 25.889317 ,\n",
       "        33.12231  , 44.93297  , 44.56089  , 38.881824 , 34.13977  ,\n",
       "        35.111603 , 36.70175  , 31.33114  , 24.316101 , 22.609217 ,\n",
       "        24.596674 , 23.799498 , 25.362696 , 30.180237 ],\n",
       "       [14.319985 , 17.797543 , 20.90372  , 19.150812 , 18.624905 ,\n",
       "        20.516281 , 22.675747 , 21.212831 , 21.055609 , 17.847105 ,\n",
       "        16.150372 , 16.272211 , 15.96396  , 17.321037 , 17.58108  ,\n",
       "        17.452784 , 18.159681 , 19.107431 , 20.080328 , 22.014404 ,\n",
       "        22.913996 , 21.415903 , 18.75547  , 17.658262 ],\n",
       "       [17.11627  , 18.093853 , 17.481787 , 21.048521 , 24.123045 ,\n",
       "        22.100971 , 19.67942  , 18.15676  , 17.620201 , 17.727667 ,\n",
       "        18.317965 , 19.122295 , 18.870026 , 20.62273  , 22.273794 ,\n",
       "        22.079287 , 22.291218 , 23.609587 , 24.123857 , 24.626942 ,\n",
       "        25.079441 , 25.6595   , 26.20041  , 24.214392 ],\n",
       "       [28.762285 , 37.25867  , 43.57637  , 40.21987  , 32.69291  ,\n",
       "        27.40528  , 23.305693 , 21.75138  , 21.609774 , 21.004124 ,\n",
       "        19.091194 , 18.780329 , 18.724392 , 22.717915 , 30.171236 ,\n",
       "        43.252804 , 48.27063  , 51.33219  , 50.59311  , 46.927902 ,\n",
       "        43.823837 , 40.655106 , 37.21381  , 32.662865 ],\n",
       "       [24.96481  , 33.65642  , 39.60208  , 42.192814 , 31.785572 ,\n",
       "        29.313492 , 31.232372 , 28.081264 , 26.768753 , 25.105722 ,\n",
       "        19.754297 , 21.59384  , 20.33908  , 18.882545 , 22.184643 ,\n",
       "        23.965498 , 20.231277 , 14.73106  , 20.941729 , 28.061428 ,\n",
       "        26.06729  , 30.348232 , 32.432632 , 32.969353 ],\n",
       "       [19.192503 , 40.087486 , 53.10242  , 44.05866  , 37.4444   ,\n",
       "        42.180904 , 29.830767 , 33.983418 , 44.888405 , 52.083324 ,\n",
       "        47.172226 , 42.987144 , 45.01243  , 48.290207 , 47.101315 ,\n",
       "        42.9762   , 34.839718 , 28.476606 , 22.39181  , 18.541521 ,\n",
       "        17.815918 , 19.888315 , 22.393806 , 24.3635   ],\n",
       "       [27.360374 , 36.263916 , 29.28196  , 28.887474 , 30.016008 ,\n",
       "        21.331276 , 14.034427 ,  8.733028 ,  6.024855 ,  5.7769   ,\n",
       "         4.6584992,  7.0297985,  8.956762 ,  9.720004 ,  9.73729  ,\n",
       "         9.273006 ,  7.834954 ,  8.356958 , 13.686812 , 16.905136 ,\n",
       "        16.610003 , 14.016763 , 14.062977 , 13.505821 ],\n",
       "       [31.89667  , 34.281105 , 40.279327 , 37.417904 , 33.38709  ,\n",
       "        34.94402  , 37.68964  , 38.09302  , 36.596806 , 39.37845  ,\n",
       "        45.161583 , 51.531525 , 67.661194 , 89.50084  , 74.12605  ,\n",
       "        55.563824 , 39.46482  , 33.925053 , 24.81347  , 23.59592  ,\n",
       "        21.947691 , 20.165808 , 21.239893 , 18.299965 ],\n",
       "       [38.92244  , 29.363043 , 26.16875  , 33.48407  , 31.738577 ,\n",
       "        31.376814 , 27.800396 , 28.096104 , 29.404053 , 32.521534 ,\n",
       "        35.35612  , 34.903652 , 29.455608 , 28.5422   , 29.101524 ,\n",
       "        27.798477 , 21.976337 , 22.906015 , 33.42351  , 32.30535  ,\n",
       "        30.598188 , 28.458488 , 27.655481 , 27.438604 ],\n",
       "       [16.340464 , 26.103477 , 31.023323 , 37.981766 , 15.207829 ,\n",
       "        35.436268 , 24.370777 , 25.451149 , 23.866394 , 20.236015 ,\n",
       "        29.049973 , 32.297047 , 20.653034 , 20.60313  , 16.987095 ,\n",
       "        18.271048 , 18.607052 , 16.346088 , 18.200699 , 17.383207 ,\n",
       "        12.537631 , 11.263162 , 17.37193  , 21.925974 ],\n",
       "       [38.09684  , 23.618322 , 13.975185 , 27.79625  , 28.660011 ,\n",
       "        31.025341 , 35.45387  , 35.47134  , 31.450722 , 34.41203  ,\n",
       "        32.738018 , 31.095285 , 31.24496  , 40.91343  , 41.726715 ,\n",
       "        38.34241  , 33.564693 , 27.098625 , 29.29227  , 34.159534 ,\n",
       "        35.67364  , 35.812485 , 36.190094 , 35.207077 ],\n",
       "       [31.539265 , 23.531807 , 34.40227  , 43.815094 , 58.318092 ,\n",
       "        27.118153 , 29.478079 , 33.898342 , 33.591263 , 38.985687 ,\n",
       "        48.41698  , 41.315693 , 36.879642 , 36.006496 , 30.74757  ,\n",
       "        28.835346 , 22.980007 , 22.739735 , 26.010002 , 15.012681 ,\n",
       "         6.921178 ,  9.729212 , 14.165358 , 16.767927 ],\n",
       "       [13.151795 , 16.520767 , 13.806566 , 29.765318 , 30.138962 ,\n",
       "        24.675205 , 21.866928 , 25.81494  , 35.069534 , 44.577003 ,\n",
       "        48.11013  , 52.77936  , 55.354233 , 53.807335 , 46.313717 ,\n",
       "        36.18623  , 28.43989  , 22.890564 , 17.948997 , 16.646204 ,\n",
       "        15.051083 , 14.770254 , 15.326681 , 15.859515 ],\n",
       "       [44.14438  , 30.65276  , 16.654068 , 38.525562 , 22.057007 ,\n",
       "        24.93953  , 20.922497 , 29.89936  , 32.18115  , 30.84525  ,\n",
       "        28.139986 , 34.671635 , 34.79968  , 38.972183 , 39.405357 ,\n",
       "        46.71123  , 52.569714 , 45.945244 , 54.54452  , 59.62593  ,\n",
       "        59.467648 , 57.018814 , 55.232162 , 58.046715 ],\n",
       "       [30.987705 , 26.722942 , 32.553734 , 42.219913 , 44.88056  ,\n",
       "        44.323036 , 48.15737  , 58.60861  , 71.37391  , 71.10246  ,\n",
       "        68.555046 , 43.039967 , 39.375065 , 43.330128 , 40.417164 ,\n",
       "        32.708744 , 27.962055 , 22.15979  , 25.573967 , 26.846338 ,\n",
       "        34.81581  , 39.079773 , 33.582355 , 32.671314 ],\n",
       "       [62.894356 , 54.4951   , 46.985615 , 52.07523  , 40.514286 ,\n",
       "        31.22887  , 33.59319  , 35.260624 , 39.407333 , 38.868824 ,\n",
       "        38.057518 , 33.232376 , 35.638737 , 34.65998  , 33.26385  ,\n",
       "        32.678864 , 27.924192 , 30.412817 , 34.487106 , 35.997128 ,\n",
       "        38.838295 , 36.34812  , 31.17872  , 31.17177  ],\n",
       "       [26.75667  , 42.56131  , 38.9243   , 39.927883 , 53.33601  ,\n",
       "        59.70686  , 63.315197 , 66.06683  , 57.909645 , 56.594845 ,\n",
       "        52.20196  , 38.34754  , 38.11578  , 45.525093 , 48.06104  ,\n",
       "        47.698887 , 46.95682  , 44.11496  , 41.16812  , 36.02573  ,\n",
       "        30.538397 , 27.074268 , 20.353317 , 19.737051 ],\n",
       "       [14.589355 , 20.28704  , 28.918953 , 33.677734 , 42.077293 ,\n",
       "        43.58314  , 41.45243  , 36.9926   , 34.340797 , 32.002563 ,\n",
       "        28.62686  , 23.383083 , 17.687262 , 15.238499 , 13.803453 ,\n",
       "        13.236151 , 13.397072 , 13.576725 , 13.730263 , 13.787738 ,\n",
       "        13.831042 , 14.07543  , 14.421421 , 14.985474 ],\n",
       "       [28.222073 , 40.097836 , 36.80936  , 34.45945  , 35.575462 ,\n",
       "        41.40133  , 46.52479  , 51.942245 , 57.668854 , 62.81315  ,\n",
       "        61.421543 , 54.835052 , 53.358185 , 57.713    , 58.005882 ,\n",
       "        54.415737 , 54.46779  , 52.156097 , 44.81816  , 33.95549  ,\n",
       "        31.649473 , 31.296022 , 21.182842 , 19.82508  ]], dtype=float32)"
      ]
     },
     "execution_count": 1125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_pred * (train_max_dangjin - train_min_dangjin) + train_min_dangjin, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.355248081684113"
      ]
     },
     "execution_count": 1118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.mean_absolute_error(np.reshape(val_y, [30 * 24]),\n",
    "                                   np.reshape(np.mean(y_pred * (train_max_dangjin - train_min_dangjin) + train_min_dangjin, axis = 2), [30 * 24]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_result = np.mean(np.stack([np.reshape(np.mean(y_pred,axis = 2), [30 * 24]) * (train_max_dangjin - train_min_dangjin) + train_min_dangjin,\n",
    "        y_pred_2]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.966687158664483"
      ]
     },
     "execution_count": 1114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.mean_absolute_error(ensemble_result,\n",
    "                   np.reshape(val_y, [30 * 24]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x287fde21400>]"
      ]
     },
     "execution_count": 1115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAAJACAYAAAD8e72uAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOz9d7wkW17dia4dEWlOHltVp+z1t/uaNtBAXzzduKZxjdEg5skxPUIIxPAGjaSnBxrpDdIgAzIgB0ItrJAEg3ANjTC3HU03NM1td/vaqutv+TpVdWyasO+PHTtcRkRGZkbaWN/Ppz55TJ7MrHMyM3asvdb6Cc/zQAghhBBCCCGEEEKqgzbrB0AIIYQQQgghhBBCpgsFIUIIIYQQQgghhJCKQUGIEEIIIYQQQgghpGJQECKEEEIIIYQQQgipGBSECCGEEEIIIYQQQioGBSFCCCGEEEIIIYSQijFQEBJC/KwQ4roQ4onI1/6FEOIZIcTjQojfEEJsRb7394QQzwkhnhVCfO2EHjchhBBCCCGEEEIIGRHheV7+FYR4K4BDAP/Z87w3+l97O4D3e55nCyF+FAA8z/sBIcTrAfwSgC8AcA7AewE86Hmek3cf29vb3r333jvu/4UQQgghhBBCCCGE+Hz84x/f8TzvZNr3jEE/7Hneh4QQ9ya+9geRTz8K4M/7H38LgF/2PK8H4EUhxHOQ4tCf5N3Hvffei8cee2zQQyGEEEIIIYQQQgghBRFCvJz1vTI6hL4TwO/6H98B4NXI9y76XyOEEEIIIYQQQgghc8JYgpAQ4u8DsAH8V/WllKulZtKEEN8thHhMCPHYjRs3xnkYhBBCCCGEEEIIIWQIRhaEhBDvBPAOAH/ZC4uILgK4K3K1OwFcTvt5z/Pe5XneI57nPXLyZGqcjRBCCCGEEEIIIYRMgJEEISHE1wH4AQDf7HleO/Kt3wLwF4QQDSHEfQAeAPCx8R8mIYQQQgghhBBCCCmLgaXSQohfAvAVALaFEBcB/BCAvwegAeBRIQQAfNTzvL/hed6TQohfAfAUZJTs+wZNGCOEEEIIIYQQQggh02Xg2Plp8Mgjj3icMkYIIYQQQgghhBBSHkKIj3ue90ja98qYMkYIIYQQQgghhBBCFggKQoQQQgghhBBCCCEVg4IQIYQQQgghhBBCSMWgIEQIIYQQQgghhBBSMSgIEUIIIYQQQgghhFQMCkKEEEIIIYQQQgghFYOCECGEEEIIIYQQQkjFoCBECCGEEEIIIYQQUjEoCBFCCCGEEEIIIYRUDApChBBCCCGEEEIIIRWDghAhhBBCCCGEEEJIxaAgRAghhBBCCCGEEFIxKAgRQgghhBBCCCGEVAwKQoQQQgghhBBCCCEVg4IQIYQQQgghhBBCSMWgIEQIIYQQQgghhBBSMSgIEUIIIYQQQqrJE78O/ME/mPWjIISQmUBBiBBCCCGEEFJNLjwKPP7fZ/0oCCFkJlAQIoQQQgghhFQTpwe49qwfBSGEzAQKQoQQQgghhJBq4piA58z6URBCyEygIEQIIYQQQgipJo4FuBSESsGxgVc+OutHQQgZAgpChBBCCCGEkGrimIyMlcUTvwr87NcCexdn/UgIIQWhIEQIIYQQQgipJnQIlce1J+Rl72C2j4MQUhgKQoQQQgghhJBqYrNUujRunJeXjjnbx0EIKQwFIUIIIYQQQkg1UaXSnjfrR7L47ChByJrt4yCEFIaCECGEEEIIIaSaKPHCc2f7OBYdqwvsviw/piBEyMJAQYgQQgghhBBSTVS8ibGx8bj1fCiqMTJGyMJAQYgQQgghhBBSTSgIlYOKiwF0CBGyQFAQIoQQQgghhFSTQBDipLGx2LkQfkyHECELAwUhQgghhBBCSDWhQ6gcbjwbfuzSIUTIokBBiBBCCCGEEFJNVLyJDqHR8Tzg0seB46+RnzMyRsjCQEGIEEIIIYQQUk2UQ8ijIDQy158Gbr8IvO4d8nNGxghZGCgIEUIIIYQQQqoJI2Pj88x7AAjg9d8iP6cgRMjCQEGIEEIIIYQQUj0cOxyVTkFodJ55D3Dn5wObd8vPGRkjZGGgIEQIIYQQQgipHlEnCzuERmP/MnDl08DD3wjoNfk1CkKELAwUhAghhBBCCCHVg4LQ+OxfkZenXh8RhBgZI2RRoCBECCGEEEIIqR5RJwsjY6NhHcnLegvQ6/JjOoQIWRgoCBFCCCGEEEKqR9TJwiljo2EqQWgV0Az5MR1ChCwMFIQIIYQQQggh1cPphR/TITQaShCqrQJCSJeQS4cQIYsCBSFCCCGEEEJI9YhFxugQGomoQwgAtBojY4QsEBSECCGEEEIIIdWDpdLjY0Y6hABZLM3IGCELAwUhQgghhBBCSPWICUKMjI2EFYmMATIyRkGIkIWBghAhhBBCCCGkenDK2PiYRzImZvgTxvQ64PB3SciiQEGIEEIIIYQQUj3sSKk0p4yNhtkO+4MAQDfoECJkgaAgRAghhBBCCKkeLJUeH/MoIQgxMkbIIkFBiBBCCCGEEFI92CE0PlaaIMQpY4QsChSECCGEEEIIIdWDU8bGxzwCaq3wc04ZI2ShoCBECCGEEEIIqR4slR6dZ38POLjqdwithV/X64BLhxAhiwIFIUIIIYQQQkj1cCKl0hSEimN1gF/6C8Cf/TRgHgL1iENIqzEyRsgCQUGIEEIIIYQQUj2i0SbPnd3jWDQOrgDwgKMbgJWcMsbIGCGLBAUhQgghhBBCSPVgZGw09q/Iy/ZNv0OIU8YIWVQoCBFCCCGEEEKqB6eMjcaBEoRu+ZGxpEOIv0tCFgUKQoQQQgghhJDqwSljo7F/WV4e7fil0pwyRsiiQkGIEEIIIYQQUj1sOoRGQjmEDq7KiWJ1RsYIWVQoCBFCCCGEEEKqBx1Co6EcQr09eVlLRsY4ZYyQRYGCECGEEEIIIaR6xKaMURAqjHIIKZIOIZeCECGLAgUhQgghhBBCSPVwLClgAIyMDcPBFUCrhZ9HBSGNHUKELBIUhAghhBBCCCHVwzGB2or8mIJQMTxPdgedejj8Wt+UMTqECFkUKAgRQgghhBBCqodjAoYShBgZK0T7pvy9nf6s8Gu16JQxlkoTskhQECKEEEIIIYRUD8cEak35MQWhYqhC6TNvDL9WXws/1uvSbeV5031chJCRoCBECCGEEEIIqR6OCegNQOiMjBVFFUqfjgpC0ciYIS8ZGyNkIaAgRAghhBBCCKkejgUYdUCjIFSYg6vy8vj9YdyunoiMAYyNEbIgUBAihBBCCCGEVA/HlAKGZnDsfFHsrrystYDWCflxMjIGUBAiZEGgIEQIIYQQQgipHnYvFITYIVQM9XvSNKB1XH4cK5X2x9EzMkbIQkBBiBBCCCGEEFI9HEsKGEJjZKwoykkldOkQEjpgNMLva74g5FIQImQRoCBECCEknYuPARcenfWjIIQQUlU+9d+A2y9P7vajkTE6hIoROIR0YHVbFkoLEX6fkTFCFgoKQoQQQtL54D8DHv2hWT8KQgghVcR1gN/8XuCTvzi5+3AsOWVMM+gQKkrUIXT/VwIPfl38+4yMEbJQGLN+AIQQQuaU/cvc4SOEEDIblEDT2Z3cfTimFDA0nQ6hogQOIQP43L8s/0WhQ4iQhYIOIUIIIelQECKEEDIrlCDU3ZvcfTiqVFrnlLGiRCNjadAhRMhCQUGIEEJIP1YH6O5yQUcIIWQ2KOFhooKQFekQYmSsEJ4DQMR7g6JQECJkoaAgRAghpJ/9y/KSDiFCCCGzwJuGIGQCRl324VAQKobrZLuDAEbGCFkwKAgRQgjp5+CKvHS4QCaEEDIDpuIQ4pSxoXFt+fvKgoIQIQsFBSFCCCH9HFyVl1zQEUIImQVTi4zVKAgNg+dKR1UWKjJGxxUhCwEFIUIIIf0wMkYIIWSWBJGx3cndh61KpTUKGEUZFBnTVIcQ1w+ELAIUhAghhPSjImOew11TQggh00cJNFYbsCcgLriOPMapyBinjBXDcwCRcwoZjYy5LvChfwEcXp/OYyOEDA0FIUIIIf0ohxDASSGEEEKmT3Qzorc/gdv3BSfN4JSxYXCdAR1CkSljO88C7//HwOO/Mp3HRggZGgpChBBC+lEOIQBwKQgRQgiZMlFBaBI9QmqzQ6/5U8boECqEaxefMqY2l3bOT/5xEUJGgoIQIYSQfvYjghAdQoQQQqZNNMI1iR6hwCFUkwIHBaFieE6xUmnHCjeXdi5M/nERQkaCghAhhJA4risXcc1N+TmLIQkhhEybSTuEGBkbDdct6BCyws2lnWcn/7gIISNBQYgQQkiczm0ZE9u8S35OQYgQQsi0iQo0kxSEdMN3CFEQKsTAUunIlLEDPzLWvgkc3Zz8YyOEDA0FIUIIIXGcnrxsbPifMzJGCCFkykQjY53d8m9fHduUQ4hTxorh2gNKpSMdQgdXw6/fZGyMkHlkoCAkhPhZIcR1IcQTka8dF0I8KoS44F8ei3zv7wkhnhNCPCuE+NpJPXBCCCETQtn0a015SUGIEELItHHd8OOJRsZqfmSMglAhXCc/Mqb5DiHXlqXSJx6Qn99gbIyQeaSIQ+jnAXxd4ms/COB9nuc9AOB9/ucQQrwewF8A8Ab/Z35SiLzWMUIIIXOH2iU1VuQlI2OEEEKmzbQiY5ohI1CMjBVjUKm0psnvO6bsI7zrCwGjyUljhMwpAwUhz/M+BOBW4svfAuAX/I9/AcC3Rr7+y57n9TzPexHAcwC+oJyHSgghZCrQIUQIIWTWeFMqldYNOoSGYVCpNCBjY2YbOLwObN4BnHgtBSFC5pRRO4ROe553BQD8y1P+1+8A8Grkehf9r/UhhPhuIcRjQojHbty4MeLDIIQQUjouHUKEEEJmzKSnjCU7hOgQKoZrDxaENu8AXvgAAA9YPwts3BGOoCeEzBVll0qLlK95aVf0PO9dnuc94nneIydPniz5YRBCCBkZL+EQcukQIoQQMmWmFhmr+VPG6BAqxKDIGAA89A3AjWfkxxvngHoLsLqTf2yEkKEZVRC6JoQ4CwD+5XX/6xcB3BW53p0ALo/+8AghhEydwCGkImN0CBFCCJkyweZEa/IdQprOKWNFGVQqDQAPvyP8eP2s/Btanck+LkLISIwqCP0WgHf6H78TwLsjX/8LQoiGEOI+AA8A+Nh4D5EQQshUCRbhKjJGhxAhhJApo6aMtU4A3d0J3H6yQ4iRsUIUcQjd+fnA2mn58cY5uZ6w2pN/bISQoSkydv6XAPwJgIeEEBeFEH8NwI8A+BohxAUAX+N/Ds/zngTwKwCeAvB7AL7P8yi3E0LIQqEWxXQIEUIImRXqWLR6Eji4Vn6kK9ohJHQKQkVxXfk7y0PTgNd9E9DYkIJebYUOIULmlAGvZsDzvL+Y8a2vzrj+PwHwT8Z5UIQQQmaI2pWlQ4gQQsisUHvK9385cPkTwKsfA+754vJuP9YhxCljhXFtwKgPvt7b/hHwBd8DCCEjY3bHF5PKrrAlhIwDX5GEEELieMkOIQpChBBCpowSbB78ejnG/Jn3TOb2NY6dH4oikTEAaKwBJx+UH6sNJpvF0oTMGxSECCGExHGTHUKMjBFCCJky6li0sgXc9+VSEPJShxePePtKENKla4WRsWIUKZVOUmvJS8bGCJk7KAgRQgiJ0+cQoiBECCFkynh+fFnowOveAdx+Cbj2ZHm3r9yvuh8ZY+1pMYo6hKIEgtBR+Y+HEDIWFIQIIYTEUbukyiHEXVNCCCHTJurgueMR+fHN5yZw+5wyNhSuM7hUOolaT9AhRMjcQUGIEEJIHFUqTYcQIYSQWaEiY5o+meNRVBASunQklRlJW1ZcZ/hi6MAhxNHzhMwbFIQIIYTE8dghRAghZMaoY5HQw6lWkxKElOOFxdKDGSkyRocQIfMKBSFCCCFx1ILYaMhLThkjhBAybaKCje4LQnav/NvXa2FJMmNjgxmrVJoOIULmjSEDoIQQQpae2K5pjQ4hQggh00fFlzUdEP4edpnHI7XZoRkUhIbBtdkhRMgSQUGIEEJInKhNX6/TIUQIIWT6eJEOoYk4hNTtRyJjnDQ2GM8dY8oYBSFC5g1GxgghhMSJFnnqNQpChBBCpo9y6wgd0CcQYXajDiF2CBVmpFJp5RBiZIyQeYOCECGEkDieb9MXShBiZIwQQsiUiW5OaDoAATgT6hBSkTRGxgbDUmlClgoKQoQQQuK4CZv+tBxCVz8D/O4PcOwvIYSQxFh4IQcdlBkZczhlbCRcZ4QOIZZKEzKvUBAihBASJ1iE+w4hd0qC0JO/CfzpTwHdvencHyGEkPkl6lYFZGys1MhYmiBEh9BAXHv4KWNGA4CgQ4iQOYSCECGEkDh9pdJTiowdXJGXXDASQgiJulUBP8JcZmTMksc5IThlbBhGKZUWAqiv8vhOyBxCQYgQQkicWUXG9i/LS1rKCSGEuLbs9hFCfm40ALvEDQrXliITwMjYMLjO8A4hQPYI8fhOyNxBQYgQQkicqE1fMybrEPI8YOeC/JgOIUIIIYpkebFeL9ch5NihEKQEDo6dH4znhCXcw1BbAUwKQoTMGxSECCGExIl1CE04MvbyHwP//hHg8qeAfQpChBBCfJJOFKNR7vHIjQhCgpGxwkR/b8NQa9EhRMgcQkGIEEJInL7I2AQXyDefk5ev/AnQ88ukuWAkhBCSnGal10qOjFkRhxBLpQszVmSMGz6EzBsUhAghhMSJlUrXJusQUjGxFz8Ufo0LRkIIIX2RsUbJpdLsEBoazwPgDV8qDfgOIR7fCZk3KAgRQgiJE3MITVgQUkXSL304/BodQoQQQlwH0CKnKmWXSqd1CFEQyic5+W0YWCpNyFxCQYgQQkicYMFnTH7KmHII9fbDr3EHkRBCSLKrpuwNCjdNEGJkLBdvXEGIx3dC5g0KQoQQQuIkI2PuBAUhVSQdhTuIhBBCJh4ZS+kQ4pSxfJRgNnJkjMd3QuYNCkKEEELiBA4hbfJTxg4uAyvH/Pvzuxy4YCSEEOK6cYeQUS+5VDrSIcQpY8UYOzJGhxAh8wYFIUIIIXGiu7J6bXKRMbsHtG8C975Ffn7sHnnJBSMhhBDXjncI6SWPnXfsUNjglLFiRB3Ew8JSaULmEgpChBBC4kRHymoldzb0DoEdf9S86g+6760ABLBxh1zw0yFECCGkLzJWsmM11iGkBCG3vNtfRtTvZySHkB8Z87xyHxMhZCwoCBFCCIkTXSSXvQD/2LuAd3253JlV/UHH7wNOvxE49Tqgzh1EQggh6C+VNurSWVra7VthVDkolZ5gZ94yoBxUo0bGPGeygyoIIUNjDL4KIYSQSuG5ichYiRb6zm3APASOrsv+IABYPwv81f8hRwo//dt0CBFCCIm7VYEJlEo7KQ4hRsZyGTcyBshjvFEv7zERQsaCDiFCCCFxXCfsbSjbIaR2Bg+uhA6h9bNAc0MKQiydJIQQAsQ3J4DyO+0cC9CVG7YWfo1kM26pNMBjPCFzBgUhQgghcZKl0q5VXuZf7e7uX5GikNEMp4wBFIQIIYRIXDsuPBiNkiNjaR1CHDufS1kOIULI3EBBiBBCSJxYh1DJu6bKbXTgC0LrZwEhwu+r0klCCCHVJi0y5jnliTauHekQUoIQHUK5BA6hEVpHAocQj/GEzBMUhAghhMSJLsJ1P+df1iJZCUv7l4FbL4Sj5hV0CBFCCAH6p4yp3pmyYsyT3PxYVsaJjOkl//0IIaVAQYgQQkicWKl0yQs4dTv7l4GdC8D2Q/Hv0yFECCEE6J8ypo5HZcXGXDvsEFJOIZZK5xNExkY4hWQsj5C5hIIQIYSQONFSabWAKy0y5t/O5U/IaWMnH4x/nw4hQgghAOC6ichY2RsUVsQhxCljhRjHIaR+hoIQIXMFBSFCCCFxvMgo3rIX4Gpnd+e8vNymIEQIISQFz+kvlQbKdQglO4QYGcvHG6NDKBCEKLoRMk9QECKEEBLHtVMiYyWXSiv6BKEWYB6Vc1+EEEIWl+ixCCh/gyI2ZUxFxigI5aLEnFGmjGl0YREyj1AQIoQQEidWKl32lLHI7TQ2gbXT8e/XWnQIEUIISZkyNgFBSE+WSlOsyMV15eVIkTH/d+0xMkbIPEFBiBBCSJxplEoDwPYD8ZHzgBSEnB47BgghpOokS6XLjoxFO4Q0HYCge2UQ45RKC3YIETKPUBAihBASJ1oqHeyaligI1dfkx8m4GCA7hAC6hAghpOpENycAQPcFobIcq64TRsUAKQ4xMpZPKaXSFN0ImScoCBFCCIkT3ZUtPTJmAlv3yI+3H+j/PgUhQgghQHxzAogcj8oqlbYSkbQaS6UHocSckUqlOXaekHlkhFczIYSQpcZzIpExtSNblkXfBM59LvDGPwe86S/2f7/WkpdWu5z7I4QQsphMOjLm2qHIBEi3EN0r+QSRMTqECFkWKAgRQgiJEy3yNJrysszOBqMJvPXvpn+fDiFCyIx59KlraBga3vrgyVk/lGoT3ZwAJtBpZ8UFJ02nWDGIMkql6RAiZK6gIEQIISROtLch2JHtlnPbjhnfkU1ChxAhZMb8+/dfwMZKjYLQrJnklDHXBeDFO4QYGRtMGQ4hThkjZK5ghxAhhJA40UW4cuyU5RCye+GiPg06hAghM8Z2PViOO+uHQVwnIzJWhiDkCz9RwYmRscEEHUIjCEKCkTFC5hEKQoQQQuK4diQyVrZDyBogCCmHEAUhQshscFwPtuPN+mEQz4mPNw8cQiVsUChRIupY1Q06hAYx1pQxFRmjIETIPEFBiBBCSJxob0PQITStyJhyCDEyRgiZDQ4dQvNBMjKmNijKiIwp4SfWIWRQrBjEWJExdggRMo9QECKEEBInVipd4lQXz5M2fTW5LI06HUKEkNkiBSE6hGZOcsqYcgiVEhlTTpfklDE6hHIZyyGkImMUhAiZJygIEUIIiTMph5DakS1UKn00/v0RQsgI2K4H26VDaOZkThkrIzKW0iGkG4BDh1AunpoyNsJcIo6dJ2QuoSBECCEkTtQhFOzIlrAAV4v4IqXSJiNjhJDZwA6hOcF1J1gqrcqRo5ExOoQGon5vYoRTSPW75pQxQuYKCkKEEELiRAUhIaRLqFSHUI4gVF+Tl+bh+PdHCCEj4LgeTHYIzR7XBrTIqYoSFMrsEIo6VtkhNJhxImOcMkbIXDKC348QQshSk7TpG42SHEL+Ij4vMqbpQGMD6O6Nf3+EEDICtkt30FyQPBYJITvoSomMKWEj2lFUY2RsECyVJmTpoEOIEEJInL7JLs1ySp6VIGTklEoDQHOTghAhZGa4HjuE5oJkqTTgb1CUERnLmjLGyFgupYydpyBEyDxBQYgQQkgcz+nvbSjFIVQgMgZQECKEzBTbcTllbNZ4niwwTgoPer2cyFhah5BeC49TJJ00Z1VRVPyPkTFC5gpGxgghhMRxk5GxkjqElKiUFxkDKAgRQmaK43rwQEFopqhpVslokl4vKTLmixLsEBqOIDI2oqdAM1gqTcicQYcQIYSQOK4TL/IsvUOogEOoszv+/RFCyAg4HqeMzZzAwZMQhIx6OZExJ23KGAWhgYwTGQP4OyZkDqEgRAghJE5fqfQUp4wBdAgRQmaK43qw2CE0W7KEh9JKpRkZG4lxSqXVz7FDiJC5goIQIYSQOGml0tN2CFEQIoTMCNv14HlSGCIzIkt40OvliDappdI1ulcGkSakDYNmUBAiZM6gIEQIISSOm1YqXYZDqKggtAX09gHu0BNSDv/5W4Enf2PWj2IhcH0xCAAsh+9BMyNLeDDq5WxQDNMh1LkN/OSXAJc/Of79LjrquDxyZEyn6EbInEFBiBBCSJzUyNiUHULwpChECBkP1wFe+ABw+VOzfiQLgeOFriAKQjMkS3jQauWMhk/rENKNdPfR5U8B158Erjw+/v0uOuNGxigIETJ3UBAihBASJ7VUukyHUIEpYwBjY4SUgdWRlzwJK0Q0JsZi6RniZXUI1UIxZxzSHEhZYtPOBXlptce/30Un6HbilDFClgUKQoQQQuL0OYRWZuAQAgUhQsogEIR4ElYEOyIIsVh6hijBJulE0YxyHEJpHUJ6RofQzrPy0jwa/34XneT6YFjYIUTI3EFBiBBCSJyJdQj5C3CDghAhU0O5Gso4ia4AUYeQRYfQ7MicMlbSJLCsDqE099HOeXlJh5D8vY1aKA0AQqNbkZA5g4IQIYSQEM+TO4CznjIGUBAipAwYGRuKeGSMDqGZEUTGEuJDWQ6TtA6hLPeRioyZFIT6ppAOCx1ChMwdFIQIIYSEeP4JUCwyVpJDSIlKhQWh3fHvk5CqEziEKAgVwY7ExOgQmiFuRnlxaZGxtFLpFPdRdw84uCI/thgZg+eWEBnjexEh8wQFIUIIISFphZFGUy7Ax93VUwvtQaXSK1vykg4hQsaHHUJDEa0NstkhNDsmHhlL6RDSagC8+JNg57nwYzqE+odODAunjBEyd1AQIoQQEpI2UtZoyMtxY2NFI2P1dQCCghAhZUCH0FDEHEI2HUIzI3DwTGjsfGqHkH9f0dtX/UG1FjuEgPE7hDQ9dCITQuYCCkKEEEJC0mz0RlNejhsbCxxCjfzraRrQ3KAgREgZUBAaCodTxuaDtM0JoPwOoejtK3Eo6kC6eUHe58mHOWUMKGnKGN+LCJknKAgRQggJSbPpBw6hcQUhE4AoVkjZ3KQgREgZsFR6KOKl0nQIzYzMyJhRTmRMCU56MjKGuEOouyePR80NOoSA8UulBSNjhMwbFIQIIYSEpJZKl+UQ6sm4mBCDr0tBiJByCBxC7BAqAqeMzQlu1pSxkiNj0WOduq/oa8Vsy7hYbZUdQkBJpdJ8LyJknqAgRAghJCTXITRuh5A1uD9I0dyiIERIGdAhNBR2RBAyKQjNjqzImF4L417jkCY4KbdQ1IFktYHaClBvccoYwLHzhCwhFIQIIRKrA3z8FwCPFvlK46UJQmU5hMzBE8YUdAgRUg7sEBoKRsbmhLSJl0B5U6rSNj/SImNWx3cItegQAvxS6XEEIY3vRYTMGRSECCGS598P/Pb3A1cfn/UjIbMkzUZf5pQxY0ChtKK+BvQOxrs/QggdQkMSE4RYKj070gYcAOVFxtIcSGml0pYfGauvskMIKKdU2qNDiJB5goIQIUSiTva7+7N9HGS2pEbGSpwyVtQhxNG0hJRDIAjxJKwI0ciYRYfQ7MiLjLn2+G5m14YcchA5FUrrELI6MjJWa8kpY1V3UZcSGaM4Tcg8QUGIECJRJ990ZVSbtEV4IAiN6RCye8U7hMqKBRBSdRgZG4rY2Hl2CM2OvFJpYPzns2un3LYShJKRMb9DCN74GyOLzril0pwyRsjcQUGIECJRgpB5ONvHQWaLikhEF8pljp0vKggJnY4GQsqAkbGhYIfQnJA1dl59PrYglOJ0yYuM1Vbl51XvERq7Q0gP1xmEkLmAghAhRKIWXz1GxipN0NsQOTwMcgj92ncBv//3B9/20JExCkKEjA0dQkMRcwjxxHV2BG7VxKlKmmgzCq5TzH0UcwiBk8YYGZsevUPgx14PvPCHs34kZMmhIEQIkajFV48OoUqTGhkb4BC6+gRw7YnBt+2YgF6wVJqLRkLKgR1CQxEtkqZDaIbklUpHvz8qaeXIae6j6JQxgA6hsUulGRkrzOE1YP8SsHN+1o+ELDkUhAghksAhxA6hSpNm06+tyMssh5DdDU8683CsISNj3J0nZGwYGRsK12OH0FyQFRnTfYFobIdQSvQpMzK2IqeMAXQIleEQovu3GKb/XKt6bxWZOBSECCESdYBmh1C1GcUhZPeKjeN1eoyMETJt1EkFBaFCRF1BnDI2Q7KmjAXFzxPoEArcR74g5FjyYzqEQtKidsOgGXQrFkWtqygIkQlDQYgQInEZGSNIn+wyaOx8YYfQEKXStJUTUg50CA1FvFSaDqGZMXDKWBkOocRtBw4h/7WiTshjDqGKC0Ke09/rNAxC43tRUdQG7bgTXgkZAAUhQogkGDvPUulKEyzCI4cHzZCLOCvPIVQ0MlbQIcQpY4SUAzuEhsKJRsZcOoRmRtqxCOgXbUYlbXx6skNIvXZqKxGHECNj45dK872oECYdQmQ6jCUICSH+lhDiSSHEE0KIXxJCNIUQx4UQjwohLviXx8p6sISQCeIyMkaQbtMXQrqEch1CRSJjZhg/G4TqGfB4QkbIWHDK2FDQITQnZEbGlGgzgQ6hpPtIvXbqq5EpY3QIjVcqzYERhQk6hOgQIpNlZEFICHEHgO8H8IjneW8EoAP4CwB+EMD7PM97AMD7/M8JIfNO4BBiqXSlySryNBrpixLHkgvESUTGgPB5SQgZDUbGhiLeIcT3n5kx6SljaU6XZKl0zCHkR8bYITRmhxDdv4VRG7RF1leEjMG4kTEDwIoQwgDQAnAZwLcA+AX/+78A4FvHvA9CyDTg2HkChM+D5IIvyyGkvmZ3B08Fs80hImP+4YkLR0JGx/PoEBqSWGSMpdKzI3PKWMoksJFuP6VDKFlYHQhCrYhDiJExThmbEkGpNB1CZLKMLAh5nncJwL8E8AqAKwD2PM/7AwCnPc+74l/nCoBTZTxQQsiE4dh5AoQL4aQl3GimW+WjCxV7wC7WUA6hkibJEFJl7B4AX9SguFqIWGRskMhNJsfAUulxO4RSok99glCkVNpYkR9X3SE0bqk0B0YUh2PnyZQYJzJ2DNINdB+AcwBWhRB/ZYif/24hxGNCiMdu3Lgx6sMghJRFMHaeglClUSdAyR3ArbuA2y/1Xz+6UBm0ULa7cmFdhCAyxpNYQkZGndBqNZ6EFcT2BSFNxONjZMp0d+VlczP+dXVsGNshlBJ9youMaZp0ClW9Q2hch5CgIFQYdgiRKTFOZOxtAF70PO+G53kWgF8H8CUArgkhzgKAf3k97Yc9z3uX53mPeJ73yMmTJ8d4GISQUlBCQO+QRb5VJijyTBweth8Cbpzvf25EFyp5C2UVXVGTWgahdm7paiBkdNQJbXODJ2EFcfzeoJWaDpMdQrOjfRNobPbHjPUyO4QSx7mk+yhwCLXCy6pPGSulVJrH9ULQIUSmxDiC0CsAvkgI0RJCCABfDeBpAL8F4J3+dd4J4N3jPURCyFRQQkDRgmCynGT1Nmw/KN1jB1fjX48uVPKeN+p6hR1CyrrPhSMhI6Nekw0KQkVRpqBmTadDaJa0bwKt4/1fT04CG5W0DiE9q0PIP27V6RBK/b0Ng2YA8AZ3DhJ2CJGpMfIr2vO8PxVC/CqATwCwAXwSwLsArAH4FSHEX4MUjb69jAdKCJkw0RNv8zAsUCTVImuyy8kH5eXOeWDjbPj1mCCUs1COlnMWQe3cMjJGyOio12RjXU7sc91+VwSJ4fgnqg1DY4fQLDnaAVon+r+uRBtngh1CKjKmHBqBQ2iVDiHXHbNUWg2MsAGtYKdgVaFDiEyJMSRewPO8HwLwQ4kv9yDdQoSQRSJ64t07ANbYB19JgshYikMIkILQ/V8efj0WGctxCAUL64IOIUbGCBmfqEMI8F/fFITyUB1CzZrOKWOzpH0TWD/b//XAPTqBDqGk+4gOoX7KiIyp2yH5sEOITAmuCgghEi+yE8pJY9Ulq1R6/SxQX5eCUJSikbGhHUKcMkbI2EQdQgBfTwVwfUGoUdNhsUNodrRvpTuEypoyllaOHJRKJyJjasJYrcUpY2ndS8PAY3tx6BAiU4KCECFE4iYcQqSaZJVKCwFsP5AiCBUslY6O7y0Cp4wRMj4UhIYmdAhp7BCaJe2bwGpaZCwh2oyKa/cLQpoOQMRLpfV6GFOrrwJW1SNjY3YIBe5fvhcNhB1CZEpQECKESKIOIfNwdo+DzJagVDplwbf9ILBzIf61oR1CLJUmZGpEp4wBPAkrgON6EAKo6xodQrPCbAN2J8MhVFJkLCv6pBnxyFjU1UqHUHmRMfZzDUatxekQIhOGghAhRBJzCFEQqixBqXTKgm/7tcD+pbjwM7RDqOjYeVU8SUGIkJFRr7v6mrzk62kgjuvB0ARquha4hciUad+Ul3mCkDOBKWOAdCCp27ba8WMWO4RKKJWmQ6gw7BAiU4KCECFEEiuV3p/d4yCzJatUGgAam/IyukM6sQ4hRsYIGRsl7q8ck5fjnkRXAMf1oAmBmi7oEJoV7R15mTplrKwOoQxhQ6vFx85HXa21VTqExnYIURAqjHqu0SFEJgwFIUKIxHXkYgdgZKzKBJGxlAWf4Y+IjS5OCjuEWCpNyNRR7+VNX8zl62kgtu8QMnSNU8ZmRa5DqCxBKKVDCJBfiwlCSYdQ1TuEUsq4h4FTxorhuvK5JnT5uxq3M4uQHCgIEUIkngM01gAIlkpXGdUllbYDaDTlpRMRgQo7hIYslebYeULGp7cvJySp1y4FoYE4rgddkw4hmw6h2dC+JS9THUIlRcaynC59kbGEQ8i1Adsc774XmSwhrSjc7CmG7a+nWsf9z+kSIpODghAhROK68kDdWGeHUJXJ6xDSlUMoshhWDqFaq+RSaUbGCBmb3qF8T2dJe2GUIGRo7BCaGUU6hNJKpS88Cjz17mL3kdUhFIuMJQShuu8WqrJLaNzIWNU2e17+Y+DjPz/8z6n+oBUlCCV6hDwP+KMfA269mP7zf/KTwPVnhr9fUkkoCBFCJOogX1thaWKVyY2MNeRlLDLWlQvo+lq5pdJaxRaNhEyC3oF0frK3ozC260HXNNR0DaZNh9BMaN+UgwWaW/3fy4uM/fG/Bf7wnxe7j6zok25kl0qrj6vaI+R50kVcSql0RY7tj/0s8Dt/B+jsDvdzShBSoqid2HBr3wLe94/SBVDXAX7/7wGf/qWhHy6pJhSECCESzwU0TbpAeNJQXfJKpZUg5EQcQlZXxlEGCYlWB4AIb2MQVdtFJGQSmEmHEN/bB+G4rj9lTMDmaOzZ0L4pnRFaymmKKpVO61SxOqG7aBCuk+EQMrJLpet+z2JVN83yIuVFqdp7kdWR/9cLjw73c4EglOEQ6u7KyzSnnHp+dveGu09SWSgIEUIkru8Q0oz4CT+pFnkOIV05hBIdQkbDj4wNcAjVWoAQxR4HI2OEjE/vAKhTEBoGx4WMjOkCNkulZ0P7ZnpcDJDHEKFnnAj7gpBX4O/mZTiEtFp428lS6cAhVNHIWF6kvChVcyuqddEzvz3az2V1CCmxJ61LS0X0KQiRglAQIoRIPEdatKOFiqR6qB3AtJ1TI00Q6kUcQh2gux/u3KpiUKB/p3UQPIElZHx6B+wQGhLHdYMOIY6dnxFHOYIQ4G9cZTgjHFM643qH+eXPrp1RKm2Ex7DMDqGKOoTyNoyKUrUpY0qcufBe6aguipoQGUTGhhGE6BAiw0FBiBAiUXl6vU5BqMooAUakHB6CyFiGQ6h3CPy7NwMf/Qlg9xXgXz4oF0FAfxfDIBgZI2R82CE0NGrsfN3g2PmZcXQdWM0RhPRa+rFBnXy3bwI/83bgD38k+zYyI2NJh1Az/F7Nj4xVtkMoJ1JelKp1CKm1j3UEXPxY8Z9Tz7GsUulAEEoRPekQIkNCQYgQIvHcMDKWZsUm1UDtmqZFuzIjY025c7rzrFzIX/wz4Mrj8nl08c/k9ax2uLtahKotGgmZBOwQGhrXU1PG2CE0ExwbuP0ScPz+7OtkrVOUM+LwOnDjaXk7WWSVShtNeYzzPHl8i25kVH3KWBkOIVExcdrqAOtn5Me9g+I/11cqneEQSvs9Bg6h3eL3RyoNBSFCiMR1wlJpOoSqi2uHpZ1JDDV2PhkZa0hbfee2/NrOBSkOAcDOeXk5dGSMHUKEjE3vUE4ApCBUGNvxBSFdOoS8In00pDx2X5auh+0Hs6+TFW1XzojrT8lNrt5h9m14GQ4hoyGPa8p5ER2EUPkpYzmR8qJULb5qdcJpeUmXTx5BZGxAqTQ7hEgJUBAihEjU2Hl2CFUbx85e7Bm+db4vMtaM76LefB64/rT8eOeCvEyWcw6CkTFCxsOx5ahiOoSGwnGlIFTTRPA5mSJqE2H7oezrpDmEHDsUca4+IS/zHBmunRGNbsrjmnJkGJHIWDBlrKoOoZxIeVGqFl+12sDKlvx4mIEtQan0oA6hAZExCtqkABSECCESZZ9mZKzauDmCUBAZiyxAog6h4DYs4Ln3yY9vXpDPrWQ55yB4AkvIeJj+yTBLpYfC8WSHUM2QS2T2CE2ZQBB6IPs6WkqHkN0JP77mC0JmniA0wCGkHBl0CIWUWSpdlfcisx06hIYRhFRkbFCHUF5kzDH7hSRCUqAgRAiRqA4hRsaqjWvlOIRUZCyywEg6hOrr8rJzS35sd4G9VxkZI2TaKHdEnaXSw+C4HjS/QwgALPYITZcb54G106GrIg09ZcpYVKS59qS8HOQQyuwQGuQQqqggVGapdBWO7a4rhcrmpvx8mMiY3ZXCp3rODTNlLPpaYGyMFICCECFE4qkpY4yMVZrcDqG0yFjCIfTA14Tfe/Dt8nLnwhhTxngyRshIqP4URsaGwnZ8h5CuBZ+TKbJzPr8/CEh3MkdFmt6+f5nRIeS6ALyCDqGIIKTp0ilrVjUyxlLpoVAizsoxeTmMQ8ix5FrMSBnmAQyIjFEQIsNBQYgQInFdmQvXa4yMVZm8DiHNACASkTHlEPIFoTsfAdb8iRoPv0Ne3nh2dIdQFRaNhEwC5Y5osFR6GBw1ZUyXDiHboSg9NTyvoCBUk8eqKFan/3pZDqE8p0ufQ6gR/369VV2HkHr/KKVUugLvReo5OUqHkGvL57kSJIeaMhZ5LXR2i98nqSwUhAghEs+RgpBWG+6gRZaLvA4hIfzd02hkTDmEfFvz9kNh98PdXywLEXfOD18qXSVbOSGTIOgQ2qheb8cYBKXSvkPIpCA0PY5uyOlJgwQh3eg/EU4ThJxefANDked0UQ4hKyUyBshjXVU7hNSUsbEiYxV6L1LCYRAZG1YQ0kd0CHX6r0dIDhSECCESNxoZq8DODUknr0MIkIsTJ8UhtHZSLhJPvQ44+yZg9SSwfkYu7IPI2BAOoSrZygmZBCouww6hobBdD7qmoaZzytjUufm8vDzx2vzraSlOZnXyrUp4FWZKbCxwumQ5hDphSXWqQ6jqkbEypoxVQRDyn0P1NbmmcYboEFKRMU2Xz/dhOoQYGSNDQkGIECKJjp1nZKy65HUIAbI/wU7pEHrdtwDf9zFg8w7gK/4e8NffLx1F2w8A15+UtzvSlLEKLBoJmQSMjI2E68oOId0/6bUpCE2Poxvycv10/vW0lFJpdfK9eae8bGzIy7TYmHKeZnUIRX+uzyHUqrBDqMRS6Sq8FylhptYKnWdFUZExwBcph5kyFnUI7Ra/T1JZKAgRQiTB2HlGxiqNkzF5RRFd1Hhe6BDSDWDb39VtrAFbd8uPtx8KFy4qVlaEIDLGuAYhI2GyVHoUbD8ypqaMsVR6irRvysvWifzr6bWUyJh/8h0ce/zocpog5A7oEALC41afQ2iVHUJldAhVIQ6uhJnayvATfB1LrquAlKi+GR8t33e/kVH3dAiRAlAQIoRIog4hRsaqS3RXKg2jEdqeHQuA179gjhLtghgqMqaFj4cQMjzB2HkKQsPguC50ERGEOOlwehQVhLScDqHNu+Tl9kPyMjUyNqBDCIgIQmkOoapHxjhlrBBRh5BeHy4yFu1zNJphpxUQF3lSI2MdOdnMaFIQIoWgIEQIkXhe2CHEyFh1GdQhFI2MBR0Lzezrq11aYMhSaUbGCBmL3gFgrMhd5ir1doyJ7XrQ9XDKGDuEpkj7lhQw8zYZAH/jKqNDSEXG1LGnuwf8j78rp10qBnUIqZ8DOGUsSqml0lUQhCIOIaMxZKm0FYmMJRxCUZEnNTLWluut5hYFIVIICkKEEInLKWME8nmQ1yFk1COCkH+Zt3jfujtcYI8ydr4KtnJCJkHvQMY3gWqdhI1JskPIYmRserRvAq3jg6+X5xB68OuAz/qfgfveKj+//hTwsXcBT/9WeN286JM6TgWCUOK4VeUpY6WUSqv3ogo47wJBaASHkGNHImPNdEGo1sqeMlZbkdPN2CFECkBBiBAiUWPn9bpcLHlcBFcSxxrQIdQMFzV2xljeKJoeTowZySHEE1hCRsI8lP1BAF9PQ2C7HnQhUNPoEJo67Z3BcTEgv1T62D3At/0nYM0vpr5xXl7uXwmvm1eO3BcZ45SxgLwy7qJoFYqDB5Ex1SE0jkMoIiYpkae1nR0ZCwQhOoTIYCgIEUIkwdh5/0A/TPkdWR6iufU09Hpoew4cQjmCEBBa90caO1+BXURCJkHvUI47BigIDYHjl0rrQak034OmRvtmMUEoq1Raq4UOVyWG7viC0EFEEHLzpowlI2OcMhagfueMjBUjKggZ9SEjY4kOoTSH0GqWIKQiYxSESDEoCBFCJKpUWu1IsEeomkR3pdKIZtkDh9CAvgdV7snIGCHTo3cQjt5mJ1dhHNeDEekQ4tj5CbF/pX8CWFFBSEvpOrQ6cReqEkN3Lvj3dzn83lCl0ilTxpxeNV9LZZRKV2rKWLRUujFCZCzLIaQEoZPpa3U6hMiQUBAihEhc13cI1eXndAhVE9fJdwgZjdD2XNQhdO5zZRxx7VTxxyGE/Jkq7CISMgnMQ3nyCvgxDcHXUwEc14MmBAw/2sLI2ARwHeA/fRXw6P8V/3r71hCRsaRD6Ci+6aAb8kS8558QxxxCRUqld+VJvBDx7yvRqYqTxvKidkWp1JSxDgAh101GY7h1dXTAR20lXmRexCFUXwWaG0B3f+SHT6oDBSFCiCQ6dh6gIFRVHCuMDaYRnTIWFCYOEIQe/Frg+z8VTn8pitCruQtLSBk4VrwgPq2Il/RhB6XSUgiwGBkrn1c+ChxcBq48Hn7N6koRs0iptG5kOIQSLlTlEgKAw+vhuqZoh1DaZkfdF4SqOGlMRbjLcAhV4diuXGtCyPdie8ix8+r9e+U40Lkdfs88AiCkAzQzMub3FtHtTwpAQYgQInEduYusMzJWafzc+p88fxMdM2XBFrUuB5GxAVEwIWTR57BoOk9gCRkVxwwdnwAFoYK4rgdd0zh2fpI88zvycudCOMCic0teFo6MpUwZSw4uaEQEIXjA4TX5Yd6UsWiHUFocuua77qroEMpzVhUlcCsOLwh96tVdfPrV3dHve9ooYQYYITIWcQi1jss4pXqtKAeQnhKdBEJxVDOqIbyRsaEgRAiRJDuE6BCqJq4F09Pxl376o3j3py71f9+ILGqKOoRGRTMAj7vzhIyEm+YQ4snBIGzVIeRHxtghVDKeBzzz2zIS3NsLRZr2TXm5uj34NvRaSmSs3e8QUsXSzU15qSaN5TldAofQPh1CScqIjAEjb/b88Huewrf9hz/Grzz26nj3Py2iIuU4pdKtE3IDTj3nzMPIKPvEWt3zwlJpTedanhSCghAhROKpDiEKQpXGdWBDg+cBt9spzwG9EZkyVtAhNCqMjBEyOn2RMTruihB2CKlSaYrSpXLtSWD3FeANfy78/Ne/B7jwqPy8kENIl4Ln7/994PkPyK+lRsZ8Qejc58lL1SNUpEMI3gCHUAUFoTJKpYGR3Yod04HteviBX3scV/Y64z2GaRBzCA05dj76/q1eE0o0NSMOIc+JT2NV67LAIcT3fDIYCkKEEInryB07RsaqjWvDE/I50DFTFhJGPVxwTNwhxFJpQkbGSUwM5MlBIRwv3iFkO3QIlcrtl+TlZ327vHzsZ4HHfxn4ox+TnxeNjNld4E/+PfDkr8uvKVdEFOUQuuPN8lIJQkU6hIABDqEKRsZKcwiN5v41HRfHWjV4HvDijQX4/UdFSr0xnCAUdQgp19zRjrw0j6QgFPQxRdbrwbqsJV8nnhNGzQjJgIIQIUTiuYnI2BAHLrI8OBZcf7F3lNoh1JSRMc+bvENIM6oxmpaQSZAaGaMglIfneXBcD7omUNM5ZWwiqOPG8ftl6fMz75Gfm/4I+iKCUPR5rWJgaQ4h1SF05o1ybaNGzxfpEAIyHEJqyliVHUI5gyeKIEZzK1qOi/u2pUPr4u1FcAglI2NDlkprSYeQ37Nl+YJQMBU4sl4PRt2vVKvAm4wFBSFCiMR1EmPneeJQSVwHnr+IaKc5hILnhzV5hxAjY4SMjmOxVHpIlPijR6eMURAqF3VSbDSB7Qfkx6sn/W8KoLk1+DaizreDqCCU4RDauANYPxuJjOVEn/RBDiE/MlbFDqHg9zbm6eOI8VXLdnH38RY0AVzcXQRBqB06yvQhx85HJ772RcaOwsiYum5wn1GHkP/85vs+GQAFIUKIxFORsRQLKqkObugQamdNGQPkLm/gEJpUZIyCECEjE51SA/ijunlikIcdEYRUh5DDsfPlEj1ubD8oP/6qfyBPYFe2wjVIHlEhR7l+oiffCjV2fv0MsHE24hDKcbpoWiik5jqEFiCyVDZlRsZGOLabjotWw8CZjSYu3l4AQS4WGasNN2XMjUR+W8flZbRDqNaKOIAi7+upDiGu50k+FIQIIRLlEGJkrNq4NjwhFxFHvYzIGCCfH1ZHPl/GLZjMQtMZGSNkVBgZGxrX79owNBGMneeUsZIJHEINWfZcXwNe/y3Aw++QMbIiRJ/XnVuA1U2PjG3dLR1Ha2eAjXPA3kX59UHChjrOccpYnLJKpfXaSGtM03ZR1zXccWxlQSJjkV4royGf+0X7fKIdQo1N+VwNBKFD+bpJjYwph9BKumBESApjhkAJIUuDGjsfjQSR6uFYcESByJjdkzu9yQV4mYzYM0BI5XEd2QvHyNhQxB1CHDs/EaIOoc//LuCz/jywcgz45n9bXCQIImMCgAccXE4vlX7zXwXe+G2yv+XEA8BT75bHrrwpY4A8ee+BU8aSeCV1CDU2gN7+0D9mOR7qhoY7j7XwsRdvjfcYpoHZjpdKw5PPvaigmYUTuZ6mydiYEoSUGy41MqYcQpFIGZ3WZAB0CBFC5I5FMHaeOwqVxXUBeHADQWhAZMzqTC4uBoxsKyek8qgThOiJG19PA3Gc/g4hlkqXTCAINeR6Q01Qqq0Azc1it6HWKWc/W17eejG8jeT1VNxm+0G5zrn1wmCnS55DyKjL11IVp4y5JUXGmptAd2/oHzMdFzVd4M5jK7i634U973HOaK+VPqT73k1EflsngHZiypgS/GORsahDiB1CpBgUhAghoYWVU8aqjZ8z94IOobSx874g5Ji+Q2iSghAjY4SMhHr/jjmE6LgbhBONjHHs/GSwu9ItIcTot6FOlO//Cnl56wV5mXQIRVEF1jvn86eMAeFxLs0hBEj3RRUdQmVFxkYQhBxXTgCs6Rru2FqB43q4stcd73FMEs/zXWu+SBlsphXsEXISkd/WCTllzHX9242MnU+NjEU6huj4JwOgIEQIieTpNUbGqoy/SHb9xV5qh5AeWdRYncmNnAc4ZYyQUVEnvOwQGopwypgGTRPQBGC7c+5CWDTs3vjOUrVxdd+Xy8udC/Iy73aVIHTjvHQKATkdQv5xLSsSXW9V0yEUXSuOQ3MT6OwO9SOW7wZSkTFgjkfPv/KnwH98i/x9qedSWt9PFr5bO+4QOi4jYyoSljllTEXGmuwQIoWhIEQIiY8STTvAkGrg/80dyEVyx0qLjCU7hCbsEKIgRMjwZEbGeGKQR9ghJD83NI0dQmVjd7OdN0V57VcDX/o3gfveKp0Qz7xHfv3kw9k/U18FNu9KOIRyOoSil0lqLTqExmFla2iHkKkEIV3DncekyDK3k8Ze/ghw9TN+Wfo3yq9F3dWDcFPev1WHkJpuV2+lb+AGpe0roXDKdRQZAAUhQkh84kZQQkdBqHL4iwY3mDKWFhlTU8am4BBiZIyQ0UiNjLFDaBBuxCEEAIYu5r+nZNGwe+NvJKyfAb7m/5brlfWzwP4lYPUUcOfn5//c9gO+IDRGhxDgO4TmVIyYJIOidkVpbspS6SHcd5Ytr1vTNZzdakII4NLunDqEVE/Wt/8CcPr18uNgIEcBQUgJPGmRMfNQfl5fSx8rrwQhvcYOIVIYCkKEkPjiSKNDqLL4iwo1Zaxnu/2FqkFkbAodQpwyRshouCknFOwQGohyA6n+IF0TdAiVjd0tdxjBxjl5+fA3SJdzHtsPyXhZmgMjSqEOoSpHxkroEPLcUNwogOV3edUNDQ1Dx0pNx2F3Tt/P1MCNaE9W4OYp0CEUPD8j79+r2/L3v39Zfl7LmDIW3QxIE4wISYGCECEk3SFEQah6qA6hyGKvr1g6iIx1Aas7YYcQHQ2EjAQjYyPh+I4FzReEDE1wyljZ2L3xI2NR1s/Iy4e/afB1tx+Q3T+7r8rPMzuEBjmEVivqEPIdPWWUSgNDxcbMiEMIAHQhghL4uSNN9BymVDrYpE1ExgBg9xV5GZ0yFhOE1GZAnR1CpDAUhAgh8YM8I2PVxV9IuIgKQglBJhoZsztTmDLGuAYhQxM9KVBQEBqISocph5Cha4EzgZRE2Q6hU68H1k4D971l8HWP3y8vbz4nL0d1CNUr2iFUZqk0MJwg5ChBSL42NU0EEc+5w+r0F5IPs9kavH+nCUIvy8v6aroDyDHl16OdoNxYIwMYMwRKCFkKogd5Rsaqi79ocCK7pn09QtEc/KQdQkLjCSwho5AaGaMgNAg1UUwTUYcQRelSKWPKWJQv/ZvAF3x3MddRc0NeKiFi1A6h2mo1p4y5jnRVRaNQozCCIKSmjDUM3yGkLZhDSMXtR42MrZ+Vl0rMrK8C8P8OyciYWqexQ4gUhA4hQkjowtB0jp2vMokOISDNIaRsz90pTBljZIyQkUgrJeXUvoHYvhtIuRDYITQBypgyFkXTgcZasevW/ev19sOfTYMOoXRce/y4GBARhHYL/0gyMqYJgbnte09zCBmR/sVBpL1/q2jkzgV5GesQitymY4ZfVw4irufJACgIEULCkwShRXYUeACpHKpDKHJoyI6M+aXSk54yxp0tQobHSdlhpkNoIMohZPgnnTVdC0QiUhJlO4SGodaSl11fEBq1Q6hW0SljnjN+oTQANLfk5QgOISUIzbV7L9UhpDZbi4ydT+kQWjkmb/Pm8/Lz2JSxyPt6zCHEDiFSDApChJB4qbQQ8iSiyEGLLBaeB/z3/xV45nfSv+8oh1B4EnmULJXWo6XSE+4QEhw7T8hIBJNmKAgNg+oLqkWmjLFUumTKdggNQ31VXgYOoVE7hPxS6XkVJCaF65bsEBq+Q6gejYzN66/f6qZ0CI0yZSzy/BRCxsZUVLHeyiiVjgpC7BAixaAgRAiJj50H5MGEFtPl48qngCd/A3jq3enfVx1CUYdQL7GQqLWkUNO+KcWaiU8Zm9cVHyFzjBJ+WCo9FMoNZERcCDbfg8rFKrlUehiUINQdFBkr4BAC5GCFKlGWQ6iR6HIqQF9kTAPcue0Q6uRMGRsxMgYAG+fCjzMjYxY7hMjQUBAihIQdQupAr/PEYSl5+j3y8saz6d9XHUKIdgglngeaBrSOA3uX5OcT7RBiqTQhI5E6dp4dQoOwgsiYCC4ZGSuZWTqE1ChuJeRkRsaUQyhn7DxQvR6hsjqEdAOorw8ZGZOvw3p07Py8uvfGdgj56x4tIQipYmljRf4dAgdQZJ1k91IiY9zgJflQECKEZDiEGBlbOp7xBaGdCzI+lsRfVESnjPV1CAFy/Om+LwhNcqdXMxgZI2QUGBkbiaBUWlOxFI2l0mUzyw4hIeSEMPmJ3HRII3AIZQhXyiFUtUljrlOOIATI2NgIHUIqMqbN9ZSxFIfQUB1CShBK/K43fEFICZIDHULsECLFoCBECImPnQf8DiHuKCwVO88BN54BTj4sF7H7l/uv4//NbUTGzicdQoAUhAKH0CTHztPRQMhIMDI2ErYTdwjV2CFUPrN0CAHhyXRWfxBQwCHkC0JVcwiVFRkDpCDU2S189TAy5vd7CQF3Xl+bVsoEVsN/L+4dAC99OP/nsyJj6zIyZukr+LFHz8NLmyIWnTKms0OIFIOCECEkxSHEE4el4+WPyMsv+t/k5U5KbMx/HrgRQaiT5RA68AWliTqEOGWMkJFIjYwZgMPXUx6W2z923prb5toFxHVkfGVWDiEgFHPynC7H75dTnFa307+vXEZVmzRWVqk0AKxsjVQqrTqEdE3Mr3vP7vT3K+q+yPjYzwI//43A4fXsn3dTpkQCwej5XbuOf/u+Cziw/dP4zClj7BAixaAgRAhJ6RBiZGzp2L8EQACvfZv8fOdC/3Vc5RAKTyKPkqXSgBSE1AIj4RD6x+95Cn/6ws0yHrEfGePJGCFDE0TGIg4hvcYuiQEEDiE/SmTodAiViu33p8xUECrgELr/K4AffEWO+k69DeUQqlpkrKQOIWDkyFgjMmVssRxCviC0+4q87B1k/7zapM0olW5D3lbXAQDRHxkzEpExOv7JACgIEUIYGasC+5eBtVNyQdHYBHbO91/HF3lsEZkylhUZU0QW9pbj4qc//CJ+94mr5TxmodHqTMgouCmRAwr9AwmnjPml0poWuIZICdhdeTlLQUi5e/KiT0LkCx9Bh1DFHEJlR8bGmDKmz2uHkOelO4Q0PVxjA/lr7MDhmfhd+6XS+44UfLqmK9/jY5GxtFJpOoRIPhSECCHhaO9oZIyC0HJxcEUuJoQATj6YPmlMlUr7DqGGoWWXSisiDqG9jnzO3DgsMEWjCIyMETIaqZGxmnw9cYx6JmrKWC0ydt7h76s8AofQPHQIjSFsBFPGquYQmn2pdE2VSs/rlDH1HE+bwKpHnvd508YyI2NSENrzBaGO5UjxJzMyljKFjJAUKAgRQiIOoUhkzDwEfu4bgVc+OrvHRcpj/0pgN8b2g+mRMb9fxPYPDevN2lAOod22XMTsHJQlCHHKGCEjEZSSJiJjAGNjOQQOIS3sEOLY+RKZB4dQkQ6hQdAhND7NTaC3V9gF3Dd2XhNw59EhZHfkZdIhBIRRLgCwc9yaWaXSRh1eaxu3LPn1juX43XDJKWP+zwUdQlxHkXwoCBFCIqXSkcjYzeeAlz8MnP+92T0uUh7KIQQA2w8Ah1f7d+dUZMx3CK03jewOIUVkYb/XkYuSnbIcQoIOIUJGIisyBtD9mYMVTBmTx8KazrHzpTIXDqE1eZnXITTwNpRDqGKCkOuM93uLsnmnvFSdOgPopUwZm0uHkOWLnqkOoYgglOsQUmvy/t/1/lf/KN5lfT0Af+hHX2TMTImM8T2f5ENBiBCS4hCqSQEBSHeSkMXC6gKdW8CGEoQekpfJv62/aHD8KWPrTQNtK00QOh5+XIsKQvLnbx6V1FOi6Yy3EDIKTkrkIBCE2COUhZ0yZWwuTzoXlXlwCCl3zzhOl8AhVMXIWEmnjtsPysu0PsMULMdFTRcQQr42NQ3z+drMcwjFImM578NuSuTX5+XTb8MT3v0AgK6KjMUEISu8H3YIkYJQEKoQhz2+IZAM+sbOR04i0rpmyGKhxL31SGQM6F+I+YsGy5PPg1ZdR3dQh1Bk0aMiY7ttq5xRzZrOyBgho+BY8oQ3evKmc+LMIPqmjGkCNkXp8pgLh1AJHUJGQxYEV80hVGZkbFhByHaDuBggX6NzKQjlOYTGjYwBuLzbCT7uqshY1AFk98Kf09khRIpBQagivHqrjc/5R3+AT7xye9YPhcwjSYdQdFf59os8gVh0lCCkHELH7pV/4+RCzO8QcvxJGHVDT5/isbodfpziEAKAm4cluBAYGSNkNByz/2SCDqGBqJ4S5RAydHYIlUrgnphlh5CKjI0hbAghp5VVrUOozFLp1nGgtV1YEDIdNyiUBgBNE5jLl+Ygh5BaZ+dGxvx1T7JUGsDl3W7wcSfVIRSJjAl2CJFiUBCqCC/uHMF2PVzb6w6+MqkefVPGIgch1wZuvTD9x0TKY/+yvFQdQroBnHgNcCPfIVTXM+IStVa4oE9xCAEl9QhpBhcyhIyCa8f7KoDwc/ZJZGK7LnQtjKXoGjuESiVwCM1DqfSYXTjNTaB9a/zHs0iU6RACsgdcpCAjY+Fpqy4Adx5fm3kOoe0HgHu/TH6ct9EaCEL9v+sre6FDSApCtZxSaU062bipSwZAQagi3PI7PbiwIal4viDkO0PCg4m/YCq4g0PmlCAydjb82vYDKZGxeIdQTc+wZAvhx8ZEzPofdQiVIwj5kbF5nCRCyDzjWP0nvOp9nScHmdiOF0wYA9TYeb7/lEbQITQHkbFxhY0TrwFuVqxjscxSaQA4+WDhWgLT9mKRsbnt98pzCP2/fhH45n/rXy9njZQbGetie02+fjqmioxljJ0H+r9PSAoUhCqCOjmbyxGNZPYEkTElCPkHkzveLC8pCC02+1ekq6e5GX5t+0Hp/Irm2IMpY75DyMjJ6LeOy11eEZ487XUs6P7J1E5ZkTEgFCwJIcVIi4yp+AEjY5lYjhdzIRi6KKcPjUjmwSFUUx1CYwobyt1SpXV1mZExQP4OO7eAo5sDr2o6LurRyJiY07HzeQ4hICx8zo2MpQwF8Lm818H92/I53Fcq7bryZ6OCKwUhUgAKQhUhcAjNZeCWzJxkqbQ6CJ14ANi4oz9aRBaLg8vSHRQRb7D9kBQCb78Yfs1RkbFw5HK2IHSib8Gz2zZxz3Fpxy/NIQQwNkbIsORFxigIZWK7LgydDqGJMU8OoXGnZZ18COjtAwdXx39Mi4LnhBuHZTBEsbRlu0G3FzDPDiH1HE9xCAHh+3BuqbQv4KQ4hK7udXHX8RZ0TfRHxtwUZ5FW4xqKDISCUEVQBa+pBbGE9I2d93fONs4CJ16bf7A+uAb8xBcBN5+f7GMko7N3Edg4F//a9gPyMvq3dW1AaHA8ueiq6Tn9Ga3tcKdV3U3HwtmtJpo1DTdLFYS4u0XIUORGxvh6ysJyvGDCGMAOodKZB4dQWR1CacfQZad0h1Dx36GVcAiVKQh5nod3f+pSOW5Ay4+MZTmEjALCvFrzJMQ3z/Nw89DE9nodKzUdHdONO4DUbcYiY9UazmE77nwKhXMOBaGKcNN3CPFFQlLpGzvvH0zWz8poUO8g+2evfBq48TRw/anJPkYyGu1bwKVPAHc+Ev/62mn/+xGrtmsBWg2u58khKrqAkzVy+S1/G3jHj8e+tNuxsNWqY3utUXJkjLtbhAwFp4yNhO3EXQg1XQSj6EkJ2APiNNNATRkbt0NoyLHpS4Frl9shtHGnFD32Lg68qpksldZEaZvcT13Zx9/85U/hwxd2xr+xgQ6hgpExrRZ3dQPY79owHRcn1xpo1vTIlDH/PT3oHkp2CFWnN+6b//1H8OOPVug1WRIUhCrCzSP5xsOdLpJKUCqdiIxtnJMHr7wTiAN/gpXFCXZzyYU/kILKw98U/3rDXxT3DsOv+YWRrudBEwKayNmBO/0G4MG3x76037GwuVLDibVGeVPG1OMihBQnNTLGDqFB2K4Xi4zpmoDrzek0o0UkOFmeZYdQSQ6h9bNAfb1aglDZU8Z0A1g9Fa4jczDt5JSx8hxCPVuugQ96JThpBome6n04NzJmpcbFlPP6xFodK3XN7xCqhUJQ4BCKRsaq1SH0/I1DfODZ67N+GAsHBaGKoDqEuKghqfQ5hPyDyfrZ+MEmjX1/gpXdyb4OmR1P/zawfg4497nxr6td0qj7y7EA3YDjysXWMP0Znudht21ha6WGk2t13DhghxAhM8MxOWVsBCzHRS0SGVMTxxi3Lwm7Jx0hZbpMhiXoEBpT2BAifVrnMuO65UbGAFlNoNaROViOi0a0VFoTpZ3TqNvpWiWsNawBDiEh4q6e1AdkpxZKq7TH9lrDj4z5gpASfFQkU490dOlGZdZQPdtBz3bx9JV9HJUh7lUICkIVQXUI0SFEUumbMhZ1CNXzra1qpDkdQvOH2Qaeex/w8Df0F2hquuwAMqMOITt0CGnDWbLbpgPb9bDVqpUYGfMfMyNjhAyHY2WXSrsWcPUJ4Mrj039cc47txB1Chu9I4ECOkrC7fdMpp05ZghAQThqrCmWXSgNyw+pgsCDUFxkT5UXG1KlRKYKQ3ZEuKj1H9BzkvHft1Ofnjr/RdmJVCkJd25HC0cDIWDXEkYOu/H+6HvDpV3dn+2AWDApCFaBrOTj0lVI6hEgqKjKmDkAnHwZOvUEWB0dHWqZxQIfQ3HLjafl3uf8r0r/fWJNTUhR+bt1xPehCDFXauNuRz5HNlRrWGgbaZgkLEEbGCBkN187vEPr9/1P+IzFs142VSiuHkJ3VpUaGw+7NdsIYEApCZUSfjt0L7F+qTlG7HysvlY2zwP7gyJhle7F+L00TKKveS61zOmZJDqFahjtIYdRDN0/qA0qPjO0EDqG67BAykx1CGZGxirhC9zvh//PjL9+e4SNZPCgIVQAVFwPoECIZuAmH0Gf9eeB/+2PpKomOtExjnw6huUX1A60cS/9+Yz21Q8hxPWjacJGx3bZ8jmyuyIVK13Lgjbt7xyljhIxGWmRMfe5Y0hlotaf/uOYcy/H6RlsDdAiVhnIIzRKjCUCUI2wocakqG2IZzpWxWD8LdHfD6VwZyClj4X3L9Uk5ipDrqchYCbdndwY/xwc577MiY36H0PHVOlbqek6HUDUdQvvd8P/58VcoCA0DBaEKcDMS3SjrzZMsGcmx81GMgqXSVVkQLRLmkbxUJZpJ6mvxyJjfIeSpUmm/ULWIsLPn78xstWpoGBpcrwQBmlPGCBmNvMiYY8rdaZZL92G7bhATAyKRMW6mlYPVnb1DSAh57CtD2FBOkAFixtJQdqk0IKsJgIEuoZ7t9om1ZZVKK0GoU1aH0CCH0CDnvb8WS7Jz2MOxVg2GrskOIcuRryflNsoUhKqxhjroyt/pa0+t4RMv3x5/U7JCUBCqAGrCGIDS7JVkyUiWSkfR6zJSlmaJtnvh2HI6hOYP5QBQBdJJGuvxUmm/Q8jxPOi+QwhAoUXXXjuMjDVq8tCiJneMDCNjhIxGWuQgEIQs6dSoSsxlCCzHC973AAz1HkgKMA8OIQCot0oShPzNlqq47SZRKr1+Vl4eXM29muW4qEfEWk0IlPWydMoslS7iEIqKOGn4a7EkNw9NnFiTgmogCEX7iNSlUVGHUEf+P994bgP7XXv8NWiFoCBUAegQIgNJjp2PkjeqOFoESIfQ/KHcP/UMh1BfZEx1CCFwCAHFdsf3/Z2ZjZUamjX5PBp7ccUpY4SMhmvlTxmjQygVO1lc678HWvO6m3b+D4D/8GWL0xFi9/qda7OgsRGfxDQqlXQIlXzqqBxCA4qlZWQs+tosT6gNI2MF1xq/+D8Bf/zv079ndbNHzisGlkpbqZGxncMettfk66dR09Ex3XitQ6ZDaEHeH8ZErUPPbMrXJSeNFYeCUAWIdghxdCpJJXAIpbwlRGMGSaKjQukQmj9M5RBaTf9+Yz1RKi07hFzXg66Fu+NugfcN09+JaRhaMBp2fIcQI2OEjERqZCwi7tvdxRERpojtxqeMqYjK3DqELn8SuPaZuNNznrE7g+M00+Cb/g3w1r87/u1UziGU7lwZC+UQGhAZM+24WKsNMQV1EGqvvHBk7OJjwGM/A6Tdv93JHjmvGNTN6dipkbGkQ6irImOOKR9LMGUsUSpdkU01FRk7uykFuXYZJeEVYSxBSAixJYT4VSHEM0KIp4UQXyyEOC6EeFQIccG/zGgzJdNi56iHuq6hbmjMwZN08jqEojGDJKo/SGh0CM0jQYdQhiCU0SHkenLKmCaKO4Qsv3S1pmloGCU5hARLpQkZidzIGDuEspCRsagLYc47hJSgnxc/mSesOYmM3fulwKmHx7+dqjmEXKf8yFhzQ65FBjqEvL6x82VNTnaGdQg5JnDrBeDGM/3fK+IQGhgZy3YInVSCUF1Dx3LgRd/X0xxCerUiY5oATq7L39FRGdNuK8K4DqF/A+D3PM97GMCbADwN4AcBvM/zvAcAvM//nMyQ/Y6FrVYNhlbemydZMgZ1CAH5DqHNu+gQmkesI7moMDIs+jkdQkJEOoQKTNhRkYqaIdBUHULjTuxgZIyQ0XBTBCF1guHa0iFUkRjBMMjIWH+H0NyOnVeCft7EonliXhxCZaHct2ZFHEKTKJUGpEsoxyHkeR7MvsiYKE2oVedGnaJrFvV6e/o9/d8r5BCqD4iM9TuxeraD/a6NE6tyPbdS0+G4HhwtIfSr21dUqUOoa2FjpYbVhvzdMTJWnJEFISHEBoC3AvgZAPA8z/Q8bxfAtwD4Bf9qvwDgW8d7iGRceraLRk0r9c2TLBm5HULqYJOy4Dy4Inf71s/SITSPmEfZ/UEA0FiLLyL8UacyMiaC/owituxAENJDh1DPHrdDyF8QMTJGyHA4Zv8Os6bJ15Td9XeTKQglkZGxyJSxeR87rwR9e0HcXvPiECqLwCFUEUFoEqXSALBxNtchpBzI9cSUMfmQxn9tqpso5BBynXDN/MxvRx5kB/jQvwT2Lo7vEHLsPkFf1X+oyJjqarTgr5PsyHt6UhCqyHv9QdfGetPAal3+bo56XDsWZRyH0P0AbgD4OSHEJ4UQPy2EWAVw2vO8KwDgX55K+2EhxHcLIR4TQjx248aNMR4GGYTK3ZY5opEsGUFkLK1DKFJEmqR9C2hty4MfHULzh9nOnjAGAPV1eamKpV0b0HQ4HnxBSD4firxvqAWboYlgylh3XIeQoEOIkJFIOaEAIE8U1OudkbE+LMdFLTplbN47hNTf0l6Q469dYCT3IlG5yJg9GUFo7TRweD3z29ENJ4Uuim9YDWKoyFgQy2oAVz4drk8uPAq8/4eBzi5w9k35tzFo7HzKUAA1IEiVSq/UE4KQ00uPjFWoQ2i/Y2GjWUOrLn8nbUbGCjOOIGQA+DwA/8HzvM8FcIQh4mGe573L87xHPM975OTJk2M8DDIINarRoCBEslB2+GEjY3ZX7nQYK3QIzSPmYVh6mUbDF4RMf5fZlSeRrutBE3KKB1BUEJJRCyFEiQ4h/wFUZDFDSGmkRcYA6RpSrhIKQn3YTrxUOuwQmvfI2IL8La0CI7kXiaqVSo8QGetaDr7rF/4M/+a9F4IpUH00t4DuXuZtKEEoGhlTU1DLOK8JImNFSoiVs2fFr8hVYuDOs/LyB18B3vJ38m9Dr+fHPN1+QX/nUF7/xFoYGQMAE7XwcWUKQtUQRva7UhBabdAhNCzjCEIXAVz0PO9P/c9/FVIguiaEOAsA/mW25EumgmnL3C0dQiSTXIdQjiDkmFIQokNoPrHa2RPGABkZAyIniHJXyvW8ERxC4QSQ8qaMMTJGyEikRcYAeZKhXu+eS7E1ge26schYbe4jYwtWKk2H0GIzQqn0q7faeO/T1/Hj7z2Pv/XLn0q/UnNTCkIZbh81xTTmEBpiCuoggrHzRTaxlLNnZUteqr/9jfPAxp3huioPo5Ef83T6HUKHfh/OelO+rytBqOfp4c9kThmrhiAURMZUhxAdQoUZWRDyPO8qgFeFEA/5X/pqAE8B+C0A7/S/9k4A7x7rEZKxUc38uqAgRDJwHSkGCdH/PSNnyphjSsHIWFkcy3qVMI/yI2O+Q+jGzZv43v/ycbiO7BByXA+aEEM6hLygb0Nl2zlljJAZ4HmpO8wA/MjYfvh5RbolimI5XiwyppfoQpgIixYZW1qHUEUEoREcQsoVdGajiU9fzHABNTflbavJqAlM5RBKi4yV8Np0AodQgU0s5expbspL5Q7bOQ+cfLDYHQ4aO59SKt323S4tPyrWrCtBSNU69MLH1ucQqsb7/H7HL5Wuq1JpbngUZdwpY/87gP8qhHgcwOcA+KcAfgTA1wghLgD4Gv9zMkNMP8qh6xSESAZ5B3l1YEnbgbR78vu1ZnUWRIvEoFJpv0PoqZcu4XefuArT7AGaDtdTglDxkctWZAJI6Q6hZRCEnno38GNvoJOOTB71ekkVhGrxyYKLEjWaErYTdwipj615XTstUvzPseVaY5kcQnpNHqeqEBkLqgWM/Osl2O/K96M33rGBncNeeixLiSsZsbGgVDolMlZGmlM5hHrDdAg1t/wH15Ei/M4FYLuoINTIj4w5/ZFf5RBa890voUMopVTaaIQ/WKUOoa6NjWYNzZoGIdghNAzDvaoTeJ73KQCPpHzrq8e5XVIupu1iY6UGXXDKGMkgzwasD3AIBR1CPNGdO8yjAZExKQgd7d8GsCUX67p0COmaCHbgiliyo5Ex5RAqtLjKQ1eC0BIsZj7xi8D+RenOGDSBhJBxUCcsgyJjAB1CCSw33iFkBA6hOe8QWoTImOoZXCaHECBdQlXYEFNCszacl2C/I99jXn9uE+99+jou3m7jgdPr8SsFgtAusHlH322kRcaCCYAlvDbVqVGnyJpFRb2iDqH9S4B1BGw/UOwOB0XG/ImvUZS4oQqTlSDUDSJjpvwntPh6Xq9GZMxxPRz2bGysGBBCYLVu0CE0BOM6hMgCIEul5QjpMtr4yRLiuTkOIWVHzegQokNofrHaQG1wh1DnUO7KCT+37nhy900foj8jWsaqpoyN7RDK669aJLr7wIt/KD+uwMKMzJi00cMKvR6KCEBlogRFsR0XNa2/p8Saxw4hxwo3YhZBEFLuyGVyCAHy/1MFh1DQNTlsZEwe895wbgMA8OrtlN/VQIeQEoRCsTYolS5jypivCNmuF9xX9pX99Ui0Q2jnvPx4+6HUH+mjSKl0X4eQg7quBS6pIJrvJqaMJd/3K9IhdNiNdyytNnQc9Zb//10WFIQqgNq51zUBZx4XNWT2FHIIpU0ZiziEPIe7zfOGeVjIIdQ78hdh/iLE8zzoItyBK+IQMidSKp0jRi4Szz0a/h/4GiGTJq1YVMHIWCau68H1EHMIqfe0uYzbx/6OCyAIzaFDyHU9fOtPfASPPnVt9BuprVRjQ0w5dYcslVYOoUAQupXyu1LiSoYgpCaWNmrhfQcO5hIjY0CB7sO0yNjOBflx4chYXa63sh68Y4UOaZ+jnh1MzwJCh1DHjUTG7AxBqALrDtVVtdGUv4/VusFS6SGgIFQBwiljGh1CJB3PTS+UBmTWGciIjPXkCYaKwFRhUbRImO0BHULSIWR35ImF8AWhsFRaWbILdgj5J091Xea3xy6VDtxpC35Qf/o94ccV2KkjM0a5ftK6PvR63M1QgROFolhu9iSjuYzbR51edAiNRM928alXd/H0lf3BV86i1qJDKIf9roW6oeGOrRU0axpevSV/V59+dRf/8LeehOd5Ax1CanOpYURfm/KyjPMaN/L6Hhgbc1IiYzeeBRqbwNqpYndoDHA/u1ZfZOzItIO4GAA06/IX0HZVZEw5hBIbARXpEAoEoRX5/281dLQjfVWe5+H/+bNX8PGXb83k8c07FIQqgJoyZnDsPMkit1Q6MsEgiWNKwUjt+LFHaH6wTbmoyHMIaTpQW4XnTx3S7DZQa0lBKBIZK9KfEY2MCSHQMDRGxhRXPwPAF1x5Ak4mTV5kLNkrtOivrRJR0VhD6+8QsgfFSGZB1CG0CILQHDqElAg41ujyynQIKYfQkKXSHVn0K4TAncdaQWTsdz5zBT//xy/JdYJy2wwhCGmBQ6iEyFjkJnrWCJGx/UvAsbuzN1aTBButGa9bx+p7/z7q2UGhNIBgkta+qdYWZrgmj1KRyNh+R0XG5O+lVTeCyJjnefi/3/MUfuDXPoN3feiFmT3GeYaCUAVQUQ5NY6k0yWCsyFidgtA8YvnjW/M6hAC49TXU7COsoQ3DPgI2zsL1POgiKggNvrtoZAyQ+fbxS6WXRBBy7fA1UoGFGZkxgyJjadcloSAUmzI2xw6hXsQhtAiRscAhNEeCkC80jCUqMDKWy37XwsaKPEm/69hKEBm7vCsvXc8DGjJOlikI+SJN3eh375Wx0T2UQyitVLp3IB1CRQmm92asbax2n5PuqOfEImOrDQP3nmjhiWuqR8xMnU5WGUEoiIzJ//9awwgcQo+9fBs/95GXoGsCNw8XfD05ISgIVQDTdtEwpEOoDCWdLCFFxs5nRsYa4YGLI7XnB9MXhPIcQgBso4V10cFpcVt+Yf1cOGVsiCkeVkIQahgauoN22gYRuNMW/KTVdcKTIJb4kkkzKDIWZdFfWyUSRsaiDqEF6RDKm1g0LwQOofmJjKmy8LH+vLVWuAGzzASRseFOHQ/8UeAAcNfx0CF0dU+uFx3Xk3059TWgs5t6G0GHkBHpECoxzjleh5AShNaK32FeZMyxpIBTi8f9j0wbq434e/rn33scj130n3u5pdIWsOSVIWGptHIIhaXSV/zn2gOn1rBzuADi+QygIFQB5Ima8MfOz6Htmcwe181xCOUU+6oCu8AhVIFdskXB9DsNBghCPX0Vq+jijPBz1Rtn4SamjBV527AdL3Yi1TD0YBE3MnnPvUXCtcKToEXvQyLzj3q9ZE0ZS7suiUTGUjqEZh0Za9/qP1k2o4LQAmzGzKNDyP+7jtVDQ4dQLvsdK+h1uetYCwddG3ttKzhJD/Sc5mamQ8hM7RAqPvRiENG/f8ccJAj5gkKfQ2i9+B3mRcZUH1Wi//GoZwcxMcXn33ccO+qp51jZghAgu0KXmMNeYspYpFR6ry2Pc689tUaHUAYUhCpAWCotSmnjJ0tInkPI8A9caR0Fjh8ZC0qlF2BRWhVU4egAQagjWtgQbZyBcgjJyJgmMJZDqFkrwyHkL2wW3VXj2nQIkemhRMfUyFjCNURBKECJA/EpY3MQGXvs54B/fh/wo/fEC+pjkbEF+DvOpUOojMhYRTqEvBE7hLpWMPnpruPyb//izSNc3fcFIfW7b24C3d3U20gtlRYziowpV2V9Va6brY4/0XUEh1Cas089l1IiY61GfJ3+BfcehwU1ZSyjVFq95y95bEwJQipW12roaPfk3/J2W/7NXnNyDQc9e/yBJ0sIBaElx3U92K5fKq3TIUQycB1Ay3g70DJiO54XRsbUAo8OoflBRcYStuMkN4wzuEdcw2nlEFo/KyNjQoRjXQuNnfcSkbESHEJZz71Fw7XD18iSL8rIHKCeY0UiYxQoA5ToE3U6ltlTMjI3nwsdBdeeCL+uImOasRil0nPoEFJ/8/FKpVeqMWVMva8MO2WsYweujdeeki6ajzy3E7ymAndOc6tAqXR431qZHUKRmxi4kaVea0YjFAOHdgjlRMbUcyklMraWiIzdc6KFzTV/009FxoyUUmlg6dceB10bdUMLniNrDekQ8jwPu20Lq3UdZzfle8/NowUQ0KcMBaElJzpGVROcMkYyyHMIaZo8oCQPXNFJNnQIzR+B7Th/1+oV7U6cFHt4ULuInrEO1PunjNnO4PcN24+mKkqZMqZp8nm5CLvfeUQ7hBZd3CLzzzCCEJ+PASoWFo2MqY+tAu+BE6O3D6wcA1ZPAvuXw68rF2jrxGIIQnPoEFJRpLESgZWJjPm/pDFKpe890ULd0PDBZ69HbjbqEMoShPwOoVq/Q6iUyFjk3Khwh5Bel3/73r6MbI4UGRvGIdTfISSEwGffc1J+EpRKZ0TGlvy9/rBnYT3y+2nVDbieFPh22ya2WnVsr8nf+032CPVBQWjJieZuDU2Ml5Mmy4vn5hcF6vUUQcj/3KjTITSPBJGxfIfQeeccAOBLtKfQbpwCgL4pY0UWXP2RMb0cW27ac2/RcCw6hMj0yBWEOHY+CyX6xEqldeVCmKG7uncoC2vXzwIHVyJf35f9ffVVThkbkXIcQi25AbPs6+sRSqW7lgPTdoNSaUPX8MCpNXz85dvBdUKH0OAOobo+oSljo5RKK0Ho8Ib8fKTIWFqHkBKEwrWbabuwHA+r9X4x7tRmCxb8jTO7lz5lDAg7oJaUw66NtWZ4zFPRsSPTxm7HwlarhhNr8vfOYul+KAgtOeECxx87P8tdLjIbHAv40L+MTyRJkjd2HpAHmOTuQnBQbNAhNI8ULJV+zpWC0Cmxi6NAEJLmHGOIKR5WX2SsBIcQ4AtCCy6iRDuElnyXjswBeYKQxrHzWahIfaxUWsxBh5CKo2ycA/ajgtCh/LreoENoRIIOoXEjY8BiFHuPwwil0gf+5CdVKg0AD5/ZiEW0nKRD6MnfAF75aOx2erZ0IGuakAXrH/7XULpt2YLQ4A6hiCBUXwUOr8nPR4qM5ZRKRxxCR0E/Tv97+uZKDaZnwA06hJIOIf/vteSbUYe9eKSu5Rdwt3sObrdNHIs4hHZYLN0HBaElRx3saro/dn7ZdzBIPy9/BHj/DwMXHs2+jufm58L1Rv+BK8hR0yE0lwQdQvmC0KveNizIxdpBXVqPXdeDJsRQGX0rERlr1vSSBKHa4rsYXDucxLfkizIyB7g55a+MjGWiNtCipdKaJqCJYrHZiaEKa9fPAgeX+79u1BdDEFIbRsmOkxkSTBkbt1QaWP7YWJ7QnMF+V76/bEScGw+fiQsngflOCUK/+X3AR/5t7Do9yw37g578deC9P4S1w5cAlCMIRSODAwUhVQRtNKRoc+Q7hIYZOx9ExlLef81+QegwRxA61qrBRA1mryNFyb4OIV+MW/K1x0E3LggpN9WRKafabbZqEUFoAd4vpwwFoSUnsFn6U8ZmustFZsPOBXnZvpl9nbxSacB3aSQdQr3we3QIzR+WLwgNmjJmC1yr3QkA2K9JQcjxPOiaCBxCxQWhuEOonMjYggtCrgvACxd3S74oI3NAcOKWIvKrOEFQ2L7Ar62SsSMbaFEMXZsfh1D7Zij+qK+nbdjMI3ZHCuNCDL7ulFAi4Fh/XvXevuzF0kFkrLhDaL/jC0IRh9BDCUEoFhmDJ9cuieiY6TjhhDHfJVezDuI/Pwau56FhaBCiQKm0Y8rYnKZLMfDQ70MaxiGUGxnrL5Vum/J3nxw7DwBbrTpMGDB7vdA1GKUipdKHPRvrsciY/PioZ/sOoRpW6jpW6zpHz6dAQWjJMYMFjvDHzlMQKhPTdvE9v/gYnr2aE8eaNTvn5WX7VvZ18kqlgfST8qBUmlPG5hLzSC5aBuzGdm0HN5p3AwD2a9sAEEwZ04aIS/RFxmplRcZS4oqLhJriZDAyRqZEkVJpddJAQShAvc8pIVxhaCIQi2aCEn7Wz8rPVY+QOvkzGunjq+cNqxu+D84Jll3C2Hm16TJFh9DPf+RFfOCZ64OvWCYjlErvq8hYMxoZSwhC0ciYIiEI9SwXdSUI+c//ur0fe1jj4LpyE6xpFOg+dMzQ4VNbCY/x9cmVSidHqkfZbNVgwYDV86edJR9HhQShmEPI/10d9GzsdSxsrchj34m1Bh1CKVAQWnKiRWx0CJXP1b0ufv/Ja/jtT18efOVZEQhCCYeQ5wG7rwK7r0iLam6HUEqxbywy1gAg6BCaJ8y2jBMM2I3tWS5uNe8FAOwZkciYJoLoRJHFsuW4sahFo8jCqgh6fbFHY6tFWOAQWuD/C1kMipRKq3gDBcoAFR8ykg6hWa+dVDRsQwlCV+Vlbz8iCC3Asdfu9E1OmjWqN6qUDqEpOoR+/L0X8K4PvTC1+wMwlkNocyV8Lzq53sCp9QY2fdeQ6xUQhGw34hCS6+0yHUKOP0ijWSvgbI729ESfz0N1COU4NFMcQnkdQsdadfS8GmyzI98r+hxCiQ6hJX3PT5ZKqw6ha3tduB6w1ZK/8+21Oh1CKVAQWnLUAqduaNA5dr501CjMz1xKn4wwF9zIEIQ+/GPAv34j8K8/C3j5w/lFj8aAyJgQcuePDqH5wTyMLSiy6NoOdlZfAwC4aZwG4JdKi3CKRzGHkBubAFKeQ2jBp4ypRRg7hMi0yO0QUoLQhn/d5Tw5GAU7ZcqY/FwL1lIzIXAIyQEAwej57l4kMrYA75Fz6BAy/b/5WKJCIAhNZ/1z0LWw17HwxKW96br+86KoGagOofWIQ0gIgV/+7i/CD3zdwwAiDqE1OdQCm3cB3d3Y7fRsJ+wQ8h1ChiXX3WX8DtQm2EpNR8csIAipyFd0jTVMh5BybudOGQvX5G3TF4TSImMrNZgwgM4uAK//ceiRDqGXPgz8szvDyWhLhOwQCp9n6nd1aVf+Po+16BDKg4LQkhMrldYpCJWNOuH9zKU9ePNY2N07CEsok4LQzeeBlePAt/yE/PeOH8u+HT2ltDKIjKkDY5MOoXnC6gwcOQ/IEasvnPxq/DX8X7jSlMKQ6hBSE3YG7Z46rgfXi3dvNA0dpu2O/7rQjMXe0VIn52pxt+gT08j8k9shxMhYFmlTxgBZMj2zUmk1OagRdQhdkV/fuwgcu9d3CC3ACY7dnT+HkL9GHuswFZRKT8chpE5wD3o2Xrp5NJX7BBAOqhhivPp+pz8yBgD3n1wLRoAH5yV3fSHwHb8JfM5fku63yJh0045ExhIdQmW499QmWLOuFyuVHtshVCAyZkQjY/IxraU4hLb8yJjRvZX+OKKRsZvPy9fh4dXij3UB6NkOTMeNdQht+o6gC9cOAUQdQg1OGUuBgtCSowSLmq5Bo0OodNTv99aRGRyk5wpVKK3VgPZO/HtHO8DmncDn/hX57+RD2beTGxnzD2zGCh1C84TVGegQ8jxPWrFrNXxK/+xwBK8/ZUydGA06GQqjFpHIWE3+7NguoUV3CDmJDiE6MsikKdIhVGdkLImV4RAyNA1WGUUlo9CTJzOorwPNLXmc3b8M3HpRRni2H1wcQcjqzJ1DqJwpY9N1CF26Hd7P4xen6E7v+V2ZQzhhDroWDE1GsZL0bTgJAbzmK+XzHJCikLprFRkzj4Ce/D8bpvx+KVPGvGE7hHyBK7rGGqpDyP/5rFJpvQ7o4fu3ioy1UjqENppyyljdvJ3+ONRxwLFDUW/JNm8P/a6qqGC2uVLD3cdb+Mjz8txny3cIba/Vceuoh+/5xcfw+MXdqT/WeYWC0JKjFjh1Q46dLyNrS0JUZAwAnpjH2JjqDzr3uf2l0u2bQOtEsdtJK/ZVJ+lBuR4dQnOF1R64G2s6LjwPaNT02C64WhypjfJBDqEgmhqbMiYXLr1BEzsGkTbhbpFIdggt8v+FLAZ5gpD6Wq0pNwoWWWwtmcAhlOgQqs3SIWSqk/B1ecK8cVY6hHaelV/fftB/j1wAQWgOHUJWKZExXxQwp+sQ0sSMBKEhHEJt00GrrkOkdBnqWVNMVZdQpEdIblxpgTsIAAzfITRW/5OP2gRbKeIQcnrxUmlACrV6yvttFsYAh1BiM+/I7Bc8FJom4Go1NK1d+YW8DiE1fXbJNm9V6XbUIQQAb7prCwe+WKQcQm+6cwtrDQN/8NQ1vOfxKyASCkJLjhUrldbgzGpRs6RE3Q9TPTBH2O9auHGQsRjcOS9PAO58RApA0QPnUIJQjkNI7XQYK4tRbFkVrMEFnur52zC02C64k3QIDdiBC3fWI5Exf0ewaw9YXA1i4aeMsUOITJkiDiGjufhia8mo97G+KWO6FohFUyfpylg/J0+K1WbPidf6/X0LIgjNqUNorGjzlEulL97uoG5oeNNdW/jMpd2p3CcA2UsIDBWN6tkOmrX0ziFNy4ikpwhCpu3KTSZVgYAUh9DT7wF+7buA3/k7Q78eXE+ueVp1PRjxnoljRSJjvnAzTH8QEP58dF397O/Kf1a7XxDq2dA1ERZrJ/D0Bmqemf5YtEiH0JI6hA5SHEIA8Dl3bQUfqw6ht73+NB7/h1+L15xcw8vTjFzOORSElhwzWiqtlZO1JSHK/VA3tJkVS///fvMJ/OWf/mj6N/cuyVG1a6flYiy6YGnfAla3i92J3sh2CBkRhxAFofkhZVGRRFmjGzU9tgvueYAmQofQIEu2nRYZK80htOAuBgpCZNoEpdI5HUJGY/HF1pKxU4RtQApE1qw203qJk/CTDwJXHweufgbYuFOe/BkpHX/ziDV/DqHAFTvO2lh1vUxp/XPpdgd3bK3gTXdu4YlL+9Orggjii8XFj46ZLQipyFhfX/vKlryMOYQc6UBWDqHGJnRfEAoEpY/+JPCZ/w782U8D154s/BjVY9CLlkrbvf5S6SF+JwD8QSwroUADAB/8EeBD/yJ1M++ol+20AhC+r6c9lmiHkHKxLalDaK2ZLQhtJL53z/EWXr45vcmA8w4FoSUnLJUW0iHEyFipKMHtnuMtXNufjRjyiVdu4/y1w3SXkHkop8koJ5AqlnYsmcMeKjKWLJVWkTH/QKQvSI9BVSjiEPLFmqahwYhM0nFcD7oWlqsOWnCakfJ6RTPoEBrXIbTgLoZAEKoDQlvs/wtZDIqMnQ8cQgsstpZMGBnrnzJmz2rKmBnpEAKAh75Bfu2Z/yHFIcDfsFmAY689fx1C6tg1lqaiokJTem+/uNvBncdWcPfxFjqWg4PulI4pvX0pgAwRjepaLlYyHULycqjImHIInXoYei/hEOruAbVV+fGQ4pzredA0oFUoMpZSKj1MobSiuRn7P+Lgilyjp0XGenZqXEwhjIgglFkqbS2tQ0h1CK034uXlbzi3AUMT2GgafVHgu4638Mqt9nwOBJoBFISWHDNSKq1r5ZSvkZCef+A4vlrHUW/ME98R2OtYePWWVPo//vKt/iv0DuQOYlIQUpet48XuKDcyFtlxpiA0P1idcHGUgRJrpENIi/UpaJqASk4Met9IK2NVDqFuGQ6hRS5ijp6cazU6hMjkKSwI0SEUJXgfS5syNqu1kyrWVSd5971VikOuJfuDAPm39Nz5n2BodaWTeI6IDlIYmbT4zwS5dLuNO7ZW0KrLY+zAiFNZmIdDO2E6lpNaKA2klEorlCDU2Q2+1LP8Uun9K/L5v3EHNFOKKTFBaP20/HjIgm8VGVsZOTI2piDk2MDhdencT+l/PDLt4O+dhqac+mmPJRCEnFBgrohDqFnT8bqzG0GhdJR7TrTQNh1OHPOhILTkqN2PhuF3CLke1dASUR0sJ9bqwRvSNHn6SjiF4bGXbvdfoXcgDw6ZgtAwHUIDImPGguxSVoUCpdLdiEOopotgh9x1PehCQAgBXRs8ndBOcQiprHs5DqEFPmDHBCGDghCZGD//kRfx6q12wQ6hxuLHMUsmLfoKSIHImpVDKIiM+SfiRgN48O3y40AQ8v+m8x7ZtjuxUdrzgF1GqbR6TU3hvb1ryRPYO7ZWsOILBAMdLWWh1pND0LVyImNDlEqbjj92/uCKLFZvbkLrpQhCa2fkx0O+Fhx/zbNSMwZHxpxeOQ6hla3w/3h4DYAnBeDuXt/arWu5wd87Da2WIwjpkciYqo1YMofQQS+9QwgAvvcrXoO//pb7+r5+zwkp5r1yiz1CAAWhpceKOISMoMBtlo9ouVAOrOOrUhCattj25GUpCN2/vYrHXk4RhNSOjuoKUpPGhhaEUk4c+iJjdcDmycXcUKhUWi58mjUdhtY/ZQyQu3iDFsvpkTG/Q6iUsfML7GKInpzrxmL/X8jc0jZt/MPffgrv/tSl4SJji+y+KxnlAkoKQsYsp4ylTXZ6/bfIy9NvlJdq4tG8i3vz7BAa58+r6X4cePK/fzVh7I5jK0EUa6CAURa9w6HLk7u2O7BUum99UV8HIOKRMcvxS6WvAutnfEFoH4Anf951pJgyjkNIE0FkLHct71iR7kx/jTVshxAQdwgdRKZd7V/qi4xZjhub4ppE9wUhT+j9sUxVKu2YYWRs2RxCKjLW7D/mfcNnncV3fPG9fV+/+7h00LNHSEJBaMkJTtQMLTjBm9m0jCWkFwhCDTiuN/7J75A8dXkfJ9cbePsbzuDJy3tBSXD4AJVDyI+GHe3Iy0AQKlgqbTSyI2NRh9C871BWBdeVB/yBpdKRKWN+h5DnefA8BOWFRRxC6ZExf8rYuLuXmjH/Jzp5OMnIGE/ASflYtnwNdi3XF4REWNIRJeYQWnCxtWSCzsW+yJgGa1Y7aWmTnV73zcBfexS46wvk54FDaI4dup43lw4hdewaKzIGyPf2KRynLvuC0LmtFbTq8uR3apGx3kHYZZWD53mBcNU1C0TGkr97TQOaG/0dQoYGdHeBleNAcxPCMdGAJX9eRSvXz8rLYaeMuYAmgJW6Dsf1gnOnVOxeKKyXFRnbD6en4fBa32aeabt9ZfdRanV5fa+xLguro6jH1jtY3g6hngUjZwpbGncdX4EQFIQUFISWHHWwk2Pn1ZvvLB/RcqEcFsdb8uAw7djYk5f38IZzG/i8u7dgOV7gGAof4KE8GDQ2AaGPERmr9bt/kg6hNNGIzAYlzA3hEKr5PRlqbaZHBKFBu+OpkbGgVJoOIQC+Q4gdQmQyqBOYruXI51iaOwiIj51fdLG1ZGzHgyZC54KiponZlUr3DuRJZ3RinBBSDFInfsoRMM8bMuoEfW4dQmMKQlM6Tt1uy/s4sVoPIkRtc0rHFLNYZOz9z1zHW//5B3Btv4uu7WSWSmdGxoCYWOK4HmzXkw6h7p78nj+JbANH8udV39Ca7xAa0gHjqA6hIq4rxwxdeUFkrESHEJDuEMoRO2oN+bpyjJTeyGgEb4kdQmtNI3sKWwoNQ8fZjaaMWRMKQstOWCotghM8OoTKo2dLG+d6UwpCR1MUhHq2g+euH+L1ZzdwakMeDPY6kcW968oDeH1N7ri0jkcEIT86Nk6ptGNKkUktVDllbH5QdumiDqGaBkOTk3TU4kxpO7omBi6WUyNjQak0p4wBCDuE5r34lSwkgSBkDxCE1Nc5ZawPy3X7JtEAcxAZG3QSPuVS45FQJ6Bz5hBS6+GxB65MqaB9ryPvY3OlFogXYx9ji1IwMnZ5twPH9XDjoJc7dl7LKpUGYmKJOo+pG5oUfpqbgcixIdpwPITCihKEhnTAuK6MyRcq6nbMFIfQxlD3ByD8P3pe3CEE9G3mWY6X6xCq+4KQnSYI1ddkpLG7t9QdQnlT2LK4+0QLL1MQAkBBaOkxHRc1PSyHBegQKhPTlqr9qv9GdNCd3snetb0ebNfDvdurWPUPYrFJZ5a/E6AWk60TQNuPjB3tSNeQHh/RmIleBzxH5rQVdi+MiwGcMjZPqL/9wFJp3yFkSIeQ5XjB4kztkuuaGCgip0bGSnMILXjxbV+p9AKLW2RuUX2BMjLmZApCe6Z8jb645/iCEAVKhe14qGn9O8wyMjbDsfOD+knUcfjCHwB/9tOTf0yjoE5A58whZPpRy7HrH6ckru615X1srNSmP2WsYKm0Kvhtm07BUumUbza3ApFHOZlbwpKFzitbgSC0iSMZGVOC0PpoDqHolDH12L/lJz6C//7Yq/1XThs7P2qHkOdI187BlfgGXp8g5MbWV0mMunxdmWmCkKZJwaq7t7RTxg66owlCd2y1cGV3uX4Xo0JBaMmx7LCITBUl0iFUHj3bQcPQgjeiaTqErh/IBdbpjSZaDZUlj9x/cjrJxjlg76L8uH0TWC0YFwNC4Si6AxY9KAKcMjZPBA6hQZGxuEPIctxAENJjHUL5d5cWGVMOod7YDqElEYR0g2O+ycSw+iJj6SdhF8UZ/K7z+XhcPLz4r62SsZ10h1CtQGx2YhQ5CVeRsT/6V8AHf2Tyj2kUrj4uL7funu3jSKBeN2NNGQOm6hBq1jQ0a/rcjp1X6+Aj084tlVYvtdTffXNT9gUhXKesiaPwe80tANIhZEcFoda2dMMM6YBxPLkJplxX+10Ln351F89cPei/sm2GIuz6WeCN3wbc/+VD3V/w/wDkY9+/DJx6Xfi9hLtbbu5nn7KrsfOWniIIqfvq7gGm74ZZss3bw66dWig9iLWGjqNpvX7mHApCS47luKj5uVNlzxzbGksCepYsultt+A6daWW5AVw/kG/op9YbWPPLBQ+jDiE1nURZWbcfBHYuyK2w9s3i/UFAZIpJ5CCSFIR0v0NoypPWSArKFjwwMhZxCBkabNcL3h/U+4WhCTgDHULZHULdMjqE4MXdaYuEmyyVpiODlE/YIeTmRsaO3Bq+1/pbuKKdpiCUwHK91F14Q9dm2CF0WDwy1rkt4+DzuOn39G/Ltci9b531I4lRbmRsCg6hjoXNFblBF4ydn8YJrWPJjqoC0Sg18emga8O03cxSaS2rVBqIOYRUZGzVPQy/pyJjaMtNLCUIrWzJWOKQfVqu60EXCIq6r+/Ln7fSXvfRyJhuAH/+Z4HTbxjq/uT/QwlCu9IhtHlX+LUUh1DelDGtJt8DrDSHkLqvoxuhQ3nIKWzzzn7XCqo7hmGlbkxvSt+cQ0FoyYmqykbWiEcyMj3bRaOmB8p0TJCZMOqAdWq9Edpcow4lMzGudvsBucOzf3kEQUh1FER2wKK7JMBiTDqpCupgX88XhKIOoZompEPIX/+oyJgmBjuEzNQpY8ohFP/hg66Fp68kys/z0CMjUxeRmCCkUxCac/74+R381B8+P+uHMTQqttkb0CGkXKR7HWvx+7lKxrTTT7pqupjdlLHeQfHIGCAjKL297OvOAtcBnv1d4IGvCdcJc0IYGSuhVHoKceC9joWtFfk7DAqQp9EhFGwwDnYIqcjY7SN5zB63VFpFxla9qENIdQj5pdJKEGpuyljiKGPnI5Gxq3tyfW0mN7Q8T26M6o3kTQyPEn86u8D+FeniV+vyZKm0nd8hpBxCpp6x5lvZivcUzXMB/QgcdG1sjOAQatV1mI47O8F/jqAgtOSYthcscNQJ3sysz0uIWkCuziQy1oOhCRxr1VE3NNR1LW59TB7Atx+Ulzvn5S7iUIJQykm500tExprh18lsGcEhpIpTnSAyJq9j6IMdQmmRMV0TqOkiWMwpfuGPX8K3/sRHihdhzrowNTqqdRSSU8Z4Aj7X/PLHXsWP/O4zuHAtJSowx5h2NDLmZPbDqd3Q/Y7lT73j81Fx1LODY3kUVbg/E4pMdjISJ6dqaMQ8cHAVePz/kf2FD79j1o+mj8AhtCCRsd126BAydLnum0pkTHXPFIiMKYfQzUO5FhxUKp0ZGTMPAccOhl+0AodQRBBCVBASQH19JIeQ43rQIqXSV/flY+8ThIIIeAnCph97w95F2fu4fjZclyc282TaI7tDSPO7ucy8yNh+ZJLZkjmEDkZ0CAWxy2kVs88xFISWHDMyqlA5hMYer0kCeraDRi0UhA6nWCp9/aCHk+uNQOhbbegZHUL+YnL7IXl59XHg6DqwerL4naWdlNsJQUh9nBxPT6bPEB1CdV2DpgkZi3CjU8b8DiEhMEhDTouMAdIl1E04hPY6Fnq2m57NT0NL6a+aJr/2XcC7/9+j/7yTjIzxBHyeueo7L3/hT16a7QMZEqsvMpZ+EqZOHve7NqeMJTjs2UEfX5TZThk7BOoZJ3mKpFtBTROdNZ4H/NRbgN/8XnmS/tq3zfoR9RGMnR9X79OmFxnbWAlPfFfqOjrTqCoINhgHl0qr6oQd3yGUFRkLB92kvLbUBNyDy0EcdsWJCEJGAzBWcEwc+ZGxXaC5IQuUR3QI6ZGx88qB30sKwepvXIbTTTmErj8lL2MOofjabWCHUE2+B/SyHELNzbhzcIkcQp7n4WDEDqGpxi7nHApCS45lh8306s3XZodQafRsv0Mo6PCZriB0aj1cCLbqRvz+kzs6a6fkZLE/+xl5ULtviCx/WmTMseIHRbVLuUQHmoWl8Nh5WYoOwI+MeYF1PjplbJBDSEXGjET/RrOm9TmEVEztqcsFY2NphebTZPeV/pGww5B0CC1qF1JFUCcCv/6JS9jvLo54Z/aVSmdExvyd0L2O5Z/ELs7/cdK0TQdrjX4hrTbLKWOOGbpvs+hzCM2JIHRwVW4+fcF3A3/9/fKEfc5QUcuxN0qnJK7udyxstUJBqFXXp+MQSg4pyaGoQ0jPq7FQ69Pzvx/Ezhu2L0opIWX9NE6J3dAhpBw3o3QIeVJLUo6RawcZkTFViVCmQ+jSx+XliddkR8YGdAjpfodQT8sShLbCj0co3Z5nOpYD2/ViQmlRpl7MPsdQEFpyrIhDKDevS0ZCjZ3X/ekEU42M7Xdxcj1cKK42dLTzSqWFkD1Cuy9LYejetxS/s7R+oGSOOoiMccd55gSRsUFj52UHFhAWp6rFmRabMpb/nqHiFMkFS5pDSC2wnrxcsOdiHiJjVkmRMU3nCfgc43keru338Dl3baFtOvjIhZ1ZP6TCBGPnB3UI+ceoIDLG9+uAo54dbO5EMWY5ZczuDXYjKEFIHY+P5uR5u3NeXj78jcDp18/2sWQQTBkrpVR68uu/aKk0IPt5ptshNFjUUx1CtwKHUH5kLNUhdPIh4MQDwDPvCTaVmk5SEDqHM9qtiCCkCpmHdwg5bsEOIXX8LkUQ8n+Xlz4hL088EDqj+kql8zuEdD8y1hE5DiFF68RSjZ0/8AXIkRxCtZQJzRWFgtCSk1oqTUGoNKRDSB5A1prGVKeM3Tjo4dRG3CEUu/+0EkDVI/Tg24ezvKZGxhKl0nqKaERmQ+HIWOgQMvzi1CAyNoQglB0Zy3YIPVnYIZTiTpsmvYPx8vZ9U8YoCM0r+10bHcvBF9wnF+U7h4vzXhaUSluudKFllkpHO4RYKh3lsGdjLTUyJicwjl08PCxFC2zV9+98RF7Oi0NICUJq3TGH2AvkELIcF0emExeE6vp04i7JISU5BA6hAYLQwE3qh78ReOnDcNq35V1bB/K5rtY1G2dxBrf7BSGjOYJDyAs2dgHgWlaHkFOiQ0ivAbVVueG0cadcq7e25fciDiHHX5flCUJGXQpC2Q6hhCC0RA6hA9/JO06HECNjFISWnujUDI6dL5/oCfVaw5jalDHLcXHzyIxFxtYaRtz22DuQJwVRu/lJf2E2bLmjiu38zt8B/vO3Au/+PnnAjRaXVjgyZjsu3v/MtemfMGRRsFS6Z4UjYWt+cWpyypiuiYExUysjMtao6YEAFNynLxA9c3W/2HuR7p+gzcLJ4HnlCkJT2kUmo6HiYq87K3sydg4Xxz1jOvJ1FUbG0k/ClJtgv6scQhSEFG3TQSstMjaruL362wx0CPnfP/s58ng/T4JQfV2W5c4pQYfQuH/aKbjt9jry+TCbyNgQHUI9FRkbMGUsKJXOuKHXfRPg2jh28QMAgLp9EBc21s/iFG7JSHvMIbQy8pQxVdSt6hfMvg6hEh1CQPiYtx+QlykdQsGGW06ptO53CLUzHUJb4cet7aVyCO115N9q1CljACNjAAWhpScaGVMnaxSEykN1CAEysnU4pc4JtXN9KhIZa9UTkTXzUO7miMhB5OFvAj7rfwYeePtwd3jms4H7v1Ke1O69CnzyvwA7FxKRMf/jCkYQ3vv0NXznzz+GD81LxMTqyJz4gEWLFDTlAbGma3A9BF0ZajNqKIeQ1u8QSk4TC6chuXhx53Dw/0X9H2bhrLG7coyzEthGIZhKYsjXD8fOzy1qV/jc5gqOtWq4ebRADiF/fHbXdvMjY5Gx896UinAXhcOsKWP+m+HUY2PqbzPo5LOxATzyncBnf7s8oZyXKWM75+WJrsg+kZ01ZiAIzf+UMSUIxR1CxnQmJBXsEHJcL5h2qx5vVqm0Wi6kRsYA4NznAZqB1t5zAADD7BeEVoSJurWf6BAa3iHkuOGmuYqNATkdQmWUSgMRQcjfrH3NV8o1+okHwseQEcmPop/7bLzb+RK8uvrG/PsBZCyNDiEA4d+aghAFoaUnGhlTb3YslS4P1SEEAKt1A0dTcghd31eCUCjIrDaSkbHD/t2c7dcC3/af+kZaDmTtFPC//CbwXY8C3/pT8mvmQfygqMShCkbGzl+Ti6X3P31txo/Ex+pId9CAhXg34hBSgrEqcAw6hEQxQcjQROAqUshS6aRDyMWqfxAuFBubZWRMLYJLi4wZjIzNMdd8h9DpjSZOrDWCHe5FQJ00mLYLz8nrEJLHKMvxYAv/+TgvzsYZYjkuTNvFWkqHkBrMMfVi6UAQGhAZEwJ4x48D5z5XnuzNi0Poxvm5josBocg3fodQfeLv7UpgiU0Zq2nTmTIWDCnJdwil1SZkOoTySqUBv+X5BIyufD4b1n5c2NiQzrNV88b4DiHXCzbBWnmCUFGRtijqMSv3/uadco1eCzd7VT9cXmRMNDfxd93vx762mX6F6O9t1XcILcn7vuoQGs0hJH+mY3GjjoLQkmPZXqAqG74cz7Hz5RHrEGoYU5sydv3AF4RiHULJUun9Qvbeodl+bfhx9KBoVFcQeuGGLwg9e30+YmNWe2B/ECAdQirfr0561InlMKXSluP1xcUAWSqdJgid3ZKPbb9TYAEdTBmbwcl5zxes7O7oc4n7ImMUhOaVq1FBaLW+UIKQFYk2uHmCUGQntOf5Jz50rQXHztSx8yoyNm2H0ChuhNaJ+RCEegfAweXwRHdOUa+bsQ/bU+gQ2mv3O4RadWNKpdL7cnqXnn/SrfqDogwqlc5dX7S2UevJDiHdTAhC6+cAABu9q1KwGrNDKHAIRR5vf2SsoEhblKRDKAUVyc8ThOT3Rew4kHo/gHyP8NylWYvsl9AhRIcQBaGlx3Jc1BJTxmY2LWMJ6UXGdk+zVFrtZEcjY32ClIqMlc3KMWD1lPw4NTJWQUFo5whCAK/e6uC56wViUHkcXA13t269OJoQoRxCA+haYeRRCcY9f3Gpa8MIQm7qYqVhaMHtKXq2GxS3mkXei7QZCkJm5G85auZejZkPSqV58j2vXN/vYqNpYKWuY3utgZ1FiozFBCErs0MoGi/pOP51GBvDoX/sThs7H0bG5tQhFGVeBKGdC/Jyzh1CVlkOIc2YWmRsaxal0r3DQiPnVW1BLbJB1MiKjOVNGVO0jqNuSkFI6+2lOoROdl6Un69sycvaytCRKMfzAodzbmQseE0OLz6koh5zriCkHEL5ju+aoWW/R6nfm9DDaN2S9AgFDqGVEaaMsVQ6gILQktOz3eBNhGPny8d03OBgt9owUndHJoEa53liLdw5bNUN9Gw3PCD0DibjEALkSFCAkTHIUdUv3DjC2153GgDw/meuj3eD7/pK4MP/Gti/DPy7NwNP/ebwt2EeFRSE+h1CytETcwgN2D61HDc1395MKZU2bTcYD5q5mxXh1X1/kT2LMmZVpAmMHhtzLABCnqBrOgWhOebafg9nNqXIfmJt0RxC4WvUy+kQ6ph2kCTtOP5rloJQcCKb1iEURsbmtEMoSusE0J6DLruFEYT8sfMLMGUsrUOoVZtSqfTBFbkZOOhq/usoulk5cmQMAFon0DB3AQCiu9fXIQQAd7Wf9O/IH9luNIcWO1zXC0quo5Gx5Pol+BsbJTmENu8E1s4Aa6czrxJ0CBmDHEJa9iab+r3VV8M42pL0CB10rdiEuGFo1egQUlAQWnIsJ3QAFHrzJYVxXA+W46GuTz8y1rEc1HUt5spY9Xc2gx3ggjs6I6EmIsQcQtUcO3/joIfDno0ve+02Hji1hj95Yczd2aMbsozz1guy0PjKp4a/DatTMDIWcQj5zyW1ABrKIWRnRcb6S6V7toNVP7dtJRdbCZ65uo+/8UtPyE9mEhmLOIRGLZaOnpwzMjbXXN3v4vSGLwitNrDXsfp3iOeU6IlLXofQUc/BiVV/Ik0gCPE5GQhCKR1Cyj05dYfQSJGxbdmnMuu/6c6z8jl4/P7ZPo4B2EFkrAxBaLLrv9QOobqOjuVMNqputoEX/hC4/ysGXlVtip6M9FtmR8bkZb5D6ASa1m0Ymi8IKUcNABgN7GIDbzj4CAAB3PdW+fXailwvuMVP8l0vfDwrkfcA007chl2yQ+gt/x/ge/4wt+8xdAgNEIS0nMhYfVW6g+qrMvoHLI1DaL9jY71pQIxQXq+mylEQoiC09ERLpUOH0GIscOcddaIQOISSDp0J0jGdPhuu2tkMeoR6BwMLAEdG7frFxs77uw4jRMY6poMff/T8wpx8RXn+xhEA4P6Tq3jzPcfwyVd28xc4g3BtuRu3f0V+rnZah6FwZCx0CKmeDDUWXq09jCKCkJsRGUsrlbZctOo6hBjsENo5MGFhhmPny3AIRQUhRsbmmuv73WBnW7kvb7cXwz0TfS3lCUIdy8FZ3wXVduOC0Fz0n80INRAifcqY7xCa+pQx/1g6VGTMd0l0bpf/eIZh5zxw7L7yTpwnRJHI2FOX9/FLH3sl/4amMHZ+t21hrWHEjrUrdR2el+JkKZPn3y/Fg4e/ceBV1aboab/fUtdEppAhhIAmBjuEVux9bBmmLO2OOoQA7GjHocMB7vx8YN132QR9lsUdMI4biYxF1tYT7xCqt4D1M7lXURMkBwpChpa9phJCimm1Vvj7WSKH0MYI/UEKGbvkuoyC0JJj2eGJmhEIQrN8RMuDOnGOdggBmMqksZ7t9Nkjlc01cCmZKVPGykIJQlHbrLK128Mviv70xZv4N++7gE+9ujv+Y5syL/ij0+8/uYbPvXsLex0LL+wcjXZjrgPAk3Gxg8vyazvnh7+dwqXSoUNI2ZHVlDExZKl0amTM0Ps6hFTMsp5nb/bpWA5sqJ6TGex4m1FBaFSHkBNxCE2+Z4KMhut6uH7QC05ktn1BaOdwMRyPUbedjIxldAiZdhCLO7LDDqFf+tgreMs//0ChGOcychhExvp/b2oNZU99ypj/XjGMqNI6IS9n3SO0c2Hu42Ke5wWT4/IOcb/y2Kv4h7/1ZP6NTUEQ2utYsbgYMKXIyzPvkb0z93zpwKuGgpB8jxkU45Hri5wrrG5DwMP9uh+DTAhCN4X/fH/dO8IvKgfMEIKH60UjY1GH0ISnjBXALNohpKcLQsEGZXPTj4wtl0PooGsHNQSj0KpPKXY551AQWnIsxwtO9OgQKhd1oFC/X1VGeTgFpbljOrHiOyC0urdNW47MMCcZGVMOoZRS6SGnOwDhLl0vac9dAJ6/foSVmo6zG0183t0yY//JV0bcnVUnAAdXQ4fQrReBm88Dv/JOoLNb7HYKRsbiDqFEZGwYQch20yNjNQ3dPoeQg4aho56xeInSsRyYyiF07TPAb3yvjFE8+7vAH/wD+fU//Y/AYz+b/x8dlVIcQlY4mUUz6BCaU45MG7br4fiqXOifWJPvZ4vSI1TUIdQ2HZzxT9YOLf8165h4/OIeLt7u4NMLKMqXQdvMi4zNesrYkKXSwGwFIceWx6w5nzDmuF4wXSzP1duzHfRsN/84qNdlxHuImNKw7HXMfkEouu6bBI4tj7cPfX0hYVJFxpQg1MwolFZoQuRPPvafz6/R/W7GpCCk+c/3hyOCkOrIyRM8rjwOvPv7gjVXbMqYv7Y+1qrB9RJR0aBDaHqCkDVMh5Ad/13+5Aefw1f+qw/KQTRKEDKWq0Nov2uNJQit1PXYsIWqQkFoifE8LzUyZrNUuhTUibMaO6+s5tMolu5YDppGwiHkC1JHPUc6TDw3t6huLDbvBL7k+4GHvi78mhKHRtglUwdc5U5ZJF651cY9J1rQNIHXnFzDetPAJ17ZHe3GXFWg3AOuPyU/9hzgvT8ky6Wfenex27HaAyNjnudJh5AShPRkZEwJQtpAQcjOiIw1DR2O68UWVKbjom5oqBnawIhgx7Rhef6B/qnfAj7934DnPwB86F8Cf/zv5EnH+/+JFIUmQdkdQlpN/o0rHM2ZV/bVpBLfen7CF4ZuLsiksZjbLqNU2vM8tE0H600DrbqOQ9t/zdo93DiQ/88PPzcHhcQzIL9UWv6epu6eGnXKGDBbQej2S/J9bs4dQtEIYF5sSa1Lcse7K7Fkgg7QnUMzNkgEAJqTnpJ0+yWguwvc+5ZCV1cOIdUhlNUfpBi44eRHID+n9pL83C+SVry/8ZX4na2/DJx4TfjFoCMn5737uUeBT/4X4KUPA5DJCRUZU66rbX9TIBYbU7c5RYdQIAgNiIzVddHnYvzEy7t4+WYb3/nzf4be5/114JG/tqQOodEjY61pTeqbcygILTFK+KlFymEBThkri2RkLBCEplAs3bXcYCGgUKO826YdxozUNLCyEQJ4+w8DZz4r/JpuyNK6EUql1fSWiebgJ0TXcoK/vaYJfM5dW6M7hKLukcufDHfDnn6PvHzmd4rdTgGHUChoyudv5pQxMVhENh0vs0MoepuBCGVoqOk5BYg+HdMJO4T2LsrLj70LuPSY/Ph3fwDo7UlhaBKFntGx82ZJpdLARHeRyWjsB4Wt8m+1aA6hmLiaIQiZjnQ5tOo6Nldq2LP8Y4jdxY0DuVv8kYoKQod+1Hstp0No6ptpI5VK+4LQ0Qz/jmr9Me+CkH/ybGj5LpWuv9Zr563tlEDgTlIQ6uHkWlwcVOJFrlg11p0+Ky9PPlzo6oc9G82aFjiZBgpCYpAgJJ/Pb3Kflp9vx9e0T9c/C7++9VfjPxNM0coRPLp78tJfU7meF/QmKodQIAhF31uDGOf0BaGBHUIpruuLt9u4Y2sFT17ex88cfiHw2d++dA6hg649VodQq2ZMzmG3QFAQWmLUm6xSvVUEhIJQOXSt+Al1cGCegtLcsZxY8R0QWocPe/bsFmRGY6TIWOAQWsDImHThhXGpz7lrC89eOxitIDsqavT2I7tynpwe88IH4jGmCB3TwdNX9vHSzlGhUmm169kXGbOSU8ayHUKv3mrji//Z+/DU5f3UfLtyz6lJY7Zv0ZeCkNZf2Jj8P1lu2CGkFtrPv09etrblLp/63u2Xcm9rJHr74ccjR8YiHULqcoInDWQ0ggk+/sJyo2mgpgvsLIggFD0REJ6T2iGkjk2tuoGNZg17qkPI6uC67xD65Cu7gVumSrRNG5pIj7io98bZOYRGEITat8p/PEVRIoKaRjqnWJFNkbwmBbXWy+0Z0SbrEPI8DzuHvT6HkOqOnFgHSrCWfG2hqx/2bKw1akH0cmBkbIAYF0TGzGflWPnVE7Fv65rod3cFDqGctWhUEHLd1MjY9nqaIDR9h5BZsFTa0EVQQK24tNvB2153Cl98/wn814++ItfaS+YQ2u+MHxmjQ4iC0FKj3mR1OoQmgpnI9U48yx0h2v2iCMbOm448iDc2JxcZy8JojBgZW1yHkO3E41LHWnV43ojPg6RQcOK1wMad8uOv/afyd3vh0dQf/Y6f+VN8/b/5I3zNj38QntWW0ytySDrc1C646civqxGsupb9nvFHF3ZwZa+LncNeemQs4RDqRXq3ZIfQ4FLpoEMICBfdJ14LPOLvCm7dIy93zktRKEMwG4neIdDYkB+PGhlzrPDkPBCEqnfCPe/sJ0Y6CyFwYrWBm4tSKu24obslwyHUDgQhHRsrBm6b8nnpmh3sHPbwpjs3Ybse/vTFGRcSz4DDno3VevroYiV2T71DaBRByKjL96xBkTHPA64lipJvnC/HablzAVg709f3Mm8ox1ejpueKEupYeZR3TA8iY5MRkI9MB13LDVwripVJR8aG/Fse+gW/qsKgWKn0YEGo5pmpG5xamsNoGIfQwWXg8ifllDGRjIzJ111sXTqDUumwQ2hwqXR0k22vY+Gga+POYy2880vuxaXdDt73zPWlcgi5rodD08YGS6XHhoLQEqPeJJUzSJ3wURAqh17gEJIHD3UAnJh1N0LX6p8ypmJLR8ohtP2AjHZNE70xYmRM/i67C1jsZiXiUmPt2CV3FzfOAec+B7jzC4DP+vNyh0w5ZBJc2evK8lPHlg4BddDPoJtwCKn/g3pea1GHUMZi+RORaJyRFhlLOITUxLGGoUt78wABsGtFImOA7KxqbABv+J+AN/w5QGjAW/+u/N7Vx4GfeivwRz+We5tD0TsAVk/Kj8caO++fLEyhZ4KMRrJDCJCj5xdmypjjBrukIupKi6Dek1bqOrZaddzsydfsUfsQluPhKx46BQB44caIUxIXmKOendofBITvbVOfMjZKqTQge1cGCUKf+m/Af/gS4NYL8vOjHeAnv0h21Y3LzeekaD/nmBGHUF6HkDpW5oouSiCYkCC04zv4sgShiZ3Q3nh2qHJw6RAyIg6hfEFoUKl0x6vjyPP/zymPQ09zGBV1CB33e4de+hBc1ws2zU9tNGFoAndsyduJdwjNThAa5BBKDuq4eFtuYt15bAVve90pnNts4r8/dnGpHEKHpg3PCzdyRmGFghAACkJLjVq7JCNjLJUuh8BhUVMOoSmM//TppAhCsfGjN87PJr9v1EcShBbZIWQlImOtxhhOsaRzZP0s8Of+I/BXflW6TE6/Qf5tU+haDk6tN7AC//c/oENICZfKxaMm6fRPGcsWkT/xym181cOn8Hl3b+GuY/33l3QIRV11NaNYh5ADDR783++JB4D//ePAl/9/5e/ibz0JfO5fkTuYj/2c7BM6uJJ7m0NhHoYuu1JKpekQmleSHUKALEa9sSCCkOl4oSDkZTmE5POuVTdwrFXDja58XR0cSlfda06tQRPAbrt6guWR6QSbOknUe+MgR2PpjFIqDUhXxSBBSAk/t16Ul4fX5QCDoxvD3Vca+5eBzTvGv50JEziEDA2eJ2NZaai1Xu7aLhCEJvPaUcK0ijEpWjX5Op/IRqTnSYfQEGvJw66N1YYerIcbxiCHUP4m9c2jHm5jXX6S8jhSO4iKOoSO3yc3azq7cL3QFf21bziDR//2l+OcEoSSDiHNALTpnT4P0yEUdTFevC3//3cea8HQNbzpri28fPNoqRxCB/5Gzrhj56exkT/vUBBaYtSOhx5EP+QHuXldUhgzUcqrDszT6F/omOF0KIWha2gYGuyjXeDw6mxGvhrNMGM9BNYCTxmzEpGxmDA3LEmhYOMc0FgL7drbD8p+hpTXcM92cWaziQbUWNR8h1ByzHLgEEpMGTMyOoR22yZeuHGEN99zDL/yPV+Mf/ytb+y7jloMBpGxSO9WsQ4hB4CAK/yD/cY5YO1U6LTZOCddcNsPyOc8EFrBy6B3IHfbhV5Oh1BQKk1BaN7Y78oTuei0ktPrTVzbXxBByHaCxy4KRMaOteq41vEdQoeyPP30egPHWnXcai9Gb1KZHPnOhjTUe+PsImND7n4PEoS6+8ALH5QfKwFdvW+O+j6ncF15m4lpUPOIWneo41SWLhF2CBWJjE1YEEp0CIWRsQkcUw6vy02WIQShI1NGL5XbbqU+QBASAnnLgFtHJm552YKQpqG//6moQ6i5CTTWgd4BHM+LuKIF7tteDaZ69QlCwwq0Y6ImSA4UhIykQ0i+lu/wN+vObDZxda+7VA4htZEz3pQxlkoDFISWmiAylugQmvqiZklJTmmaeJY7et8pDiFAxsZWDnwL+CwcQnojtNQOgR1MGVs8lb4vMubvMh/1SoiMrZ+Jf779oFzIpOzidi0HZzdX0BT+73+AQygaHwGigpB8Xqu0YWpGH7J8FgA+7+5jMHQttXtDvTZUZMyMLMCT9uY01K6NqyJXWScZ0Wl6pQpCh3LBWGuNIQildAgxMjZ37HdsrDeM4DgJAKc3ZIeQPe0y4RGwHA8rNR2GJqANLJXWcWy1jgPb38Q4khGxUxtNbLVq2K2oIKTE8SThlLFFiYydyC+Vfu69odi0rwSh3fh9jkp7RwreG+fGu50pEAhCvpM1y6lSzCE02Q6hG365/VQjY0E5ePG1ZMd0sFLXg07LpjG4VDrLmQUAN49M3M4RhAxN639dFnEIdXZ9QWgNMA9lZCyxhlH9oLGNK8ccXqAdExWtHzR2vqaJ2GO9dLvji//y8Z7ZaOKgZ+PAEgDE+K/1OeAgJeo9LCs1HV3LhVvx9AwFoSVGOYG0hCBEh1A5hIKQPPDV/VHabcsBXvko8Ovfk7J1UQ4dy0md3rDa0LF56FvAE+M5p4JRH3PK2PyfeCXpi4zVlYU7sePwwR+VvQ15qFLptTMARH8puJracvUzwK+8E7j0CQDy92e7nu8Q8m9joENILiDVSZA66UlOGTP0dEHo4y/fhq4JvOmu7LJJ5WJLOoTqhoa6oQ2cxNb1H6MjlCMoQxBSC0VjRS70ysI8AOprUlwbJzKmFpAaHULzyn7X6ushOLnRhOvJk5J5R70PNWu6LwjlOYRkZKwL6Tbodo7wRdpTuPMj/yeOr9ZxawH+v2Vz1HMyO4RqwZSxRYqM5Yydf/Z/yCmNzS1ZqguEQvq4roF9//YWwiEURsaA7LVxoSljE46MqXL746txh5ASXEaaajqIG8MLQm3TQasuN3wMTQx2CKVNCYtw69DELazD1RvA1t1939c0gb6X5SCHkOdFHEIbQO/AHzufIQglHULDCrRjEkTGCpRKJzuE7jy2EmzWndmUa8JrBz1/TbP4DqGDwNk7XmQMmE7/6zxDQWiJSZZKBw6hiqugZZGc0gRIpbnds4Enfh14/JeBvVdLv1/LP/lPcwhtrtSgd/yF4PqUJ4wBfmRs+JMJy1lsh1C0UHm1nuIQ8jzgoz8JPPFr+Tfm+j/zyHcCX/OP+neilBPmY++SHRDPvAcA0PUXLCfXG2gVdghJUSJwCGmJyJj/vpHmEHJcD+/+9CW8+e5jgQCWhnpt9AKHUPiaqRWcMgYATuAQyth1ft03A1/4vcDD31CeQ8jzZGSssT7e4ika39HpEJpX0kbXnvb7Oq7tz3/XgmnL6GrTENCQLggdBR1CslS6B/m66nWO8Pbap1H75M9je6WqHUJ24GpIEjiEZjF2fpS+ktYJKWCbGSL27iuyg23zzohDSEXGxnyuqwjaIjmEgshYhkPIUg6hApGx5KTQktg57OFYq9YXGzJ0DbomJrOZ9sIH5TF3iL9l27TR8qf1ve11p/Hme47lXj+1AyjCrSMTv2x/FXpf+Q9TXY+6QL+zY5BDyOrIv1NzE6ivwesdwPXQ53JOFYRsc6qF0sAQHUKGiK2pLt7u4M5j4bTZs5tyTXhlryvX6iNs3s4b+yUKQlUvlqYgtMSoN9mkQ4hTxsrBjIzQVqw2jHDsOxBeloiK36TtvJxca8DpyT4I1FZLv++B6COWSruL3SFUj0XGUkqlj25IS/6gok8lFNz1BcCX/s3+76+fk3/X878nP/efX+o50arrONHwf4cFHULqYBg4hOz4lDEjZQfvfU9fw6u3Onjnl9ybex9qwkg3xSFU0wuUSqvImNDlRLG1U+lX3DgLfP2PSEdVWYKQ3ZNiTmPNj4yN6hCKnJzTITS3pDmETm/I19D1BegRshwXdUNDS+0ipwhCnUhM9FirDg8aXK0Os3uE4zX53nO2YVXUIZQ3ZcwvlZ722snujXby6Y/qRicjNmb7PSLrZyvuEFKTNpVDKP166vhVzCE0qSljZl9cTNEwtPI308w28Nz7gIe/cahptR3LCdamP/Udb8a3fE5+ubiWNiUsws0jE5/QXo/ml35v6vdTx9YPcgip57rqEDLlmrkvMpaI0QOYSWRMdQgZWgGHkN3vEFKc9R1CV1SP0FKVSo8zZcx39VMQIsuK68UdQoaWn5Mmw5GMjAH++EJrsoKQOklOlkoD0iHi9Y7kCewUpyAEGI0RI2PyOdldhshYWqm0eh4MEoTU7mLKyZz8ugZsR8b53ogLQg1Dw3bDf30X7BDqi4wlpoxp/oIrmvP/uY+8hHObTXztG/JdaEmHULR3q1CpdDQytnY6dYcwRnNTxrycEgSXnpy8hMbGeA4hJ6VDaEK7yGR09jt2Xw/BqQ3fIXQw/wtn0xemWzX/dZryWom+5o+vyv+rrTdh99o4Zsjn5Jl6F7ttK7fXYxk56jnZpdKaKpWegUNoHEEo63hj9+SxeuPsBBxCV33xfgYO5SEJI2PytZK2NvY8L9j8yxWEtMl2CO0c9nBiLf25IAWhkp+bz79fioOve0fhH7EcF5bjBWugIgx2CPVwfLWe2lEIZIyt1zT5usk6ZscEoTWgK4/1SQNOI7VDqDf1Umm16Zj1O1DUdQ2Wv7lqOy72u3ZMRFTHs6uBQ2gZImPlTBkDgHay5qFiUBBaYpKl0kpcZmSsHKJuB0WrrsPt7AP7l+QXJuEQMuX9pkXGTq03AasNr9bq+95UMBrjRcYWMMNrJyJjqlQ6VRA6KugQytuBUt1Qx18D3HoBcKxgMdis6Tje8O93gEOoMyAyponQIQSE7ydX97r4kxdu4i994d2x/3caqqwzcAhFXHXDlEo7olZsx7m5JS97+4OvOwjTF4TqayOXSnue50fG/L9nUDxa7YXHPCIdQvFF5fZaA0JgISaNWbYst19Vbx2pDiEbQkhHxFZLnlzaWgOu2cGGLt+3TxodmI6Lowrtljquh47lBCcGScLI2Aw6hEbpK0kKQtefkZPFFLZ/Qrh+TrpXHStSKj3iSWL7ltygOLgMrJ4K47FzjO2EGxRASvQIcXfIrKeMZTuE9PLd1c+8Rx5P7/nSwj+SHFRRBLnhlP39W0cWjq9mvwZSHUKAdAkNdAhtxRxChSJjjjWTUunopmMW0Rh+24o7wAH5PNleqy+VQ2i/Y6FuaIEbfSiuPQmY7ckWsy8QFISWGKWaq/c4IQR0TVS+Sb0serYDQxOxIrpW3cBm5xX/MxE4OMqk65+wpwlCJ9cbWEEX7qwEIX1Eh5AbFwwWBc/zYCbGztf9TH9s8aieB9ZRvrCgOoS0nAXHnY/Ina0v/BvSaXL75YhDSMexun8bAxxCR6aDmi6CRY866TGDyJi8XhA19d9P/uiCnHD21a8bvAOsDtKhQyh8nNLePKBDyD9AHzROyc6LgXfoF1yXERtT5dTNDaA+fGTsn//eM3jHv/swHMeKRMboEJpX9jpWn0Oopms4sdrA9QXoELIcFzVDoKXOw1M7hOR0SiEEtvx4nCnqcMwO1nW/tNaQ/9fbFYqNqW6lQWPnralPGRtxxHUgCN2Sgy1++qtl71xwu75DaP0MAA84vBa+3416kvihfwH89NuA2y9nl//PGckpY2nRpW5kk2qWpdI7hzmRsdoEImMvfQR4zVcOJX50IqX1RdG19N/7Zy7u4fv+6ydw8XYbJ1azXXJaliC0shnGF5NEBaH6euAGLlQqrV47U0S+tw8+XVcDQBzXi8WDo5zeaMpOvCVxCO13bWyM4g6yusC7vhL4+M8HjjZGxsjSot4jo29yuhB0CJXEbsfCVit+sGzVdZzqviQ/uesLJhMZ89+00qaMnVxvoIUeLH1WDqH6SGPnF7VUWr2W6pHdGyEEWnU9XiodfR7kjQMOImM5ux2f/13A//EZ4I43+7f9bDAFpVnTsFUr1iHU8U8OFcmx83qie2zn0ETHdPDh53awvVbHQ6fXc28fiETG/Ns0o5Exo3iH0K8++C+Ab/xXA++vVEHo4Kq8XD8z0pSx564f4snL+7h061B2IAGR4lE6hOYJ1/Vw2LP7OoQAOXr++sH8O4SUMN0yVGSsf5Hcs51ApDV0DetNA0dODTWvhw1Nvvcc0+Tz/HaFRs8fDogdKJfk9B1CvdHcCKvb8vJoRzp/zMP4e6LVkccHVRa8fyXSITSiIHRwFejtAS99OLv8f87oi4ylCBMxh1CviCBU/uumazk47Nk4uZ7XIVSyWNm5NfTfsR0prS9KVmTsfc9cw+985gqeuXrQN1ktSlrHIQDgNV8lY29pAmciMiasI2hwMzuEzOi61LGmXiptOt7AQmkgIlw7bl9HpOLsZnOpHEIH3f6NnEL09uX769H1QDSjIESWluSUMUDZKxfLhTGv3Do0+w5Uq3UDp8xXAKEDD36tHP2aJwCMgDpJTo+MNdBCF6bIFwMmhtGUb7JDsqhj59UJQjI61arr8YPLznkZPQLye4SKRMY0XS5kVJfQzvnAgdOs6dgwfLFhkEOoZ8d28gJBSI2dT0TG/uK7Porv+Jk/xUeeu4kvfe12UDqdh8y9j94hpHZnTdSL7cqVKgipctRzI5VKq/+b2evhdtf/f6qTdE4ZmysOejY8D6k7jafWGwsxZUz1TLTUYSFFVO5Zbmwq5vHVOnYtHU2YWBXy/7gplCBUnefoYU85hNLfd4MJrdPuEBrVjdDclD0+7Zvh8SYqQgcOId/Jc3A50iE0omsgeM/1Fs8h5L8m0nSFmEMoL9I+wQmSaupfcgNS0TD0ctdOji1FRHU8LciokbE0h9Dl3fB5mCcIZXYQPfwO+X948Q/7v6fikapUGsAqun3d2fXUDqHZTBmrFxCE6jFByK8EqMWPaWc2m7i611kqh9BI/UGqI7J3mP53riAUhJaY5JQxwFfTq/2cL41bbRPHWvEDw0pdxx32q8Dx+4DTb5RfLNklpBYozbQpY+sNtEQPHZEvBkwMvTHilDHVIbRYT051AEnu3qzWjSCGAPMI2HtVOsaAfEFILdrzImOK5iawdgbYuRDECBuGFghCXeTfRttygr4jQJ70CBHpEAq6x+TlK7faeOzl29g57OHLXrs9+PFBuqWiu5dmpIi9buR3CKmCSmCIIvxAENotdv08VDnq6smRSqVN28VKTYcOBz3Pf35wythcst+RJ1zpDqHmQnQImbaaMuZ/IcUhZPqTyBRbrToO3RqasNDwpCC0hiMA1YqMqWLStYwTCyGEnIo4bXf1qG4ETQdWjsUFISVUeF7YIVSmQygqwq+fGe02powdOISyB67EHUJ5HUKTdQgB6ZuAwOhTxv7w/A28eitlo0N18A0pCHVSemsGkSXoXNrt4M5jK1ip6bjnRLbjXcuqwbjvrTIO9vRv938vEIQ2go26VXSKRcacESf/jUFycEkWtUjXWSfTIbSC220Ljt5YGofQSBPGAkHoIHAILlpCoWwoCC0xySljgMrbLtZJ97xy68jsm/rQquu4270IbD8o/wGTE4SMdEFoFV20velmnAOMulxQ/up3Aud/v/CPWYFDaLHekNXjricO1q2GHvYN3HxOXt71RfKyiCBUtJBz+wHgxrOBkNas6VjT5cL/thk+P567foCXbx7FfrRj9peo1rRQvAlKpSP/t9W6DiGAL3ugmCAExHcvk6XSZs6uZnRndnhBqASH0P4VOSlHN0YqlTZtF8dX6zDgwnJVIRMdQvPIftcXhFIWlqc2mrh51Ju+O2QIHNeD60lhumkk3GgRelZ8p/lYq4aeV0NLs6Db8sSw5cqC1UpFxnr5HUKAnNI6/SljY5x8tk74DmXlEPLfcxwLgCcdQq0T8vb3L5XjEFIu2AWJjJlBh1D2lDF1HNJEwQ6hCfTDqQ2frOLcRk0baTPt//jlT+LnPvJSyh3uyssRHULDCEJZHUCXd7t4011b+MgPfhW+44vuyfx5XWRExowG8ODbgWd/t9/61d2TpdNGI3QIiW6/IKSnCUKWXOdOESvRU5mF6hmKRsaSbq0zGzI90PFqS+EQOhjVIeQXicM8TBf+KggFoSUmOWUMyMnbkqG5ddTvEFqtAXd5V6QYpMauDho1PiRBZCzloNuqG1gVPRzMTBBqSlHjiV8DXvhg4R8Lxs4vmEMoMzJWM8JS6cPr8vLsZ8vLvAihEgqyxs4nWT8LtHdiC8Y13Ybtabgd2fz5/l/6FH74PU/FfvSoZ6OVsBMbuugfOx8RlH/4W9+IX/0bX4Kzm8UdaM2aFiyqleBX9yNjrpct9nRmLQgdXA4jFapDaIj3TtNxcWKtDl04MAOHkCqVpkNontjvyL9HcsoYIDuEPE92aM0rVsSpuFbzX68pLkPTcYMCXQA41qqjizo2DBvClIJQwz6EJqrlEBrUIQTI90Zr2h1C9ohTxgC5/ji8HnEI+e85ygFkNOXEka175LRK5QoZxyH0um8GvuxvAw99/Wi3MWWKRMbU8XCrVY8dk/qY4JQxtS5qZBQLjxoZ69lusHaI32GkY2cIOhkxpTz0lLHxnudJh9DWitxUyRFDcqeUnflsKYomRc7uXvh/8wWhdXT6powJIVDXNfSid2BP3yFk2sN1CJlRQajW3yEEAEdubSkcQvspwyAKETiE9vu6LqsKBaElRr3JRiNjmY38ZCgc18Nu2+ybfnDGvYa6cOCceCAs9R11xy0DtTjIsg+vaT3sO9MdixkQPVAOMfp7UaeMWRmRsZhDSC2ujt0LQMgFShZBqXTBv19DTsiIlkq3hIUu6tj1d/gd18NzNw5xM3GC10lExgAVKVXvG+HXFPefXMOb7zlW7LGphxhZrJr++FRdE7ECxDS6Zvj1wkX49TUZ8yrLIaQiFbUVwHOHigMoh1ANDnpO4iSdglAp/JPfeQo/+nvPjH07uQ6hdfk+Ps89QmF0VaBVU6XS/ccH0046hKQgtKpbcgIiAK23h82VWsU6hOT/Nc8hVNO14Dg1NcbpK1k/I6csJR1CKtKt1ifbDwKXPiHf34DxHEJrp4C3/RDQOj7abUwZdVxSm2tpm6VqM+NYq4ajvMiYem+fQGQs2hGYxqiRMdfzYKWtuYIJm5N3CKWNjb95ZMK0XZzbGrzxpGvITj00fMeaOvlXpAhCq6LTVyoNyM2r/rHzM3AIFZgypiJjluMFz9vk3+K0LwgdOsbIDqE/PH8DX/2vPjgXJcwjO4R6h8ElHUISCkJLjDrPir7JGRSESmGvY8H1gGMJQeis+TIAoLv5GnlGbQw/nWgQeVPGAGAFPeza0z1gBUR3M9UbbgEWdcpY9EQsSqseFYR25eXK8bDXIQu1i1t0skxjDegdxmKEK8JED+EJ3aXbHZi2G+yCK9opkbFoFls5C6OCstpdGoaGEXUIhSek6neWVeQX3Y1N7QhIQ9OAxsYEHEJ+h8EQr2XTcbHaMGDARc9TU8YYGSuTP3nhJj50/sbYt6M6hDYzpowBmOtJY1YkirnqP8VspJRK207QlwDIk9yuV8e6dxgKAp1dHFut41aFImODOoQAuXaayZSxUR1C62dlD9qRvwGh3nOiDiFAxo5VgX5zczSHkNWVj3VIAWHWqJiVOg6mlRur6xxfreefAE+yQygyjCGN+ohTxlw3Y0NGHT9Xtoa6vZEjY4lf+6XbUqgoIggZmhac0/zMh1/Ev3vfhfCbdX8SqplYi0YFIT/muIYO0kw4fV2HM+oQStYSpJE+ZSxRKu1HxvZtY2SH0O8/eRXP3zjCc9eLr/EngeW46FjOiB1C/oZ174AOIR8KQktMcqcfkCd5HDtfjJ7twMuIiNzy3RbJ6Qcne68AAI7W75dfSJbRXn0C+OR/AZ5778iPq5O3W+R5aHhd3LIMXNnrTL/zICYIHWRfL8GiOoTUCUKfQ6huhAWUUft160QoCB3eAK7FY1xhqXTBHY/GOuD0YPbkyWqjpqEB6RBSHSDP78iD9mFid7Pds/us3V/x0MngYy0xZUzXBLbXhj85adbiDiHV16B2ZVJ3KBEXhIZ6z1rZGl8QMtvyNjYikTFgqN1z03bR0DUYwkG3zyFEQagMjnoObpQg1Kid/9UUh8jpjSk5hK58euSJlNFye1Uq3XP7l3eqeFqxtSodQk0r8nrp7uFYK3QYVgH13rhaz3cIzSQyNsrYeUC6G50esOOfIGc5hE4+FP7M2hn5HjdsrcCIEaNZ07Ud1HQBw18kp208qEjVsVYdbSt7TTjJyFghh9AIcXvH89Kf0yNHxoafMqaL/t+7mjB2bmvwBpQmBNSPv+fxy/iNT14Kv+m7f/rc6t29UOzyr7OGbl9kDEB/1+GMpowNFRmzI1PGEn+L1YaBjaaBPUuX7w8juB4fv7gLAHhhZ7aCkNrkTIt6DyTaIaRTEAIoCC01aaXSafZM0o/neXjLj34A//R/PJ36/SxB6HjnJVz3tnAoVuUXkmW0v/ZdwLu/D/gv3wYcjdYt1LMcCJGxW2R1oMHDlbaOL/2R9+Ndf/TCSPcxMpt3A7VV4MQD/bsyOahFiWm72QuuOSQzMlbXwxG13T05fa3WjAtCf/ijwH/99vgNukN2CPk7YG5XLniaho4Geuh64QndCzdkFKTPIWQ5WE1Exr7pTWEZqBKElFPo9Hqjr3SxCFE7e892Ig4htZuV/vcOOpiQvnObSXNzfEHo4Iq8DBxC/uvZPEq/fgrq5FuHi56rBCF2CJXJYc/GzSNz7GOaElTqKe+pJ1br0ARwfZKCkOcBP/cNwJ/+1Eg/btny/1/XQ4dQL2Vt20sIQvdvr8IUdQhEfn/dPRxr1XD7qDqi5WHXRquu576/GbqYQWSsJ48do6Deu6494d9WskPIv101/AIA1k8D8IZ3uYxYQjxrepaLhhH+3dPeRqIOIcf1sk8ahZCC/yQ6hOwwEp6GjGUP7652XC/doTuiIJTlSskj7Zzkki8I3bmVPV1MoToKPc/DrSMTV///7L13mGXZXR26Tj43Vq7qHKYnjyZoNCONJFBOoBESksGAQQRjE/yMgWcyxglsg8E8kBHJoEAWIJA0kiUhaZRHYUaTZzrnrqquXDeefN4fe++T4723qrtnan1ff1Vddevec+85Z+/fXnut9Wtpfg3pWcYitWh/I2YZqxe1jA2T6zUgDLtYhhCrrSwnvcsYQDqNrbGmIyUVgZpp4+gC2ew9s1K8HtoKMKv3cF3GOl5W1I5lbAfPWSSFSu8QQsXQ1i0stXX88RfO4HMJloQ0QmiscwannD2+XUiKWMY2LxBSABi4NXbftKGKQuJuBluwdlwFjgt88URGXs1W4MY3AD97muw6llEIBYqSa4mlT7eMiejp9Brob/i7UdUpXwXQWwG6S+HdWFZMFraMsR0wssvB8xwEW4fByZ5l7PQyVQgZVmgnrmfYsd2jFx/ysx8EPkwI7RrALgaQoNZNaskhCqEoIZSSITSoQkgd8zMQBkWLWijYosoLqy6ei2XQXT0JFjSLXh/eLvIOITQKdHULtuMO3RHL9JR+8TFVFHhM1ZWtbT2vtwiBPiCR6Y1DIu9lCHmqtODjLCe0kfCyI1P43m8KEALqOKBtoiKLofvvuY6ObmXmBwFEKZk2Vm0Zhulo5LWUp4qJ1AyhG/y/qdN28WVzhDwCYbz0YV5JaJYNVeK9zY/ELmNMIURrvWzbmLSlbeeVhM6y5OflLWOsFkhUkWubJIuPdY0riJ5pkU2QEhtHfEKo9KWNPmqyUEj5MVmTYTkuWn0La10DPcNGi21+efVRpBbtrfl1OMsQSmg7D1BCyI4qhLY+o/PxCxtYahOyxrTKKYRM20HPJOq3pL/bNaZiVac/L0kIPbPQ8uqxs1eYEGoXaAaQCkYSGm3AcQbO4XouYYcQeg7DTgiVFrgdQqgIWIcVngP+wz8+Fft9IiHkuqh3TuOku8e3uwQtYxot+qepRLtE6HIQmumkS3JpMOhLbtyP77xnHx67sLH9Rayk0rDj4gqh4IL/WiKE0ixjNVmAYTvksw/61auTvkJIb5PiIlh8e5axEhlC9Lm87kFmHzaveItkphByXaBLVTeW7cCwnJhFguc53H1gnHzPOAxaLJfpLBbETEPBEl1Ml8oQCoRKp4ZGJmGUCiG2qPIIoY3CTxFUCPXtqELo+aO+2Co4jusR78PaxtjOoMQnl0RzTcUrzrcEXieowRaTbIyXBQ4VgYxJfSv+XqIKIY7joFZq/gOaewghJPHZHZWeY2jrVmZ+EHClLGMjUAgxxDKE6POqYz4R1JgLP6YorlHLGFMIsbkuSYnKGjZM0o6yXSODzBe2RiHEaiIlTSEklSeE2Pog1TKmjhHVUwn0E3IJ85C0ST2/0cee8UrypmcEzMa+2NI8gmBxk16/SRlClgHomz4hJCpweQl1Tkt8uyHliOOQuXvQe7IEfvj9D+PdD54CQDOExPzPQmSh0paDvmGnNp7ZPaZiWaPPV5L8ffzCBgDghtn6VaMQGqrLGACY3bgS7HmIHULoOQy2A7BjGSsPpq6499Akzq/1YnkKa12yAAkRQt1liEYLp9w9fjcKqeorhNgic4buyJYgTIIgCqGUW5cqhO6/53p88w0z6Bk2nl0YjHgaCnKdMO8FESxKriWWPs0yxgi7nmFHCCFqGXNd//wHyQvHIjtzKQvTGOjuFme2/XwBS4MtqNhgCqGVjrfzxbIyeikdKADgr/71ffjcz7zKK8aGVQjNNlTP1qMHFEJKTmcHtiCtyUK5MWsrLGMDEEIkCBLg4aBn0/O5hTkTzzf0AoTFsIQQyWjgQpsnQcw11FyF0GMXNvCfP/L0YJZXphq0hiOEJIFHhd7SfRv424cv4JNPL3qP0y0nrjIQA0QvzZ1pCNbzihDqaBYaeQohgdv+TL5h8krqc+H/O1HLWGA8ZyqhYRVCJUOIrzQ0y4Yi8QHLWEKodCmFkLylXcbSFUJkjixzfbL3mmoZG4Dc6+p2Zg5XEkiodJQQ0goFSgPAVJ2clxNLfr25yOy9SRlCfTrWBjrhOVKNhkonK4Q8ss0pqeAeAl3d8oit0hlCNskQSrPuzTVVrGiDKYSeuLiJ2YaClx6ZwumV7hWNeGj1h1AIBdcnNFj6WtqM3grsEELXAM6v9vBv/vIbOLVcjkBIsoyJwg4hVARMXfGSw2TSOBFJ01/rmqgrIhS7D/zBNwG/eRPw7vsAAKfcPX7RIAcyhJgNhXn2S1iqguibNtS0XRiDkk9yHfccIu3Bv352faDXGQq0HXrRcMqQZWyAcMQrArOPWz/5PbiVOxuzmtQlF++X/jvMM1+KE0K2QT4bdv6D5IVtFs8PArwdMM7o+PkCZh+OqGK9Z6CjW7jc0nHDLFESsRyhrPBHRRRwcMpXDbDxY5AOYwAw21RgO8TfbwQWpHmWMY8QUsSShND48IRQa4GQmmqTPicjhBKed/k48Dt3kjHgN28C/uQNcEwDpu1Cpaekz9YQOwqhkSHYAnrYDmB5BfdsAYXQhx+bx3u+dDZV8ZYJTyE02PsIEUIiUwhx+MPPn8Zffu289zjDsuPZc1LgvqaKuDG+f1W0FN4udAoohESe3/6GHLYxuGVMlIGa3yTAVwgxy1hA5cBqknpJhdDFh4H33k+6mQHXoEKI2O8zLWO0HhmnHQh7eYTQFoztem6GUPlQXCa6Te0yNsC57JtWqUBpgGxYR0Ol25qJ8Wox0mWqRq7jE5f9Gn1xk9bcSRlCbKxlCiEAttxIbTv/CvOL+JHl/04fSMm+bcgQsmwXq3Tj2SyZIWTabmIkAMPuMRV9l44rJcnfZxdaeMHeMRyerqGtkQy/K4X2UAqhTuj7HYXQDiF01ePYYhtv//0v46NPLOCD37hY6m/ZDgAfVAhxO13GioApgl58mEwawckGIAqhiZoEXH4aWHwS2HMXcPP9aL3wR/E15+ZAhlDVJ2mY6oAVXyVCl4PQzXQpqPecchW7xyrYN1HBI+cG61wzFJQ62ZG0ii1wTNvxZNvXjEJo4wImlr6Ku/hTscl6HG28QngS/OkHw8VVhZB00Db8HYqoQqioXQzwCh7B6Pi7h5YGiEQhxDzed+4bB0CsEUCgq1KB3bxhFUIzdda2W0sJlU7JEKL3UF0tSwiNEevkMCqc7nJ4MZVFCM0/CqyfBQ69HNh7N3Dhq7DOfon8mUDeQ9/LEJIBcIXvix2kI9g1b3iFUHbBzVRuWfbbSxtknB9ol3FIyxh7TUngoTLLmM1hs2+GjtmwnXhwdkghtBcAMMb1oFtOYtel5yI6Wn6GkCRsc4aQ6w5nGQPCtjEnahkLjOf3/Rjwlt8FZLoRUHSRePaLwNkvAOcfIv9XmoMfawl88BsX8fGnFoZ+HqZY5bNCpSmJWqUNGDItY7y4NaHStJGInDJGDUII+ZaxJEJoY6A8qN6glrHIxqFmOslNUxIw3YgrhBaYZUyqEsV1cPPVI4SmvR85Ug0N9BMtaneZj+Gl2ucAx/YVnNvQZcx0HKx2yOsZRRVC1FZm2Q60jHXCrjEVGuh7KKkQ6ugWxisSDk+TseJK2saGyxAKK4TknQyhHULoasd/+vDTAFwcmqri4ZJKDzbOP5dDpR3H3ZL3s0Y7rNy2p4mqLOD45bCaZ61nYrKmACvHyA/e9D+Ab/td6K/5L9Ah+x2SgqHSTCE0dT35OmCGUN+0U9uPeq9FC7t7Dk7gkXNXQiFEC8OCKijTdj1yQrtWFEKU0KlAj03WdY4WDq2FMCEUJBaSFEKOBQglJjcqiRasbkghxEkVrPcMT3J84y7yOKYQ6pVoDzvXVMFzwI1zjeLHFcBskyxoltt6Yqi0YSXfv0whVFfE8qHSQKkA6Bh6q6EdREgVUgQmEUKswHzzbwHv+BOywH72AXIodHHes0jnQlLV10t1K9tBMrzQdgxPCOk5oZ1zTRWuC6x00l+HdcYZaJeRXUMDW8ZolzGRhyqQ1+9bhBBix+O61LKZpRCiBEIT5PrUnicFMgmVzibiRZ73MuO2BY4FwB1cIQT4GWhAoMtYkkLoBuBF3+9fC0UXiey6vfh1QjBJg20alEFXt/Af/vEp/PEXzgz9XJqnECL/T7SMUXKC1SdXwjKmmYSUSsvUUWg9WGZBy+pmM2n+HVAh1MvIrUkDz3Gxzue6lVHjRsCyncIKIXr9chxRURs5CiGpjhq0RMtYFX0IoFmQ9vYQQrbjwnWB5Q5TCDmQExoeRBG2jKWTc7vHKj4hVFIhpJkOVFnAddNkM/LM8pWrZfwuYwO2nWfXgNGGIgo7CqErfQA7SMej59fx0OlV/Ogrj+DVN8/i8YvlAoIZ6x6sc4ns+blz0f/B50/hW3/nCyN/3o2eAZ4DxioSrp+t42TMMqZjsioBK8fJDt74AQB+Jku4yxgdcNsLZNelPkv+P2iGUNakyxaatE32rXuauNzSYxlIWw7WnaJgjpDlOKjRHdprxserBwmhiGWMIwUJ30khhPobyRlCpS1j5HMWrS7UgEKIlyvY7JtYoF76IzPkemhHCKEiu3m37G7i0V95w+CEUIMsEpbaeihUmoUkZlnGZIGHLPDl284DA3fxAxAnhDguPZuotwpwAqCMEYvokddAOPExAC5knhy37gj+dS3XBlYH7sBHSCGUQdQUQV7BPUdJzawcoUvrZJwfTiE0oGXMYqHSPFR6S2/oJDieFbkWXWTEVAYJCqEGJYSeL7axtmbmLipEgYO5nZtpjLgZZvHJFEKVyWyFEAO7FoouEln2VefyttnFPvrEArqGnUnOFgVTCAkZljFGTrC5sptLCG2NZSyLIPEUQiU205j6b6SWsYEUQvHPvYxCSBR4TFQlT6myq6n6GUIAUVEnKoSChFCNtJ1PeMma2/f/zh7BPVkA7Jy0NQu6ZRfuMlbUMrZrTIXuUgJ8gLbzqihg70QFPAdcWO/l/9EWoa1ZqEgCxAKfTQx6G2hQwpxZxrY7I+4qww4hdBXjDz53CmMVCd/14gO45+AkNNPBM/PFd73ZgB+0jD3XMoSeurSJc2ujZ6jXewbGqzJ4nsP1s/WYQmi9yxRCJ4jihycDLyNqQpYxL0NogezYMRnrgItCzcwoDjzLGCEA2CL++OVtXoAGul8VgWW7qCnld7muKCihU+HiCqEqRwoHZfMMKcSZ/JoVWd0lv0APEheOWdIyRs6vZHX8a8LUIMgVuC5w8nIbHAdP3tvRyWsyBVta6GAUY5XBQxRnGr5CiBTgBTOEDNoSmOfK7cyzz3qYHKHeKlCbDv8sixCqTvpB4LfcD6E9j9u5M1B4uhiH4JFxkAM20h0MDGZ7VCUey0N2ADNtB1LGAsQjNVvJr9MzLK8RgT5IGHN3hXwdNlRa5KBw5PvFNvl8DHrvpHYqCmUIEQKh5lBC6HkQLO26LrqGXcAyxm9vqLSnRhjCMsYUQo1d6V3GgshTCG2cJxZZht6K//02EUJ/8/AFAMOrAoGAQigjVFozCWnUoDklLLckEVvUZYwdZxqYXXwgy1jSBvHACqH0IOM0RC1jRMlYXCEEAFN1xVMR37y74SuEAD/P0jvIeKi0LdVRT7GMVUKEEAuV3lpCKKiIXuuSPMKs+YnB6zJmO5nkXFMV4WaRv5ceATYuJP6tZtqoyCSIfawiec1LrgQ6mjWYOgighNAu73tF5K+d/NItwg4hdJXCcVx85ugSvv2Fe1FXRLzoIMkeKWP/SQqVFnhu+1unbiEWNzVo5uizDtZ7fqjdjXMNLLV1bAYGvrWugYmqBCwf87uGgXRMqEhCsmWsPU927JiMdcBQac20U8MF/VDpKgDgJmoVOra4zZ3GvO4OxYgo03a8gvzaUwgZcUIIpCBRuzT3y8sQGidfNy/5Dw4phKxyHSx4AZCqkKyef01YfYgKOf9HF9uYqikYp7LqdiRUuuxu3iBQJQENVfQtY2LBDCHTRlUWIZa1uQ6rEHJdn+SJPm8iIbQSVhPd+CYAwMv5p7zFuQ3eV7TItR3L2AjAsjwOTtZG0mUsLZ8DCCiEUl6HqYOAQRVCdJEyoN3ECIRKCyD39mKHzFcGJdiNgIooBLYwEGSiJAFQBZlHtOcBIaSZDmzHLRAqXZKYHhZegO0Qi889dxOCfOJwOYVQGiH04H8H3v82f2HM1BbAthBCF9d7eOTcOuaaCnqGHQqWHwRehhAlApK4Ed0iZAyrBzMXwIK0NV3GAlbrJOR17EyCk2YZswxSsw6QIdTPUKWkgY+ESluOC8dFYYUQAEzRDnBNVcS+iYqfIQRQi3agDu2uEDVvoM6yxBpqnJYYKl1xaU3dWw3YLbdYIRQ4jytto3iGUKCm6pnp5BzHcZBUUiPG8gxNDXjfW4HP/Y/4cdkOLMf1yMnxqoyN/hUkhIz8ZgCJcF1Sv9MNEBg7CiFgBIQQx3ECx3GPchz3AP3/JMdx/8Rx3An6dWL4w3z+Ybmjw7RdHKHdgXaNqdg7XvEIoQePLuHE5WxCwU4IlZYE/jmlEGI7AaMmEda7BiboIpp1aHrXZ07g5FIbhuWgb9qYVBxg45wfEk1RlYWwQsgxSQHVWvAHIKU+XNv5gpaxXU0VDVXEsZxrZeSg3a+KqqAsx/UtY9cKS0/fm5pgGVNdcl1yoPda1DK2GQiIj4VKl5zglAYUp0t2CR0bsA3IKjn/xy63MddUPLKNkRLdbSSEAGC2ofih0hFCyEhZZJ1d7WK6ISeGTmYiKwC6CMweWRAFSR72vP2N+ON7a+HHVidh1eZwhJuHIvgKIZbfBKlGQq93MBS6NEPo0HR1aELIsLJDpafqCnguXSF0MUAIDZUhNKBlLET2OJQQogohtgHkPSaqNGCqEKnqqUYUjvztNZPnNgTaVDVZRCGUqKbYKniWsSEUQje8Dvj5c0B1IrvLGAO7FswUQkhvEaL97BfJ/7eZEFqhIbv3HiLE5bD3PVPesFs/TSGkSgL9x2MzawG8RZaxXIWQxEKlixO4bBkQ25Bh2ZaDKITM4UOlGQmtZLzfKKZp44rJmozdY8Qu79ldYwqh+GaPwyuQYSZmCKlOgBDapgyh4Dhzmc45pTKELCeXnGObhrAiCqEznydRD2yTIgCmGGXPSxRCV67LWEez0MgZtxNhaYBrByxjrR2FEEajEPp3AJ4N/P/nAXzadd0bAHya/n8HJcEKzL3j/i7OC/Y2vYX9T3/gMfz2p45nPoeTohB6rnQZsx3Xazc8amn7es8kCiAAd+0fx+4xFf/ni2fwKx962isI9rkLgOvECKGaIvo7VxLdcdPbxCbEPP1yfeBQad1y0jOEzC7Z+aPBxBzH4aa5Bo4vbrdljCmEilvGfIXQNbIrTc9fhTNiHmZGCPk/oMUVC9tupSiEnJIZQgAg16HYPVIU0p1dme7+bPRMzDYUCDyHmiwE2s6Xs4wNi9mGiicvbWKlY2D/BDk2WUjf1dzsmfj62XW88saZ8kH4wxJCCRkD3vNmWcYC0MaO4Hp+3ssQslzBW3juKIRGAzbGHpquoaVZQ6lZ8ixjAs9hqq6kLkAvbgyrEBpdqDQJIwYW2kwh5NDjYgutFIWQXPcWOgpHu+Nd4wqh1QI5M52CnWpEYbsVQiO0p/BS2DLGS57NPQRPIZSSIcTsJUdJaD56q/HNji0Eu8f30Tlk2OwwQvb4Yc1JGw8s0BkAxisy1rPabF8xhdDglrGYKoLNcYOGSg+gEArO7+w9pKrgEzBVJ/fIZE3GriZZMy0EW89H285H5nZbUKDARFJmt0rts+iubBshFBxn2PuIdYdMAKupLIdkCFWzcqcqlBCKkr9HP0K+JtQ6HlknMYWQlE2QbjE6+oAKIbYuqU2TelvvQBaFHYXQMH/Mcdw+AG8G8H8CP34rgPfR798H4G3DvMbzFfMbjBCqej/bO17FwkYfXZ3kFeTlwvih0oEMIZ7bXh/8FmK1o3vk1qgL142erxCaqit46BdeizfcOofVjuENgLvN8+TBEUKoWRH9vBBGCK2fJeQRI4SUxsAZQnqgQInB6JKd3gBu3NXAsctt0uVou1AyQ8h0Apaxa4WlZxlCMGI2DCVGCI2Tr7xASKHNgD87aG2yzXKWMQBQGqi4PaIao5O7Wql5v56jBVJdFQcKlR4FZhoKLqyRMe31t5JQdSkjVPqzx5dgOy5ee8vcEJax7SSEwnlD/eYRohDiyeds72QIjRxM7XZwklzrw4TMFuniMpNBCIUtYwPMRcOGSgcsY8watKGFQ2N9hVBKhpBc9RY6MshzXMuh0g+fXcO9v/ap3LbI7DrKUwiRLmPbmSE0QnuKIAUsY3qyXQzIVwgxK9nRjxLyUtsE9t9HfjaAxagsGFmwb4LUVcN3F7ShSIJnFUqqkYKBzuNVKdsiI8j+5zxC5GcIDaAQSguVZipYZm8vCNtxYVgOqlL5DCEngRAqoxCaqvkKoYkaqZ9abL5VmnGFUCQf0OZlKDATLWOyHcwQuhKEELnnilnGyPEzF0NWfcdU5CHy17GBox8j3yeooTWDnBu2IT2+jRlCXz61EosG6WhW7ridCHY9KA1PQSYL/GD5f88hDKsQ+v8A/CyA4Igy57ruAgDQr7NDvsbzEqyF7Z6AQmjPuIquYePoIrmYz650M+Xp7OYJjnHic8gyFuwkkFu4fuF/AR/7GfL9P/wY8NU/ynz4es/ARC086E/WZKz3fEJoSqOEEGsjT9FQJK8dokfOrJ0mX1nII+t88Mh7gb/5Pv+PFx4H/uCbM4mUzN0io+d3+KK4aa6Bzb7pqam2BSUUQqzFZu2aUwildxkTrciCP7jbpo75ljFeHIllTHX6pGCkk3ul6l8Ds4wQUsSYZaxsi9hBMUuDpQ9NVXFkhhybnJEh9OlnlzBVk3HnvvHYDmIu5Brp+rUdhJDjxC1jADrNI2hyPdS0JQCABd63jO20nR8JurqFquxne3iE2wAwCnRxmW4oqaTTpaBCqCyh7dhAn2YDDmg3mVl+CH8r/yeIsDyFkA1yb/sKIbbQSlMI1TwyWgJVEl7DBfLF9T4cF7EOoVGw+zLfMnaluowNYRljEORA23kt2S4GFFMIcTzpmHr6QfKzAy8hX0sSCINA9xRC5DiHIYFd1yUKIdHPEEpsuBXYgBurSKEsyRgEGZh/DPitW1JDeQcBC7ZOg2cZKzH2eG3ng6q3f/oV4H33k+9LKoT8RhUjsowNqBBSvcYuwfk2EiodVQjxCkTO8fLX/F+YkFxyjTlBQijt/hkRgpaxxRKEENv87+gWXBdQM86FwjYNg+TvpUdIJmLK5pdmhevG8aq8LZax45fb+J4//ioePLYU+nlHt1BXSm6g/uOPA5/5r+R7uU7iLYwOFGknQ2hgQojjuPsBLLmu+8iAf/+vOY57mOO4h5eXlwc9jOcs5jf6aKqi19kAAHaPkUnwkXPE22k5bubuF6tdgqy3yHPb64PfQgQ7CeTaBc59CTj+CfL9sY8BZz+f+tC+YUMzHW+hwTBWJWx4ixJCDZNKT+WwIqdZEdHqRxRCG5Q8qlF+VGkQhcnJTwPPfsSXYl/4GrD4RGoxYdFQt9TdE6MTOx7WaezY4jbmCNEMoyIqKEYIXHNt51mGEGfEvOecmUMIMdKhuSdOCJVVCMl1VF0aKs0UQtUa2CGxQNy6KqFNCaEObdfJJ3jmtwKz9Bhed8ucJ8+XUoIwbcfFZ48t4dU3z0LgufKdEbNaxBeB14UkgRCy9XABpW0QL3rkse36YQBAs3UCAFmce6HSUnUnQ2gE6Bo2aoroWRSGIS9M28mV5GcrhHqYpouS0kVlfx1gWWPRgM+CmN54HPfyxyH3l70MIQssoytMCKUqhKQauXd4ySOEruVQaXa/edaRFLAxsZanEBK2WV3tqREG7/DogRfDCiFWl0QhSITwyVIIzd1Gvj/9WfJ14jDw7X8E3P3O4Y8zBxq9hnePkZbXwyiE2H2hSILXIDK57XxUIZSxAH75vwNuextpILJ2auBjSzqGLMXMMJYx23HJ+7YM4OH3EsX7K3+OBJKXANuUHSxU2v8/I7XKZQiRsXeiJntkhTd2sQwhRjolWLxtnvy94ETObWBD0+2u+pbeUdyTGQgqhL56htQjbFMtCxzHQRZ4j7TMsozVKwpMiGHylynX99ydWD+xc8zsfGMVCS3N2nKRAVtzzW+Ex/K2ZpbvMnb0AeDpfyDfRxVC18raY4swjELo5QC+jeO4swD+GsBrOI77cwCXOY7bDQD061LSH7uu+0eu697juu49MzMzQxzGcxOX1vvYMx6etHdTtVCw01i0HXoQaV3G7OdIl7GQQiivcLV0stCzLbKIy1gsrlPGm1nGGCaqMgzb8V63Yq7HF40AmqrktyZlCiGmCGETEWWl0V4A4AKrJ8nPGVGQoiDwipi0xYvZ81rOMxyZJf8/vbyNOUI8X7iTGrP91ZXyRc0VBX1vVRjxdqVGB30o0Hl6D0cJIYax/ZEuY+UzhBy5jhr6pICikn5eqnidxeZoy+ymKqJDr8tnFjZxw1w9+Qm3AIzMft2tc97PfIVQXAbc0izcTDvklVYIAcMRQqwFeIwQGidfg8+bQh61aoQQqm0eAwCYQUJoJ0NoJOjqRC7OFgDD2JsMOztUGgCmGzJWOkairWRhU8OhKTLOllY4eoq06YEtY7JB8sx4bS2uELIduK6bbhkLKoQAQJAhceFuhNcifEIohdxgjyuaIcTzV6jL2CgUQpEMobTn5DhyPaR1GTP7hDAQVeDcl8nPqlPAnf8cmDg0/HHmgCmEqrKQmelVBJrp11KsRk66t4MKoYmqnG2R2f9iQgoBye28B4Se1VkWw1nGALopd+6LgL5JyKBX/2Jpq+KgNnSBD2c3eVlnpRRC1DJWlb1cRK+xi1IncQ1mn8y7Vj82X1uUEBKdyPUU2NB0u0HLmILzqz1/Th8xgqrpSxt9KCKPb7phOuMvfEgC5zkUsjIiG6oI3ZXC5C+ziU0cJKoqO/z+vFDpAEEK+ITNVoGte4IuB9d16aZQievN6IXrN6XuuTUUaYcQGpgQcl33F1zX3ee67iEA3wXgM67rfi+ADwP4fvqw7wfwoaGP8nmISxt9TxbLsHecKYTWyUYel00IsY4JQRWAJDx3QqWDCqHcwtXSyADXWST/L0QIhXcB2P/PrRL1h2xsJBJCDVXy/csxQog+XmmQUOLWAvn/Cg0IZ4uDFAWBbuYQQgkZQjN10mXq7Oo255YwW1wO2K5rRRbBcbh2fLyMEOISilKzhz6nYkOYpt17AsVVkBBq7k2wjJXbfbKlGupcnxSMrJCXKt5kPRewjLU1C6bt4PELm7j7wPY1gHzjbbvwnh+4Fy857O/MpbWd1+1w+K1YtssYQOwLw1jGOD6eiZGUTZRiL2tLM+i4Kqob5L7mhECumFwj58m5Rq7zqxTMMsYWIL0hyIu8tvMAGUcN2/HH9gBafdO7z0pbxtg11Ng9sGVMMgkhJPTXPULIooSQ65LNIT9UOlJAM1UIU5aKMiT32reMsdDxxRxCiC2e8ixj275gsPzF59DgJQAuGXOyMoQAohhLIzMsncxnU9cDi0+Sn9WKLVRHAaYQUiQ+U7FXBD7xIPiWsZQMIRaiO0YzhDLzGFn9FVUJD4F8hRDvPa4ogssAy3GBZx8gx37k1QMd40OnyTgWjVrIgxDZ8NHyatwEsCDpXWNqfIOARSjo7dT52ubJPSalKIR0V4plCH3XHz2EH/vzR7Ykm9OKbOa/4saZwg1AJNHvhJel1mqqEvqQYAXzDFltM36QfI00vkkKlQaw5a3n2WZG8H7XTAe245azjLUXwv9Xml6eqyLwMCxne7NWrzKMostYFP8DwOs5jjsB4PX0/zsoiUsbcYXQdF2ByHNY6RiYa6g4NF0rphDiwgqhRELomQ+PdEdjOxAihHIVQvSxK8TCkbVYZDtAUYUQU1ycWyVkjajHvcgAsYx1dCqjDBJCvORn67DOB4ygYseVoxDyciCy2s5HMoQ4jsPh6RpO54RrjhwFg7OZQkQSONL68Wph6dfPAWe+kP57WiyoXIKE3OhC51SsCVNxL36QaGCWMTYJ2abXIa4oLLGOOjQaKk3vYVH1rl/PMkYzhI4utNE3bbzo4PYRQrLI49U3z4aUVALPgefihFBUycDzA3T3CbaIt03gyb/zP+M89FaByiQ8H4H3nOPkayIhFJagG46LU+4eKGtEISRLsq8aZEqMHZXQUOjoFmqK6BFCw1rGojlgUcxQyX50Eeo4ZKdyki6EEsev/rof1hmFZx/dPbBlTLbIWMT3VwMKIf/6NWzHu69iCy2mCgkohASXhkpfw4QQI2DzLGOLLQ2SwMXm+yiaqgTDdgqrMIa2l400VJrOKbaZrRACyLWgt8mYGY0XsPrEbjZ9A7HKAok10FaBbRYpooCZhjJUlzFG3AYzhJJKYy2gzhmvyF5gbyqYHW+E9bSWpxCi9WDZDKGX8U9hD1ZgmhaJUrj+tel2wgycWu7gv3zkGbz0uim84oZyjg+2Yc0US+z+UkvkG+6frOLvf+xl+Nbbd3skiG8Zo51dL3wVeOjd5PvqFJ68uImf+KtHYTuupxDiowoh2jjkojsNrr/mEUI2L2KxpeELJ1bwT89cLvV+i4CNHTNU+fSGgLI6D5LgE0JZaq2mKkKHDEuPEEKCDNTn/P8HoEUVQhXyuW11jhCbu4IKIda1tVSXMUYIyXQdJtdpx+e2dw89n3OERkIIua77Wdd176ffr7qu+1rXdW+gX9dG8RrPJ7Q0E23N8hRBDALPebuQu8dV3DjbwImMTmPJXcYSOmWsnwU+8H3A0/84kuPfLiy2NK8Iz806MIsTQqu0rWh0p2O8Qpjos6s9kr/SW4stBAFSOAJUis4m182LZCeNLYjlOimoaPGOZbJw9OwqKV2IUlsHew9o+x2+Ajg8XcOZlW1uPS8XVAjRolPkeSiicPXkVnz5d4E/f0f6ezBYl7GEotTowuAreEa8Fdj7ovDvGEEk14HKBLkG2G7iAAohU6xB4UxUBTukEJqoSuA5X05dV0V0NMvLINtOQigNkhAP8osSQqW7jAFhy9iJTwJ//y+Bi18v9rcJbWm95wTCXeHYYj6yS65bDr7i3ALe6gOiirYyF+g8OPod5OcjugaxjKnejvDg8n2zSKg0vY+iQbZd+rpsLkps9PDE3wJ//d3A5Wfiv+tQV31zL50Tyo9/jBDi+muBDCF/MWBabnqGEADsuQuYu518TwkhjgO0a9gyVlQhtLChkUyanDw1piAqEl5+cqmDW37l48PZtNlYPjKFEEiOUBGF0NP/QMbMhUfDvzM18rfTN/k/q8RroK1CMBh9pjEahZAqCV7eXrSLEQmetkMZQgCybWPe+D5qQmi0XcagbeC90q/jR8WPwFk7SxbL179uoON775fOAgB++5/fFctTzIMQUWelht/n4EUHJyAJvEcIhSxjAPCh/wf46u+T+2n6Jnz22BI+/Pg8Vjs6bC7NMkbG1fPuLASj5W3itE3eIw9/9aPPDkz+/sbHj4YiQBjYJumBySpEnsPrbilOCMlCMYVQQ5WguQmEkDrmB8THCCGm5vcVc8A2KITsuELIs/qW6TLGHBkv+7ckrqE6STautZanEM5q1PRcx1YohHYwJBY2SCEQVQiRn6ne726Yq+PsajexSw/gT258JFQ6trhiNz1b3FwjWNzUcGiKTL75ljE6kKxQ4iWoyqBwXRf/65+O4+f//gkIPBcLcWME0bnVLsZUMXXhyLIIWprpE0L6ZvixTCkEkGLNUwhR/jRFWZPbkjOhgwJACKGL6/3t7eDFVFA5YOoP8WpTCGmbZJf25KeSf88UQkhWCJl8Be+vfC/wXX8R/h0jFpRG3IbklM8QMgSys1/jtJBCaO94BQcmq16B1lAldAwLXz+3jt1jauL4st2QBR6mFb4P2eQvC+QaF3i+vGUsSAgxuyYLTMxDyj1UxjJmWA7+u/UvcPnfngV+4SI2q4cCCiFaoO4ohIZCT7epQiiSGTEADNvxQs7TkKYQYjkSrNNN4hjLutwcfSD+u/YisWyN7SX/H0AlpFBCCN2VRIWQbtvpCiEA+MGPAff9KPlekMDZJiqScE0rhIIZQlk2gIXNPnaPZRAkFGxe7xQghOY3+jBtN9R9rjTYplAkE3AgsBDcogohFkAdnL9dN6wQAoj6YhQKpoLwFUKEEFrp6DESpyiSMoSitbFuOTBt1zv3E4UIIaYQGrVlLH18EqnatkztVDv3acicjT3cCmw6R67Lu3FxvfxxL7d17JuoYFeB+ygKPvLZawEV2CDwLGPBUGmA5iP9PPCLl4Dp67FOz2FLs2BRy5jgJlvGLri0GQxVmGzQh73ptl04v9bD50+Ub4zUMyy8+7On8A+PXoz9jq3pfuSV1+GDP/6yUjY8UeACCqHsDCENMmwjMEYxQiip1oH/mTK1GlNVZnbeGwF8hZBP7rPxvVTb+fY8+XrfjwE/9RQZB9UxQG95GyU7hNAOripc2iAD8t6JJEKI/GzPmIrxqgzHJYVxEhhPFAqVTmqdyhYmg2ZuXAFopo35zT4OTZNiqbhljGb1uE6MdPnfnzmJ3/30Cbzqphl8+P95uWcRY2C7Qz3Dxu6KSYqmatw/36RKos2+Gc7zCaqJgoTQvnuB1RO0hTXLEEpRCGX5q20zTjxRHJ6uwXWB89uZI6Q0CymE2OQnCRwUib96FELsvng2YREHeMWyCj1uRzJ7MIUqekmhg0GFUHTita3SljFdINdYze3517mo4v994034q399n/e4hiLCdYEvHF++KtRBAPG7G3b4fDOCiE3QAp/c/SUTQUKoRYsAtjuUh4QuJN5zAhGF0ArZMY/kdnkqJ5W08h6rSF6R5mW17BBCQ6GjW6iNKEPIsPIzhFIVQvQeH6tI6YsyRvIkEkLzRKLPriG7vPxesehc1iOWMYcTAHDe3G9Yjk+05u28CzJgG1CfI4SQbjmZC/j5Da0QOV5GIeQvbodYXLDxYRSEENtkcCxKCGUs3INkUTBcml3DokqCpYHkcXILwYgRjuMwU1dg2q4/rpaEZgYVQswyFp5nWL4U6/Y7xiwyWZ3GWEj7iBRCrLNslkKI4zgoolCKEGqe+yQAYBe3TkhpAL/3cBc//TePlz7G9Z6Ra7lMAxujnIhCKMsil/d8ssjHM4QA4Na3euQoszl1dAsm6zIWDfWnNd55RgjRGmJdJ8f8z160D9N1GX/9tYKbTQGwsPuL6/HrhKnmp+oK7tg3Xup5JYH3xqgsy1hDlaBBhptJCG2E/sbrJOdZxsKf5VaBrRFWOoZHADNivpRlrLVA6+6m/zN1HDB7qPDkvV01G9JXADuE0FWItS6ZhKZr8V0c1q1nz3jF68rUSZHKs131oIJT4vn44ortRG0hIXR2pTvwTk4SPvDwBWimg7fcsQdAwS5jgK/EAfyMEQDPLrTwW/90HG9/4V783vfcjdv2RHJf4PtlAWCfTD+zlC5jAC0cg37sNIXQda8khdfm+QIZQhkdGLyOR/Ei7TAlzrY1R0iu+zvjGWCZViLPoyIJwxXRowQ7Byc+6Qd8MjiEUDQ5CTzceFcWowtLrCQvUj2FUAIh5JilLWMaT85txe37RaikoqlK3ngBkGwrgOzIfd99B0u9xlZBErgEhRD5zHzLWMKYlQd1jOxmW7rvG48GCqaht5oclJqoEKJqokiXOTOy+A4TQjsZQqNAl2YIkQXicC3STdvNJUrGKxJEnosphFjx3VQlyGkKRzY+LDwObJwP/661QAKlBTq/DEAIqTYdZykh5HKkNpiiO8um7YbyVzIhyABTCBlXyVg8AIIdgOYjOUKm7eBTz1yGaTu43NIKKoTovK7nExBWJA9lIJgjJIRCCiE9WyEUrFmCpAZrTy1VSKg0uMQNsSSsdvREa0xZBFvAM0Ues/gP8lwA2Vzj+WRCyL+3ydzJNgUzFRE8T0izESmEilqoFIkv3pDD7KN58bMAgDluDRydGy/YEx4JVgbrPQMTtcFasXuWMXbPDKkQAggR0o9mCE1eB8ze4j2G2ZzamgmLy247f8GluUj0c1qjt8JsU8E77t6HzxxdCqlXioA5QZIIIWYZE0va7wDg1t0+2VHJIBEbqgjNleCaxRVCWiTfiW1+b1eotO24WKPkU3tQhVBjd/hn1B5Xdbuh13o+YocQugrhyfLk+OlhlrHdYxVfKp/S+tBxXPAcYkGutuOGJdRMKbNFhNDllobX/NZn8ZmjSyN5Pt2y8e4HT+HeQxN41U0zxbIOWEEeXBQG3u/jFzYAAD/5uhvjLcQpZJFHjTLuu6R0QijRMhZ9LNu14Hjg4MvJ9/OP+kGSRhd47K+AP/2WkPok0zLWS2mXDXhKqjPbSQgpxdrOBxVCqiR4k84Vh9ElhZ3eAn5tDvjYz/q/M7sAXLQEqrSJ7gYaHThiFb0ksjZkGRsn3/dpsexYfvFeEBpPlAVVpxuwjMV3vL/19t341be9AJ/796/GS67bviDQLMgiH+8yxtQ1VLExWNv5cfJVa/n3fGueqL3+8BXpOS1MpZeUiyGpJH8gQCSju5JIwEZzkJoVCZt9liFEF3gpnQR3kA8W5FxTRHAch4okDN1lLC9Umuc5TNXlBIUQeV1CTgnJBaWlk7EeAI5/Ivy7NiWE2CK9rGXMcaDYQYWQ7RFCzOZWWiFk6VCvJrXmAOjqltd9KJoj9GsffRY//P6H8XePXITluNhdQCHE5vViCiHyWQ+tEOIEnygcBnSTodPv4/LaJlpWxmJbrpHXBcIbHaavPoVcBcYPFO4w9r6HzuGdf/LVQY48hGAL+JASe8DnAsjiVkgJlWbnmi06C3dVkqojUwgFjzMLpez2Z78IwerhEecGzHAt8JsXAKmGrltJjaDIwnrPHFgh5IdKk//7jVMGX56G5gNWb9385tDGDesm3NYsL1RaSGk771nGqNp4TSMXykRVxjtetA+W4+Izz5Zb37Cw+4vrvZil1fIarZT/DH7zO+7ED3/TYdy8q+GN/0loVohCKHSPaxukdkpqoAF/naV46m0OTVXMtlCOAMHreqlFzhFT5jbKKoSaEUKIXh81SgjtKIR2cFVBz5gAbpxrgOOA62fr3iTVSSGEbNeNBbwxxjnUaczcWoXQWteA42I4P30An3z6MhZbGn7itTd4i4FMhZDr+kRLEIH3e+xyG1VZwL4Em14QzEY2K9ICPIF8GaOFSqtvksU9U3yEFEKUEKrPAbO3ku/PPeT/3uiSENzzX/aDppETKu3lmcSLtLGKhOm6jDPL20kIlcwQ4nliU7hagkzNHnDkNcDr/ytpw3npEf939H1t8hP+Y4MwenCkarZCSG6QohoA1s6Qr7ZVOkNoQyKBg019Htg4R4rRStwS1lAlfO99B70gwKsB2aHSZKwShQFDpQFyj7cCCqGT/0RUGmljXW+FBPs2diX/vjrpk3cAsHbab9EafA+2Q5o30fF2rCKhxdoV7yiEhgYb75lKtioPTgg5jgvLcQsV39MJra47rNsJVSslqkIsjYzLgpKgEJonReqgCiGjTVSKAFGsORZcOoYwm5tpO57dOM8axyxjFfkat4xpFm6YI/PsQoAQ+ugTC3jvl88CAD72JBkb9ow4Q2gkCiGjRzaOUjaoSoFuMsyvtsHZOtb0jOd89S8C3/6H5Ps0hRAAvO3dwGt+udDLd3ULXcMeuqUzaQHvqy4BWmcN+FwAIR5YmRydZ9oRyxhTia/nWWSkampjkLLQClqoUtWJSVh8AgDwMfsl5LmXHweau2G5bnIX4gy4rouNnlG63TyD99lHLWNDKIRCY1d9BnjbHwDf9NOhxzASo6NZMEG7jEXHXr0FR1Bx1qX1wNppQJCxTq+5iZqMA5NkQ66sUo2R1JrpYKUT/luv0UrOJkUSZJHHL99/Kz7+k6/IJBFZhhAXIoSoQkiukw2MmELIgSrxoU3z8aq89V3GAjUi6yzI1r21UgqhRaCxJ/wzWitWqcp2RyG0g6sK3o5AwoB433VT+PLPvwbXz9ZzsxOIQihCCNFiMDTxbXGGELvBRsUiX26RAezO/eMAkE8IRXdcGUETeL/HL7dxw1wjt9MIk8XOCIwQSu8y1op2FQoSNUzG2tgN1KaIIuF8gBAye/7xsdwj+BlCibu8KQG3DHvHK1holZO1DgWl4Xc1yQCb/CSRpwqhq2RANjrkPL38J0gXnuD9QZVPGx4hFFUIdeGKNeiWE+9AEVQI1aYJecPO8QCh0ivSbhiugEb7NOlWN31DvGX6VQpZiCuEPEKIhkoPphAKeOCDCiFmGU1TrrHHRmXFDNUp/z6zTWD9DDBzU+xhLJOGFU5jFdKyWjOdQIbQTpexQcF2B5lKtiIP3p3QZONPAUKIBNmGi9+gioDYNlIUQpJKr59A41WzT67RYSxjdFwyIRJC0/FJZbZDrFOFEMchVwkFQQpYxq5hQki3cHCKhOoHFUJ//42LODhVxY1zdTx0itzLQWttGvwMofw6xre/DKMQ6vhjxbCg14Ou61BhwOIyLGO77yTtx4F0hRAAHPomYNfthV6ezYFlyYYodMv26uKxUSmERMGr+6KEFbu3GRlYkQUoIp8foitVRmcZK2ihIhlCBe/XlRPQq7twyiWL48rqM0BjN2nBbpc7Rx3dgmm7XuB2WUQDvTXTLjZOZSA2dt313bFanZF6Lc2ESUOlk9rOu3IdPajoqrvIZpGgYL1nQhI41GQBqkSuibLE5HxgTLoQCfJmljFpC+u4ukzazvPsHnddnxDieVL7RkOlDTtmQxuvSttmGQOAJbqGiar3cuE4VI0b2eyjtWLFIWu6bW28c5Xh2lg1PM+gmQ4EnksdEFnxUstTCDnpCqHQIswjhDaGOOp0MHY3M4ivBFqaBY4jAxoAqirJKLyi+S4TdEc/qBBa7OCmuXi79ijYDtEkWuQHCeRLXY0UjmxHLTghMctYk7LV0zcCl5/yf290/PPBOqMhx0+eQwjJIg9zO8kWmXV3yLaN+ZMfh4rEXz2tjo2eX5AHQ4oBLxtpnR8n/w8Wf45D/k//thddqLKWngrd/Z2+0ScqbLO0Zaxtcjjn7kJl8xR5Hhb4eQ1AEnjv/DNErS0iz3mkYWEwyfPmBXIvCTLZHVqm91JKFz9PTdTck/z76qR/n62dIYvvhM9bj4QUhxYvXpexIVpSP88R7TBCLAKDtZ03IhbFLCQphBg5VVdFyEJGhpCoEvI/2M2TBZ439wxuGaPj0gI3S57bNsELIvaOV7xNE9N2YiRlKgKh0leNfbckXJdYCscqEmYbChYDGyHzG33cMNvAiw5OeAQFs+JngalE0uqtILzF7VAZQr3R5AcB3pyiGRoUmJ5FJhVep6wEhVBWIHUKWCOTsmRDFJoZVwgNSgiFFULJXcZ8hZC/6ByvSvmbm1JlhJaxYgohRUwho5Owchy9xnW47JINLd4xgOYe2I5b2jLGPotoE5aiiAZ6B4PDB0VVziazbccPIw9ZxqJOAqPjqfk3a4fIzwQJ610D41XZO8ZmMCOwIBY3+x65Es0RYgTqIAqhouB5DjavQHDo2GhpZDOCbaZFa14Qsi5KCI1VCtwPQ8JMUQhJtDNxIfRWyYZrtLaj71eltusdhdAOrir0TRtqgQGREUJphbDtup43moENMNupEGKT1KATdxRtzURdFr1dndzd4WiBPXkd+Urf72pHx0pHx41zDeSBecjH0SZKIyX+NwLPoa6IaHmZIYwQSgiVZkqEmRtJ5zOADFBGUCHkB2H7odJJGULpodIAsWSVXlgPA6UYIeS3neevrkWI0fULcnWcEHSuCxz7OLBIyLs1LkEhZPUBuOAU2gEvWpgEFUIAJYQoUeHYpRVCPcPCKXcP5OUnSTD5NUUIcekKITrR8zwHx43v3maCfcZLR8nXXXcQ2yjL2UqzMrK2pKkKoWl/Qc/OGWvBHIBpOyEVX5gQYhlCOwqhQcFUsRWqkq3I4sCWMUZI5mbrgBBCq109dC360nUhvdMPC/KtRgihoCJNoITQgAqhS/xuQlD21yEIEr7086/BLbvIGGNYTm7rag+iQixj17BCSDMd2I6LmiJisiZjPWDnmN/oY8+4ijtp956KJHj3ZxZkkYci8oUyhKyRKIS6oyOEqCra0HUonB+imwpG+iQphKTyhBBb4EbtwWWhW7anlBmlQsgLNk7JEGJkIEA2BXM3N6XqCEOliyqEClrGXBdYPo5u8wgW3YC1nCmESqq4mNJmcsguY8FQ6by8pDyokhDfiAuA2LfJ9x3dguFZxqIKoba3sblWOUQPWMZ6zwi937EBCKGFTQ13HxwHQHKEgmAE6lYSQgDgiKqfm8TWGxmEUD/h3IxX5ZGt7dJgWA4qkoCGInoZQh3NQp1mCBZCWm1H369ikXWKPuQYdS1jhxC6CqEVHBBrrMtYStt5x3FjFqgrkSHEugblymwLoq1ZoVaD+ZYxWsiwoMSJw+QrVeAcu0wGgpt25RNCLDiv6bSI3SdlMGqqot+tgRV1oVDpGrDnbuDgy8j/g4v48QOkGEyyjOUphJSxVIWJKHAxNcaWguUk5SmEAn7pq2YR4tiE2GEBwOoYWaiZfeDvfhD4xC8CANZAJ89g8UetQDxVgnSjO8pyg5z7PS8k/5++Eegu0/yP8paxjm7jlLsbfOsifb44QXG1QhL42I5MlBAS+eTd20w05ogH/vSD5P977w7/Pu2abC2Qv6vPJf8+uKBn92UCAWdYGYQQDfw2evmB6ztIBlsksd3KqjSEZcwLtc8vh8arEkzbDc03Hd2GLPBQRIFYxtIyhEQ1TggFFWleJ6jBCKF5nha68495cw27Bk2bEEJykVwOQfIyhK7VUGlG0jUoIbQWaDHd0izsCaindo+rhRcVDVX0reAZGIlCyOj688+wEMicYvbJmJOrEOI42ikrSSGUb6+Lgm36DBJYHIRuOp5SRhJ4VGVhCEKIKW8Ez2GdZhkL2lLGqlJMJRjDFiiE8kKWC1vG2ouA0Ua3cRjraEB36bjT3ANrAIXQeo/l6Yymy5hmFiSuM1CRhEyleTADinQZI8ceJ4Q64FSyLlhRqLNAlLHeNb3NYYBmBJbszrawqeHITB2TNRkX1pIVQltpGQMAW6xBdjSSXZlECAUbaCB5bTpZlbCSdz8MCVZPzTSUkEKoVMv5BZKb5QkCGKKE0NXS5fgKYIcQugqhmU4xQiiny1hSqLRAB5iQdJdZF4wOGRhGjK1QCDUihFCmXYAphBgz3Jgjtg06AB5fpIRQAYUQ80nX7I1UaxZAdpTilrHA4zkO+NcPAi94O/n/NM0h4QQSemamEEJmBiHUXSGWhBRIwjYrhApaY6yAX1odYmE3UjCCRw4QQgDZ0Td73ntawTh9fGBCp7/jVfL+Y8oFnifn/ta3kv8zQmH15ECWsa5u4Ty/3//BdDzT5mqFLCaESjPLmOB3sgD80MlCqEwA++8DLtDONntfFP69kZYhNA/UZr0FVAzVKVIk2RZR7jX2JKoEjRSF0EbPAHgeBl/Bhx8+Efu7HRQDswgzhdAwodKMgCySWTHunUd/LuvopleYpu7SW3oyIRTctRzWMiZQKfzmeeDGNwDwSS7DIpaxQgstFiqdt9FyFSMYODpR9RVCC7Sxxe4xFTfM1lGRBOwpkB/E0FClQpaxq1Uh5Ghk3DPzFEIAuV5HpBAamWUsoBAC/LD+QRBs0JFuGSMqhGAdfc/BCTx2YSObFBpll7FIq+80EDK6wPVG68l2/ToAHC674+TnA2YIsXtrYMsY6zLmWcbsoVrOA5G28wlYD4zfbc2CCUYIxUOleaVBcsgU2gCEKYQCIdpNVSy1vukZFjb7JnaNqdg/UYkphLyaeEhiLA9dZYY0JOhcDhBC4+RrZTzBMubErIt7xito61ZpQqwMDNuBJPCYa6qYp2N4R7dQV0rUykcfAMYOAHO3hX8uVQFehEwJoWFVjNcydgihqxCEhc0/NRVJAMclKBAobAcJodJMIRTMEAoMRnqr/AHnwM8QGs2A0dGtkIRXlQX0swovVtQw72h1ilqAKCG01MFYRcps0cgwRic91dxMtWYBQLOSYxmLgqk6qlOkCGQKIU4ANi545yhTPtxbzXwNkeeGLshKgQVn51rGfIUQIYSuggGZ3RPBDCHA7wZGsewyhVCg+KNkkphGCEUxQwmh5WNUIVSeEFqUaLHC8fEdkKsYRRRCUUl5Ydxyv//9nhIKobQOYwC9v1yiLmQB3gkwsjKEAHRdBba2kyE0KKKNF9SczIgsmJHMqiyMJRBCXd321LpyqmVM8y1j2gYhfgFyvcl1QG0OHipNd3EXxL3+z26+P/SeDNuhC60ihBAJlR6k46Nu2SNTAg+DbiBjarImY40uWlmQ697xCkSBx4++8gjefvfe1OeJoq6IxUKl6TU1VEBpIIduaNBNBlcj9V0hQiiqcmF11EAKIfJ5jEIhpESI9mEUQrLAg+c5b46Jt503Y22tv/2Fe+G4wIcfn09/8pGGSmdsAgZQOEOIEUINUicsgtaxNEOo7Kbh8JYx8tWzjFlx0qEsKjkbBKwrliRw6OgWLE6E6QrgEjOEGlBFHosiI4QUrPeMEAFW9jpkXQ93j6nYN1HFpUiGkKeaz2lyMyz6KlVCtxd8NVCOZYxtwjDspZ2Z50fURToJhuVCEXkcnKriwhq5rzqahUbRQGm9DZx6ELj5zXFXB8cB6jhkk4yN+jW6CTIK7BBCVyGKWsZ4nkNVEtDN6DIWVcF7lrGQQijQ/ngLgqXZJDWq4LG2ZkUUQjlBxGzHNUQI+YPdUkvHnvFKIdn4LCWNFGMtVyHkMeZSlRT9WTtr4wdIhkR1ihSBvTVSgM3dBsAl6hGQyTK1A0MOISQldHTaUhS2jNHdEGoZM2yn/OJ/1GCqJqZyYrsma6dCD1t2KekVsoyR+8knhHJ2lMcPknO/TPNuSlvGLKyoB/znGmAH90ohqctY1BY5kGUMIJM/QM7dxCHyfZMu/lIzhBbSA6UBnwTurhCFUEKHMSDbMqZbNtqODMnRrvx1fo2C7f5WZPIZV6XBFUJeqH0By9hYNZ5bQlQE5OeKGCc4AYQVQgDQX6d/PO8rVxkhNKBCaFmkRGZzr2dHlSMKoSKkV7DtfFly/vcePIVvf/eXSv3NViBo9ZmoymhpFkzb8RYtu8fJIubfve4GvP3ufYWft6GK5drOD60Qym90UQh0k8Gl495gCiHWdn4AhdCILGOaFa6Ni4T5fvAbF/Ejf/ZwrNtnkCBlpZ+TYBmLEkI3zDXwgr1N/OOjl9JfdISWMb2oQkgsmL+4chyQG+grMwDgBUsPniFkguPIuRgE0VBpzRxeIVSRxEylOVuL7B2voKVZcBwXOiTwduB6t01Suyp1KJKAFW4cUJpwBQnrPROTtbBlrAwRvugRQhXsGlNDofcAYFrF56RhYFQpIdSa98kf1vSE5WZa/gZFKFTaNgHLwJ7xbSCEqOJ6/2QVKx0DXd0qZxk7+WmSIRncJAxCHYNotLzXer5ihxC6ChGd9LJQVcR0hVBCqLSQmCEUJIRGnyPEQrpIkFvGZLNyEvifN8RUGFGQSdofjAtnCI3TRXNtNkQIrfeMwi0z33jbLrz3B++FrGUTQk1V9MMnlQZQm8l+Yl4gSpH6LCkC+zQget+95OsqsZdkdmDoZR+TKHBDt30tBWalybWMsd0Q3tsZuuK2MUbwSFGF0GnydeIwIChYc2jBHrKMkftJrhZUCPECMHUEWHqG/D/NrpSCnmETn3tzHzBzc6m/vdKQxHiXMTNiGUuT8+di4hAwdzswtg8QZaC+y7eOpSqE5tMDpQH//lp6mtjOUgK8mcSZoaGK4DgyBh5f7KDrKqhBK7S43EEcWqQVc55FIAtluoyxLpObgVDZjm6iThVCxEJYRgABAABJREFUxDKWliGk+NcPs421F31FGrOM2SU3TrRN9LgqWsIUAC60CxpWCBW1jCmAZUAVCTkfXUhnYWGjj0tbuDAoij1f/VX8T/EPUFdFb+G20TOxsNEHzwFzBdTASSAKoeIZQu88/8vAZ35toNciGUKjUgiROYUzShBCo1QIOUwhNGTb+YhCqKlmE0JfPrmCn/m7J/CJpy/ja2fXQr8jHcvIfRvNsWFo62ao1mR421178eSlTU+tEMMoQ6ULKoRUqahC6AQwfb0XoH3JnYbDiUB9DpbjwnXLzbXrXQPjFSkWT1EUvgKY/L/wOJWBisyjZ1ip6w2mato/WUVbM+G4hBDyFEKnPwf86hzJdlTHoIo8NMsFZm6GLVZgO66XJwoQQqitE2KpCC4FrKtNVULPsEPjrOWQjd9BP9OisGp07mkv+GIAVutWJsg1/KuzwBN/Cyw9i79c/25c55wBnv4H4L/OAL86g+vnH6DvSYu/wIhgWCSn78AkGQ/Pr/XQ0S2vsVIuTvwTUJkkMQJJUMcgGEwh9PwlhMqtPHawLUjyaaahroiZCqFoqDRbpMS6jAkKYVC3ghCihbphO+ibNqpyymW3chzoLpHcj8nDqc8XyxDKWwywHdebvpV0G9p3Lxn0aAjves/ALbuahd6LLPJ41X6RDJ5MdZCAZjBk7lW/EM6NSMGFb/6fpF3wxY/5P2SvoflyxtTdk95qpo1N5PnttYzJxRRCfpcxzpOj9k27+GC/FWCquWiGECOEvu1dgKWj9TdG+PGB75VKE8BKKmEbQmM3sElDoUtaxjq6RfLE3vqnmef/aoScYhkTec4buxI7IxbF2//Qz774jveQxfeJTyZnCJl9cl83CxBC5x4iX9MIoYgag+c5NBSSM/DkpU3cBBUV6Ghppqc62UFxaJ5CaHjLGNsRLJLXwM5V1DI2XSeLA0UUkgvKqEKIzQf9dWD2VvK9ZxkrrxDq8XWYYg34rr8IFb2M5DJLKYRYqDQl5y0H9YI71RrtZmY78fzC7UR17WncxV8Er4iYoFkf6z0D85sa5poqxAF33stmCO3XjgKnesBrfqn8i21BhhDPFj1cAZXPCBVCIwuVtsL5mmMVCc/Mxwmhrm7h5/7+CfzfpxZx3XQNF9Z7+MRTi3jZkenAc/kKISGSY8PQ1qxQVgzDDTRv8nJLw/7JBNJulKHSBRVCVVnMVyMDQGcJmDjkvdc/tb4F17/kW/E6QfTmWNN2IPDFNqXJhupgdjEgTsbptKPUMKjKIhyXjO1J9fJGz4TAc9gzVsGxxTZsRgix633tFODawDf/e+CeH4T6+EmiXL7/f2FpowucWA2952ZFgusCLc3EI+fW8eqbZmNrryCemW+hKgvYN1FFs0Lq3I5ueTY003a3PFAaAIT6DAxXgNSaB8c2cFnUwwu/j8wFX/0j4PG/BJbuwpjbxss6nwYeWye1VGcJjfZpSMJUzPY2SrC56+CUTwixfK9C6C4BEwfTN1vVMfD6jkJoRyF0FaJv2IUHxKoslAyVJv8PTcxGz7dJRFLlR4HgDZYp72WL6kCIchJaEe+omtNRwCtq5Bpwx3eQUF91DOgT8mujF+4YkIuM7kIMDRoy947f/zK+sjkO7H9x7tP+9Bdc/NJDbrgIZN2OKKmVunti9EgXkEzLWLzF95bCI4SyFULMLy0JvJcJcsUVQlFCiMloV6llbNcLgBteh64twAGXmCEk18jEWki5UJ0COovk+wFCpeuKCBx4yTXVYQwgBGs0cyVGpgyqEAKI5XIfVQUdfBnJV1Iaydek1wI8wzJWowuK8zmEkB2/T8eqkkcI9VwFNU4rpDbYQRzBDkEAUJXE0moWBr/LWPFQ6eA8FtypTLqeAaQrhLRNn2weIlS6y9XI3H7zm0ONBaSAQigadJ6KQKg0gFJEGxu3Cy1MtxCupaPJdUmXMbrIWusamN/oY/fY4JbaRrB7aAbYWCW7OlFklAjE7+gWCa239dERQpRslAKEkGba+OA3LqartqWKT6YDQymE2D2WVn+4rot3f/YkfvoDj+Evv3o+9XmInSg/Q+jDj8/jgScW8AMvO4S/+tf34ZU3zuATT18OKTiCHcuY4jqq8Iiq0RmadEMydfyWquT8OcPXMV5eWs6aoHD+It04ZNfoEiZwdvylAPzrtoySvHT9HEE0VDp6jgeBmjN2rfeIqqlZIYo/x3GhuwGFELNJvfTfAGP7IIs8OQ+7bsflKrGJB7uqMbvcR55YwL9838P45DOLmcf32IUNvGDPGASe864vL3MURDW/1S3nAaBRUbCECdib1DImqj7h25gDXv7vSOObM58Hnvo7AMBdrQeB058Fbvt2QK6Ds/rYPVbZcsuYJHCeQuj0chetvundh7kw+9lqS3UMPN10T7R8P0+wQwhdhdAs25Oy5qGmiKk7VrYTt4xJSbvtRsfP1tgShZB/g51f7eF3PnUieXFn5hNCumXDsJxYl7FCljExUAhSy5jjuNiIdAzIRQFC6K79E5hrqDi22MbvfrpYN6Gltk46NoQIodnQe9AtJ7n9aG+FfK1Ox39HIW43IcTzhBQqqhDiOajyVUoIsV2TjXMk6FshizjLASxejWQIEbKhUiU7Ll29wHupTfv3XskMoa5uoXol1VRDgGSuhD+f6MJVTLK5DoO0a9JrAZ6hEKpQBdblpwG5kRpAHQ2VBvzFy1OXNqFxFVShbWlnjucy+l6oNM0QCigLyyJqUcxCVRYgCVyoQQJpcuB3GYtezwDSFUJBQshTCJW3jHW5WmIAqacQst3i3XsEGXBtsCm2zFjsE0JXdvzmLA1N9EiXMaYQ6hpY2NS8/KBB0FBJvZVpfYc/VsmOThp1dC4Xev7LLQ13/edP4s+/QO3DIyOEyMmUWGtlvoJPP7uEn/7A4zi90k3+G1H1W80DZFHFi6UtzYD/eaRZxla7Bn7j48fwwW9cwrs+k1wvua4b2xAbq0joGnasrnni4gbGKhJ++c23YLqu4E0v2IXFlobHL254j9Ej0QwCzxUKlQbgL+LTxm8WBj4ClVBRy1hVLmDxdF0y9tSmQzU4Oy/sPJUh1te6JevnCIRIhlBqjVsCefMBI7HqioS+SdYUOmS/7Tz7SsfkYPdbpg6NWsYA4PELGwCAjz+VTggZloNnFlq4cz8Z9xmpEbyWLMfd8kBpgIxnl90JOIwQYnNRELe8BXAsYOM8nnEPYdy8TD6fm+/3wtP3jle21CpsWi5kkcdYRUJDFfGhxy7BsB288MBEwSfo+c19kqCOgdM3IfDccI0ArnHsEEJXIXTT8ZQSeahlpOk7rhsLVPfazocyhHr+IqgAIWSW3IkNKoT+4qvn8dufOo6jiwndzNgifDmdEGKZG9EMIctx08kOjxAK5AaoY4DeQquvw3FLtsxcOU4sdiyTKAGvv3UOX/nF1+LHX30EXz61ipNL2aQIQCaajm6lEEJMIZRS1LMFRmaXsW22jAFEjZHW4puCnTdR4L0F3hXvNBbNEJJUUiA7FrFl8f7Ou8mrkQwh8rdqrQGOA/pFdsuDVq/SodK2l2FyrYGo1sLXZJRMGbjLWBqURjzX6tkHgIf+N/k+SyEkqVT55pLMr5Qg+iR7zlhFwuWWjmOLbVRqDVSh7yiEBoRm2pAEzrP+eFbTAYgIXyGUXw5xHIexihxuOx+Qrqe2fjb7lBCi93lvlagvLC2BECqoEDK6JJ9m5Rg6XD3RosU2gHRmGStilaIKxZpI3kcZko0tXq84IWTrqHAGqrxv+VmlCqG9QxBCdUWE6yLVps9gOw44OFBAz+Xysewn/safAZ/4JbS+8l5Yjos//NST5OejyhCiljHV8hVCbOGTes8kKYQGUAcBPsGQVjeyrk+7x1Qv3yUKVkcqIctYslLn8QubuGPfmKf8eeWNpI565Ny69xgtkkfEc0RVH0QrIVQaCC7i0xRC9HPKIoT668DD78lVj2mWDYHncscnT9GXdb/qbdLJtDoVssexMZD9rEzW00ak41ZZROd3zbQLr3/SwD6LtHGIdQlrBM6jDslXZ7JOj3TNoAbG9bOrZJ2yJzCONOl65KlLZP306WeXUpUmxxbbMCwHd+wbB5BMLpqRDMKtQkMVsehO0AyhFEJo7z2eU+HnzR+GC46sMw7c51kj94xvrUJItx3IogCO43Bwqoqji22IPIeXXZ/RuTkIs59LCEHbTIwweD5hhxC6CkFa+xU7NbWsUOkEH7/fZSxoGeuSG57jCxFC3/t/vopf/eizhY4PCCuEvnqGEBeJu46s1ffa6dRd0rZHCIUzhICMiTBRIdQE4GJjgxQIRUOlARDCaup6Egacg++8Zz9kgceffyVdBg2Qc9XSKCEULAKrU4QgYAohM8UyVoAQkgTOs2dtG4oohIJdxobY6R8pol3GAH+yDHzGpu3AEiKEkLYBcDw4uZ7ZBTCE4HkraRnrGTRD6BqELPIxz3aUTNkSQih4TVoG8I8/ToIHp64nXvMM6PI4+SZDIRgNlQZo3sVCC4btYHZ6ClVOK9TCegdx9COdOPMWAFkwSnZ0GauIaFGFkO24obwzhbadDylIHJsswkSVLDCUJtBd9efamGWsYNv5k58CPv8bgNHFM+ItiTvKHMd5nfz0ohlC9DiqfHlyh+WdFMpN20KwnX5Ob3t2lmOLbeiWMxQhxBZvefet7QAKAo/JssHbJvCRnwAe+j1c/+VfwCRaqHHM5j6iLmN0TlFtMq/1OTWU2ZKIJIXQgB0sGcGQls/BCNbD0zVoppNIUmkJSpmkrn99w8axy23csc9f3E5UJcgCj5VOuGNScAzhOS5EkjA1ejPJMlbJuQ5YDWemqK8A4JkPAw/8JLB+Nv0xyKj5IihUO3lK8qmQGsqMEHZFW88/cXEDq93iTVmSELWMjUIhlLdBsN4zMVGVvHXEZt+EEcwQYmMw3ZxTJcHLQn1mvoXpuux1HAZ8hdCJpQ54DmjrFr50aiXxtZlK7a794wDgZQiFLWPutljGmqqEy+4khM4iaWoyltBxkeeBF/8r2Le8DU841+H47JuAe/8VWf/Q8PS9ExVcbmlb5kAIbmYw29jdBycS781EmL1cyxgsDQ3RSh8PnwfYIYSuQpRhyGuyiG6KAsFx/fwNhlgLZ8chN4tcD3XeysKZlS6+HunYkAXD9gflyy1SqPWNhJuOLcIdE1g/l/hc7QSFEJvUU3OEGOsfVAhRtrjVJjtmpULxVo4TdUABTNcVvOLGGXz++HLm49qaCdelCqgoCSGq+RlCPXo+MruMXQmFUD03QyjcZexqsYxRclIOTCIeIURseTbryBG1jLUWCMHKC6jIYrEFVfC8lQiVdhwXPeMKB3APAVkQYDtuiOzR7RRCqEQORyaihNDZLwD6JvCd7wf+7SPZO0kAVmhnOXcqPa8pTSEEAONVCXtnp3YUQkOANF7w50hmERiEEPIsYwVzK8arMjZolzFm1/YUQoHMHg/R+ac6SQh8r80vlb0zZWBRhRBT0v7MSXxAeYen/o1CEjiv7XyxLmNkLqyK5fOA2Lh9pQl9waELOm0Tiiigroj4wgkyB9+2p1gDiSSwBWRed0DbcVBB4DyuZNjGO5cB1wHu+SFwcPA64RHcs4deK/JoFUJVh8zFeogQSlMIqaNTCDmMcEgew4OEEACsJaiE2HEqkVBpIEwIPbOwCdtxcSdVYACEGJ2qy1jt+OckWkvxHBfKEErafGRQRB6SwIUW8SEUUQix3+U0HCnadbhQ5legTgzOuWy88jKECtSJH39qAd/2v78EnuPw0iMFlRoJ8EOlyf8zG6cURCWnjuzQ7nHs3G70jIhCSCcuAHpsish7hOTT8y3csrsZ6vTLiEnbcfFNN8ygroj45NPJNtHHL2xgoiph3wS5RpoJJLPpOBC3IVSaWcYEq0vWNTd+S/IDX/EzaL/ljwEAX7rjvwOv/gXyc6oQ2juuwnGBxc2t6TRmBALgWYj7q27K6dwcRJ5CiGaETgn9HYXQDq4euK4b27nIAlEIpXcZiymEKOtsssnADCx8CxJCbc3CqeVO4RaLuunEJtXEgjG4qF5JllizQTOaIZT6nICvEAoOCJQt7nQIIVQ4FM/USI5MhjogivGqlEtwsIKoa9hwWNElyHRX2e/2kW8ZS+8yJfEcbSu6za3nc9rOs91DSeAGCjLdEjD7opRECJHP2NtViyqE2n7r8poiFFtQhQih4sUQI4MLd1u4yuC1xQ5MwltuGZPr4Wvy6EcBqQYceXWhP+/wND9qKn0MMBMCfNmu8utvmYNSbaDG6Wj3SwYI7wAAKfSDjReGURaWaTsPkGBpNl6nEkLBojKqUK1OhQkhNq5wHO32WVAhtHIcGNsPyDWqBk5+mCwShVCpLmMA6iK53wploFGwRdOVVgj5hNAGABIAe3a1B54Dbh2CEKrnWYUoLMdFBYHzmFLPkCej2WU3vhHr0i68WfoG5lT6mY84Q6jm+AohpsxNXQCJlZEphPK6jLFMLkYIrXcN/McPPYU//vxp7zFMaa5GMoSAMCH0+AVyX91JFRgMU3UZq92wQihYSwk8h+DhMUIoaW7lOBIGnK8Qymg9z4jfHEKIREiMSiHE6sTpsGWMqiRtN/s8BXF+jby3z/3sq/Cam+dyH58Gxnt4lrERZgilbRD0DQcVWfA2lolCSPbHassIbSCrkuApxk4stXHbnrC1KhhufP1MHS8+PJm6af7sYgsv2OvbGZueZSysECrS5GBYNCsSsYwx3PytqY+NNnIAELKMAdiyHCEWKg0AR2bIhtyrqA20EHJDpccBABNCf0chtIOrB6btwnFRuO18TRHQNZJDDpO7jLG28/SiD4bnFiCELNo6XjOdwje/YTuYrMmhY0mctIyuF9abJrFuJUzS+ZaxcEAcAI8c6rRJgVQ4FG/tFNnNK0EIEVtM9mI2GFLa52nRpY6TRUJUIZR0bXRXSNgxHdiSwPI2RhbOWwRyo4BlzIHAc+A4zlcIXelB2eySgjhIzkQsY96umpigEKJd+6qDKIRKWMbYYq16jWYIyQmKiujCNaZqHBZKwMboOIQQuv61ucoghhZPFpT6+JHUx+gpodIA8C2374KokKJG62VYCnaQCrJp4n++wxDJXoaQWKwAH6v6hBAjPupqmBAKFZUxhVAKIcQeU9QytnLc6ypou27qjrJEcxGIIqJgqDT8DKEy5I6nELrChL7o0s+cEkKs09j1s3VUh7DXsoVfXut523FR4dh5V7MVQu158rWxG1+vvAwvxROY5ei1IY227XwDXTguB92VvfE0lRBKVAgNaBmj9aaZMoazDCG22FvrGvjok4v4h0cveY9JUgg11Tgh9MTFDcw1Fcw1w8c6VVNiCqHgGMJz4bbz/uZj8nzcVMWMLmMFFELsPs9VCDmFmsxUiqgkAxuH7PxznK/gKtNlrENrj+makvPIbARDpV3XpUrG4eoZNWeTmG0oeAqhvgmDi2QIBeowVSQd3E4udWDaboxUriuit77ZP1nB3QfGcXKp413XQax2jNC16ZHMgWvYcrYvQ+gy6CbynhcmW8Yo2GcZijOhlrF9E4RsubCWQYAOARYqDQBvvWsPPvAjLy1H7BexjAGY3FEI7eBqgtc9pYRCyHWTBz7bcVMtY54klHmcpWKEULAQOrmUrfxgYB5o1rIXSLF3GV3S6rCxm3TxyXj9ZiRUGsgoQlkhE/ws6ODQ75KFYeFQvNWT5GuJ9t4kqCy7QA4GKfZcRggFsiXoTl1mhlAg7DgJTB221bYx13Vx/7u+gL/46rm4PScBlu13VGAFWqr9b7tgdOO7sxFCiH2OjlDxiVUgpBCqyoMohIoTQlGFwrUGmV6TWQqhodrOJyHYdn7xcaCzSDpmFMQqNwHdldCr7k99TJI95xU3zODb7tyDl18/7V1bei8/bH4HcfQjCiG2yB+k3XmZUGmAEHuseGcLwmCGEBAlhNIUQhvk/0FCSJCLWcZcl5AMdGMiKS+QgeV06ZZdvO08gJpAxuA88iMIRggVyk3bKrguJJcurmg9wzqN3b53fKinrivFMoQsx4XKFEJzLwBal9Kt0153wz34lHMvZJi4vfMlAIA7KssYXdxKsNCFCtv1F/3pGUJUIcRIkjzbRQY8hVDKa230TAg859lBLrc0rHZ1nFhqe3NDYoZQgkJoflPDoak4kTZVl0MZQtGNB573M4Q+9uQC/v6RiwCSLWPk51J6lzFPIZRFCNFxoZucNcNQtA17JS86AQhlTbL5VBUFX+1cwjLW0y1UZcHLABoUQQUwuxaLboinIStDyHVdb/5gdVMrqhBiljEKReKhWTaenifjya27w2QEx3EeWXxgsoq7DxLVzaO061gQ65GuxgLPoaGEyUXDcr0N3K1EQ5Vw0aWdiW95S+Zj2dgeijMJdBnjOeDC+tYphNi9qogCXnw43Qnh4bG/BH7nTkLyOVb22EW7CE/wvZ0uYzu4eqCXJYTowJck63YSFEIeKcAWVyGF0HguIRQctE4U6JwF+DfzWMCWlaoQkmvA4VcAJz8N2PFCNMkylrcbQFr+RnYx6ODQ77Uh8FxI8pmJPu1SkdHePYqk4NwoNgNda7ouPVaPEAoqhDIsYxn5QQAgUbJoq4OlL7d0PHWphQ98/UJYjZEC03a9xZhX1FzpQdnoxfMbmPqKfs6siDLlMX9xZ/TIPdT0CaFClguWIwKUUgixBfC1HCoNRBRC0bbz0TFr6BdtkIWObfnE8757Cv/5h6pvx78wfgF9J3n6dF039h4A4AV7x/C73/1Ccv9SQsjo7xBCg0Az7dCu+VCWMc+yWtQyJqOtWzBtx1PPNAJdxgB/HgcQVwjV54D2oj+XRAmhIgqh1iWymUM3JizHSW1TLAs8Wn0Lpu16AaaZYBlCwgAKIYsFUV85y5hl6hBAxxNazzCFUDBoeBB4VpScMd22XS9DyGWbR6355Ae358lnXp3CF7r74YDD3s5TAIA+BlPkxBDoXNmDAstxPZV4pkII8K/fYRRCuZYxA2MVCVN0oXxssQ3XJX/H6kyfLAgohCghFFRXtPqmRxQFMV1XsNrVPTW9YYeVKEIgVPp3P30C73uI5FimE0JFFEIjsIwVVAjltVr3XouXAKXhvVdF4mFYLhyaiQgUC5XuGvZQajsGPpARqHuk33AKoazPwrRJZmGyZYxd6wYg+qQNCZUm7eIrkuBZG4Ng19z+ySru3DcOgefwjUBXO4AQVJrpxDJLG6oYaTvvbItlrCYLmMcsPnjzbwH3/XjmYz2xghwkhKqA2Ycs8tg9VsH51a1RPJNNwpLXxNIzJLCdEa5ZCiFaj00rtpdz+3zEDiF0lSHRp5kBtjOZVLTZjuvJMRnEaNv5YHiuGljYpiA4ARZWCFESY6wiecx4aoaQXCe79f014PxDqa9fT+gylprTk1TIUCm21u9ivCKFAuKy3wxdwCmNYo8HaJeXHMtYQCHUdqKEkBLIEMoIlc4jhLZJIcSui8cvbqKLSm6GkOU43qJfvWoyhDrxDi/sfNQIGcjuOVud9Iu6Nt3tbTDLWEGFkCD5hFOJDCG2e3/NhkonZK5E83e2RCEEAEab2G4EGRjP7iwWxKLdxMPuzd5YHYVFC+tMgoEWILZWbAzdQRh900nOEBrCMlYocBl+3lyrb3pjAFsYMWVbOFQ6ohBq7iGNE9ZoPkrIMiYXyxBilurpmwAQAiJLIbTUJsdQqHkCJYRUrlzHMNtxvfv4SradX1wNbGpFFUJDEkJsfsrbRbYcF1VqGbMnrgMAvPcTX8YTtMNQCK0FoLELmuVgoc+jo+7GmEbUKR03247zldOrxeowjoNLSaGeq8B2HD9DKG2zimUZshwhSxtcIZRrGTMxXpHQrEjgOZKzwvD0PPmekazB+1SVBCgiH1IIbaYQQlM1GZrpeNemboYVcxznZwht9k2IPAeOA2bqyeegmZkhNELLmGkXyxAq0mmRbRxynNdlTKEZY8GmDUXaznd1C/URWNU9y5jj+rbAgmNxGrI+i6ALo1kRwXHk/RpcukJIFYlC6OhCGzftaiSOtYyc3D9RRU0RccvuBh6JEEIsLH2yJsX+NngtBVXzWwmO41BXRDxeuS/33mbzQGjzUa56pOeByaqXKzVqFM6/C4Kt1To03Dvr/dHf7a25OLdFpNa1gB1C6CqDP1gVOzWsEE3qNOY4cQeRn8fBMoQC7bVLWMZEnsOJgoQQs4B825178K++mRRHiYW70SEs7vWvJcXz0QdiD2lrJiqSEFps+ZaxlMImQyFk9DvFA6UBX/Zdoh2sJPCxTkpRBDOEWjYt2hMVQikZQswylgEvQ2iLWkMynFr2r4uTmxxZ4FjprLtp+/kXuWqv7UKS5zgSKn2OTn7q2Cy5b2zT3wWmCqHdYxVcWOsXIzMYoVfCMsbUR9euZYyc7yzLmOjlno0wQwggBcPKCWDyiBe6WgRs7Eq7Rr2Q4qwChhLSVk4Hvh0kQ49kCFWHaDvPbCxlLGMAWTQyJSMjpHyFUEaGELWTYvmo3ziAQVCKWcZYJg21jFlOeptiSeBxuVWGECLvj3dM1GTBywrJQ5Ak6V3BUOn51cAijNYzh6drGKtIMatHWXiW5hQymIF0GSOLP6N5GADw+DNHPRtSCO0FoLEbC7RDT69xnf8rO/t8/fzfP4Ff+dBTxQ6ezis9qLAdQiICETVbEEwhxHKEzMEVQkUsY+NVCQLPYbwq45l5nxBi3ycphACirgiSlq2+6S3Og5iixM4qtY1FVZwCD69RynrPwPe99CA+9dOvxGwz+T03VDGjy1iBUGlGPrDOXykgWUfFM4Qya6fuqreh5VnGJGIZC86vRWrEnmGNRCGUbBkbsstYxiYxm78rkgBFFHDfYZoJGeoyZoYyRxVJgOuStvJJ6iCAzAvTdcV77bsPTOCxCxuhcXGdhppHIyqi15JpO9tiGQMYGZU/XjPSNUS20lBpADg4tTWEkKe4LquYYrVVl3Z4zlII0d/NVVy0NCsx++n5gB1C6CoDG8AqhRVC6Zax5FBp2mXMyxCiN7BUJQoFs5cpWWcs9q17mji51CnUsYqRGD/48sP4sVcdgSrxyWoeZhmTa8CR15Cw18jztzUrJuH1i7QyCqEK/VWnXMt5vU0WcyVaQiapIKLYCFjG2iZPA6ITFEJpLTmLWMaiHea2CCeXOmgoIvaOV/DkMj0nz3wIOP7JxMdbgQ4CAs9BFvjcgjuG058FTn9uiKOOoECG0LkVspMwNkU7bPTXYwqhO/aNoW/aIZIsFez8lQqVpgqFazRU2rsmM0KlR95ljCmE9A6wfKxUHhjgkw5papRCXavoteXuEEIDIZohNJxlzAHPIVVhEwWzPm/0zYCi1883AHIyhGjgPJaO+o0DGPIsY64LfO43gG/8GVyliQ+fsrzNhiyF0HKbLHQmimx+sIWQbdAupsXIHc10cDN3Ht/Gf+mKKoQWEhRC3/3iA/jCz7262ELTsYEv/nZi5o/X9CDnOiMZQuQz15qHAAC7uHVoF74BPPVB8qDjnyBzlkcIkYWVM0XGI8flsGllL7h7ho2Hz64XOkeeQgiDKoQGzxDyM2rSLWNskTxRlbBO66EjMzUvt0VLUAgBZFOUvX/TdtA17GSFUJ08/0pXh+O4MG039FzMMqbRpinTdcULuU5CdpexAgohu4BC6Mm/w27tVKkModi89I0/A1ZP+a9FN7QY+cUyhIKW7GKh0pa3/hgGfCBUOu0cl4Us8OC5ZOsqmyOYrewtd5LxeNMSyFjtunQTOUAI0eNZ6ehezlUUb7h1Dt9xjx/K/MbbdqFn2PiLr5z3frbWZQqh8JqjGcmjspzt6TIGsCysQQkhqhByXeyfrGKlY4y8wyRbq26pQojGQ8yoZHw6t7o1SqerHTuE0DZipaPjn/3+l72JPwlaQM5YBJ5lLGHgSwqVZrug3uIq2mUMAPQW0sAUQrfvHUNbs7wBLgvRHf+KJKRkCAVyW26+H9i8ACw8HnpIW7NCdjEgpQgPIlEhRF7H1nuenLwQjHYpuxjgL3qzcoQ2+6ZX0HcMG7j1rSRLCYi0nU+wjDlOIULIswtug0LoyGwd99+xG49eJufZ/fBPwPzHf4PX/9aDnn2BIbq7nUoYZuHB/wZ87teHPnYPSYTQ/hcD+18CTF0PADi72kNdEVGb2EV+313xCSGqELp9L7mnnryYrbwDEFAIFd91u+ZDpRO6MulbTQjJ9P7trRKP+cxNpf6cLXbTcq6iBWfyMVBCyHh+Fh7DgnQZ8z9fRSQLgEEsY6SlbfFSiDVH2OyZ3uuxoE2/y1hShhAlhJhCqD0ftosB+Zax1ZPAg78GbJzHU2Ovxk/89WN47MIGrAR7OIMs8J49pFA3TTZX2jrqiohOwTwgzbTxo+KH8evSH1/RtvNLa3FCiOQEFiTa5x8FPvWfgBPxDQxJ4CHwXG7GHekyRs6jJk3AkZuY49bw+pU/g/uxnyEP+tR/Bh74Ka8r5cIGmRflXbcAIMRNO0edpVsODNvBQ6eybUcA4HDMMkZCpXO7jLHrYBQKIYdlCGVbxgD/GlVEHi87Mo1nF9rUTpRs7awpohdizpQOSZmQrBvWasfwarGYZcx1vYVvnnK8WSGvm1hPFVIIFcgQeuCn8Jb+hwZXCFkG8OH/B3j4T/3XonUGs4ipEumCG5xfi7Sd7xn2SKzq/vyO1HNcFhzHoSqLia4Bb8ymn+m3vIDUb7orAXCJOsg2wpaxwOd/MIUQ+r6XHsLPvelm7/8vv34a33T9NN71mRMe2cOax0Q3oaMqHct2UrtGjhrR/KI0pCqEAMDScHCKfC6jVgkl3avF/pAS+p0l8rWAQmhKJu/x3BZZ36527BBC24hji208fG4dj57fSH2MZoV3HPPA/JxJBVhSqDT7vzeJeYRQ3S9OM2xjjElmOyfLnXx5ezQUryIJKZaxrm/FuvFNAMfHbGNt3Yq1AWWfVaqvP0Mh5Bi9Yrum3pvp+JaTglAKKYQM7KLS5K5uAd/xHuAFbye/FBXA0mHRXZyYQkjfBFw7N+ha9NQYW68Qun62jv/3DTfhzfcSSwNn9SH1llBfeRyffnYp9HjTdrzAa4BMvkUIIdd1cXq5g3965jIcrQXX7OHxhK4OAyGJEJq7DfiXn/QIwbOrXRycqoKrUSKnt0qKe7nhPea6mTqqsoAnL20NIeSFSl/jhFDIMmaHSU8hEDpZBJt9E589tuSpImJghO7iE+S+obaboujTzzytmwsjjCoFCCEu2J1uB4XRN8KEEFsAJG2M5MG03Gw1VwRZlrFENainEGKh0rMA6LwcJYQEJZsQotlBl9/6V3jH/HcDIEQMUQiltJ0P3EuFumkyhaJtllQI2TjCzRMiJCeLcCuxvBEnhEqhv0G+pizUFTFfwWo7fqi0xskwa7uwi1vHQecSyUd0HKC3AqydIuHgjd1YpLa+xr5byctDze1mxmqezx1fzn1bTppCKDVUOiFDaABCyHV9siGNaNjsmZ7yji2Wd42puG1PEx3dwvk1v/tPlBypyYJ3jXqL1oSajimEVjt6YnixwHNwXV+tPV7JvldYHZrYhU+QyDyemSHECKGULmO2Begt1J1WIYKEkdKh2rpP7WjMyh4ghJhCSBEFmFbUMlYsQ2gUzSzY0Gu7buo5HgSVlPxGv306eQ22IayDXjOWRsbgSKg0w4Gp4p3/fu5NN2O9Z+IfH70EwLeMRYn5KClDGq1sj0KomRWOHsBm34Qs8OG1aaCb3oHJLSKEiiiuk8CEDZ5lLEMhRO/XcYl8DlsVjn21Y4cQ2kawSWslg0Rhg3nRlH0m2UzqepEcKp3WZawaIIQ2Ul+vQweO62bIgiZ10RVAVCGkygkKIdclhREbYGpTwMGXA89GCCHNjO3+sM8qtUiz9FRCyDV65S1jJRVCSZ2Uoljvmdg7QY4pVmBQhRD7+1iGEPOg51rGWKD41imEWpqJpbaOIzN1yCKP19xB8hBs8DAh4I3Cw/jssTAhZNlhhVAl6fpIwLs+cxKv+a3P4V+9/2H02hvYbLXx1t/7Ep4qQr7kwehm7yiAyEoPTdf8z723Snb9qToIIEXmbXuaBQkhmgFVwjLG8j2qIyigrgSUhHsjOl4I0dyzHLznS2fwA+/5Ol783z6VvFBihO6lR8jXEpYx13XRM7MzhNgYnpmvQAkhwS6YL7WDELSEXI26InrzUxmYthMiTfJQD6hyo62wky1jEYWQIFFSCMkKoYy8NSwfAwC8+0nOK5QNmv+RliEUvJcK5eWFLGNCbkctBs2wcIQjCkm5f7nQ32wF1jYCCmdG7pQBq39Ssl2KbFgQQogs/vquAr0yh73cMg5yi+Bch7xGkHBq7sHCZh/jVQnKLqIy6LlK5kLNdf0Q788eX8q173sKIajUZkj+Nr3tPLlel9Y2yP/Nvp8rVALBDagkQsi0HbR1yyNg2GJ5rqnitj3k/nh6vpXYdh4AqgGFECOEktRg7HlXuwZ0mzw+3LyAnDeWH5KrEKJ1aHqnsVqOZYze5/2NxI66bEHbdDYLESQ8z0GV+PC8FGx24djE1h5QCAk8B0nkYDlOqC4s1GVMt0drGXNcbzNlFIRQM0X5khTL8bVfei3+1auJMg+WTv4FM4QC18mBFIVQEl6wtwmR57BI88HWeiY4DjFLIwkot7x7mHSN3C6FUIb1MQCWzRVqwBPopndwktQ0F7aIECozRwPwLb9FLGMAIFUh2TpmGsqOZWwHWw82UK9kkCi6VWB3OYBaRqi07bheS0cGVjR6i5BghlBlnHyfsavW1oi1iflos8gthmgQciWpoLINwLHCqoyb3wwsP+v7n0EHpchknyjTD8LS4pYxQYLLS5BdvdiuKUNS96kcMCImLVARIIXMbEOBLPAJhBBRCOkpBZE36edaxra+y9gpGjR+/Sz9jCh59jX7Zjxk34o3S4/g5MnjMAPnyoxYNhKvjwR88eQKbpprEKmq0YGuEXLzwaNLOX9ZAKzjXQos28GFtR4OTVXDhFBrwbeEUNy+dxzPzLfyrXoDhUpbqMlC7D6/VpB0b0QzhMSApLwIWIcY1wWOLiTYX9l5vfgw+TpVnBDSLceLNUsjoNlYnGkZo2RjFdpAJMbzGaybVTRnr1kpttMZhWk7pXYf1UBHM5LpxntFcrJlLKIQAvwxIqYQkrNDpVdOAI3d+PqijZkGeT7LzssQIj9vqGIxa5xHCJmEZCvaZWzzotdZq6qNYAweEOstmh1RnR5MIcT+JkUhpBZQCFmOC5XT4bgcNFdEX53FLdx5yLRzG9bPkHqHobEbl1s65hoqUJuGq06gBzVzbLAcF45L2qlfWOvntktmhFAfCmzH9TYFUwkhuoD60MOnCZngmH6uUAmEiIaE2oOROBO08xJTbOxqqrhhrg6R5/DMwqbfgSpGBPsKoVaSrYVClQQ0FBErneRaiudJhhDLL0p6jiCCLcsTIVX8+tq2YnmYPvHrEiVPlBSi1+GY2y7VZCakEGLXcGuekqOupyS3HUKCiTyxjAU5oCQV+Z9+8Qz+/d/6EQ7dLQiVZtf7KCzwYxUp8dwEQ6UZZhsqdk2Ok/9YfWoZiyuEFJFP7TqXBI7jQsex3jUwXpFiY3VDFWEHCLHoJulWooxCaKwSOS8BhdBYVUJTFUdOpjASufAcbdNz7mUIFQiVBrz79eBkdccytoOtBwt+Xu6kS8LLZgj5IYfxSd1x09vOewO+3iaTPC8Usox1dBLqzIrRIgoh3bLzM4SCWUYMN30r+Xry096PNvtWrIMEnxdEnKQQAuBKFVSgoxkd5DLfTBtQynUqKaIQ2ugZGK9KqClCvAikCiHfXx25NjxCKLvLmLf43sIModPL5DwyBRk7ps+L9+EL4n3Y787j09yP4fJH/rP3N9FuH4okoF9Akv/0pU3cd90k3nTbHFS76+3GFZHPZ8J1qWUsfQK5tNGH5bg4OFUDKvRz762RwouFxlLcvq9Jg6VzZKjs76JWtQx0dQvVa9QuBiTfG9HrwW87X+y61UwH41UZishjNSnjrDIOgAM2zgHjB0pZQINhuXkKoSKWsSr0Qv79HfjwbQXh8qURCeYsCsN2IInFi+9geGs/mmWU2GWMEkLBHUp2rycSQhnvYeUY3KkbcGali5vmCNlOAmGd1DbFbO4tlB8E+ApFS6f5LMUIIX71hPd9Tb8yhFBbM2HoVJVRn9saQkgSctvOM4VQHzJ0y0VXmYHIBa4J1iVultjDML4fS20ds02FhIzP3YoN1DJ37lk98MID4wCAZ5PI7wAskHnCEqqhrqdpdYlNM1Qcs+/XZwOESgfJhaTX2ogQMJMBy5gqCbh+to6n51vePRVtwV6VRa+rXWLOSQBTdTmUIaRE5hnHdbHZpzkvOfdLvkKoQnIxbRP4XzcDT3wg/PugEvBjPwP8/svCv6fX4ThahR0DFUkIB7p7CqFFoEvvSVqTuS7JGJUEHqaVrxD65DOL+OA3LqKjEyULyRAanULIdl2PfI42jhkEqYSQZxmLtmCmawSmEBKDGULksfsnq6U334LHsdYzEh0JbE3D5i/TKbdJMQwaquSd0ywQQihyXwUUQgCx043aMsbGuUIZQuceAv7bXmDzUiBDqKhCiHRMOzBVxfkdhdAOthrMz1rEMhad9NIgZ6hjknYNY/aL/oZPJBQghNqahboioqGIUALdS7JgRBVCckKGUBIhxIpmejyu66KVNCiBTOypRZrZjyuEADhCBSqMWCZRJvR26QwhNrCnefUdhwQZTlRl1NWEzAamEGI7ZNFro0s96HkKISFiF9wCsMD0veN08J28Dnjnh/DCt/807nnbv0X//ndjzW1gc95fPBhWVCGUHyp9ZqWDrmHj9n3jeONNExA5ByoMvOzIFB69sDHcItvoAnAzFUJnaIexQ1M1YvNQmsDmeaB1kbQxD4BJjFlGRCpufRvw/Q8AY3sLH2pHt67ZQGkgfm+whQprRw+Uv251i7Qkn64ryWOtOgZ8798B3/Yu4DvfX+p4g5kEaddoz7OMZRTLvACbV1DltIFULc9nRENBGRoFdzqjiI4/eZAEHpLAoW/a0CLdzliOR2hRVkYhRMf6RLgusHICvbEj6Js2bqSEkG7ZcNz0LmnsvRVWwrIw1ZJdxuQ1f0xvmkOS8gNirWtAAR3767NbQggpklBAIeSgzhvoQ4Fm2WjLs6HfG4vPkm9e/UvAOz8MjB/AUkvDHM0R5N76e/hV/kczu/+wMfPOfeQaeiaHELI5cm3aUhVWUCGU8l42TTKvcJbmB7PWZxMfm4WgMjZpM4oRMF6XsYBCCCAdbZ+eb0GzbAg8F2vHXQ9Yxti8n9R2HiCt51e7emIuicBx1DLGMoTyQqXJ71NJO7lOFqXaJskxWT0Z/r2t+/faMx8ieVLBRblHCHVREYvNfRU5oq5m17CtAxe/Tr6fpDZ+uj6QRS6h7Xz89c6t9uC4wKPn16HTzKFRhko7jjvSJhl5CqHYpjsbny2Ntp33x2tGyJWxizE0A8ex0TMSiUbmemDzl2ltn0Ioqk5KQ6tvpRNCtDnGrqZaaE1YBoYVJ29TceEr5FpfOebPu4wIzVUIVT3r22JLG6hBxbWOHUJoG8FuuCxCiIVKF7WMCTwHSeASZb+Oi7hlLJohFGhD6RWnGb570vad+EhnGgpWMtROACFxdMuBEswQSlCAzC/TiSt407JwXYcMpppJOmokEkISn9NlLK4QsgQVFU4vtxuht8tbxnIUQm3dguOSCawmi2inZAjprCVnLEOoqGVs6xVCiy0N41UpPNle9yq84fb9eOOdB1G5519gjZsItduOhggXyWh4gnbtumPfGO6aIX+rciZ+4rU3wHZcfPlkSlBjEbCdhYysKCaLPTRNr9fqJHDha+T7mXBIcUWiUv28nXZRBg5/c6lDvbje9wrnaxHREF4jYTeobJcx1olvui6nj0/Xvw64+53AnheWOt7gdZlOCNGg7xw5vSPVUIVeyL+/Ax/eHBkjhIplIURR1jIGkDGqZ5D21EGl0nhVgiLyYfI32nYe8HPGEhVCKdds5zKgt7AoHwAA3LyLjE+MnEhVCNF7qXDzhAEtY8rGKWy4NWxyDTStIcbfIWA5boAQmiOLAzOHiI/CyxBKfg+qlLH5RGE7LuqCCQ0ydNPBpkhsOsy29cRjdHHe3A1c90o4joulto65Jl2ETh7GhrIvk+BkxzBdV7B/spJLCDGFkCNW4bgubDtbIbSik+uJtzS/e2bEDl0EeURDlICZpNaxXWPkfrltzxiW2zourvcTF4VVGirtBjqEpSmEJmtEIeSprQP3LrGMARt9E5LAZRP68FUsqaSd0iD1IrOuRBsIWEZATewSC2GQDKbXIc+5aLjFQm5j6vtugNQ8/TnylWbm2dRBIAl8nBCKzLWaaXtj2tfPrnsk8WhCpQMKIW10TTLGKhI2exkKoRghFFAI2Xooy5GN8YMQQmMVybMyrnXNRIWQdy3Rx1mOEyM+twpsQzxvEzVZIRTupjfTUAo1GiqDUl3GmPJy/Zz/M0bwF1QI3XNoAgDwS//4ZK5q6rmGHUJoG1GIEGKWsYISUfbYpF0eEiod/hnPc+C5wMQcbFcuVQkJk5Mh1KCD9UxDyWWDmVw4eDMnZcT82eefJt8EyRaOI3kqVELvBQYmWLwUMYNESMoQAmDxKiowirejBQhZUDJUWslRCLFJa7wqk92uJIUQgJ/8C0I4JFrGRDXXasS6FmxlhtDipp5LUPT5KmTLL3CiIcJFMoSevLSJiiTgyEwdvEkIHAUmXnRgDFVZwFdOJweCFgIr4DLO88X1XthPXp0Glo+S7yNdq6pJ7WBHANZlzbPnXYOIWsYSCSGuJCFk2lBEgewGj7g4CVnGUnaQol1M0uBKVdR2FEKl4TVeiBDjRbMQoiAdXcqVQlW6Ex+1jHEch70TFVxY66GtmfgvH3kGhtYnHTOD3QMbdCHIcvsYhIxQaRoofdolf3sTJYTY55HaZYxZxgorhFiXMQM1WYRmOvn5ZwAq7VM45e7BhjiNSTtZXbPVsB0XCg1zRmOOfC2rEvIUQimh0lm1BoXluKjzBnouUQitC7Sz0+67AADj3TPkgbT2Wu0asB3XUwgB+QQnq/lkkcctu5qFLWOQarBsN9BlLPm9LPXJdcPbuk8IRezQRWAGxu0k8oll9rCF8h37xvHNN0zjnoNkYXbrbmLRf+jUamKUQk0RYTkuDNtBq29BFvhUNUGDWiB9hZD/fDxHVCobPRNjFTkcnpv0XGqOQkiphwkhM0oIafHPkz0WCF23Y26xa5hYxgJjYFDlduZzZNyhdY1DM0YJIeRGiLvwebq43vPES18/s1ZMBVsQwVDpjm5BEfnyLcYTMFaRyGZrpG5g83Ms/yioEIpZxsj73D+kQmi9a3iEZ/QxAPDhx+dx/HKbzEnblAvZyLM+UmRbxogzYIbWXKNslOGFSheZo+kciY1z8d8VUgj18fLrp/FTr7sRH/zGJXzg4Qslj/baxg4htI3wLGPtrAwhsjgu41NVUnaskkKlAUAU+IhCiBJCHEd2LAtkCAFkZyqPEPJtTtlt5/UenQijuS2C5O2YZu3+DKIQMniFZAgVVQhZOjmWspYxMVuZc4a2ONzVVFFXE3Zk6aB7YXkdQFKo9Bo5hzkFDNtx2MouY5cDsvc0aFwFku0XR9FQaTUpYyqCJy9u4gV7m2R3KVBESY6B/RNVXNrI6O6RhwKE0FrXxFQtUDR69xDvSbIZGDGQJ8kti7WugZZm4bqZctfj1YSoZczbDQow2YMohIhljOwGjxJFMoSKFsuuXEMFute1bAfFkNQlBvAzhMru6pmRzKoiqHgKITsWcrt/oooL6z187vgy/vRLZ7CwtkHmn+D43NhFvqZZxqLv4at/BDz4awCAJ/VdqMoC9tGulOw6TKuX2XxR3DIW7jIGwLPkZKHeOo1Tzh50pFlMOVeGEDJtBwoXUAgBQxBCq/HzAKIWKNJ2vsYRy5huOljlyPzA7bkLjljBQY7mWtB54zJVX8w2goRQtjrLz8ERcMvuJs6sdBPbbDOYIOfSECqFuowt9ahCyNb8tuXsui2BILmQrBAiYzRrFT9dV/Bn//IlmA1YxngOWGrr+Nbb469fo+NsV7exmdQJKQBVFtA3nEBAdViJ6riul+eYh9yFtNIgG4hMcRxVCNlGXHFlJBNCDSeb7GMgHVoD55NtFgLEthboqOl1GRN4GLYTUgVFQ6XPrhAFyF37x/HohXVP1TUKa1dwfm8H1hfDolmR4Lrx8+N3ck7LENJiodL7J6p49U0zeNVNM6WPY6wiYrNP5qW1FMvY3vEKVInH+x86h1/50FOw7O1TCOVaH0HIupaWpRCihFBDgeOS2nRUKBwqTS3VAID1s+HfiSqQ17UtEAL/E6+9HhVJyM/9fI5hhxDaRrCFQt+0U335pMAsd1qIOqZYqDRApOXeJN1bCVuNcgihtmahrgYUQjk78Ek7/hVZiBUujk5uPFeKqB0EyevGkUUIEZVUOYWQwatQuRIZQszmVDJUWspRCD10ahUiz+GFB8ZRS5Lo02NnUvjYRDb/aIyESAKzFCR1kBgVFltarkJIE2pQHD+0LdpVSpVI0ZYG13Xx9HzLa0nrFVwAYGnYNaZ6bT4HAiOEMqyBpGgMTOzsHpo4HLvWKoGuRKPE6ZVIgPc1iJhCKEEeXJYQ0oIKoa4+Utlv8BymLQq91rk5Kk9OqqIGzQtE3UExpDVeaKgiTNtN3xhIAckQKrcbW5FF9E0buumgEpmv901UcHG9jxOXybik93vx+WfPC4FD3wzsvSf889lbAH0TePbD/s9cF/jUfwSWjgJHXovHNyo4PF3z8wM9QihHIZSwM52IACHEFny5OUL9dVSMVZx090CrzGIWa7Gd+e2AHbSM1WjezaCEkKX5XaICyFQjU1i2iypnQIMMzbSxgjF8wrkXwq3fBq46CYmzYXOSN8cstcl85VnGkJ+JFeyUdcvuJlwXOLbYTn286ZL7xeRV2G5QIZR8vyzSty4whZDcKK2OBvLbzl9uaVBE3lOeRzFWkfD+H3oJPvlTr8Cvvu322O9rgWuUtMZOJxSY+jgpQ4jjONgusbAVsVdKAo+KJHg2nxjkiELIiFxLlg6oTeC2twN3fg/5WYpCqG4XVwj1owqhmZv9/8/c5H3LuozJQkKGUGTTkHVd+mcv2gfNdPD1s0Q9N4qGFqye1SwHHc0aiV0M8NcJ0RwhzSQZg7HNconWrWa8y1hFFvCeH3wxjgyw+TZWkdDSLHQNct0lWcZmGgoe/Q9vwOtumcVKx4DpbG+GEJBhfQSJtXDdhGyuBMsYUKzZUFEkrSET0VkicycQtowBxcLwqWUMIGOBKvHpa8rnKHYIoW1EkARJs41FQyqLIC1QOa0VrcBzpBiwTTLp0DaUAAB1vLBCaKauYL1nZGbS6AmBYGpSKCMdUDpupHBOsIyVUgh57VLjJIUGohAqvCNh5BMFSYjmpETx0OlV3LmfkEENRURHs/CbnziGL58iGQYODberC5QQCl4fa6eBpaf9jmwZYAuDrbKMmbaDlY6OubFsQsjgq1AzCKGKlEHugYTb9U3b2yFHII8IZh97xlUv3HogFMgQWu8Z4a49LIcrYhcDwl2JRonTy+Q4j0w/hxRCCZO/GMgYKAKmEJqqyTBtF63+6AiXXogQSlEI6RYqkpCr8uSVOiqcPnLl2HMdbO6IWvKinVqKIqpQLIKKxKNv2NAsO0ZM7Z+sYqNn4tELGwBALGPR+ac6CfzAA8DEwfDPX/hOYNcdwMd+1p+HtU0yP77yZ4Dv+yBOr3Zx3UzdO2aWqZSXIVRYIcRTe5tteAu+XEJohQTmnnL3wKzuwhRa6GtDkPIDIpQhVKMkvZFOkiQiWP8kBEurEg+tSJcxzkDfVaBbDnqmi3/P/wxw3SvB0c2DrjjmqcZYy/jZMpYxegyyyOO2PWST6tmF9PeqO1SpHO0yllKXXO7asFweokMVQs3diY/LQ5BcSNqMOr/Ww4Gc7k3fdMO0F6IehUcIGVayiiEAlrGTlCEkMMtYn1jGimCyJmMpbfGrNEht4hFCnfDvLRoq/R3vAe785+RnwVomcB3WChJCVTmiru6tEhVSjSpbAvVJsMuYFbGMRc/T+dUuGoqIlxwmdc7T80SxVB9Bl7GqLEAWeKz3DHRH2CQjjRDqp62xWF2vd8gmdMIm8qDHYTsuLq6TmjfNuluRBcw0FGz0TFi2AylP0TIi5HbLg59tlGsZY4TQCK36hbuMrRzzv2cKIZmOGXl2MfYY0183KKJQenPpWscOIbSNCBb+aWGnmhkvMPMgi8lkiOMmW8YkgSeDf59YkELtyjMUQq7roq2ZqCtU2ttQ4ObIAxMVQpJAJKoBIomjctpNOzLgFLWMiXxytwyWx5AwuGtQUOWM4j5oz0pUMlSaLXoTiLO2ZuKpS5t46XWkSKwpIpY7Ov73gyfx+589RR5jkeP77hfN4v47duOG2cDrH/0o+Xrzm3OPw+/WtDWD3HJbh+uGdzmTYAgRQiiS4aFKfKio6egW/tOHn/ak5WyyYZNPaFfN0rCrWcFKx8gN/kyFXoQQMsOycqYQCkiyGYJdiUaJ0ytdyAKPvRMFdj+uUogCD55LIISC2Q4DKoSmab7TSnd0xQkj9ccqUrplzLQLjSm8UiMKoYJtvXdAwD73qAKrSGGbBGOAUOkqVQj1DTt2HPsnSPH5ldOETDCN5C6XiRBE4C2/QzqjfOo/k58FAn11y8bF9T4OT9e8MdPPEMruMla47TzghVuzBV9usDQtxk+5e+A2doPnXPTXLxV/vRHBsl2oLEOIbXTpnfQ/SIK2CdSpNSmREErObAwdh+NAdXXadt5Bz7D8MYHOFS3OVxozy5iXSQegnqMQCnbf2TdRoRaH9Pequ5QQ4ollzFMIpWzoLbV1aJAhOlQhNECgNBDegEraPDy/1h8orJfBVwjZyTknAVRkAXagm1Xwvvfazhe0jAHA9bN1nFxK+cyVBskNYvV0VG1m66SRBOAvXCMKIbNCiJyKtVHoeNRoB18WJ8DOXdAyRjeMxQTLWHTT8OxqDwenq9hDu8eeXCLHGcvhGQAcx2G8SgKg29tBCBkphBAjDdi6SCgxXhY4jrNU0Z11bY1XZWz0DDgutk0hxDZSWH2dhNS1V0QhxGqukSqE7LioIBErx8nXxh6gT/PfGIldSCFUDd2jmTEkz1HsEELbiJ5ue7LYNIVQn8oZy0CVkplM23GRVCMShZCT3J0qgxDSLQem7YYUQkD2ze8rhAIZQnJ4ZxMAeIvciGtGAiFUxDImCcm7dkkdXih6rowqp/t+8zxpeQGiIAlKhkLo4bPrsB0XLz1CzkFdEb3Ygq+cXkVLM7FhkM/ujjkV//t77g5Lap99ANh1e3ynOQFsx4Edx/nVHj759GKp95IF1oUizzJmiDWobt/LZzAsOzTYVyQBluN6xePHnlzAe798Fp9+lrSPZNebVzwHd4DNPnaPk9e/vDngpKRTv36OQmgiyTIWkGQHwboSjRKnl7s4OFVNXQheK2BdToBshVBRZZufIUSuj1HmCDEyYqompyqE+oZdqEskr9RRzVEI/eYnjuG/PvDMYAf7HIWXISSH58lop5aiMK3yodJelzErfq6ZcpFdy7aeoBDKwt67gRf/CPDwn5LOhSy/pbkHSy1Cuu8br0CgDSLYNZmvECrRPEEgylzWRair54xdK8dhcRIuC7vg1EkRbq5fguu6w+W5lYTlkAwhh5eJHQcIL7Lz4LqkDpg6Qv7fTSaE8ixjjgso0KFDgWba6Bm2v3iuEaJqHT4htNTWMVWTQ+NermXMU7kI4DgOB6eqOLOSnnmh2dQy5mUIZbedDxFCrYWBAqWBMAkUJYRc18X51e5AYb0MfoYQtYxlRACwzVbWyCOotuZ50nZ+vWfmtpxnuGG2jlPLneTNCqY4adMaK5gh5Lpko5ONC7TW+NMHn/CIA2ib0NVZdF0FqrlR6HiqwXxO16WREJP+uZsOWMaoQqiIZez8GmnHXVNEjFclnKAk2Ci6jAFkbFrvGehoo8sQYplUSQohNWl+Zk1ZGCE0QoUQADxD1XuMVEvCeEXyiLmyc9KgmKop4DlgJWMd5zf0idwXogKA85Q1W0IIFQ2VXjlB7rldL/B/1ihDCFXChFCK8+a5jB1CaBvRMy1v4ku3jDmlFUJEHZNiGUvNEHJLE0KsOGkGMoSAbHlgmkII8Hc2NdOG4pABZc2MDDh8XCGUlPkziEKo68iosN3E5WPArx8Czn4x9b342TLlCKFoTkoQXz2zBlng8SLaUYPtjkzXFZi2i88fX8Yabf86rUaKjv4GcOGrwE356iAgqBAiz/O+h87ip/7msVLvJQuXN1kOQvbixxJq4OF6BZIRCXVlhBe73j5DiaDjdFeK3TvTKQqh3dSyNrBtjEm7U6yBtkPa24bCAcf2kq+ztyb+DetKNEpc6x3GGIIKR8P2bRAMjPByilrGTIdmCJHzk9XVsSwYeTNZkzNCpa1ihbJcRS2HEPrSqRU8fHaIjnnPQbDPPdpt0e/6U04hRGxfg3UZi7adB+KdaBwzOcMuE6/5JbKI+8yvhhRCXotuutiRBD4QKp1NCA2iEGJjcb5C6ATWlH2QRAkuXXw6q2fw0ScX8M2//pnhMt1KwLKJZcwRFD/rL2rVyQLLD2GZfAkKIUXiQ5tZicfhOJAdHQZPLGMhVQKtt1Ycv45YamkhuxgANFUJhu2kzhueZYwulK6bqWUSQn2HKi3FogohDT1XwZizAXQWB1cIZShP1roGuoY9EoVQz7DyFUKMEKK1ZFAhJHCc1zkwKfg3CTfONaBbjmcHCoFtKLUpoRskhFhdSlUofZ4qby4sevk80DZhSk2sowHVWC90PBVqGXNdlyxuLY1cbxOHgMpkKBTccfxQadcNb1gGLWPM7nRwipyjPWMVb86qjcAyBhBlzHrPROdKKoSihNCIFEKMRHlmnqyrmII0CUHSPo3gHzUEnsNkTcZyxsZZ6mY8x4WUNTVFRE0WRkoImQm5kolYPUmI/GAEikcIFbWM9byNaiWle/dzGTuE0Daip9vYP0kG/rROY4NYxhRJSCxQXBcpXcbITkg6IbSR+DqsKGSh0rN0Qf7548t4ej5NVRRP9GfvjxU6Hd1CjdNguTzWonWj4GcItfomGqqYWPimKoQY4xsNqwbQdSRfXr58FHAd4Mm/TXwfAHwlSkmFEGO2zYRztLDZx64x1ftM2Gf7U6+/ARNVCZ965jJWKSE0qUT+fvkYAJfsKBeARwjRAbbVN/3iYQRgsvddORlClsS82uTzJG2f/XPKdlDmN/rQLRtfOLEMAF5Iq0cIMYVQJENo9xj5+4VBFyF6G+CE1F0F0jEC4eDJ614D/NAnU89FZcQKIct2cH6td013GGNQRCJZf9enT+BDj5HiOVSo82EiMw+aRYL5GSE0ytbz7ByOV6XUTKheQYUQ5Dqq0DMtY62+uaUh8NcidE8hFLWMDUYIkfNVbhHC2jsze2IQE1XJswfdvKtBmxqUUAgBZI65/nXA5adChNA6lfWzBass8NDodZhmMTg4WUVDEb1xsRAEGbBKhEqvHMdl+QCx5EzfjBW3icrZT+GTT1+G446WlM0CazvvCkogE6RYhyYA/mZYBiGkigIMy8kMzbZtF7KrweTVgEIoTAhdtvxFyuWWHrNaM6VEGhkXzcE5PF3DhbVeaqajZkczhMKqzCBc18VSS8fX3FvwcvcbRKU9pEJIpuN8EOdpWPFQhJDsbyC1NCszVJqdA48QCtSlPA+ssY5nBRVC18+Ra4zVJiGwaIEWvX+DhJAd3qh838PkOquh749f/Q3oYh1rbgOyXowQUiUBjkuvjWB9/8qfA37o46FOh7ZL5laJfgbBDY5gnAObg9gG8J5xfywbVQD0RFXCRs8ghNCoFEJlM4R4gYzTzG40YsvYU5daaChi5vUZzK7aLoUQQGrprDE6y50RVdYUaTZUBkkB8InorZFGAsEIlFKWMfoY6ipRUqJYnsvYIYS2ET3DxnhFxlhFSr35QoVDQaQqhFK7jPEwswghSwPM+GKaBRw2aIbQTEOBJHB4z5fO4gff8/XEY0vrMgb4E1Bbs8jCCCrWehG5f8Ay1srY/UlVCHlqjzgh1LZlqNABx/En7aMfI0HUSRgwQyhLIbTZD2fRvOjgBF5x4wzuv2MPXnPzHB48towlKnQZkyJ/zzyzCbk1SWCWMbbA7BoWHLf4QjsPiy0dksClhuYx2IycMzqedD2YGcMsFxfX+/jamTV0DRtTNRnHL5PPf7mtQ+Q5X9YdzRDyFEKDEkIdco5TWteyRVlox53ngQMvSX3KiiyOlBC63NZh2u5QhfTVAlngYVgO3vfQOfzFV8+Tnw3RZUynKsvJqgyOS89rGwR9gwRGV2Ux0zJWaAyXqqhAy1xsb/atLcv8ulbhZQgldBkDstvnJj7fAHNuhWZ1JG3gcBzn7QK/7Mg0OFsnBEVZTN9I5ujFp4DKBCCpPiHEFEJiUCGUXM694sYZPP4f31B4kUueLKwQ6mblXFkGsHYG89IBqJKAmirjn+wXoXnhM/jKcULwbpf0noVKu6JC8lkEpVyGECOExg+QTYGUDCEgvV07QBbUkqPD4lUaKh0giemCZdGqeWTJ5ZaGuUaYNMyzQEYbdhyersNyXFxcjytjHcdFjxJCtlghXcZoHZB0blqaBd1y8CnnXj+ke8gMoaosJFqRAODA1DAKIfK5Lnd02I6beZ2zc7fRj3ds5TkOa3SuKJMhBMCzUIXAFGrMMhbMELLonESJ4vkeOY46p/mEkLYJXWxgzW1CKkgIsXFMM+1wfV+djNnZHRop4YXTBwmhwFzLNlrZZ8c27HiuQK5LQUwEFEKjIpkqkgBJ4JIJobTxXq5tmWVssaVh32TVj6hIQHCTsWzny2EwXVcyVT3ZhFA4jHmmoWTaz8qicJcxbZOsX9l6VlTJvMmOMQ9eHhJ5LyRDaMcytoMtQtewUJEFTNflVEKopWV7oJOgiHziLk9alzGR58juEPPHR0OlgcRdNTZRMQZflQR84Edeiu9+8QEstfXE7i5JXcailrGORwgpniTeQ8Qylk4ICck3L9uVkeMDQsumE4+l+bLe7hJw8eHE1xg0QyjaSSmIjV74Pd0418D7f+jFGKtIeNmRKWz2TTx8kQxQohNZ2K4cIwXveH5+EBAPlWa5EKNiwS+3NMw21NzuSrbEAhRbiYO9Twj18ODRZSgij+968X5cXO+jq1tY6eiYqsv+60QyhOqKiIYqDm4Z09uZtsD1Lisai+8gVSR+pJYxNnkzld61DEkkGUJtzfRIn+B4wUjtIoSQ67pEISTyEAUeE9X0sXYQMMJelfjUtvPdogSDXIMAB5aefJ26rotW39yyroDXKtjnrkYKRL99bnFCyHXdcOBvQVRkAV3Dhmm7ibvNh6arODhVxaHpKmSYMLgBdpvZAu7M50lQJhCwjJHnkwTOG1eSNn8Y8sbkGLxQ6QKWsbXTgGvjorAPqkjI0k8690C0urhVfwwA0De2h9S0bJIh5BFwSr1chhAjhCrjpC5K6TIGpHcZBADOMSHAhiWo6BkW+gmh0mtuA+tdA5t9E8sd3e+aSXEd7R758Ll1uK4bI46j3XcOT5Ma52yCbaxrWF7beVuohLpKJc3/y22ymXKyeS/6Lr12h+wyVpEEmFZ4LLtACaEsG00eGIEwT7OqsurnSlQhFAmV7tKadLZRTNHXVCXsaqo4sZRwjXkZQrS2NHtk8xHwsy2pCsV0gQ4qGBc0n9DWNtEX6lhDA4JWzDbMxqKeYSdv+AZAMkZJhhAQUQgFiDtvvKXXPSOEaoqYSW6UwXhVxlrXgGE5Xs7qsOA4DmMVqbhlDCBOgi0KlQYQu8ejCNaU4jYqhGYa+QohkeeS58mtVggVtYxFCSGl4d+DZRRC9L3sdBnbwZbCNXq4f+FdmFPMVFl7e4BQtbRQ6bQuYwLPEZVIb5XsYgSZcMaoJuQIrdKF8HTdH7ReeGACr7yReDbPrcR91EktAz1CyFMImahyGrquvwPqH6wcajsfI4QufA34yh+kL9AMekwJeTAtiz6X2ScKoeo0IaCOfiT+PEButkwaGNNvJCzsslRP9x4iRN3ji7R4sCKKl5UTwNT1ROpa6DgiCiFaYGa1eC+DxU0t1y4GAC5Ta+kdb7AP7oaMVSTUZAEX1/t48tIGbt87htv3jgMATi51sNzW8SPCR4DFJ+nztEmbZMD7jPaMVQZXCBnt3A5jQMQyloOqLI60m9QStecVLVyvZsgCjw7dkfZ+NqBCyLRduK6/mzlVk0cbKk3tYKx9cfJjrGIWJDqO2CkKBs10YNgOzB2FUAh904YkcLGCuSaL4LiIZax9Gfj7Hwb+5nuBU5+JPZduOXDcuNooD1VJ8K7HpPyhX37zrXj3v7gbsw0VCkxobrlNHgC+8rO/5i3GPUKIzhki7897Iw2XF2Sgcxnqp38RVU7PtozRDmPn+X1QJR43zNWxuetl6Lgq3sCTzZVR56elwWs7z2oapVEuQ4jVPeo4WVgkZQhRi2BW63nJIQsiUalhuU1ywrxcMZpxseY2sdzR8ci5NbgucM+hydBz3LFvDAcmq/jI4/P4jU8cwzf/xoOhTS+/yxg5nsOUQDqdQAi1NAsWBFhCBYIgwHEDGUIJtSNrpT49MY7POXeSHzYGtYyR16nIQmwsO7/Ww2xDKWaxTYEikk6VxxbzQ3u9DKGeAVngQ/Vx8P45WEKxdMNcPcUyRmuIfkDdwxbONlMIkevUtF30UcG4oBPy1TYBs4seX8e624DQWQD+9geBlZOZxxJS3/coiVSbTnys4/oZQkBEIRSoVdnPWTdFjxAaUaA0QGopNp6OKkMIIPk9UYWdVlQhNCJCqK74MRf5hND2ZwgB8EQKafERbO2VSABKlbBCKEdtVBZeqHSKAhaA3wxAHfOvd7nuq/SKdhkDfIVQmuvkOYwdQmibYFgO7sIx3LPwV3ix+wTaCQUWa+seS3LPQVoaemqodDBDqBouQnzffXzHg2VxTNXCqoRD02SBf2Y1Xoj4GUL+AKxGLWN6hkIo0mUsRp589Q+BT/0nTyEUG9AyLGMbFp14zB7JaZi6Hpi9hWbzJEBvk0GjIAHDwHGcZ4uJHUMGIbR/soKZhgId9PdWZJBdOV7YLgbEuzWxXd9RseArHT3UNjcNLiuU9HaodS4Dx3HYN1HFxfU+ji62cfPuBm6kXv3jl9vYaHfxQ/33Ao//NX2eDlAj7VnZYL5rTB08yFRvZ9oCfdtG8YJBlQT0Rzi5sB2YmeeAQkgWeY9s9n4mhK8HnitGCGmRzLKpDDVmGWz2TfzZV86hS3f6VTmdEOoZNqpFCAamWjTi4yZ7TaB4d7XnC9Jy9nieQ0OJdGZ67C9ILtyJTwFf++PY3zCV6iAKIYakY9k/WcVte8Yw21QwznXQ5QZQQIzt97OHqF1nvWegoYgeGSaLvvJwpAsIQQLOPwTuq3+A+5Qz2V3Gzn4REFWcxl4okgBJ4PGud74UX+bvxhvER8DDySRPRgnbs4zRz01uDGYZU8fInNJZij3EVwilj+eSS3MoqnUstfVw58Hdd2Bj32vwsHMjVjsGvnZmHZLA4YUHxkPPwXEc3nLnbnz51Cr+zxdOY61r4MmL/kZdNJ9xoiphrCLhzEr8/W72TDzo3IWLh7+TdpkNK4SidVOH3kPTdQV/Yn0LrFu+HajPpb7fLLDxqyIJsXyj82u9oW3PHMehpoh4Zp6o2g9PpzdaCIZKRxUHPK2VFZEvpby9YbaBk0udeO2ZVEOwsT7S7MS0HfS4KsZ4ahnTyHvp8XV81rkT7vRNwLMfBr72R5nHElLfdy6TH2YQQjznE+tBQshMIoToc++lGULVEQVKA+Faql7SIZGFRIVQWoYQQObk3mgtYxzHeY148pRwwbXAdmcIaabjKeSiaGtW+ro0YhmbrivY7Jsjs1sZtgNJ4LJVrmYPcMyIQqju34OFLGNRhdCOZWwHW4SeYWESdAeD30jMOdDMcFv3okhKQ3ddF05aqDTPk92h3mpcTsoGQTu+q77aMSDwXIzAODhJJuAkqXLSgp8NxiwMk2UIWUIFa5GFIXgx2zK2chyw+qgKNhwX8QBWL1Q60vnFcbFhMkKoT1r7NncTQsxMsRrp2cqRLMgin9hyNcsGx3Ec7jk4AZ3tLgcVQqYGrJ8lORMFIfAcOC5gGTNGSwit90xM1ApM5tSOZWutVDno3okKvnF+HW3Nwk27mjgwWYUs8Dix1IHVWSEPYru3RscvephCaFwdwjLWyVYIdcPBrkVQlQX0R6oQ0sFx8IKTr2XIIh8jbaLXg8jzsAuEn7NxkLUTnqzJcdXhAPjM0cv4D//4FL58ahUVSUgMlv27Ry7iG+fXC7edZyS1oycTQsz6tBMqHUZXT+/i1lClsGXs6APAnruBG17vZ64FwEi94Qih9DJqri5iBhtYF5JtG5ngBWCKEv5NZhkzMF4LLho4P0NolJkTgd3xGVFPt4y5LnD0o8CR16Jly4FFYwUvesP3YhqbeCF3IjWAfdQwbYcohEKWsTKh0hvkqzpGPnNm9wnAzxDKUgiReUit1rHU0sPZkOoY1t/251jEFFY6Or52ZhV37BtPJBbfcuce2I4Lke6Of/WMbx1iYx0jzzmOw+HpGs4mKLVbmonPOHdj/r5fgUDbqwdzYqJjDGtSMlaR8HX3ZnTf8sckJ28AsHqjKoctY7bj4uRSZ6j8IIaaLKJrEOVgpkJIJu9ho2/G8m9YqXwgJ+clitmmgj7tOBhCku3cZIQQs4yR69SyXfS5ChqcRsYveh12uRq+4NwB90e/CNzwRnKvZcyDVTou9k2bqN6lmq+SiIBFSjB1dvD4kyxjSsQyNkolT1AZM8rnTbOMpSpC5RqgU9J1RAohdhxAvkJIlQRvfZTWJGArkNcuPttmF7eMAaPLbjQsJz9QOkjke4RQ06/jS1nGmEJoxzK2gy1Cz7AxyZHCZMZd9XZggvBCm8tmCEl8bAeOzfXpbeedFEKI7qxF7UkAVrs6JqpyjGSqyAJ2NdVEQqiIZaxDLWOuVCtnGXMc0moQQAM9+nqRIs3LEArv1nQNCz3mjTe7RCHU2BOTP4bfTLu0XYxBEriYQqhr2LAdNzPA8J5Dk8kKobXTpCtaJCgwCxzHQeL5gGWMZQgNX6y7rksWKwVUM5xKBmmr3/Y6r0V3Q/ZN+OTgzbsaEAViRXj8wgbQjRBCept0FwC8c3dgsoaVjoGNQcgAo5N5ntd7JiSBQ63EIjLLYjQIljs6Jqvytu4ibRVkgY/ZumK7t3wxhVB015wUhMMTcWzx1dZIDhwjBILj7q9//Cj+5Itn0DPtYu14abg6b+YohHYsYyFs9MzUMbOhimix892aBy49Atz8ZkKcr53xw1wpWND7IF3GGLLsZjPYhMC5uOxOpj4mE0wB6imEzNBuerDt/EgVQqL/GlNiRvD5/KNA6xJwy/3QTTuU6zT1wvvh8hLeIDyc26Z9VLAdFwpngJNoHTOoZUxpkhbd7cXYAryIQkihhFC12kCftjIPXmOMyL+43scTFzfx4sPJ18dNcw285c49+KU334IbZuv4WoAQMmwnZns6MlPH0/Obsc0nNpY0KxIEjhBCQTI72vCCbdYxVYBuDz53+ZYxMTSWPXRqFSsdA6+9eTDlURBsvN0/Wc20TrJ7tZWgEGJ/V1axlJqzFVQISRE1qGcZoxlCtoM+X0GDo13G6HXY4WqQBI4c2y33A62LwMJjqcfCCK+eYRMys7ErtTmGTTeM2WKbjSM8F7GMRUKlZxsqhLQ8mQER3FzbakJIM530DZtgN+IRKYTYcQDk+swDm9vEAQnYQeCTOMmEkG7Z6RsfkTUTO/7NqNtjQBiWUyw/CAgTQnI9kCFUJlSarCXlnS5jO9gq9AwLExxRCE25q4k7bi3NQhNd7NeOEfVHQSgiWeQHF0zs+6T1IpMMo7eWrhCK2pNAGN/pFEXCoekqziZYxhIVQildxnillmoZ00wbuuWEZYutS97NWwcp+mI3cEqodFuz0Ad9r+3L5Hmau7MJISNbOZIFOSH4e6NAi9N7D01AB/3MgyRdyQ5jDKLAeS1FPcvYCKxMHd2C5biFcnV4JUUh1Fn2HrM3sMt34xx5/GuP1PDE2QU0XLrj6xFCcYXQHftIOPoTAYl9Yejt1F01gJy3iapcahexIo+27fxyW39O2MUAcu7ZWHAD7dqSpBAqYp3ydjM9QkhGq2+meuOLwgyMrVVZjAXjA2SsO7fahe243k5tJqhCiDPjO/qAX1BZthu6NwAQK8uQ72komJpfhOltP6ttG7DZT7dVNyuSr749+lHy9Za3EELItYH1M6HHe5axshlCOZYxBrlHbBuX7PFSz++BKkCf7dZxYa0XI90lgffew8gzhCgmhT66mu43oQji6AOkG9eNb4pb+dQx2IdegTfyD0Mvo440Nc8yUxamlyHELGNlQ6U3yN9KKtkgso1YjhDLUsnKRWKWsXrDn0eC10xDESGLPP7vU4uwHBcvPpRMCHEch3d99wvxvfcdxIsPT+KRc+u+1ct0YiqXN9+xC+s9E59+9nLo561AlyCB56lCyJ/3o7UJIwFYQHOS3b0oWL1RkcI10AcfvYiGKuK1t8wO/NwMLFj68FS6XYwcAzkHjpuw6UDn8yKL9iBSCSFR8e8jZrdj46RnGSPXqeW40LgqatDI89CxtYW6d73hxjeRe+3ZB8j/tc1YrVqnHYA7mkUUQs303CfHcSEEuoyxcUSNWPv0SIaQwHPY1VRHniHkvYcRtZ0H4oSQZZNcvnTLWOD6EUZnXWsWVAgB/npgu7uMAUjtDpapqpKqIYUQEzSUae6QBdN28jc+g4SQOgZwPFmreQqhMpaxYIbQjmVsB1uAnmF7lrFxawU9w/YmSoaWZuJP5P+JV332O4DfuYvscBYAu1GDk61DFwtJljFJ4P0MoUqkEMlQCK11jVSLyuHpGs6uFguVViOLqY5uocZp4JU61ntGePFGLWPBgsbDip/103DJa8eKNKMLgAPE8EDc1iz0XLqgXjtFn2R3bHALv5ls5UgWJCFuGfNbOaaram7fO4b/8Z0vIv8JknSrJ8jXqetLHYdIyUDTdrzrZRQseLT7TeYxyBWYrgBH8zOEpjefAn7zBi+/aR/1Wu8dr3jn/Icv/jL+q/ge7z7yCaEWmQQE2RvMb6eE0OMXNsq/GdZ2PgVrXaNUfhBACKFRBqsuPZcIocBk/733HcTrbplFPVJsCjznjWlZ0CO7mWMVCYbtDK3OCo7VFdplDEBI+WBYDk7S9sOpBWcQtPgUrRRCiI4PdztPAr91I1EFAqT4+f9uBx55T+n3MTJ8+r8A772ffP9X3w185N9t20tv9k0vVDmKphrIEDr1IDBxmJAqM9RaG8mHY0HvZUNt1YIKIWY5eqqTvVBNxe47AAC//PkufvtTx6lCyH/vsuDvYo50R7kyAUxeBwCY4Hu4b/P/Ar97V5z4O/UZ4MB9QHUSmunEd5Fv+hYc4i9DaZ8r/tr/9CvA+9860GHbzDIWVAiVyRDqb5BAacDvqhWpw5gdNW08dxwXdZB5qNEc834eJIQ4jsN0TcazCy3saqq4N0UhFMSLD0+io1t4doGQZbplx0iNV944i11NFX/99Quhn7foPdGsSBCo2jK4gRhVCbP31qyQcXgYQoiR6VVZ9GxqPcPCx59axJtv31060D0JjJw4lJEfBITv85hlbFiFUFKjGLYgbewiX5lajdVygp8hpPFVVNweIbSpZazlVjyrFqqTwMGXASc+Sf7/njcDn/zl0MuxuImOblKFUHpnOM8yRj+HoLo21HY+0mUMAH769TfinS87lPrcZRGsG0etEGpppqeGY3VAZoYQgzBahdBYRSrk/mC15XZ2GZtukNdMUwhpVk7uUiAHkZHIaY2TysKwSyiEKuPEat3cR+656iRpFMQyRrOQ2HZ+RyG0gy1AV7c9hVDTXPF+FoS+dgH38sfRnXoBAJfYmApAiQzoQEAhlKBiEHiOTEhm1+8qxsAUQmaCZayjxwKlGQ5O1bBGW6gG4bUVDwxulUhB1dIsVDkdnFyDbkUWb9QyFpQ8e1g54X1bdVMUQmaPBkGHL/W2ZkJjyptVSgg198T8sPHnKuBFTYAs8tCjhFAvgeSKgOM4fPvdB8jnECTpWvOEzEsIy84CI6Z6gWtvFJYxZu8qQpQosoAuVDj9lne+Gr3zAFxgkxSye+lOyk27fEVWQ1/ErcJF7z5Cb42oJJjFS6x4n1FTlXDdTA2Pl1UIuW5ul7GNollJAVQlAabtxkjBQbHyXCKEApP9626dw//5/ntjRDZRNeZ/dnGFEJUv94fbrQqqk6qSECO1AVrUm35eRi5ooH/dbSVeF2yH7Yh7nthDWYeZ9iK5zp/8+4Hey0jQuggsHyX3y/JRYs3aJmRbxiS0dXquO4uE1OA4P4snkiPUYwuEshlCgeI4k/xrLwIAPr8oDTbO3vStwI9+EU/qczi51MF6L0xGB3MmRrp+eNP/AL7/AUBpYozrYVq/RIj36CZV+zIweRgAWTREF/cCJeLkbrHNLQBkDlh6diAFHOsyxolBQqiEQqi9CDSomoN11YrUYXmWMdt1cYgj572+21fwRq+Tg1M17J+s4AM/8tJCi+C7D5Ba7fGLGwBIbRUlNQSew3fesw+fO74cCqDe7JvgOKJM8hVCrucmiimE6HtjC9iopawMGJkeVJ58/ew6eoaNN98xWCv7KJhlLI8QUgPNTeIKIfK1NCFESRhv3AmCbSAyhZDXZSwcKm3ZLnShBtXpkYU03exadxuhhizYfScZw4wucPkp4NI3ko+lb5JruZn++TquS2IEWNt5w28AE5yPoqHSAPCOF+3DK28ssMguiCDBXzZDNQtNVYLr+uM8W1uoqV3GAhuBI7SM/cDLDuFX7r+10GPZ3CZtY5exqZoCnkvPECJkf8pnpjRDYyw7f0k5uYPAtN0SGULj5OsPPAC88mfJ+vbHvgS84B35L8TWdpTcUkQBluPGhBvPZewQQtuEvumHStd00rkiKqmrn/kEAKD9gneSHyS0fk8CmzCCZAgLYE2SkUsCB9mmjK46Fv5lVoZQJ10hdIhKdc9FbGO6ZUPgwy2CmSfayxDSLVShQVDJYLwetI0JEmCb3mfVDE4WgeK+ahNCKK4Q6iSSJiHLGM0h8hVCKZYxS/N3HksiqcsYW6RmZQh5ECthhVCOHDj1aQQOlu2iE5Dwj8Iy5nfeyn8viiiggwpcve0VHhVzgx4MOY/7Egghzuhir7jpK4T0FvnnWKTwF5XQdXvXvnE8fnED613Da9OeC7NHFt+ZGUKDKYQAjCRHyHVdLLf150TLeSBcmDdTikEShJr/XFGFkOdnH5IQCrZLrspCjNR2IiGthQgGatedRDvRTsiOeQa06wlbmDJl3Pkv+3la2w2zT+w07UWgu0wszgk2463ARj89qyyUIRTMyFPqQHNvaBMB8LNSyuZhBC2BWaHSaM3D4UQsWvXQAr0wOA7WzG2e+qytWaH5IiilF0apEKpNA2N7AXUcTa6Hqr1Bfh4MWXbDjSmSur9xzb0AAKUftjBlwugAVr9w/ROE5bhQODOcIWR2AafguMuyBIF0hZBXbyU/p+24OMLNQxfqmJw74P08aiP9w3e+CJ/4yVcUDlVmtRe7vnXL8dRKQXzPSw5iuq7g7b//JTzwxDz9GxN1RQTPc0Qh5BKFUDVBXQ6QcynyXOrvy4CR6VWZbIq4rus1WJgu0JW0CJhl7FDOZ8nznEeihYgW+JunZVrOA3kKIWoZ9BRCyV3GLMeBzlehOF30DAt2h4zxq2j4CiGAqB0tjagf4ZLxLECcMmWt1Vkh43MjwzLmki7E0QwhVeJD6rEkQmjUEAXeIxJGqRBiBBk7N5pBN2y22TJ2z6FJvONF+wo91iOE8lQxI4TAc5isyVhOCYLuG3b4OgxCHSPXJBURsPPYGrLmYjAsO98y1t/wjwUAJg7638/cFMrESwU79wHLGDAcGX6tYYcQ2iYEFUKS3UMdvZjneObiP+GkswfCgXvJDwoTQvG2kUwiyacohFSLSldTCaFwca+ZNtq6lTqBswX8/EZ44a0nJMRzHEdCdung3Ov3IcOCVKGEULDTGC8CjumpqUK7B8vHgXFScKlOWoZQL5YfBBAyrs9CpZkVo7E7RyHUj1nPiiKpy9hGkg0uDRGyI08OnPo0PA/TcUIhodttGVNEHh2XEEKs0FQ9QojcI9N1Bb/+jtvxzpce9P/Q7KFpr+OWZoCwW6dWBKVByLqAsu3O/eNYbut4/W9/Hv/yfQ8XeyNspyOry1jB8OwgPEJoBDlCm30Thu08ZxRCktclB6m5BCQINf861VMUQrFsspJg3XF+/FVH8K0BmwMbc6NFQ6EMIakKi1cwwbU961IQjBCa42iQbJQQch3g2P8t+1ZGA0aazz9Kj8Umoc1bDI1280kbM8dohpCTlJE3fWPIZgz4odJVqWSotBy3QCeivQDU5+CCD3WIKgO2u82ONbibHiyURxoqzaCOoeF2ULdpLdIKqGWMLlE6VKdgUXVcjFijpEqlFCFE59+CCukgSNt5AzwjhBixXzRYmnUbBaiqg8tQCCWP5RYlhDZrh9CsSN7jo59NU5WKjRMUFUkAz8Gbu3XLTtw53zWm4hM/+QrMNlT8/SMXydvS/IYcTCFk2q4XdB2tATST5Kwwsn44y1hYNWk5LgxKEo0qJ4V9jodyMoQAfy6OfnZMlbovpzV4FIzA6CblZCkRhVDMMsZCpV3oQhWCa0OBSQgdZQx9iw+pmryuskdpjpDRDl2fPM+hrojg2M8yFEJ+l7Gw4k0RhUiodNwythUguYzlyfks1Lx8JzKX9vMUodLWWMbKgEVIbMl4noHpupIZKp2qhGVrSLpebYzYMmbaLiQx57MINgMYFAlt54HRbJhfK9ghhEaN3hrw4Z8gF+j8Y8D//XnAcdA3bExybTh0wJnj1sOEUH8ds2sP45POPag2aRFblBCSmGUsoBBy0hVCIs+j4tCFb4wQYqHSYWKHWYImU1ptM99olOQ6t9pNDFIbq0hY65LBx+yTSVKi3adCyilqGWNFUKiAWjkO7CPkmWqT9xO7eY1uotojpBDavEjsV5JKJgTH8jqbhbBFCqFihJAasYwtZE72aZCYQihECA1PUpRVCHWhgjM6vqVQpyqIQOH+z+89gN1j9Nqh1jDOdfCmmfXAC5+lT9qgKiqfLGLB0isdHc8stIpl+LC8iRRCyLQdrHaN0mRMUgjxoFiist7Z5wghxBYdDbqDnYSyCiG2+zsyyxhd1PzMG2/CS66biim+4oRQgaKW42AqE7kKoV1MIcSUCkwVJDf84OTtBtvpDlrFImTLViAxSy6AiaoMxwVanQ5RD8YIofCO+sCWsaBCSMz429Y8+LE9uGG2jq+fHYwQio4ZwY48cqBQHmmoNIM6hprbRdOhtUhQIdSj12F1KjAmReZHuYY2qqhSVbSHJ/8OeOS9ya/Jrq2CGYpBsLbzfNAyBhTLETI1oL/mb7QIElCfjR2H33Y+xTJmu7ien8dm7TA4jvM+k7LXWBQcRxb7bO42LCd1136yJmP3mOqNS62+6dVobKFp2j6BFyOELBvKiAghRi6wz820Hc+GMaoumTN1GXVFzGw5z8Dm4uhnN1GVcHi6Vvo8RVUoIbDa01MIRS1jLFTagSkQMqsGDVZ7GahOxrs7sa6yxz/u/yxig22oIqTeIv1PukKIdRkTvbbzvkLIDLWdD4dKbxXGqxLqsliqWUceGgqzL5Fzk58htDWWsTJgNfR2d5DNIoT+//beO062rC73ftYOlUPnfHKcmTP5TGZmmMAAM+AgSUCiIFwFAcVX8RrQe6++er2voveKyhUQFUQkgwiSEYYJh8kzJ+fQp3N35bzfP9ZaO9Wu6ordfbp/38/nfE53dXXV7qpde631rOf3/OqWjMnYEbFe9WkKArqCZK3OlE1SLNdpO3/6J8D3/4RnbumhxpxAtZBjxtRzwNd+DQFVhPdvoBwhEoQ6zekfA49/Enj2C8BDfwk88tfA+Z8inS+iF0lUBngd6TBbcNZYzp2AYpTxuLELoZgIGGxQEJIXarsYUq4TKq2pDMFKcw4h2Ra6v4YgFKlRN3roYhJ7R6tV2+2DYRyf4RO/Uo7/rwmHkCNbSZSMpcWk2LSTZheA9DSvqVZ00/GUc4sbxbRnwnwyV0ICIZQufyUwfj2w/238By6V2PlYubYcQl6CkK422L7T7hAqF3mZRisOIVVBqQsOoYUG8pAkfp07hFghZbqmfAWx6K2V91DKc0cEAFx8FoA4ry8+w/8PD1Y5hK4cj+O9d+/E++/dhXLFwPOTDXSuKdR3CE0lcjAMYLynOWFQvsed6DQm67zXi0NIDvb1Ahe5INSAQ8i1m9kpQahYNqCrzJysugU+92e70V3Oor8XfSzhyPSSyNKQkVoOoZ33WOf/SiMdQg5B6Ij3fTvI4jJltjLba2leOFJCtrDe+DgXnG0BmNkWQ6Udbed9daZRyUkgOoobt/XhwKkFRylGo7ivGe4uY5JuOYRClRR6ZJmuyETiBybOw1A/pkRJ7ki8+po0p/QjWrCVNhoG8K0PAT/5iPdzFsX704pDqFxBwFEy1oRDKCUX0bZxNTrq4RCqHypdzi5hhC0gGeHZSlK474TzIRrQzcWtl/vajk9TzDlhIluyOYSY+P2yeUxVJWMFLkRIQcidf9gMpXIFjFk77vYsvU4tet9xx3Z86d23NiSKys+u+7X71RftxmffdUvTzy3npJ4LYDmPiIhOambJmGw7b2UIFTQuCEVYFkZ6Fgj1I1csO0vbQn1c5M4uAH4xd59xXncjfg1+0d2wboaQ6DLmMx1CYjNFdzmEivw8q7VZ0yl6Qr6OdhgDbGKdeG+kaFdT3HCESrchLrSB2XZ+BbuMAVxI9BQ1wYW0mg4xl0MI4AaBzpWM1eky9uSngO//ER+X3GvZZmGMrxWf/Rxw4GPoK5wH0JkN80sFEoQ6jdyJeu4LwBHRDeDQV1HMJuBjZbDRKwEAI5h3WupEV4Gi3gPmi/D2kk07hOwlY/z/WqHSwXINQUjV+HO7HEKzws3TX6NkzKuOOpEr4txCFntHqhfXO4ciODadQqViwBCvmR7k97OLFbztvN0hJC7kMgtiYA8QiMNXFJ03PB1C1TbiVL4IRVGhvubjwC9+B7jn9yAOgv/vlSNUyrbsEPLqMraY4TbuhnZEtIAl0qWmABgtlowxFMuGQ3TrRGvFxUwBsYDWUGcEv6YghQCUYsrcwdTzYtFbSxCyLeJQSPIaYQA48xP+/+CeKoeQpir4tfv24LX7NwEAnj3fwOdJPn+NDCFZEmk6lxrEDCHuwGs9s84cQnKhUKuVOGB1x1sO+6QWAOJictXu5KRUrji6OJmLQrGQqhaEGpvYVoL96KtRMpYwS8akQ0gKQvP8/OzbxhexDQhlHUcK5hdEqKk/VrUw6QaLywjPMtsrvSAcKeEB64dmFxFL7JdiS0Nd4Ww02nZeZr1dt7kXqXwJJ2eb6HglSLsWmr01M4S6IwgFyin0ySB/u1smI67ZNkFoOFY9Ps4rA4gWZ6wbLjzBQ8ld7dxNTIdQ84KQ4QrrNUsIGgmWls8XcwlCruMImCX6NT53ogNoMsq7tA3FOicIcYcQ/wzUcwgBYhNKjK9L2aLZMcwShOwOIVeXMREQLsWCdruM6YolLhXLFVvJWGeWILGAjp1Dtcu87ZglY66MlpBPa2mTxa8p0BRWI0NIzCP8cT4/kWKnnF+bJWOWQyiCLFiWl7vmSx6d+2TZ2KYb+eN6OIS4I49ZpWoe1C4ZU6pCpeudZ53ius09uHZzT0cf0yznE9dQGci+x2NNAsCVIbQ6gtANW/tw285+bGqydLFdQj7Nc8OyWK6gXDEaLhkD+DnYuZKxOl3G5AbF+Z+2LwgBjqZBkbLs5kgOIaJV5E7UyR/yhWugBzj4NTBhr1akIMQWXIIQ/zBV/DGuVAbiHQqVrr6/pjCEK2JgCvZ43CFQXTImHEIDNUKlfZoCv+a0CR65yCdhXoLQrqEossUyzi9mURGvmV84hBxlZ4p0CPHbZE2wOQgO7AICcehFUTLmVnMLGU9BKJ0vI+xTq8UYj0UDAB5KWS605RByX1gS2WJj5WKA0yFkTlybD5XWVQWlcnccQr013GNu/JqKlBGCWkybz63mlnEIFdPO7+Wk6NwBQA9za7TLISQZjQfQH/bh6UZCXZcpGbuwyAWnRqzpdqRA0JmSMf43DqwTQcgsGauzO9h423nhEBKPGfFpUFj7GUKliuHIuzBzRMT76RZ7G138VYJ96K1TMhZBBhEmzmlZrpOZ4zvF0TFe3pqeqfrdriMF89wSz1oYv77rDqFUvoRFUZraE/S+1siS5uyiEITsJWMeeTLZQhl+TWlaTPFritmhqWYpRT7J5wDRUVwxzoWJ5y404FJ04RaRex0OIeu4O9p2XhKII1BcRA/zcO3YHEIXl2oLQovaAHrKNoeQLHPMznuLmWaGUPMlY+b1Xzqd5XveiCAkn89eZhMbrToOTeUCQC2HEBOCUDoqHUKyZKx990MkYJWM5UuVqmBkO/Yy9UTOKhmTm4SGYY1LXl3G7A6h9krGKtBUZp6fpbKBokf32ZXCLBnrUAkUY8zxvjiQgqQ/yuehUuwsS4eQLBkzUNQsQUjNzQPhgWqHEGDNfQb38Pmv67obCeiIFKa5a7pOMHLFMKAwq+181hYebd98yXt0D+wG7793Nz7y89d39DEjrpKxh0/MYc9wtGb0BfTuhEo3w/bBCD71jputtc4KEfarnjlYy4aKm4LQonlTNKBXNU1qFe7OriUIifFo4WSHBCFLhAuXFgFQhhDRDnnbhM8X4a3v5o9jaJ5b61l8E4xAHPuUk4hOPQKceZg7P8y2eeKkDvZYyenL4NV2vl6otKYqCBs1MoQAIT7kua1ViA9zyziEAKedGQAOXkzCjwIuj4pBMLtg7iruGuYTtWPTloXfH+aDZ5VDyCgjnStAtXWIwOwRruD3bBGCUC2HUO0uY54lKrUcQtKd02qGkG23TrKYLTQhCNkcQubEtZWSMe60sF/4OxMq3XjQckBXkEYAWtEqGVNzYre5lrW/4BKEZBvpUhYY2AkoSpVDSMIYw5UT8eYcQrUEoSUpCDV3HgQ76BBK5kpmC+H1gBzsY8uUjNlt7LVwO4QUhSEe1DtQMua0Lbs7DckFkxQWGi1BYmHhEMqXgMUzjp8tZYsYVRb58/fu4gvwUt7q7CSdDMkL/Dp96sdVXbS6hv36GBvli5PZo7ym3y7KZhcbHsfq8fEfncQN/+PbODPPxQLPkrHEJPp8/P3IJ4VI5hCExGSvYIn92WK5JeeGbIzAd9gZkJq2rlELp/kGgk243zEYgU9TWhKEpFi4XbTUrtllrBslBsEeaGXbe52oIQgl8tBVhj6PMSCpD6CnPM9fn9M/AZ7/Mv+BUXEsIgDw101ew1twCLnbeVsZQuK6vnjW2XEsPQvkEs7ncziExvi8xTUfCOhqTYeQOncERUNFNsJdrCNxPlZEOiEI+a2yjlqh0hK/rppju33zyS5+yuuUe26SK5YR0DrkECob0BSrvXmxXLFKxpYLi+0CtRxC7WDPdgKAo1Mup7E/wq8/8tpTygNM4Y58cJGsJAShMMtByy+IDKE6DqGB3SIXrdohFCvOLZsxaQpCsu28XRByOIQ8juESIWorGSuWK/jp6QXcvL2v9i/ItYLqBzqYZXQpEPJpnqXrWdecqgqvkrGgjkSHHEJKKYM+Q2wYZ+adRgm7Y7XDDqFgiT8nlYwRrZNP8c5YsXFgz0uBK34WAHDN9Ff4z0P9QN923K8+igef+EXg4y8GHv6IeZKzQA+/XxMOIaumvdFQaeEQUjTPfB3TIfTTTwB/dRNQLmEuVYBfUxCuM3mOunZJDk0m8HuBz2DkU3fzRcK/vAn4/NsBADsH+UD55NlFBMEXEIFQFIx5CEIAcrm809EzcwTo38kH1EAcakHa+9wZQrUcQiWE/R5/i+kQcgtCcuexRYeQR8nYUjMOIT1YbaVvxSGk8OPoRqh0I4HSgGw7H4BWSqNQLAMwoGRlyVgtQcjl2IoOc/cdwMsGgZoOIYDnCR2dTi0fLC0F3ZolY1n0hJrrDgNYk1Cv0qBmkZP1ToYvriZyYl6r5TzgXXLphRSEA7bJfqcEIc3LISSeTy68ZIB+oyKDEhpAnGXQf+orwF9eCyStbkxL2SJ2BfnCIjd0Db8xedEShKSTITEJ/OPPAn9/P/CRW/gCtpsYhtNBGR0DhvdxF98nXgL8+MPWz77wTuBLv9TW082l8vjzbx1Btlg2O3XF3deaYg7461sw9Mj/CwCopKzAYxM5DtjE5Uyh3PRnWRLUVQQ0BaxSBv72DuDbf8AnrP9nP/DoR4G5Y/yO8QnoqoI9w1E834ogJK7VL7uKZxHZ2zI7BKFuXA9sk+x8dLOzRDEzx8vLA3FMJXIYigY8c0aSvgGoqABffT8/P+aOAptuth7Djv28aiFDSJVikpzY2zOEcgn+3jzxj9YvfOrVwJffbT2fFrTGFcAmutqyk8A//1V5hQJl8RTOGoNQRcDpz+3fhL96w3XV52wL2J0oy5aMCYeQYRhIF8oI+Z0lYwDM+ZxX2/mgT3WUebVKqcLFdPtjdTpDqBkCpkOow4KQWAAfODWPF/35D/lnPTbGz6lgL59TmF3Gco4uVsVyBSUfFy/H2By0cs7MEKpyZoxeLf6/Chjczc/bnHVdifo19Jdn+BqkDrJkzJ4hxBh3HRYdGULlrgdKd4uwLcrimfNLyBTKuGl7f+1fkJsGqxQovZqEfSoK5UrVtUDOqZovGeuMQ+hdmb/FByZ/nX/zubcBX/pl/rVsAuA+jnaIDANbbgMABIv876GSMaJ18km+K/WObwMP/BkfEMb3Y0v2Wf7zUB/Y6/4Z78Dv4e93/iWvAV46B+QWUYIKf0hMYJoqGat2CFklY95dxsJGmj+H1yRSOoSWzgH5JaCQxGyqgIGIv+4iNOJ3XgQOTy7hfuURsOwC8MxngVM/Amb5JLk37MNAxIfP/fQcQuC7eswXQdinIWVXqRU+icrnck4L5ewRbpcFgEAcihCEqnbtCt6h0ulCyTGxNpEDgrtkTApEHewytpgpNt6+PDIksoPAHQGqz7nYaRBNdBlL50tQRIvPTlgiF9JFz91hL/yagpzhB4OBUjGPGDJgFSGU1MwQEhMpJi5ZoX7r75c7ZlqwqtRRcsVYDOWKgaNTy2R4SEGoxuAyuZhrOj8IsAShhjqdLcOlvGPnhZyQ1ssQ8nuUXHqRK5WhKsyRZRUP6mYYcauUyoajJMftEJILnFdeO4FfuG1bw5k0WpRn3Axc/BEv/xLBtoVSBdliGdv8/HzMDolFQHKSd3eyO4QWTvEOX0NXAJVi97N8ykXeZl4SGwWufj3wtm9wx6Y96Hr2MHdltMGHv33ULEV+/PQCFObhtjj5AyC7AP3wV+FXASMthAbZAQWwygFs5afZQp2wzGUI+lS+WDvzE/6+TD4FTB/k5SDPfgE48u+8E9w4L4O4YiyG5y4swWig9NGOdAi98roJfPZdtzjG4JXIEJIk4nudJYoi+BaM4eJSznTCuEn7RaDuc18AtrwAeNu/A7d/gN/mFoSkWMeUlgQhXcwDEBQuAJ/NIZSa4uPDhSetX5g9Chz5Jt+ISE7yblD2OU5IZFBlbAsP8M9/zZKxfAIJhM33ozfswwNXNe/m9SLic5eMLRMqXapUBe07HUK12877NVuXsbZCpQ1HyVixbLWdX+nW2oC9ZKw7DqFTc3zuOJ8uANe8AXjPo1yM9oWteWW54BAdShUDSf8YDKbiOkVcv0P9yBQ8BKFttwPv+Skwdq0195mznKExP8MmYxLo31H3mCuiy5huE4Q0hYm8PmeG0EqUjHUDXeUdr1L5Eh45wT/DN26r5xAS669VKhdbTaRg7I41sHef80QL8PWII1RaM5titEWpgNuLD6G3JMacpfN8nAWqxwe7kN8qr/l74HWfAvQQ/AVyCBHtUkjxSUhsDAiI+uG9D1g/FxP5g4Fr8bTvaiAyyCdFuSUkEUZULoqaEYRkqLRtYV+/ZIwhYqRqK6q6WFjLwSufwjPnF7F9sNppY8edUh+YegK9FbFb/a3fA2DwD7EYbHYORXB+MYttsgmZL8TrWD0cQvlC3hKESnm+CJKDYbAHSt7DIVSpCIeQd9t5zxrdmiVj7TmEdM256wI06RCKjvIJbbnEHQHuiWuDaKqCYoWHSof9GgI2W3k7NFMy5tcV5MDvaxSz6GU2EahQQxCS52LPZv6/QxASwqAe8A4DB9AX5pOvZZ0iuSU+wNUQ/s4vZpvuMAYAIb1zXcYu5QmaF41kCPn1xgShfLF6kRQP+dp3CLkyhHSVQWGWAC3F3v1be/F7L7+8YfeWHhsEAAwuiHBmcc2X9febtUUAQKr/Kv7zxAW+OA0NAOEhvnA+9SNefrOPu1G73v5dfhal2BId5U7NLbcAI1daJQyGwa9VDY5jXhybTuLTj57BG2/ejKCuYi7Ny2yrnCiHvgYAYKmLeEHgFJTsHJ8g2if2ng6hUnsOIV21MnFmD1uv/blHeWnUrheZC7/Lx2JYyBQxueQtWtciIybkIQ9Hq8+RIdRdQWghKsZbR5YVvwZPJXIY8cgPAoCMXwTbVkrA1T8HbLnV6rpUSxDq2czL8MrNfW6DRSvoGoDlEMonreeS52cuwedr5Txw7NtmALgD+Tiu46x3PWLFDDKGvyvvRyRgLxmrE7YKLngUSmXzOKWIbReEpJPx+4en8dtffMYUK3OlcscyhIpCTLeXjJXKFUfXxpWkK4KQzbklM/4K5TK//sg5ix6ydRnLOQShYqkCpvvBerfiRiEIlQJ9SOZK3nk3AzvF/+IzadsEGDNm4WdFlPt31z3msugyppnvi2Fupri7jF3KG1ARv45kvoSnzy1i20AYA3ViL8zNY3VjOoQAVOUImaWEtVxijPGx1lb+GwvonXEInfpPRJGBr5Ll67lCClg6awn4AHcnA51xCIUH+Lwm1G8JQpQhRLRMPmlNQiSXvRwAUIJm1rSb4klowBSElhC2cjQ6FCrtJQipCkMEmdofIOkQEoPXzNwMjkylcPuuAe/7C7hDiF9MMoUSXlB+GGWmATtfZJUxVIrm5GqX6ArxwF6hCPkiCPs1pArVglAun7fK1eZP8B1qWSokXivGXDtdcuHi83AI5UveC9BaodJtO4RUx6RqOplDMldCf4NBzIiN8kVfesZsZdwKusLMUOmIXxPOC6dIMbmU9Q5ItFEqV/Dy//0j/NvTkyiUKkgXyg2XjPlUmyBUyKJPtjT2x5fvMiazg+yC0KA4D+o4hMwuePllBqnsYt2BZXKpPYdQJzKEcqXK+hKEGsgQ8mtqQ4uSvMdrEw+23wKVB6NawyVjDH5NtTmE+PW22VwKPcKvqfEcb3Eq83Zk16ZxdRFLRgjZ6Fb+84VTfFIU6uMiTGSYC0IAsPNePpHtdvt3eS3sF4sS+yJ6YDe/PpeL/JpfzrclCP3R1w8h5FPxq/fuxo4hmaHjumZWysChr/NxRtHwEu0A9PxCtYPSFIScXcaabTkvCflUBDQmxCjG/94zD/OvAf53X/Yy8/5XjPFxrtmysYzZYbN6vOp6hpDtWjgdFtdee7e7UD8Mw8DFRM4zUBoA8iEh/jAF2HM//7qG0OK8zhuWK7bRwy0uiscXLgDNz3evvQQh+w7zoX/jQpd7XJWP4zrOgKbW7M7JihmkEeiKYyvi15AulFGuGLxkrE4pj990CDl3+L1Kxr753BQ+9cgZTCW4WztXcHYZa2fTiJeMWU4UWTK2GuViQBczhMTcV3YBrRqvfBFbhlDBWTImyuowsBubGA/ETyj8s1e3WUfvVh79YLvmj5V5Fl0mtr3uMZcrBncI2ZyvKmN8jmgLlc6tUKh0t4j4VaRyJUwlcstnP8oxQludDmOriXQIuWMN5KZX3XHStV6NBjTHtadlxGaLAoM7e2WkxNwxKz9o253WMXSKUB/0/CIAKhkj2kGWjNkZ2IWz6iYk1Zjp6jDb8oX6gcw8jOwSlipBK0ejyZKx+5WHsff4x/gND/1vhI/xHVOvMVdXGKJI1xGERIaQmJw9fZwvVu7YPVj3OKIB3RQS5lIFvEj5KWYGbuS2WQDo5V035ETs527YhPfevROX9YsLjR7iEx53lzEAxYKtZGxG7MLaSsZYKYeYVnbauE1ByKvtfAlhr51h6RByZ9a0myGkOUvG/uGh02AMePnVDeYAybyQ5AV+IWxREDJLxgrcIeVVivP6jz6MD3+r/qJyNlXAM+eX8LEfnbA6/zQobmmqgiLj72ulmMWgKi7yvVvqZAjJhYJYhEpBiClAn5j41HEISfFv2VaYuaWan4t0voSlbLHpDmOA1ZWoE13GeOeR9XPpbsgh5CFceuH12sSDmnmOtopXp4uArlgOoTI/tmYXOSzsEtnFNf+581w02Kwv4qLRh5wa5dceWY4lF9TRUV7WC8YF8v6dvAzm4FeBH/xpU8fSMPK62rfDOgbJwG7uBFk4ZS2480vOIN8G+dbzU/juoWm8566d6I/4sUPkzlWVFp59lJfRXfMGYNsdeEHpYQSK9QQhW5exFkOlAZ5Fcrlymu9YXvEKfuORb3CXVO82LkTsfJF5/z0jXBA6PFVD9K6BdBV6lSHqtnO92w6hyYC49v7H7wDf+W9mt7tkvoRMoYyRuPeuejkwgJKhAJtv4TuwQG1BSJ5b8jrfZLC0zH1wvPf+KH/P5XOlZ7iYJc/P3m3887J4tjqI136cJ38onM7Oz74bpZhBFv6uCELyGpkulJAv1R8HZCOLfNHlELJtEro7n8nGCzkRZtyJUGleMqbYBCGjfuegLmNlCHVO5Ig6HEJcEKpaSPpCvLTrHx4E5o87S8ZE8DYGLVfPAvg6ou6moarz6/DsEeC5LwLf/2MM5bkglAhvq3vMFcOAyhgUUSYGwOYQquAnx+dwYiZllg9eqkj31kwqj8F67iDAGSq9wTAdQq5g6exyJWNA1XpVjtFttZ6vVIBD/8bHDkA4OsXYOXvUun5v74Yg1A8tz92mVDJGtE4h5Vmi9HHfz+M7Pa81vzdrjkN9QGYOlewiloyw1fkqEOfdNmRnqTr4NQVvUr+Nq09/gtv0f/i/ED/6JQC1HEIKYsjA8DfmEDp4+gKGon7sGfbuvCSJBjSz1GEmmcU2dhG5wWuA3S8Brvl54O7f4XcUH+R943H82n17wIoZAAzQgwj7XIKQygfDfL5g7ZCe/AHPgxjcy78XF4IBLeschOXEX68hCHmWjHXLIcRQKPOAx0yhhH965DTuu3wYWwfql+GZyInq0jm+AJE25CbRVBkqXRaCUHWG0Ewyj3ML3sKKRDoYHj+ziJ+e5u6vRh1CAFBWxOtYzGFQFWJP79blu4xd9Vpg/9t5VslVrwVe+FvWxEoLcueYR5mB5RCqPUD959EZJBbnaucHtdhhDLC6EnVKELqUd+zcmKHSdconfQ1mCHk5hHqCPiRypaazW+zIXW47doeQXDA13UbZLVqISdXT5xcR9WvoMZYwa8RRrBjA8BW8tMX+e9Kd07OJLzgGdnHB/Pt/DDz6t80dS6PIa+H2O/l1Xe7QAdaCZuawczFv777ZADPJPD74+adx+WgMb7uNL2xkI4Ie93kid8cn9gN7X4bR8gVsLxypLQjZru3ZQuuC0N17h3DfiLwuvY7/n1vijsV7fhe4+3etsnHwa5BPU5p2q2WLvHynVoMISXcyhHoAACkjgCk2CFz7Ri7C/+jP+VgU6sdUnZbzAOD3+fBX5VfAuP3XrRt9IX69Ts867yyv/zL/pMnW86HSIspQnNfwYB9/Hrv4NHvUOj/v+T1e7rjtDuCyB50PGIhzB0ZmDnj6s8CP/wLIJxHQvVs0AwArppE2uucQAnjXsGLZqOty8akKDMMa86R45BWOL3lGCkIiSFgR3cHayRAqliuOLmOlcgWF1XQI6Z13CIVt2U4ziRqC0L5XAZtuBE78ADj3mDlvMQwDpQoXzcwSMABzZX69612uFF+2nv/e/wv84E8wuvQEZowYllB/vl4xDPMcle+FpirQVIZixcB7P/ME/s93jyFfbD1nbS0g3VuzyUL9cjGAC2yqz1x3bCTk+sp9XVu27Tzg6RAC2hSEzv8USF3EfxoiPzFlC/afPcyD/rUgn39c9xZgx12tP5ebUL/Z+ZgcQkTreDmEAPyHcRN+MvwG8/uIrLEM9ZuCUAIha5dcBmTllp9Ia6qCHcoFBEpJYPp5XstZ5pM0z0mkyhBjaVT8saqf8TsEHBlCpy5cxO27Bpet95a7JIZhYHFxEQoz4Iv08MnfKz7CdwgBZ6tAgC/2fWGAMYT9qjNUWpSMFYt5RPyqUI2/Duy61xJnxGs1oOWcDqGCt0PIMIw6JWPdyRCyOmwY+OZzF7GYKeIdt9e39DqQDqEzD/NAQlkm1SS6wlCsyJIxVWQhWK+ZYRjIFstYWMZRcTFhlWa9/1+eRMin4uqJnoaPo6Lx984oZTGgiHO8dys/58oeg4gMgh3eB7zsz3i5zPY7gTt/w/bHSZGpWsyyd5uoxR989XmcnZxE2ef9uTi/yP/mVhxCAC8xyTRZMvbIiTnPrg+NhhZfCkgRZTmHUCO71N4OIR3lirFsGaSbZK6IN/zfh3FmLmMuauw4HUKtlYyZ4beCzz/0HP750TN45nwCV4zHoOcXMI8oz3TY+4AlrNgdQoCzFfHCSWDq2drll+0iP1/hIX5dD9uEF1nSOXvEuZhvsmzs9778LJL5Ej78umvM13THkBCE3MKzfOxgr1mSFEGmWhCSYr+ry1ir4uq77tyBl18ucpQGdlljw8Buvvi77b1VvxMLNN+ON52vnXPkcziEujCdE8LKAqJIFQzgwb8CXvV3vHy5mBYt5+sLQkGfij8vvRqFrXc6fyDc0Q4K7TmEQqVFLLGYM18vNirC2O2CkO383P1i4E1fBN78JWDTDc4HZEwc56y1Iz13DLuGIjh8Mel5TVJKWWTh78r7ERHXyIU0FxXrOTfkuSEFSHldtG8SaqL7V1BXsbU/hGfP89Bz+6aDV0OMZihVuBtIltwWyhUUSxVH/tVKEvTx4+hoyVhAQ0aU8s2kapSM7Xkp8JavclEIMEUHWZ6lK8y8jpehYLrEP0/9keUEod1c4Jw9DBgVDF34Lk4YY8uOd+UKzDm9FOsUxkvICqUKZpJ5zKYLl/wGVMSvYyqZQ7ZYxmC0AeePL7whS8Zk12V36/mWBCG/dAi1Uap/6KuAouErZblutI0Fs0f4OjI2yuf9P/OXLW+SexLqNzsfU4YQ0Tr5VHWGEGR4pfWBMi2moX6gXICavICEEbI5hHr4/7agrppkFzHExP1EzSUTziKvNrCawhBHGmV/j/fjmQ4hvlvHCilct6XGfW1E/BoMA0gXykgscddIKGL7vcgQAFadDi8FIfCFu7NkjE+AioUcr3EVqjH2WtkMctLap7odQmLi78oQyhbLqBjwdghpNQShdh1Ctm4ds0kutlw2WkOQ8yI8yF+LE9/n3w+0JgjJwEC5yHCXjBXKFVQM3gGtHtNiEbB9IIx8qYI/e+3V2NRXndVUi4q05Baz6GcpbtGNjoiD8HAJFdK8fLDeQC1EJq8cIZ/GJ771JkmLmQKC5RROprwXX3InvFZ46nIEdBW5JhxC5xYy+LmPPoyvP+P8vMjAz/XCtkEe9ChLgrzgbpzGHEJ+jwwhoIFAcRenZjN46Pgcnj6/yINRXTvaHXEIaT6kwT83hhZEYnEO/+e7x3BwMoGrJnqg5+YxZ8RQrFTMLDoANoeQSxCyC8WlnLe42i7SYaN7CKOBGBep7A4MoClB6DsHp/Dvz17E++7Zhd02V+rOoRoOodwSd634IkBsFBciPGTScIltUFR+fbcJQu2UjAGwlSVHbEGvu2rePdZCO95soVxTALa7LLrSsMkXAZiCJRazxuXRq4H4Jv51eAAXl7kuSiGiqsQq3F8/VFrRm3YIhctLZvaKSXSMn4vpORGALnK2EpM8t86jpNyBFK7k+TxzBLfsGECmUMZT5xad9zUMqKV0VzOEAGA2zed39UrG5M/kLr1c0NmFbU3hztXbdvbjus29eOb8EoplAxXDmbXTXqh0BZpqtTcvlQ1x2+o6hDrdZQzgbiw5N6o5XskmM2K+IgOcuUOIXzsSiGA+w9+3ZR1Cg3sACPdrsA8MBo5Xxpa9znCHEP9azk81hTkcZAvpglk+eKkSDWg4O8+v08s6hABeUbABS8Y66RCSbu+WO40ZBnDwazC23o7zFTHXMdeNzCoZkxvlnSY0AJZPQEOJSsaINsgnAQ/nTaZQdnQJifptGUIAlFIGCYStshtpeW5kIj1rtZw0u62U+YRB9XD1+IwCAqy4vENI7NZFkOV1zIbB2+ramT8BFPkAKMWsVK6EVEIIQjFb219V56JQLYcQPAQhuYtSKPBBV6jG2HWfdR/xWvUqGaeaK4UFVwmfFAU8286rGn9Od8lYu13GZP28aCcNAIFmJiSKAkRGuAMMsBYfTR8H73aWLshQaedCO1fgXy/nEJpK5KEqDB998/X4xFtvwEv2NZdpZIjXUSnl0ceS/HMgnXVezoZCZvmJey13lyBqaw1bdTyGgcVMETGWwRPTFc+WwnLnr6FdJg/CPq1mmYEXMuDT3ZUo24arYS2yYzCCA79zb13nlV9Taoa42vHK1YiLa6rcVW8UWSaRL1pdcew4HEJSEGphkZHSejClDCIf6EeMpXF+MYtCqYKrRsPQCktYMIRDaGCXJQTLLBY5ITIdQi4xolbXvnYwxXH+fv3ld47inx4+bf18YLewdDfvEMoUSvi9Lz+HXUMR/KLLQbmln2fMjfe6zhOZ+yXGunMj9/Cbfb2owhdCp7qMAbBeC1/Iem/qiPVmdmANyhWjagKaKZTN3Vs3clxRlS51bFIUwB9DUolb4zJj1qI21I9Tc2moCqv5+ZXXqqrPb8hDEJJOUH+UizfJi2iIhVNAPoVweQlJtyAkHULpGT7/6N8pHEKT1ZlBXsjjlOfz7BHcvL0PjAEPHRPHX8zxuVApD2ZUkDECjoV1p5AuyrkUH5/rlowJ91Ay73QIqa4ywz/62Svxmy/Zi33jcUwn8zgjFs/y/u0KQqWyAV1RbN2sKlVdG1eSQBdKxuT7Mp3IIV1wbhJUITczxeZWUXTd1VUGBHuR1vswU4liVmQRVTki3chr/ug1vIwewDFjvAGHkGGuD+zXEbvIPC8dQpdyhpBfg8zIbtghtAHbzpsOoaq28yJUuhFBSJTlWyVjLTqEZg4D88dR2v0A0hDjihSEBvfwUOmFU41dv1tBNBPYxGbhT53tznOsQUgQ6iSyLZ5LgOCTvApCujXxlCnsxYA1aU0YYauDiikILS7/vPauMpNPAbAcQl67VCGDD/i1SmPcGUJh5PhxnX8c+MjNwLHv8PsV0sBHbgUe+zsAlp05lS8ik+TH7Qu6niM6Wu0QKmbMnB/eRaO6y1ilVOA7uce+C2y5DQj22P4gLqpNsFnk7JNpcyfb6VyRZUOeghDAFzpddAhli2X4bBbqhpEOmvCQ1fK5STRFQalSEW3n1aqwXilWLWaKdTNXphI5DEb82DkUxV17h5o+DkPswLBSFj0sxf8eKQjVcggtJwjJz12NvBJ7a1g36UIZpUoFcZbBdCloZiTZmU3lEfFrLYsx9Z7fi4U0n/S7xblLvetHKzSaIZTzaDu/WTjXTs6lvX6lJsWyLAermGUPdpxdxmyT+iZJhzfjidI2pFkYMWTM3dir+vnnj5eMib/9yldzV4N0kMrMnrFr+P/9u/jnQJbcdKNszHVd/eyBs/jXA7ZJ0+BevnGwcMpsCtCoIPQX3zmK84tZ/OHPXlm1YPNrKr71a3fgzbdsdf6SKwh+cetLUDBUJIIT1U/gC5vHX6kYyLVbfinHBS0IjF3LN4P6tte8ezSgmzl7XvzND47jxX/+Q8dt6UKpKvxXIs+3ruQHSXq3YEpzlaBc8Urxs604Np3Clv5QzQW2vFZVOYS8BCEp1ukhPtl3bx55UcgAf3M78IM/QbS8hKTinnOM8e6msyJXamgvnyclzjfWnCHUx+8rO6XOHkFPyIcrxmJ46LjIQHr4r4C/foF5nme6FCodEaUY8w04hKySMZEhpFe3ndcUhgeuGsWu4SiunOCfoQOneKmEfN90VWkrQ6hU4Q4hc1OsYqBYWv0uY50MSpZu85Oz1hhTUxDq38GvFZFhADaHkHhfFnr24bQxjMNTScSD+vKv08Bu/nnZ9yrzc/lMZduypakV0WUMcApCdgfZ/HooGbOVojckCMUnWm7aciljOoTytRxCy4RKlwvmxrnpEGpVEBKVELntL0JSCkLSobnlVv5cyUmrsUWnEWvK/8/3N3jD079gCl3rHRKEOsjDh88AMKoyhGQbP/sunxQjMlqPeVsCIfSGW3EIHUYBGs75rQ+HdAh5hUoHy3yRUNJrhM65uoxFWJbbVtMz/OfPf0k871EefD1/HIClCidyJeTT4rjdeUqxsepcgELKcgj5NOTEjjz/A/hjaigj6mN8Ujd6lfP3+7YDPZtxU+kxV4aQLBlzCgkyRb+2IBTquEPI3q2DOzxa+OhJNbzF/CCA50flixUkskXEAjrPELJN1KUgVChXqnYK7Ewl8xiOtW6rNWzlXWHk+Hniq+MQKjYgCPWJrhpzxz1/bG8N62YxU0AABegoIWGEPUvmZlMFDCxXz1+HiL++O8DNvBCC5G6wJFe8tC3creDXVJQqBsqV+gOzV6j09sEwVIXhaJPdnUxBqFThJWOuTBB/hxxCB1/wF/hA4V24mPejV8ngHS/YjvGeIDYF+DVowYjyUGkAeMGvAe95jDsZAWD8euDXDvIFBsCdKr/yUx62DtTu2tcOtpIxwzAwncjj+EzaEpB33svvc/I/LWGqgXHs8MUkPvafJ/Ha/RO4cVuf531G48HqxYlLENIHd+IF+b80nUIO9LApOMvNg7ZLxlQffz9uehd/7etsGiznEHr4xBxOzWWcIn2hjFCNBZkcV7rSYUzy5i/jM/FfcG7UbL4J+NXngU034th0ygz89kIKbllPh1CNDCE95L155MWJ7/FNgKlnEa0sIaW6S8bERsriaf6cO+/ljzv5tBXKXo9QP7B4xvpebMDdumMAT5xZ5I0CJp/iY5RwEWXg78p7IueQckxwl8faqZUh5HYISeR7KLvg2Z007ZWMyS5jwiFU4m3nO+nQaYZuhErLueQJmyBUt9TkTV8CXvbnAGDOdeUG4fE7PoxfLf4ynj2fQF8jnVv9UeBXHgdueTew+SZk3/MMHjP21s1LBICyYTmEpHtLU5jjnJDxCpfyfMM+z2+oZOw1f89zKjcYchx0z/utioY646TcoM8uAuhAqPTSWUALoBAcQdoQ46l0aF73ZuCdPwDe8V3g9g+09vjLIQSh69gRhEsLjY1D64BL91O+BvnXhw7xL1wZQmbbWNvEs1dc6BcMSzBJGGGrXrjJkrHzyjjO61vNm5RybYdQoMInxKW6DqGcad+OIMtL2eRC4NDXeRthWaomBJ6oLbi3kBYuDXeeUnS0OhegkDFzfuSER9puZcmYxsoYKE8D5byjEwMAYWF/Oa7KP2EJUYBNEHIeg7RQe2YIAV13COWKZce50DBmeUjtjIplj0NVkC2WUaoY2NofrioZs3fBqlc2Np3IYajFLB0AprCmlnMIIcff/7olY+kqp1cV9kBbDyJ+DckaDp3FTBFx8PMlgRAWPfJmZpN59DcyoahBNFBbkPJCOoTkbrCEBydfujt2reDXG2t/nPcIlfZrPDD1SFuCUK0uY5aLCGhtkbFnyzjSCOJc1ocBLYtfe9FufO/XXwgmFssOh5CqAdFh5wO4F7XREWuC1hWHkLwWhrCQKaJQrvDsDFHigO13cnHXKHM3BtDQOPbZA2ehKgy/9dLLmjselyDUF/JhGr1YyHh81nxhU3SQ43J7glDWKlWVJdF1iC6TIXToIn+/5tPWtbdeyZimVi/yO06wF3og4mz2AADxcRTLFZyey5j5Tl7IxWRVGW6oH8gvObtCFlJctFMUa/Noud3Zg7xMHtOHEK4kkXYLQvbPR6ifdz1lKj8/G3IIDVhfj1zFNxzKJdy0rQ+FcgVPn1usmgtlutRlTIa1zonzo15mmZkhlHdmCDkdQtbvx4M6NIWZHUbl++ZTG3Nn1qJUqUBXmGMOtJpt56Uo0LdcNk8TyAXwiRlLgK87VgV7zA0uKfbL8WWwfxAphHB+MduYIATwzUKFv7+B/k3QFLZsuU65YnUZ89UoGZNcyvMN+d4oDI29noHY8puP6xBdBMxXZwhx8dYrj9bEtV6N+DQwhqYbKJgkJ4HoKIoVIOV2CPlj3BE9cX33wr/dDSlmDnfnedYYJAh1kPGgOPld2Txy4hm22b4HxaA0VbYmUlk1bO1+NiUIHcEFbQLn1E3mTWaGkMc7HCrzQSuv1XEIFTO8kwiAMBMlY1IQyswCZx/hORGAKfDIDKFkroSS7I7mEmMQG+XWa7vgYisHkmq+aVsUJWM+lDCcFzkVbkEIAPY+AB1F7Ek+4nxcoCpUWjqEanY10kOd7zJmdwgVa4eE1sUdINsC9lyDbYPhmiVjABdJnjm35LnTdTGRazlcGQDgExlC5TwCyPP3X4qHNUvGai86+GOGgPjmuoJQLUFmKcvzgwAIh1C1GDabyrflEIoGtKYGSOkQsi8OAZ5pcylbuFtBLm6WC/jzcggBwO7hKI5MNeeWKZT4RL1Q5o5Fd4lnQLdyjeTkX2+hsxAXZhUkjBDiLANFLp5EOY2ZIdQM0m3XlQwhyyFkL608Pi1eX80P7HoR/3pgNwDW0Dj22Kl5XLOpx9wsaRiXICS78sjMLwe2DCEpfrf1WWpEqLYRDeg1d03n0wXMCFHN7grMNFAy1lWHEEQpt4eYfnoujVLFWEYQkiVjbkFIuMDsZWNFa3MI0VG+KVWjBBgAD00/8u9c4ElegIoKUjbXtfk45nP28+fdehv/vtEMIcn2O3n52eJpXDnOz7nnzy/wTAuAl5YBSHepy5gUBuWY4K/j3GjWIaQoDH1hH85LQUizwpfbKhkrG9BUZooK+WJZtJ1fnQyhqybi+NqvvMAskesEspRPloypCmv4NTMdQuJ8Geux5lXLBkp7wBhrqDzdMOBdMubxvqwHh1B/pDtlnOuJsE/17DK2bN6pa72qKAwRn2Zee5omeRGIjaFYriAPHRWmWXlytbJvO4m45pekRGLP6V3HXLqf8jXIsJ+f/GXdXaLEL8x2V8iAqGWdzvvMsijD3vVLD/L8heUm0qUCMH8SF/XNOKOIzITIiOkQ8ioZG9T5gD+Vr+F20Jy39yg5PrmwiySH/s1aeIsPqj1DyJCCkPvDK10udgteIW1mCIXdgpBZMlZCX/YUv81LENl8MzJaL24pPmztptfKEGrIIeQqGStmuVupxUmeWT9frrQeCuwOkG0B+yR124AUhGyh0rZJ+9HpJB78qx/hM486Q9VyxTIWM8W2SsaYcFop5RyCRpa//2YGUA2HkK+BhdfArtqCUKB2qPNipoiY3SHkWTKWb8xyXINoQDfPvUYwHUI2capcMVAob7ySMZ8pCNWfZHu1nQe4IHR6Lu0ZFl4LM1RalIzpSn2HkK6y+rtoNdBUBXtGolhCGGHDlnMkFspml7FmqOe2A4BcAvjkz/Dslb+5Hfjkyx33/f7h6WoB4PxPgS/+F6sMzS0I2XbHcZkITo2N8zFgmXEslS/huQsJq1Tsqc8A3/3DZf9M/rcsWZlKAMbiQUT9Gp6/4CEk+CKm89VyCLUZKu3Vba0GUdGeuuSxWDx00TreOZdDaLmSMbUbLedtVDV7EBwTImAjDiHPkjEA+IcHgaf/lX9tz4qTzp5ared/9GHgb27jG0z7XmnenHU7hCLDvAsdYIlQMti3kS41DkHohfz/mcMYigUwEPFj8vRhnmkBmPOabJccQprKW8TPpRroMibODZnjYQpC9rbzrmPsj/hxboHPfZwlY6132pEdxeR5kDcdl6szhjHGsG+8c2IQYAl1R6dT0BSG/rCv4XbVRSH26+L9iQd1c8Owv1lxXLBcaSrAS8bk22/PIpObGnbnZL3SxLWOnOe3M3fbKIQ8Gp80lCFldsW2tZ4PiDGjmAP+8ZV8nvHD/9XYgSQuANERMQdjKGkh7iYFPLt4dxwxThzQrkNWCddcU6w3NtaqossM+vmkIGk4J4hyImR3CMmL02y6YE44WNA2SDFW1crPk/kTgFHGlH8LDqjXADe8A9jzUiiV2iVjwwqfeJ7M1pjIak7nR1wVO61SJNlyG3Dwq8CM+JCkpoFy0VTiFzNFMLNbiIdDCHB2DylWO4TM3Q1ZMoYy4ulT3L4tJ3V2FBVzvVdhNztnLaCzi3wxojgvZtL6XsuG71kyVsq17A4CbCVj0iHUSpnCznuBG98JbL6l5eOQA380oKE/7INfV50ZQraSsQOnFlAxgGfOO89BuYvdTskYEyKdVskjYEiHkFzEthgqDfB8pdmjPODdRd0MoWzB5hAKVZXLlcoVLGSKbU0qIn6ej1VscOdwXnTFmre5BaRDZuM5hPjfu2zJWB2HUMWwFrCNUJRiT6liBqPa4V3GyuZ9m245b+OykRgSRhi+csZqFZ/hgbWLiCzrEDoxk8J00haELq+7tTKEDn8dOPkDfi1VfcDJH5qTnmfOLeGtn3gMn3rktPN3jvwH8NQ/8zFHCwCKiumE5cI5PmMTs/bcD9z4LmD3i/k4JrIFavH46QWUKwZu2NrHt65/8CfAE/9Y93dMcosOh5CiMFwxHsPT5z3GTt1yCMlsv/ZLxppzCAHw3L0/fNES5OxlollXh1I7chG5Wg4h+XnaUSdDqGao9JYX8BDcxKSVS2jbHDKzf2q1nn/281wMuubneX6KION2CKkab8QAWOLOVa/lcyXpFKqHnG/oIWDkav71Et8kuWIshtykrfOqCMFOdylUGuAbGzKrJh6s3Q1JuoekMCAX9fbrmOq6pg1EfKaLNeizuowVm3Uo2ihVuJgur49yDFwtQagbjMQCuGoijsVMEYNRPwK62rhDSHYZE+cLYwyjcT63atotKYj69cZKxlxdxuxt5y8btTZzL+X5hoyyaLU77EYi7Pd2CC27XvGoaDFdavPHgePf4R2Sn/rM8gdhGGbJmJzvlXUxviha1fq0K6g6cNdv47Oh12NS22RVw6xz1s8VeQ3Qr4kd/aLzIu7lEOoJ6lAVhtlU3pykaKEe5wMGe5adSMtJ/GxgCxYrAeCB/w+IDEEt5wEYng6hWGkOBUPD0VQth5DzAxdjQhyRIsmVr+YBjTMHRbcrA0hNmWLOmfkMIshwm5/7wyvt2/buITb3h+UQkhlCVslYJHmirjvGiI5imM2bggUyc57ikRQFZD1+FXrY2yHUYn4Q4HQ45FotGQv3A/f/aWNOmRrIspftA2EwxsySMRkIa9/FfercIgDnzjUA0xUw3IYgpOs+lKBALefgN7LLZwjZOtHVZWAXv6+w7tuJBOpnCEmHUNkfq3IISYv+QBuTClmi2GiOkCxbSxfKpvAgF1XLWnjXGY2XjHk7hPaM8AnF0enGS6jsGUIlj8yLKodQG+/JvvEYEhCfa1kik5mH4YugAH1ZEfHtnzyAD335OesG6bbzKr8EuKAfHQXe+EXgvv/BbxOTuS8/yT87T55ddP6OLO2ZP266Yi6Ka8HekajTIaQHgfv/p8gzWn5j47FT81AYcN2WXmDmEBedGimXLhX4593mEAKAqyZ6cHAyUS0g2jKEpChT0ynaCMVM0w4hwDts89Bk0hwXZMmYYRjIFMs1RSt9JTKEwBcK6UK5qvPksekUxuKBuq+h2Xbe/dmNDAKv+QTPgpDzAbvwb84VajiEckvcsfOKjwBDl/OyMQA5vaf6vnIjSgpCwV4+Vwo04BSRvxMd4V8runm8V4zFEFw6Yd1X3J7tUqg0wBe4yVwJY/EALhupXT7hU/nrIQUeOWYodRxC9g0PKcL71Pbbzmuiq6qmMORLZXE9XT/lO5qq4F/eeQveeutWvPr6CdEVszFXldllzDa+jIqysb5wbcGvHrGgZnaX86Iicouko1XOTxWFmcdxuV0QuoTnG7JyoZ1y/42Ct0OoUj9QGvDsim02UZHzhqHLGgtnzi7wDXhRMgbYBCFfhJslVoI7fwOng5fjnLaJSsaI5unVuRAxW3RexLMe4ZWyXns2aTmE9IhLvGjEISQEoYXQFmsxL0q+/Ch6ThSV5CTmlD6cmc9W/cz++wCQZiGEmdh5Lma4wLP3ZQDE4267g/+fmISqMIR9Kk7NpRFGDiUtXP3hlZM8eWGolPmHXyxgpGsn5coQ0lBGYOmY1WbZAzU+hj6WwtySWPRl5oBQP358bNbcDQa4QKewOnXRXiVjpVxbyrR0h2UK5dYzhDqAnABuG+CTbr+moGLwXTzAKQgdmuSv45GplKPEYUq4AtopGfPrCvLwwVfJwW/k+fuv6vw19so9sXWiq4sUDD0snlG/hkKp4jlRW8oW0a/xzwMLxqsyhGQeyWCbXcaAxjsv2EvFpCBltQC9dHfsWkGKPFUuAxvlioFi2fAMwNzSH4auMhy+2IRDyGw7X/bc0bY7hAptOoReff0mvOrWK/g3clKVmYMhxoZ6O/S5Yhmn5tI4cHrBWrDXDWjPAMe+A+x9gJfAygDq3BLKFQNffZovap866xp75MRu7oTpiplK5NAX9uGy0ZiVIeQm0OM5jj1xZgFfeuI8soUyfnBkBvvG4/wzIkOCixku+NRDimeuhf2V43EUSpXqIHFf2HQIyc9Uw8GtXjRZMhYzO3FW794fmkrimk090FVmlozlSxWUK0bNsrYVaTsPnpFSrhhVn7/jM2nsqFMuBtTJEJJEx6z5gL00WJaM1VpE5BYtIVDzA71bAQBZL0FIzjvsAdGNYgpCY/zzYut+dsVYHNtx3ooJkA6hLpWMAdYC94GrRuuWqMpFfjJbFNkw0gViXafcx2gvUepclzErLyigcxG9sM4cQgDf8P39n7kCH7hvD89davA1k+OM3bk1GufXlL5wa3OsWECv2/K7LMYJL4eQdCrtGYma0/dLeb4RIYdQw4T9qmeXsWUjCjwdQjrfgJXzhuF9fB6fS3g8gA15vY+OVgtC7q7VXcavKTirTPBjamSD6hJnfV2RV5m4EE6m8y6HkEeoNMB3Y6RDKA8dkYhrYtWoIBTfhGA4ZgV4CeGiShA6/1PTjpf0DeL0fNrjAeEojZpDD8KGEEfk5DcyBGy6id+27U7+vy1Y+tRsBlGWheEVAhyI88VEYpJfGJ77Ir9dLDCqQqUVLggNswWouYW6DiF/3zj/3RmReZOZQ0brwc//3SP42lPWpDKVLyHi18BqKc1eodJNTvzdmN3T8iWeIdROmUIbyIF/2wB/b8ygRzF5sU/apUhUKFVwas46V2RpylC0dYHMr6nIw4dwRQwOsuzCFwEuPgucfcz5C7ZOdHUZ2MP/9xCEIm73mY3FTAGDek4cSm9Vl7FZsWPfboYQYHW5W46FdMEU3Ta6INRIhpBVTlc9rOmqgonekJmP0QiFsnX+87bz1RlCpYqBUpkvcNppYxz0qbhyx2b+jbzmC0EbgGfmjOTsfAaGwUs5zy+K65YUV/NJYPEskJyyfuHE94BS1spRkZO57CIeOTmHqUQe12zqwfnFrOW2lMcD8Fp+cS2cSuQxFPVjx2AYF5ZynmVFtcaxP/y3g3j/vzyJ6//Ht5A+/zx+dfwQ8PyXgWc/Z93J/XvTB51lcPLnLkHoKhEY6y53hS/MS5QNw8zoGihNAamZ6uNuhGKmpZIxtyhsGAaOTSWxZySKvrDPzIjx2kyyY1/IdZOeED9udynt2YUMtvTX//vNtvOFWoLQCJCa4qWSxYzlbtODXPDxEoQqFT5/sL/vYm7g6RCKuhxCzSB/R7qMYqMOh9AO5QLmont5TlGiu23nAWsce9lV9fOPzFDpXNHhmrTHTbmDr+1dNM0uY1rj5U9elCqG+Tx+jYvoxXJ7Avpax6c13pnNzBCyvReyZKxVh1A8qNcN9C27HELyXLULh+O9QfSIksRLeb4hyyrbaoKyQQj5qkuDG8oQ0vx83ejKEErlikCal75jeB//3+t6np4FFkSJunSExsbMxh7mWnIVBKFTjK8rMXtsRZ97NVi/V+RVIKLwBeXFnFP4yRaqS8YAbmGcTeVh9O/E6cowb+1up1FBaGAX+kI+LGSK3ApqcwiZ9uDpQ8D/vRs4/O9A4gLywWGcmauxOLI5hKaNHgQMWTJmm/xe9RpewrPjLv69+BBHAhouLGURRs77w8uY1Xr+J/8H+Pzb+e1iN9AsGSs4HUI7mLCU922v+VJEBviCKjcvyoUy85it8AuJfbdECkI16YJDyHSH5EvIFSur5xASu1DbBoVDSAY9CqFBTtrlTqEcRA/Z8i3MkrtaXdoawK8ryBo+xKQgJN0/8XFeb/zxF3PrKMBdApViYw6h8ABfRHgIQvLc8irZWswUMaDmAD2EcIi307YzKxbG7QhCsTrlIm7KFQOL2aKZzWEJQqJk7BKeoLVCIxlC8rWpFbTaF/ZVdWyrR6EqQ6jaIQRwkapdhxB/QEuYAQBk5sCkQ6hS2yEk80QAV5mXP8oFoc/9AvD1D1i3H/waf66tL3A+b24JPzg8A5+q4NdexBfXT5+zPV5m3vraFIRyGI4FsFU4Ds/Me4wpHuNYpWLg4GQC12zqwdUTPfi3vg/jrqc+AHz2zbxkbOxa85hMykXgo3cBD/1v6zbppnIJQpv7QogFNDx9zjV+6iHePbOUw3ymCMaA+FffBnzzv1YfdyO0ECoNVF8DUvkS0oUyxnuC6A/7zZKxTLExQajbDiHporJ/fpK5IhYzRUz01heEzLbztT67sVH+nqSnRdt52+P1bPZu+VtIAjCc7/umGzCFfhhe78fwFbxMzCt/cDl8ISA2wcvSAIdDaHNvELvYeZxiE/xYRHZiFt1zCA3HAtg2EDZFz1r4TUGo5Lgm1nUIRTwcQm2WjPFQaWYeU75UQbG0em3nVwKf2rggVOqGQyioY6mOICSNpPL9l+XOqsKwdySKK8fjuHI8bmYYXcpNLPojfnzsLfvx6usnVvtQ1jxhX7VDKFcjl7EK1zgf9YsMITlvGBYOaHtciOQbvwV89k38aw+HkCHn/st1Gu4wfk3FCUMKQus/R+jS/ZSvQXylNIqGiosu443Zdt4VDDkY8WM2VUDipg/gFYX/Vt1icjlByDB4bePAbvSGfShXDD7RlA4hZnMIJc7x/y8+YwZ2JXIlz/baduHjQjkOXyUndu9sk9/9bwd+9VmgdxsPJRUOoZu392HbQBh7eg34QjUmLLExLiBNPccFnvccAPa9CkDtUOkBJl6HOjt8gT5+wa/IC05mDucLfHJp351M50um7doTr1DpNh1C8vnS+dKqlozptgwhwJ7Nwi+8smRM1rDffdkQVIWZ5WMAd7z5VKWtCV0soCNn6IhVxPsqL/hv/grwwJ8BRtkKLZcB5Y1kCDHGd4o9an7NDB8PF8Nitog+NQME4ugJ+bDk+lzMih37/nZKxpoQhJayRRgGqgWhOi6Y9YwpXNbJZVgucLtZQcgqGRNdxlyZF/bPTqHUnkMIQLXtWghCmsLqOoROCUFIVxmePLNo/cAX4Qvs+RPAkhDJZZvu3S8xxXboIR7WmFvC0ekUtg+GsX9rLxQGPGUXmETItfk7kIKQH5v7+PdnGxSEzi5kkC6U8bobNuGf33wZAunzwC3vAX7pIeCXHwHu+A3nawHwRgSlLDD1rHVbDYcQYwz7t/bhXw+cxf/zr09ZzkczWymDhXQBPUEdbOmcZ+ZYQ7QYKr2ULeIzj54xj2taCM6DUT/6Iz6zZCxj5g+ubsmY3CCwdz+TbrSJ3vrjosyfqFsyBvA5QSHjFP533gucfsgpRgLe7/ut78Nr1Q97d1y7/q3A+56yzvlmeffDwK3vFcc7yo/VMKDk5hFnaTxXGDWPpcw0FKF1pe08AHzo5ZfjX955c22Hs8DeyMJ+TbQP29UZQt4lY42KG24qFQPpfMkM9pUlY8VyBbq2fjKE3Ph1tfGSMSH228eXF+4ZxIPXjGHPcGuOiFhAR7pGN0OgumTM3q1wU18IX/2VF2Ag4kdfSApCl/YG1D2XDZvXXqI2Ib/miNcAgFyhgZIxQIzzi+a3ZhOXzBzgj3NxH/B2CM2f4M2J7D93CELic7DSDiFdwanKEPDOHwCXv2JFn3s12Firii7DCilkWZB3DrMhS8bcwVwDUV4ytpg3kEGgumPEcoJQ4gKf8A/sNq2l85mCrWSsYLUYTQu7//kDQDEDvZeLJ547ui6HEAD+PHZRhDG+28YYt3wLh9D/eMWV+O4HXohtUQOsVntA6RCaPcJ33QZ2mVlDfk2Bwqrbzg8qQpBwhYc6EJZuJTnJj7WYxsk0/1sytsloKl+qHySqh7gjyN6pqk2HUFBXoTDuTskUSq11GesAL9w9iF+5eyf2jvALq7tkLFssw6cp5s7U7qEIdgyGHcHS2UKpZtebRrl8LIYcfOiByyEU7LFcZ9LlIzI/GnIIATxnymNXOeKv3eFnKVNEj8IFod6Q7lEylodfU+o7y5bB6jC0fMmYFC5kO2e5EMsV6ose6xW3cOmF6RCqMXnpD/scC9rlkJMRKSZXZwhZC91imyVjABxZPgD4NTs8AE1lZvmmF6fm0ugP+3DleLzaIZSZ40KOFHPOPMSdd7JcDHB0tDw6ncSu4ShCPg27h6N4UjpsDMMqGQMAPYhSuYLZVB7DsQA2CZdITYdQIWl1TwPMlvCXjcYsK/aWW/ku4tBey8lhm2CaE0W7+0++VvK1s/HHr7wSP3/TZvzrT8/h4z8+yW+UZaeFFObTBfSHVC42pGerfr8hWgyV/s7BKXzwC8/gS09wIcrs3Bj1i/OUf29uJtUYL+RCzt0Br9NYDiGrhPCcyCDctIxDSBEdpqrazkvMzqOT1d0kL3sZ3xw48k3n73gJQqqGhBHwDitW1MYCpGvhj/JuZfJ4i2nuvhPjzCPJPhji8Ysqfz3cHbw6RU/I11CHT/v1yO4QUus4hOwOWBkk7G+j7XwyX0LFAOJCWPCJkrFCudI1wWwt0IyrynQI2V6PsZ4g/uJ117Y8T4wH628+yZIxuTyQnxm3QGg6hJYLFSbWBWGfWhWpkCs1uIHtWq9GAhrShTIqmTneEEdmwnk5hJKTVil44gLPetN8VjMNUxBaaYeQgkyZAWPXtNXM51Jh/V6RV4N8CjklZOaNSLKFEkI+tSoAcCDiQ75UwfkFPrHydAiV80AxB0/kxHhgN3rE7y5kCs6SMfkOy8n8qR8DAKKDmwAAp73KxmzCh0MQKqS9d0PtoZCSfLL2hzcmdtjmq7uGMcYQ9mtVXcb6mXd4qINAD/Lww5e5iLf/NZ9AHkzw18XuEGqoZAzgu9GSYq4th5D8u1KiZGy1FvRDsQA+cN8es/zF3b0pV+AXf1m+uGUgjF3DUUe77nShjFCbx3/leBw5+NAHIfQ5ygS2cGeYKQiJc7RRQWhgNy8/kCVngojpEKoWZBazBcQgHELCbl22LcLnUgUMRPzL7srWo5lQaZnVsXUgDIVZC7Hchm0730SGUI3Ja3/Eh4V0oapTUi1kboYU9N2Lbr+9ZKwTIal2h5AQtBHqg64odbuMnZhJY+tAGNds6sUz55fwnYNT/G/0R4E5IbZIh8XBr/Hr+857qp67lFnEuYUsdgpX2t6RqBUUXUgBZdu4pocwly6gYvBrSk9IR8Sv4dyCR6MC+XflLVH54GQCCuPBpfZxzPO1kMiJ5PwJXj5m/7nHuDAUC+APHtyHu/cO4W9/cIKXUMhrSCGN+XQBm0MFAC6xqxmadgjxa8Bjp/i16eET/HmdDiE/5mXJmDj3ai0MddvOfjfpFxsEc7a5zVmRx7WcQwgQAew1M4RsC4WiyyE0ei3/+aGvOX+nxvteKhtdd0uZx5ucNM/dZ3LDyCr8c5Mx+GvV7Vyn5bCXsNqD9u3H5b6myQwhXbWyZHSVtZwhtCRKr+Vmp9/mEGpbQF/DyO6tjVA0u4x17nyJBS0noheyy5hZMqZWd6ADYHMIrd/3irAI+TRki2XH3LehDCGgWhAS891KapZXdpiZcBedv1cp89sKSb4Jn5w0NwlkjiMCq+QQ0tTaztZ1CH3KO0k+gaIadgZxQiygPSZ0cjfmqJh097oD5LwmxXZkWczAbvPCvZAueIdKywmvKL/pG90KoBGHUK/425K1y6Zio8DZR4C/vs06pnyq9oc3OsYzYSolz5DoiKw9BcySsT40IAgxhiV9AEhO4uIk33mdKvHJpUMQyi0nCIkJvr1srE2HEMD/Lll6tFolY26sDCHLIcQFIf66b+0PY7wniMmlnLmQzhRKCLXTqhn83De0AEJMfFbstcGKCvTvtAlCYlHa6MLL7DTmDIGL+DX8rvaP6D38L1W/spgpImKkAX8M8ZCPZ6/bcqdmUvm2Ws4D9VtOu5EOof6wD70hH+bT/FisDKGNdeluJEMov4xDqC/sR6li1G3Ha6coAg2lW1F3Lbr9tlKYjmQI+SK8dXZu0RJwgn3cISQmRouZAh496SyfOTWXxraBMF5/4yYMxfx4+ycP4ItPnOfX38Uz/E6FFBe1D38d2HF3tbgaiCObnIdhAHv6VeCfXoX92nFcTOT45FCOH/L6qwcxJVrOD0e5ULqpL1S7ZAxwCLTPTybx/vgPEPjhH/LafEUzu0Q5fsdRMiY7U5aAeeH4kXlLdcaFD9y3G0vZIj750Cmr7LSYwUKmgAmfuMZn552O0NwS8A8P1m83W6nwTYMmBCG/psKnKeY48PCJeRiGYc4ZBqN+9IV9SBfKyBXLpn2/ZpcxbWVCpWNBDZrCHCWX5xayCOpqQ13a5ELDk/Agf//njgEwnK+novBueMe+4xyPa7zvPMC4y0KMdDQlLgCzR1HWgriAfpxI8vdoocTncV0XppbB7gqyXxPtG5Pu16rfwxHSTpexxSw/X8xwYk1Bvrj+2s678WlKwyJaSVx3OpmpFBNu5FqdxsySMZcgVMsh5F8j81Wiu8hYE/u1OltoQRAyDNx76Pdwn/IYKulZW6fG0WrzQHqGu0ABvj5NXDCbABTFdYfJtaRvZQWhoagfi9li3Tyu9cTGWlV0m0034mjvC8zJniRbKHtO6PpNQYi7JHqqHEI9/H+7bd7O4mkuUkSGnKGP0iHEilbJmGsHNNg3jlhAw3TCw30khI+KomMRYqGeT9XeDd3/duCyl/MOME9+Wtw/WfvDKydUgGcb+XhQx6IM9VVUVMDgRwFQ/YBeX5RJ+4YwiHkMiBKzeSMKTWHmBa5SMXAxkaufBSNFL3uwdKk9hxDAQ43lxD+4Rhb01SVjFQR9KrYNhNET0jHeE8RoPIB8qWIuBjKFcs0ShmbwBWyLUrcdc2C3JQjJco5wgy2DTUHIWTYW8Wt4rfp97Dj8d1aqIviCPl+q8I5noT7THWUPlj47n8F4T3uCoF9ToKusMYeQrSU2z77Jm8cKbDwLt9vJ5oV8bbzazgPWYmc2nff8uZtCmT9epoZDyBEqXTba3/FmjE+cUtNASuyiRYahqYq5aPjEj0/h9f/3YVOsTOdLmErksU04+b77gRci5FPx7PlEdQDj0jlg6SwwcUP1cwfiKKS4YHNV7jHg2Ldx68KXUK4YXPgxW8deyf/Xgw4RAwA29Qa9Nxhkd5HTD5k3HZxM4MXKY8CP/xI4dwDo2+HMd6knCAHWtSG3xMWEOqLMFWNx7BuP4bFT8zaHEC8ZG/WJ4zUqznF2+hBw4vvA4/9Q83FREmNnk+NCzJZfdzGRw6m5DKaTOfhUBfGgbua4zKULtg6ltRxCIkOoDediIzDG0OvK4Dq3kMFEb7Ah12TII6zURFGAyAhw8Cv8+6HLnD/fehsX3rxKBV2CULliVIW/dxzZsUw6hPp2woCCg4v8edPCIdTt92Q5GGOmSB2o4RByO8sCuoqIX3MIAD5VRcWwMqOaQS6kZJc6v8533EuV9R0q3UzbeSn2d1LIlA6hWpsf0iEkHUFy7HKXOV63uQeXj8Y6Mt8j1j5ynZqxxSq0FCo9/Ty2nv8qHlAfAbN1S7V3aDSxf59P8o2j8CAAq2xfWSWH0PVbemEYwONnFpa/8zqg5SsyY2wTY+x7jLGDjLHnGGPvE7f3Mca+xRg7Kv7v7dzhrnFuex8e3/VezGcKjjC3dL5UwyHEJ35Hp4RDqKYgVMMhJMKhISZrgCwZsxxCrIYghOgo4qEanQiEoFRSg0gZYhGcT9TOS9h2O/Dqj/OuNYe+xhfbhXoOIZsg1L+r6seDIltJUoKYQDeQAZAPDWME87hxmH+vRwexfTBsCkKHp5JI5kq4bnOd09IUhOwlY9nOOoTWyADrXmjL3YCfv2kzfvDrd8GnKWYL1MklvgDK5MsdOf5QyC4IuRwLA7uBhVPc1WCGzI009sDukjNBhGURZVnEMqcdGUNSfAwWF4HQgDl5lYHruWIZp+cz2DXU3mDEGEM0oDeUISTFqN6QT7Shpi5jgOUC8kKKmrXcU16dkurhdgi5F5puh1BHFjgxsYNmtl4dha4ws6zgwmIW5YqBI1Nc8D41xx2f20RIvK4qGIr6MZ306PI49Yx4TI921YEeGLlFqArD8PlvAwA2zfwQGkq4sJit7hSih8xzUjpdN/WFcG4hW12SN3IlEN9slv0sZYo4v5hFn5LhTtFT/8lz5OzYgq5NEpPWxNIuCAXiVhhGDXYPRfk4K4Rno5DGQqaAYc3WAcIeXCyfV45nXsjxoQmHEGBlid22k/8tD5+Yw0wyj0HhtOozy7Py5rlXK/NOutZWwo3izuA6t5BtqFwM4ONdzbbzgHXe+yLAtjudPxvYw/+3u7VqZEcVK5XuO4SidofQYahDezAaD2Chws+DDAJgDFURAauBXOg7HEK2z4rXa9Uf8TmuoX1innrbH3/XzLxqlEVXyVhAU5CUjst1LAg113a+8w6h+DIlY9UOIe8MofuuGMHX33d790VWYk0gHUJyI6JSMUQofQPvf7CHX5cNg5emA9jJzkPNzdscQh7xIvbv8ylrTIeXILSyGULXbO6BqjD89BQJQstRAvABwzAuA3AzgHczxi4H8EEA3zEMYxeA74jvNwyDUT8Mw7noyBa9S8YGbSVjjME7VBqoIwhdtNq1+1ToKuOlJbZQaXPXOjNvOSeCvYAeRLxWa0rx+wUliDTEhM8dKu3F3pfxifqFJwAYtT+8ckIVHQMCsaof20M1geYEoUpkBMNsETcN8wHvU++9H2G/Zk5GD5zik/4bttZpP2uWjHXWIcQFIX5erJUFvXuhnSuWEdQVaKqCuBBGZAtUKQilCyWEa5QwNEM0aluwujuIDezmu/bzJ6wBI9KgIKRqouTMWe4Ryk1b3xz6qvnlUrYIPwrQyxkg1Gc69eRk9vhMCoYB7G6x44ediF9b1iF0cSmHLz95Hr0hHUGfipF4wHztTYfQGnGYrRS+hkKl6zuEpCA0l2pQEBKTEels0F2TZbtDqFiu1Gx33xRR0YHRFEHHuENIHMuUcOUcFF3/js84BSEAGIoGeCaN+/p7UXTnsgvy5h8Th1ZIYkefD+qxbwKxceiFJdygHObOALmhMCLcPnoQM0LcNgWh3iCyxXJVhh4Y42U/x78H5FN4fpKX/0ZgE2MG91T/jrupQnKSbyBER63Ptm3yWI9dw1FcTOSQEu6NbDqBYtmwmhUAzk0T+bzzJ4CZQ94PKseHJscFWTr6kitGMBj1OwQhwOpkOJcqLCsIKQqDqrCuh0oD1V36uCDUmBhW1yEEWGL/rhdVu4D7tgNM8XYI+a35Q6ViwDBWQBzzhfg5N38SWDwLDO7B3pEoEgZ/LdJGYNXzgyQ+WzC0xOkQqj7OgYjfMT95w42b8Zl33gxNYaYQ3SiyOUPc5hCS41/bJbZrmKZCpSvdyBDi14taJWMyIka62GSg9Wq72ojVRc7r51ItZFYG4rycu5gx59e72Dko5bzTIZSacjSYcDiEckvcfCDGdDnfU6UgtMJt50M+DVeMxXDg9Pzyd14HtHxFNgxj0jCMx8XXSQAHAYwDeBDAJ8XdPgngFW0e4yXFoJjMTdtyhLhDqHpC1xf2wa8pmBftb6sG5+UEIVutJWMMvSEfdzUIQSfAima7T2Tm+CI70GOGIsYC9R1CORZEXhELjXxSOITqBPvuvZ///7TIaKnpEBoBwKp3hQUDET9mk9bEswRxMWpg4j80vhV+VsSVgWkADEqoFyGfajqEHj21gJFYoP7OZpccQmG/ar7eay5DyNZlzO3+kS3oJ5f465EtlNvOEAKA3rhNDHQ7hGQp4ewRfp6HBwGtiZbvA7uqOo0pKb7ILjKfuYOB5EXkLx5CD0ROUajfzDuQ+QfSwbdruP3BKBoQrTjr8NZPPIpzC1l8+HXXAgDGe4JmlstGDZW2t1CuxXIOIbnQbtQhZIVKe+9oV2UIdUIQMh1CF7hDJjwITWVma2JZ4iu7/h2dSkJVGLYP2gShmJ/fTy6WmTgu2a7d0yEUR6CcxP3RE3y8edF/g6EF8WLlMS4IybJNWf6lhzCbyiPsU83rxeb+Op3GLnsZb5Bw7Ns4KAQhf8kKqvfKkkOgx1nGlbjAX5+B3VY5aKOCkOjWdzLBx9hsii9se1FLELI974/+HDjyH9UP2qIgJPM99ozEcMPWXjx+ZsEhCMk8wPl0wczSq1eyoatsRRxCdkEokeO5Cpv6GnUIaY5On1XIoGZ79zuJHuCuT/v1PLfEz2/Fel1KZvvuFRAaomPAie8BMICBXbhiLI4k+PmfhX/V84MkftMhZL1O9TKEAGDfWMwMlge4aHTz9n70hX1VcQjLkcg6HUJ+TTHHv5UQMVcLv95el7F2MTOElgmVlueCWTK2Rs5bYnXYv7UPIZ+Kv3/oFABrM8zL0FCFHIcnnwYuPoNCz074mLjm2zOEjApv+iKxO4QS5xyPJZ3RalA8tr/aQNBtrt/SiyfPLtZt7LFe6MgViDG2FcC1AB4BMGwYxiTARSMAQzV+552MsQOMsQMzMzOdOIw1gSz7sgstmRqh0pqq4Evvvg1/8qor8Rdi8efAFIQWq39mGI40dsA2YROCTq/PsAb/DG9hjM03cws/+CCd8FqcCuEjCz8CUXkMieUdQvEJYOxa4Jl/5d/XyhBSdZ4TsOkmzx8PRP3IFsvm7mjBEK+dR2vhqt+d4AsL/7mfcCeUoiKoc7u6YRh47OQ8btjWVz/3wO0QKhd56Nky+UXLIdueA2unZEwKU7KMKVuobjE5EPZDVxkuLFoOoXa7jAGAz2/bXXaXXfTv5P/PHrFKI5uhdxvP2LIjuhs8HXshMPkkFzm/9SHs/M470MfEwjDUb3XsE0HOR6aS0BSGrf0NdjmrQzSwvEPo2HQKb7x5C+7czeuox3uDZpaL2Vp9HXdo8UJVGHSVtZUh5G6d/cUnzuE9n34cPzrq3XJcTgBkxVDdDKFSpTMhqdExHnC8cIo74hQFPrtDSApCwiF0dCqFLf0hx99sOoTkbpr8LF0UJWMepZdLRggBFHCX+gSg6MCe+8G234k7tWdFydgcF6iGLgOCfUDvNsylCmYOHmC1Hz+34CEIbb6Fj2cnvoeDkwkMhHUo+SV+u6IBY9dV/44rpJJfB8a4Y2ThFL+9YYcQfy2OCud3LrUIAIgZVuczZGzngRxzN93ENzg+/RruFrJjCkLNloxxMX33cATXbOrB2fksTs6mTUHICp8vIp0vISAcm7XQVWVFHCn9YZ+5cyxbzo/3NOgQ0lVkC3WueyP7+Hi96z7vnw/uqS4ZqwqUFrvJK7GoHboMSJznYuvo1fjFO7bjrfdcA0A6hNbG9bkVh9AfPLgPf/Om66tuH4j4G3ZXShYzBQR11bw+BXTF3Jxb1yVjqopSxXB0a6qFXPR2MmQ75FOhKax2yZiZIQTHc69nkY5Ynr6wD2+7bSu+9vQkDl1MmOJtNNDABrC8HossuMz+/2L9zC4IAS4RyPb1kihJFXEpcg6m9W3h85L+7U39PZ1g/5Y+5IoVPHchsfydL3HaviIzxiIAPg/g/YZhNPyKGYbxUcMw9huGsX9wcLDdw1gzuMtNgNqCEABcNhrDz92wGXfs9ngN6jmEsgu8jClq7fb2hnyODKEen1g8VSp8Qh/qB37un4AH/woA6pSM8YlpsuJHONbPJz3pGb7Du9zkd+/LrJ3WegFg7/w+8ELvakJZgjCbyqNcMVBowiGErbfz/JiZg2YIcUDnDqFzC1lcTORw49ZlYq1kwLF0CMn/284Qss6BteIQGo1ze7vc1fdqMakoTJQt8dchky8j5O/A8cvXUw/xYFE7vjAQ3yQcQpPeroZ6+CLcvuphTT3oEzkoiUlg4RQCqfPoZ+LSFepHXLj15G7o0ekUtg6EO+IAifh1M0PBi0rFQKliOM6P8R4uwp5fzCJfLMOvKQ0Fua43/Jq6TNv5+mKZX1MR9WtmDspHf3gSX3t6Em/82CP46enqGnE5UZfUcwh1rI2yFPgvPGEKN5rKM4TypTIWMkUwBhy6mIRhGDgynTTdL5KhmB+ZQhk5VVzHhi4DwPgC1hf1vC4/O8/Pp73Fg1xA8oWA4SuwCVOYWkhZ44ceBD5wCLjqtZhN5c0cPABm+dDpOQ9BSFGBwcuA2aN4fjKBa0d0vlO4537gg2c8mws4BKHcEhdgYqP89rwQcOtl1dmY6A3Bryk4OF8BFA3FFBd/IuUla7LqLhnTgsCbvwK86mP8tsWzzgc1M4SacwiN9wRFaL8P14osu3ypgiFTEOIbB6l8Cal8uX5HTPDylJUQQXrDPiRyJRTLFTO7akt/4yVj6Xwdh9C1bwJ+7aBnCTkA7vicO8ZbFANcsPPoMAasULv3V34UeO+TwK8fBfq2Ix7UsW2cj1GZNeQQkmVZdsFYdTiEGr9m9Ud8mG3QXSlZzBTNTD73cazrkrEGHK0SKWR2MqeHMYZYUG+6y5i77Tyx8fjF27cj5FPxqYfPmA5V+2Z2TeT1+OwjgBaAdtn91s/kGCsbw2Rs863kBevnS26HUAUKA9S+LcBvnQPGq4XqbrN/ay8ifo1vjK1z2roCMcZ0cDHoU4ZhfEHcPMUYGxU/HwUwXev31yNxV7kJwAWhYCuZK3qAd9byEoQ8gnbdDqG4Lgaj/BJ3uIQGuDtH1cxj9RSEFBVQdCyVfRiKh/nOXUIot8tNfi97ufV1vQAwze+we9uRpR2zKW6ZLxlNCEKBGLD9hfxrcZEJiUBLWf++b3yZx5GiV0EsbGQ3mXYFIZvKvlZKfjRVwURvEKdm+d8q2867GY0HMbnIW893KkPIPJfc5WIS2WkseaF5h5D4DJjvHQAkJ5FmYZw05C7FBSB5AYpRxA4m6pjDA1AVhm0DYRyd5iUtR6eS2N2BcjGAdxhK1pikAVaZkl1ckILQhcWsp2C3UeBBnbUXlaYgVOf16Yvwa+RCuoCDkwm87batAKxsMTvuybx7oemvcgh1IkNInJsLJ01xSFMUFMsVTCe4QHn1RA9S+RJOzKZxei5TlW0lhYWlsvgMxDdZ7sqY9+fo0Unhrpp51hJnBvZAQ5k7Y+ydQjQ/wJgQhCyHUNCnYkt/CM/X2kkb3A1j5jCOTqVwjWwYGIjX/vzbBSFzvBvlAlC5AJTy9btZ2lAVhh2DERyZTgOhflTSXPwJlha5s1ULVgtCgTgfg0evcR6DpEWH0Afu24PP/ZdbAAD7xuLmokw6hHyaAr+mIJkrIZ0v1cwPknCHUPcX1/22xhUnZvi10V6qWI+grWzbE8bqzy0GdvMNKen69HIIdaFbU01UHejb5ux8KT5jGfjXdIaQXRByd5WqB3cINVcytpgtOrIx7ceha2vjNeoG/iYEoWKXzttYQGu4y1ittvPExqMn5MNEL+8iKt3sy21KAHCWjPXvQqh3DPOGmDfL66S5+WJz4yYmrZJxV8lYoWybV7VZodEqw7EAnvrQfbj/yibXIJcg7XQZYwA+BuCgYRh/ZvvRVwC8RXz9FgBfbv3wLj3kboizZKzUettGd7CmxOxCYzknekI6704khIuYJiZgsnuK/DAKYkEdhVLFLLVwoAWwWNIxFPPz35O7o8sJQgO7rRKFFgPABm0OoWSuiGITodIAeIApYP69QeEQkrslVd3c3Ljbzre4E+zGPrFvqCZ3hdg6EDZ3fL0yhABgLB7AhaUs8qUKKgY67xDyYmA3z43IzDXvEJKPXbJNYBMXsKgN4Gwpbn4vy8guZ2KhIc6ZPSNRHLqYQK5YxpkOdBiTRAKauevihQz3dghCIu/q3EIWuWKDHR/WIcu18rVKxmq/PlI0f+QkX/w/cOUoxuIBM+jYTsFVM17LIZQvlpHvmEPIdp4L96euMpTKBu8cBpilhF9/ehLlioFdVYIQP/fnS0KsiY7yzQD5tYuLSzk8NSvcUJWiNTkTGW+hxAk+hrjGD3fJGABcOR7H0+cWPf+0M8oEWGYWofISLu8Tz1fvmm4f+2TwpBSEAN6RJJ9suBXtruEIjk2ngFA/b4ULwJcXf1eov7rLmDw2KaK52+W2OC4Efar5ugV9KvaO8OOX7xvALfoJKQgtI75rKluRjlay+9l8uoATM2mMxgOe2Yhe8FDp+qWydXF3GqtXMrZazhNxPBkjsGYcQvJaaN9EUJfpMlaLgQjPEKrqIliHpazTIWQ/jnVdMubq3lqPklky1tnXo+aGL6odQtKtpa6RUkdidYkFuLtMzlUbKxnr4f9XisDALigKwymM89tCfc7/7ZsvSZsg5HYIlYw14SRcK9fzbtPOK30bgDcBuJsx9qT4dz+APwbwIsbYUQAvEt9vGAK6Cp+mYEmUjFUqRs0uYw0R7AGyi9W3J20TZEFfmIdKVxQueFiCkPjweQhCAN/x+7NvHcHpOavrS0ULIFH2YyQW4IsJ+UFdbjeUMSsYssGJupsBhyBUal4Q2nM/AGZefALCISR3S5a9uLlDpTvlELIJQmslQwgAtvaHcWo2DcMwPDOEAGAkHsRUImcOEJ3IELIcQjWEw4Fd1mvfIYdQUh/EyXwP/37qOe40AHCZchoGmDmoXTYSxdn5LH56egGVDnUYA6wMoVqT6ny5WtQI+TT0hnScX8wiV/J+fzYC/mVa+S5XMgZwl8NsqoCfHJ9DUFdx1UQPLh+Lebpa3CGC7gm7FOZkyZi/kw4hwOEQKlUqmBIOoTt2DyIa0PDR/+SZNl4lYwAwW/Rbj2N2+agWVr/x7CQShs3p4RKExktnUU5NcaeooFSuYD5TMJsoSK6e6MGFpRxmkk4nwVwqj//+MB8Tt7NJ7IyJsaleLpwUhL76PuBzv2D9LaYglBCCUGMbD/vG4ji/mMXFUhhafh4+VYGSnefjW6jP2yEEcAeTP245hApp4BP3c2s80LRDyM01m3oAWA4hgJeN8ZKx0rK7s2+7bRsevLpJwbwFzAyuVAHHZ9MNu4MAHiqdK1ZMZ0LTyAYUX/hF4DM/L96fHsddZC6KuxvgiiEFoTXuEFIUBqkJNbPQ6Y/4kStW6neLc7GUqeMQWgMLvW7RSFdMSakiymI67RCqUzImtFPLISTcWuv4LSGagG9IFE03e2MOoR7razGHOKdOoAyVj58A/5+pfKw98h/An+/j43jvVp4l6FEypm+wvMzVpJ0uYz8yDIMZhnGVYRjXiH9fNwxjzjCMewzD2CX+3xj92mz0BHUzQyhXKsMw0FrJGLC8Q8i2gOgN+VAxgES+hLyhI6KJHTlTEHK2WpcD9WOnFvCX3zmK13/0Yd5RBsD0bb+Pfyjfh+FYgP9eoyVjAHDzLwN3/y4P/2wBe3voZK7UVJcxAEBkCPiZvwRueAcAIKRrKJQrPF8JVkZDTdyh0nnRDafNhHuHILSGFvVb+0NIF8qYSeaRL1U8S5LGegIolg0za6gTXcZMgc1XY0Flb0Vdo9Rl2ce2C0KJSWQCQ5jNK/xcOv9T80e72Tm+OBXllHtG+Hv9f//zBBgDbtnhFFNbJeLXURYisRdeDiGAu4TOL2SRLWzckjG/ppqvjxeN5Ctxh1AeDx2fww3b+uDTFFw+FsfxmRSyroWOWxByB276VAWMAekCv8Z3ZIETiFvXH+EQkhlCMlB6a38Iv37fHiRzJSisumxnWDhNjqg7gbt+G9j14upQRxtff/Yi+vptvR+kIOSPIhscwW3Ks1DnjwOjV5t3WcgUYRiocghdNcGv0c+cX3Tc/vnHz+FQmf891wanMObPW39vLYI9/PP7+D/wY7rjN3hYvBSQ07O8FLpBJ+qbb92Cu/cO4cCMgmJyFr1hHSxjdwi5BCG7WBUbtRxCc8eB0z8Gnhfm5zado3fuHkRAV7C5z7oORkVpabpQQngZN+bbX7AN914+3NYxNIIs5Z5L85KxbQONC0JyQ6xu2VjdB+gD7v0DYOQq4NDX+HykRsnYqu3mRkeBF/8Rvq/d1lQpVjfxCRej3+UqlS6hZtqM99vmZQAXwkvLdN5ZzBbQE7REY7sgtBZ2/ruFWTLWQGeiQrnS0fwgSSyg1+4y5nIImW3nySFEgIuJyVypSYeQbX0kys6/GnwF/nnoV62MUEWxxtoT3wNS08D+XwD2vYpv9KRFgym7ILRGrqUbAfr0d4GekGXVlMKQ3TbbFLUEoeQFvrNpa8UthZTJpRzy0BFW3YKQc1ErBaFDolxiKpnHBz//NADgxPBL8JyxVQhC/XziDTS2GxodBu74daDFgDqfpiAe1DGbyiORtZeM9TT+INe92VzABH38NJ9K5BEUDq66qD4epC0dQjkRgNaoIFUDe8nYWlrUbxUT+4MXecaSl3tpNM4XPcdErs6KZQhJos2WjEmHkFh4VspAagq54DASuRKM6Bgw+ZR59wArgtk+H7KM4/uHZ3DVRI/52WoXeR2wh84DwKcfOYMvPH7OnEC6XS7jPUGeIVSq1M3IWc80kiG03OeqL+zHVCKPo9Mps/Tq8tEYKgZweCrpuG+x5A6Vdl7PGGMi66VoHl/bMGaJNkIE1VXLIaSrDL0hH37+ps24fDSG3cPRqq5qsaAGn6ZgKl0B7vwN7qCRmwEuh9B0MofHTs3jxsu3WTfKkl8ARv8u3KY+x7+x5cPJwPUBlyC0bzwOhQFPnbXGLMMw8JnHzmJk0y4Yqh+/sV+BWhCv9XIlYwAPn77/fwJ3/zZ/faQjSLpkG3Si+jUVf/3G6zAxNoEBJYVXXjUIFJLeglB20Xls0RHLISTvt3iG/9+mIHTfFSN44nfvc1xjIn4NqVwJ6Xx52QyhlUIe38HJBJK5ErYPNF4SLgWhZtwlVbzg/cAr/pp/bVRqhkqvmvOEMeCWd0ONj62dLmMeodIAFwIUhqZKDeVnfSaVx4XFLO79sx/gt77wTN3fqVcytp47Wsnxu94GhqRUNrriaovV6iIMy01nxrNQhhBhQ4qJZoZQI4KQqgO6mMuLuftseAe+6Xd1jpRjbeIC0LMJeNmfA71brCxAppibPIVOleITDUGvdBeIB3UzVHpedGVoeUFZzyHkck30iuc4MZNGHjpCSoOCkBAC7toziGfP8+e6KHajh2WGkKTNyW+jyHr1ZL6IYrMOIRfSnTWdyDWmdDPGhS9TEFpq6/kl0iHE2NpqGy7bqUth0LNkLMZdB6dmeVlhRzKQzAyhGoJQeNB6zT1aZTf02NIhlJ4BjDJK4RGUKwYqkRHTAVaW55fMWQEXYOT7dadXB8AWkflY066Smn96+DQ+99NzZkaO+/wY6wnykrFiGYE1dO6sJH5NqbvjmhMOoXrctL0Pe0ei+P2XX44337IFAHDFGN/ZcpeNuZ/La5Hn11Rz0tSxiYsUhKRDSBEZQokchqIBKAqDpir41DtuwsffekPVrzPGMBT1Yzphc8fVcAh987kpGAZw19VCBIpNOEqwgqN7AQCT2iaHY88ShJzjWtivYedQxJEj9MjJeZyYSeM1N24F698J/8Ix2zW1p/brIH8Wm7CCnQHLqSldsk2UJvs1Fdfs2YFYJYHfvF28JqE+/vqka5SMAfy9SLgEIUktQbsJ3CK8LC1tpGRspegP+7BtIIx/fJjnrTVVMibGFLcLr2l6NlnnQpVDaAXbztdhJBbAWllXS2eQO3dOVVjTopUUhM7Mp/Gmjz2CcwtZPCuumUenklXvba5YRq5YMaMJ7McDbIySsUYcQqVuOYSC2rIZQtJN6xMlYyuRRUasfWSGXTJXgk9VqgTlmgTiAJi5qRQN6Ob8yETm9SUnnfMROY4H4qajqFg21vV1Yq1Br3QXiAd9WBJ5NR0RhFLTwGN/5/w3fbBqcj8a54vgZ84vIQ8dQSYGg/Qs71bmmrjGhDhyaDIBTWG4cVsfFjJFLKQLpiA0Eg+4BKH28hIaZSDix2ySl4wVjRYcQjbkZHQqmXNMTuqiB62SsQ4LQkFdXVNtwyd6g9AUhoN1BCGZbyFbSndEEFrOIcQYDxPVAo78koZwO4REuYcR4Z+ZfEiWWDBM+bfyL23nuaIws7PYC/d0ThAaFsKaY7EOIJkvIlcsm5kDVSVjPUFkCmVMJXJryl22kvh1pX7JWKlSVRrh5q49Q/jG++/AW2/bZk40JnqDiAY0PHfBKbxXdRnz2NEO6Ippy+/YxEUK/UIE1VXeZWwqmTPzgQC+ATDW4y3QD0X9TtGxhiD05SfOY8dgGDtHB7gz0tX+nQkR6KuF68yspF/8hwP40hP88+QuGQN4jtCB0wtI5IowDAN/9h9HMBDx4+VXjfHHnz1iXVPrleHK6+3eB5xuU19rDiGTUD8Ag5d+AbwDSqifd+M88HE+XroFodgokJriTkN7+DRT+OvWYfhEuthQl7GVgjGGt9yyxZzg7xhsxiHE/4ZMsY1gaYnMKFzNtvN1eOPNm/HmW7au6jFI/HUcQs0KZ7Jk8F8PnMPxmTQuG43h9FwauWIZL/8/P8If//tBx/2lGFGr7fx6XujZGw4sR7FidKUsJhao3TRGZnmp1GWM8CAW5NEGM8l8Y+4gSSAO9Gw25/ZRv0cTFZnXl5h0OpblRpTtul4sVdZ1aelag17pLhAP6ljKdMgh1L+L29r/7QPOf0tngJErHXfd3BcCY8DjZxaQN3QEpCA0d4x/8FwihHQIXVjKYTgWMDspnZhNYTqRRzSg8YmcvbXqSjmEon7MpvOtZQi5MAWhRN4UwZZFD1Y7hOoFoDZA2CYIrSVk6/mDk9wpFvAQe/ojPjAGsxtZRxYpy2UIAcCWW/mOcLMCmtshtCS65MV514NsQAhC4UHMaOJrV8bWdZt7MRzz4+qJnuaeuw5yQe92CCVzJeSKFZtDyPkeSBfXmfnMBu4ypi4TKl1GoNGdLBuMMVw+GqvqNFYsOycjXguYrjiExq7l130xQdJUhlLFwFQib+YDLcdQNGBmDgEAhq/g4ku/lev21NlFHDi9gDfctAVMUYDBvfzzZmfTTSirfnyheAseOTmPh0/M4VvPT+Hzj/Pwx0EPQegtt25FKl/CX3z7KL53eBqPnprH++7ZyV0wA7t56/DUFBd21DrXkf4d/HN81Wudt0sBSDp2mu1mKcezKVEKFx6y3E9f+1Xgh3/KS6QdDqFRflt6xukQ0kMtl0bXI+LnO7SZwtopGQOAV+/fhKiflyTWEiO96EjJmGTfK/nrPuAUL2UZTDfcFs3wkn2jeMutW1f1GCReodIAX/g3u/iXc9iHT8wh4tfwquvGkSmU8cjJeeSKFXzhifMO8cEUhGwZQvaxaz0v9Jp2CHWhxFB203UH/AP2kjGnILTa7jpibRATOasXFrPNOVSH9gJbbjO/laXPDkL9fByt5xASONrOE11n7cw01hE9IR2LYjCcE4JQf6uC0M2/xCfEhsfAEnY6FwK6ivGeIJ45t4Q888GPIu+Icvy7wHVvqfp1u1tmrCdgWsCPT6dxUYhEAJwOoXqL9w4yEPZhNplHIldEmTXZZcyFnIzOpvJmeciy6CGnQ0j1dazL2Fp0eOwdieE/nuct2L0EK11V0BfymQ6hjnRJW67LGADc+/stPrar7fzsEQCAMrATwHNI+QbRDwCxUcwlZemIs6Ty11+8B7/0wh0dnST1h7mwZheEDMPgglC4bGbkuMWFF+4ZxL7xGJ49n1iT589K4FPrZwjliss7hGpx+VgMn3n0LMoVw3y/i+UKwn4VhQy/9npNTAK6YgpCHSsDveXd/J9AUxSUygYW0jnc2mC4+eb+EL57eFqEMirAznuAD54BGMOz55fwxNlF/PDIDKJ+Da/dP8F/6V0/rH6g0atQ+H/O4eT/+A6++dxF2D8JusoQC1ZPIfaNx/G6GzbhEz8+ib9/6BS29Ifwuhs38x8O7OZj2YXHl3d89m0H/usFQHGd72aGUPMlYwAs4ffMT8Qx7QK23AJsOwl87D6re5jDISR2MhMXXIJQdzZIYgFrZzWyTKj0ShLxa/iVe3biyFSqqeuiHC/aLhkDuFD4W+eqzgsZAk8uB4tagpCqMDTb7y2gq2Yp4/6tvdghuhv+x3N83pDMlfDN5y7iwWv4povMyXN2GbM5hLT1+z5JscvtMvWiVDa6kqd05Ti/fj1xdhGb+pzzdlkypjAShIhqZLTGhaUmBaHX/D1g66AbEd3KHIQHrDHULgj5PBxCFCq9opD01gV6gjoyhTIKpQoW0gWoCjMV16ZhjH+AIkPV/zx2JrcNhJEtlpGHDh+KwLHvcJfE3geq7qurCsJiojYaD2KiNwSfquD4bApTyZyZG+NwTqxgyVgiV8JssgBDEa9doEExx4VcQBtGAx3GJG6HUCDe9k6wtF6upZbzkp+7YRNkR+BaDqbBqN9cpHQkVNrMEKpzTjHW2uvudgjNHgViE4hE+WCzpAmXQHQM0xDnt0sQCuiqZ0lMO2iqgv6wHzNJy72RLZZRrhjIOxxCStXv/c9XXQ1NYWsmU2Sl8etK3Ql2qw4hALhiLI5ssYyTIiML4PXrdru010KTO4Q6XDLmQlcZ0oUSErmSpyPHi8tHYyiUKjgxY/09YAxfeuI8XvmRh/C7X3oW33p+Cq+7cZN1TazxWQsGfHjFNeP41wNn8bWnJ/HSfSO4YiyGoWigZunr//Pivbh77xDedcd2fOodN1mvjXR1XHymMYHfLQYBtpKxVgUh8Tk/8zAvRZXfh/q4U+iiCMp1O4Tkc2bmrDa6XRKE7OPUWnIIAcA779iB//Waq5e/o42OOoQAz/PC7XogrHHEvYmgtuAQAqwcoZu29WOLEBm+fXAKmsIw0RvEvzx21rzvonDJO0OlN0aGkNyYaKTtPC8Z6/xrcflYDBG/hkdPzlX9TK7Z5WfFRyVjhA1pFphczDVXMgY45hAjsQAyhbIzy8o+z7bn4HqUjBVK5BBaSeiV7gJxMQAuZYuYSxfQG9JXLKxtu+gYlYcO3SjwFq3BXoeNz3Gs4oM/2hOAqjBs6Q/h2FQKZ+czVl7FKoRKbxNupSfOLoBpOqAFrVyYJrELMI2XjNlCpd0dZ1okJCZla61kDODByVv7+QRPdmVzMxSzHFKhTuxaL5ch1A7uDKHZI8DgbnOhNa+Kczo2iosQ+UT20sguMhTlna4k0mGSL9XOEAL4BO/Tv3gzfvmunVU/2wj4NaXuBLsth9CoCJa2lY0VShWH8LmcQ6hbJRCayszd9oFoY9fAy8Tfc9D292QKJfzG557G1Zvi+OIv34rfeulevLvBc+nXX7wHAU3FUraIl145ir990/X46zdeV/P+fWEf/u4tN+A3XrIXE702wVd2MKuUWr+mKioPopdt4JstGZPjWXqaC1R2UWtwDz82oI5DaJZb4/2xrm2Q2Cfh60EAtgShDmQI1cDMEKIdZZOaDiHWfIYQYDndb9zWh4neEBTGS/F3DEZwz94hPH3OymGTHa7sm6EOh9Aa6cTWDZpzCFW6IsSoCsP+rb149OR81c+quowJtxaJqQRgrZMK5UrjayYPNvXxOf7Z+Yx1o309ae8eLPMEXQ4h6jK2ctAr3QWkyLKULWA+ne9Yy+pG2CYEoSLzQSllgSPfAHa/pGZWg1SCx0Rb8R2DEXzv8DRmUwW86DKZrbLyodL7xvhF4cRMGobqbyu/xx6A3HKodAcEIUW4O9aiIKQoDG8VuQfxoPf5ancnhDrxN8hzqSuCkM0hZBjcITSw2yxxmWGWQ+hCRQhCLodQtxiK+TFtcwhJh4k9Q6iWuHDjtj6MN5HdsZ7oVoYQAOwcikBXmdlpzDAMFMoVx2LcO1RaRTLf4QwhF/Z8CXeb91psHwzDpykOgevJs4solCv45RfuxLWbe/GuO3egJ9TY2DQY9eM3XrIHAxE/7toziIneEK5qJVvLFwLionysnWuqP2pdn1t1CAG8XMyOPZfGfnzhQYCpQhCa5x0JB3Z3bTy0d8PsiBtzlZGdPjtRMlauGPinh0+b+YySUlmGStO0VuJT+fXQ73YIqc13GQP49Seoq7hqIg6fpmC8l49Fu4Yj6A37kMqXTLEhLd3Ets0juzC1rkvGtMYFoWLZ6Fru1Y3b+nBkKlX1WXGXjMlzgQQhAnA6VNvZkJCbQecW7IKQreIk5lUy1mPeRF3GVhZ6pbuAnGQvZYtYSBdXVhASnT8qqh+YFe19N99S8/5SIJEdyrYPhlExgK39Idx3hWj17YvwLmWKBqgtlr41yea+EKLiQvTt+KuAl/15y49lF2AaLt1zZwh1QBAC+OTIK7R5LfCmW7biX955M3YOee+4S8eYT1M6M4GJjfL39YpXtv9YbjRbhlDiAlBIAQO7zPd/uhIDXv4XwLVvxMPly/Hl4V8Gtr+w88fhAW8JbjmEEjaHkFkytgZFw9XGpyl1u7bk23AI+TQFu4aipoAi3Qb2ch2vHe1bd1iusm5NXOxCk7vNey10VcHu4YjDIXTg1AIY42HprfCmW7bisd++p/Gy21rITmZtCULyGsWaF5T1IHcYAbyLoR27QGTPOFJUoHcLMH+Cl4yF+oD7/jtw74eaPfKGWMslY60gNxA6UTL23IUl/M6XnsVr//YnmFzKmreXKiJDiBxCJp12CL3j9m34o1fuM691W/r452jPcNQcW2XXRTMDyyZu2kvX1vNCz+wy5sq8m0vl8cqP/NjhmChVupeTctM2vvh+7JTTJSS7jElByEcZQoQNezZg0yVjNmR21dl56zptbcgwIDJs3e4RKk0ZQivL+r0iryLSIbSYKWJuhR1CsmTMUAO8OxlQ1Y3DjjxW2TFEtpJ9++3brcGBMf4hXiF3EMAdK1eMcwvhQnQvsOelLT+WfRISbapkrPOCUDyor6mQUDuqwnDT9touGekQCndS0Nr/C0C4C84cs2QsZwZKY2APAroKn6rwoLvr3wrERpEsAo+NvqHlksRmGY4FMJvKmzupsuSoWDbMkor13IGlVfyaUrdrS65UrurO1gxXjMXw/IUlGIZhBtQu5xB6y61bTJGmew4h63kbdQgBvAzu+QsJGGI3+MDpBeweipolza1QKzOoKQY6IQhFrf9bOSY5KXWPjQ6HUE/1z2aPCEGon3dk65KIbD/v1kXJmBjzsg204V6Oi0vcXXliJoXf+/Jz5u2WQ4gWEJJOZwjt39qHn712wvx+iygz3zUcNeeSMkQ2lS9BV5njmuxwCK3jMU6OBW5H65NnF/H4mUU8fmYBx6ZTeP9nnkCmUO7aOXvleA98moIDLkHInbfVG9YR8WvO8l5iwxJzOIRany/EgzqiAQ1nHQ4hsYkWGXIaDPzVDqFCuQJfG3M6ojnW7xV5FekJWhlC8+nCigpCYz1B+FQFTLctHAb31Lx/3OUQevG+EfzWS/danWckof4Vyw+SyLKxhkWcGrReMuYKle4Af/SzV+L999YW6NYy0iEUuhRKGFQvQYi/7rGgZoowAN+1Xsm/aSjqR8UA5tLcJZS0dWGQbqFWnS7rGb+molg2zMmsm3yx4ggtbZZ943HMpgo4O59FsSQdQvV3tEM+Db/0Qp6LE/fouNUJ7G68wQYzhACeIzSXLuD3v/IcPv3IGTxxegH7t7bmDuoo0oXTRhmwaS9vNj9IIm3r7pIxf9TKNXA3MRjYDcwcBsqFrpeX2nMbwmt0A6EZfKoCVWEdyRCSHRqv39KLY9Mp8/YShUpXIfMT3WXqqtKaQ8iNjCjYOxK1RSXw8SydL1W52+zi0Hre9PDXaDt/fpHPKWdTBXz/8DS+9OQFHJlKdq1kzKcpuGyUdye1U3GVjEUDOp78vRfhjl0rk6NIrG3kxinQ/vprU2/IO0PI3mEMqJkhRA6hleMSWNldesiBcT5dwGK2iL7wyjgPAD7QXzkRR6AUBjLgHz57zaaLoagfUb9milYRv4Z33bmj+o6hPstxtELsG5eCUHslCgFHyVgLodK5peVbJDfI/q2134u1jnQIhdZoyZsDVeMljqUcMDvFuwJFhgDw3Q9pay9XDORLlRXNdRqMcvF1OpHHUDTgEKfkca3nyXKrSJGsUKp4durLFdtzCN29dwgf+spz+MZzk+YuuH13rNbE5G23bsW1m3uwc6jJLJsG0cXCLerXqnb663HVBL9+fvInp83b1oYg1GGHUCuE+gHVB/Rurf7ZwC5+zXeXRw/sBoyy9ftdpFMZDmsFxhhCutqRkrHpRA6MAVdN9OAfHz6NSsWAojBTKF7PzpNmuf/KUfg1BSPxgON2VVFM52A7vGb/JgxG/dg6EDaFukSWj2epfKkq/8rv6DK2fhd6cvzOF12C0AKfU86l8maOz2Km2NXXYt9YDF956gIMwzAdnnJPxS4KdkuUIi5NYkENs6lC2+PPpr4gjtu7nfpCvElQbMx5R6+28yWD5sIrCL3SXUC6UE7PZWAYVmeGleIf334jrt8h8n/qlIsBwLvu2IHP/dKty5cCjF8PjFzZoSNsDEsQau+CpCrM3LFpru18hotC5XzHHEKXMrLLWOhSWaBoAZ4htHAa6NtqlpZEA5rpxJElDCspckmn1Uyy2iEkxSF35gOxfOeWfKn1DCGA17tfOR7H15+5aO7syvp5VWE1r5GKwlrO5WkEOVFvtMOY5LrNvfjHt9+IR3/7Hjx4zRh8moKbtq1McHpdhvfx3cHhK1p/DFMQatEhNH4dsO1O77b2218IjF1bfbt9LO2yIBRxOIQukevtMgR9akdCpaeTefSH/djcF0KhVMGscFrKDCFyCFnEgzpeed1E1e2q0pmspXhQx4PXjJtfA06HkHsxKcc1xtb3+6QoDLrKqhxC5xalIFQwx3+gu0HoV47HkcyVcMbm0siJeQ+ttYlayLKxtgWh3hDOLWScAvTEfmDiBucdB3YBwT4rYxDSIUQn6UqxPmYaawxVYYgFNJyY5Xbm3hUWhEI+DfCJ8q5lBKF4SG8sU6JL4Zn12D4Qxmv3T+CuvUNtP1bQxzsUNVzWoQcBowKkpvn3JAhhKNqFDKFuovm5QyiftOyo4IKtFGHkAmVFBSHxOspOY3aH0FK2yEs+O5HVss6QrqBUoVR1zTIM7vRqxyEEAC+9cgT/8xuHcXqW72jJvK/VzCWRu8eNBkpLGGO4fdcgAODDP3cNPvTylW1wUJNgD/CBQ+09htxNbNUhdPfv1P7Z7b/G/7mxl5d1WRAK+1QoDDBwiTgyGyDk65BDKJnHUNRvdls8v5DFUDRgZgit53bmnULtwmvkFoRS+VJVuSNjjOfrGB3KI1vD+FSlavNCOoRmU3mHWNRVh5DYWH3m/BK29IdRqRj45EOnMBzzU2YQURO5Ed92yVhfCLliBTMp7ogHALz1a9V37N8B/OZJx00FEoRWFHqlu8REbwiPn14EsPIOIQBWl6VlBKG1jKIw/M9XX41rNvW0/ViyJKipLmMAkLzI/ydBCGG/hpBPvXQWKFqAC0KFlFMQspWMSUEouIIZQoNRPxgDzi9WC0KJXLFr4cSXOiPCoSZDZe3I8M52MoQA4P59vK79356ZBGC5M1ZzUiLFqGYCpd0wxtaGGNQppBDUaoZQK4T6ePt5+XUXYYwh4tcQ9mnrZuEc9GkdEoRyGIr5zZbnMpfFdAit41KkTqGyzovcsjORFSpdRsRjvhXQlHVdLibx62pVlzEzQyi9cg6h3cNR6Cozc4Q+//g5PHVuCR986d6mSpCJjYWsdGmnyxjAS8YAV6exBimUKtC19X+tWCvQyqNLvOXWLWY5yqpMxGXHpEtYEOok0l3QVKg0ACT5wrBTGUKXOjsGI1V5BGsWzc9LxvIJR2lJNGCFSmeK/P+VFLn8moq9IzE8cWYBgDWBll9TuZg3shOivdW0RApC7TqEtg6EEfapODEjHUJSEFq9SYlZMtaGILTu8LfpEGoVOZ6Gux++Gg3o6yJQWsIdQh0IlU4Ih1Cv5RACrFBp6jK2PJqqdPx1CuoqdJW5Ssaqz1+/rkLfAGOc2yGUK5ZNEWg2mcdsyiYIdXF88WkK9oxE8ez5JSRzRfzJNw7j2s09ePDq8a49J3HpIzfPo210GQOAzaL1/Om59DL3rKZYrlCG0ApCr3SXeMW14xgWWSGrIgjpvPuDvR5zIyMnKw0vtskh5Mk//MKN+K/3X7bah9EY0iGUTzkWjrGgboowGdMhtLILrxu29uLx0wsolSuuUOkSOYRqMNrDhcgLix6CkBDfOyGm9YZ9mBLlfDIUdTUDN6UY1UyHsXWPdPyttCA0uIeHUftjy9+3TaIBbd3kBwGdKRkrVwzMitKDWEBHLKCZrosyCUIN8/57duF99+xa/o5NwBhDLKA7u4x5OG/9mrIhykD8uuJoOz8pnK19YR9mUnnMpwvmz7q96L1mUw8ePTWP9/7zE5hN5fGhl18BhT4nRB1kqVi7DqGt/WEEdAXPnF9q6vfS+RIqBjUJWEnole4Sfk3F++/djfGe4OoIQvteBfzsR727qGxAgrqKWEBv3H5f5RAiQQjgi+VLou08YHMIJR2lJbGAhlyxgkyhZGUIrbB1ev/WPqQLZRy6mEQyVzQnhOQQqk0soCPq13BhsV7JWPvvY3/YhykxeffrfCddX8XJsywnIIeQjXbbzrfKbe8DXv0JM6C+m0T82rroMCYJ6u2HSs+l86gYVjD/eG/IdAgVy1IQouvncty6cwC37uy8yy0etMqxU7nqtvOAs6X1eiagqWZ4M2A52a6aiKNQqqBiWLlL3XQIAcD7792NPcNRfO/wDF513URHYhiI9Y1ZMtbmGKSpCq6a6METZxab+r2P/vAEAOAFu7rvxiU462e2sQZ5/Y2b8bobNq1OBkC4H7j651b+edcoQZ/aeLkYQA6h9YAWBHIJoFJ0OAlkyOIjJ+bNMoPVcAgBwKMn55HMlTAQ8eHCUg6JbNEMnSaqGe0JeDqEch12CKXFwtWnKvBpyqo6hLQWQ6XXNe22nW+V3q0rtsnyplu2mEHJ64GQTzVLdFtlOsHLbOQ1crwniHMLvHtSmTKEVp1YkDuEDMNAulDdZQzg1+hS2btT5Hoi4FORtbWdP7/Iz9OrJnrw/cMzAICrN/Xgh0dmuj6+DET8+Mw7b8Y/P3oGr76+uuscQbgZjPjhU5W2Q6UB4NrNPfj4j04iVyw3tGl3cSmHj/7wBB64crSrHVwJJ+tfpl9l1ksg5KXOLTv6cefuwcZ/gRxClz6aH8jM8q9tC8ebt/cjqKv47qFpM9NipYOyR+NBTPQGceA0F4RkOVDFAJWM1WGsJ4gLdTKEOuEQsjs6dU0KQqt3HZciF5WM2VitDKEV5MFrxvGqdbR4C/q0th1CMoNlUHSrmegNUobQGiImHELZYhkVw7vcJKCrqyqwrxRBXalyCDEG7Buzyk2vmeDzypVwoIb9Gt5x+3b0hGhjgVieN9y0GZ//pVs7Mqe6dlMvimUDz11ILHvfTKGE//JPP0XZMPCbL9nb9nMTjUMOIWJD8Msv3NncL9gFIS0A6JdIkDJhoQWANN+Jsy8cA7qK23YO4LuHpnGFmJytZJcxyQ1b+/DDIzMoVQzsGrJKX9oNRl7PjPUE8cy56lr0TjqE+mwTZp+qwKcqq9rK+o7dg/idBy7DVRM9q3YMa47VyhAiWqYTGULTIttL5jOO9wSRzJfwhv/7sNnEgwSh1SMe1HF2PoNUnm+0eJWMbZQMoaCuYs6WE3RhKYehqB+j8aB529WidGsjCGTEpUXYr+HKic5shF+3uQcA8MSZBVy/pbbjZzFTwLs//TiePreIv37j9djcH+rI8xONQYIQQXjhE6Hc8yeB+PrZpd1QaH4gJ8QDV9bI3XuH8O2DU3hKiAsrnSEEAHftHcIXnzgPwOn+2Aj5Cq0yFg9gLl2osh531CFkK83SRcnYarY+Dfn4zi5ho3cb0LMZGL5itY+EaJCwn7edL1cMqC2KNrJkTF4vb9zWh4neIA5dTJohva0+NtE+8aCGpWwR6TwX57y6jG3pDyPiz1fdvt4I+lRkFywBdDFTQF/Yj37b+CJF/tV0oBJEtxmKBTDeE6zKETIMAwdOL+CZc0s4NpPC9w9NYzZVwJ+++mq8+IqR1TnYDQwJQgThhXQIVYrA7pes7rEQraHZXF1+pyB0115ePviNZ3lJ4EpnCAHAC/cMQlcZimXDIQj5dRKEamG1ns9h20DYvD1f6o5DSFcZLxmjoNq1RbgfeP8zq30URBPERPlQKl8yw3SbZTqZRzyomy7Kqzf14Ee/eTeeOruIB//qx9AURmX6q4jsMpYSnTO9uoz94Sv2rfRhrQoBXTVdawCwmCmiJ6ibglDUr2Ew6seD14zh5u39q3WYBLEi3LlnEJ87cA5n5zPY1BfCT47P4U+/eQiPC5EoHtSxdySKj7zxego9XyVIECIIL3SbVXHvA6t3HETraLbMFVeb6NF4EPu39OLA6QUorDNCQrPEAjpu2TGAHx6ZcXSQIodQbaQgdGEx6xCEciK8sxNimj1DyKeJkjHawSWItpDhpMlcsWVBaClbRE+o+nev3tSDV18/gR8cmWnrGIn2iAd1lCuGWdrnFSq9UdqdB3Vnl7HFbBG7hiLwayqiAQ2DYsz/i9ddu1qHSBArxq/cvRNfePwc/usX+UbOfx6dxUgsgD/82X247/IRDER8JOavMiQIEYQX0iEU7AM237K6x0K0ht0h5NGe+hXXjuPA6QWEfNqqDUQvvmIYPzwyg56QDk1hKFUMCpWuw5jIXzi/mEWpXMEnf3Iar9k/YXYe6w+3H7zsEIRUBX5yCBFE20QDXMhJ5lrvNJbMFWt2vfnjV16J+UzB82fEyiA7uV5YEoJQBzoUXaoEddURor6YKZqBzgMRPwaoSQCxgRiNB/GLt2/H//7uMfSGdPzOA5fhjTdv6UiZP9EZNu7VmiDqoQUBpgJ77gdU+ttqKF0AABGxSURBVJhckjgcQtXhsw9cOYrf/8pzq1IuZj+G7x2awfVbenk73kKZQqXrMBIPQGHAiZk0vn1wGv/9a8+jUjHw2Kl5bOkPdaQTl6PLmKrgVddPkGuLINok1hFBqISo39tdpKkKhqLU/GE1kc4vKdB7hUpvFII+XjJmGLz73VK2YLrbXn/jJvQEqdsXsbF4z907sWckijt3D5obBMTaYeNerQmiHooCvO5TwBjZeS9Z6mQIAUBv2IcXXT6MM/OZFTwoJz0hH/7uLfsB8MyBdKFMDqE6+DQFt+0cwFeePI/Tc2kAwPcOT+PQxSTu2jPUkedwt51/8y1bO/K4BLGRkc6eRLbY8mMkcyVsoc4zaxa3IORVMrZRCOgqKgZQKFdQLBsolg30iNfnnXfsWOWjI4iVx6+peNlVY6t9GEQNNu7VmiCWY89LV/sIiHawO4Q8SsYA4E9fc7XD1r2aSOvsauQZXUq87obNePenH8eFpYvwqQoeOj4HALhxW+12ps0QC+hQFYZyxaDsIILoEGaGUL4dQahIO8trGCkInRWbLBvaISTG81yhYp7zXvlXBEEQawFaeRAEsT6RDiE9DCjeZVgR0eljLSADkUkQqs+9lw+ZLp733L3TvP2GrX0deXxFYegVE3edsoMIoiN0JkOohFhw44oMa51tA2GoCsMz55cAAKENnA8iS9GzxTIWM1IQojIxgiDWJjTbJQhifSIdQh75QWsRmR1EJWP18Wsq3nrrVlwxFsO77tyOsE/FQMTn6DrWLn1hH3SVbZiOOATRbawuY60JQpWKgVShRA6hNUzYr+HK8TiKZQMRv7ahr5/SIZQtlrEkyiR7WuyuRxAE0W1oq4UgiPWJdAh55AetRQLkEGqY996zC++9ZxcA4BdesA2qwjraKa435MM5NduxxyOIjU5AV+HTlJYzhFKFEgwDiG3gzlWXAjdv78eTZxcR9m9cdxBglYBnC+QQIghi7UMjK0EQ6xNTELo0HEIBcgi1xAfu29Pxx+yP+KBTZzGC6CixgIZEiw4h6Syq1XaeWBvctL0Pf/OD4xs6PwiwNniyxTIWswUAlCFEEMTahWa8BEGsT2TJWI1A6bWGlSG0sXdW1wK7h6OY6A2u9mEQxLoiGtCRzLXmEJLOIioZW9vs39ILVWEbusMYYAuVtmUIxalkjCCINcrGvmITBLF+0cWCnhxCRJP8yt278O67di5/R4IgGiYa0FrOECKH0KVBNKDj+s29iG9wN4wZKl0oYzFTQFBXzTIygiCItQaNrARBrE8usVBpaTH3UanSqqMqDCo2biAqQXSDWBsOIfl75BBa+/zNm67HBs6TBuAMlV7MFKlcjCCINQ0JQgRBrE9khtAlUjImdw9l6RhBEMR6IhrQcDGRa+l3pUOIQqXXPn1hCk8O2AWhbJHKxQiCWNPQyoMgiPXJJeYQkt3FyCFEEMR6hJeMkUOIWP/IkrFcsYwlcggRBLHGoZUHQRDrk0uu7bx0CFHOAEEQ6w8eKt1ahlCCMoSIS4igve18toBeajlPEMQahgQhgiDWJ6ZDKLa6x9EgUggihxBBEOuRWEBHplBGqVxp+neTuRJ8qkLBvMQlgb1kbIEcQgRBrHFoq4UgiPVJZATYdDMwccNqH0lDmCVj1GWMIIh1iHT3JHMl9NbImZlO5PCTE3PQFAX3XTEMXQjkyVyR3EHEJYOqMPg0BdkCLxmLB8khRBDE2oVGV4Ig1id6AHj7N1f7KBrGLBkjQYggiHVII4LQ+//lSTx0fA4A8Esv3IHffMle83dIECIuJYK6iplUHoVyBb3kECIIYg1DKw+CIIg1gGw7T4IQQRDrERkInagRLH1sOomHjs/h3XftwKuvn8Df/uA4Hj+zAEA6hGhRTVw6BHUVJ2fTAICReGCVj4YgCKI2tPIgCIJYA/SH/VAYqD0tQRDrkpjNIeTFPz18Bj5Vwdtu24YPvfxyDEb9+N/fOQqAh0qTQ4i4lAj6VJyY4YLQWE9wlY+GIAiiNiQIEQRBrAFedPkwvvn+OzAUo51EgiDWHzEhdnu1ns+Xyvj84+dw/5UjGIj4EQ3ouGvPEB4/swjDMJDMFREjhxBxCRHQVSxl+bk+Sg4hgiDWMCQIEQRBrAFUhWHXcHS1D4MgCKIrSIePXCTbOTmbRjJXwl17h8zbrt3cg6Vs0fwZOYSIS4mgKANnDBimjR6CINYwJAgRBEEQBEEQXWUg4gcAzKTyVT87OpUCAOy2ieLXbu4FADxxZlEIQuQQIi4dgj7eKGIw4je75REEQaxF6ApFEARBEARBdJWwX0NPSMeFxWzVz45Op6AwYNtA2Lxt52AEUb+GLz15Hql8Cf0Rat1NXDoERefQUcoPIghijUOCEEEQBEEQBNF1xuJBXFjMVd1+bDqJLf1hBMQiGgAUheHqTT34z6OziPo1vGb/xEoeKkG0hTyXR6lcjCCINQ4JQgRBEARBEETXGesJeDuEplLYORSpuv3azT0AgF990W4MRWlhTVw6WA4hOm8JgljbUEIfQRAEQRAE0XXGeoJ49OS847ZiuYKTs2m86PLhqvv/3A2boKsK3nzLlpU6RILoCDJDaCxOJWMEQaxtyCFEEARBEARBdJ2xniASuZKj9fzpuTRKFcPTITTRG8J779kFjUJ5iUsM6RAaoZbzBEGscWiEJQiCIAiCILrOmAjYnVyycoRkh7FdQ1HP3yGISxGZITRGJWMEQaxxSBAiCIIgCIIgus64WBzbc4SOz3BBaMdQ2PN3COJSRJaMjVLJGEEQaxzKECIIgiAIgiC6jlwc2zuNnZnPYCjqR8hHU1Ji/XDvZcNYzBQxQl3GCIJY49DoSxAEQRAEQXSdoagfqsIcDqEz8xls7gut4lERROfZORTBB1+6d7UPgyAIYlmoZIwgCIIgCILoOpqqYCTmbD1/dj5LghBBEARBrBLkECIIgiAIgiBWhLGeAJ6fTCBbKHO30FIWm0gQIgiCIIhVgRxCBEEQBEEQxIrwqusmcHgqiVf/zUM4MpWEYYAcQgRBEASxSpBDiCAIgiAIglgRXnfjZkQCGt7z6Sfw8R+dBABs7idBiCAIgiBWA3IIEQRBEARBECvG/ftG0Rf24WtPTwIghxBBEARBrBYkCBEEQRAEQRArhqIw3LFrAIVyBX5NwWDEv9qHRBAEQRAbEhKECIIgCIIgiBXlzj2DAIBNfSEoClvloyEIgiCIjQkJQgRBEARBEMSKcvsuLghRuRhBEARBrB4UKk0QBEEQBEGsKAMRP95661ZcvSm+2odCEARBEBsWEoQIgiAIgiCIFef3f+aK1T4EgiAIgtjQUMkYQRAEQRAEQRAEQRDEBoMEIYIgCIIgCIIgCIIgiA0GCUIEQRAEQRAEQRAEQRAbDBKECIIgCIIgCIIgCIIgNhgkCBEEQRAEQRAEQRAEQWwwSBAiCIIgCIIgCIIgCILYYJAgRBAEQRAEQRAEQRAEscEgQYggCIIgCIIgCIIgCGKDQYIQQRAEQRAEQRAEQRDEBoMEIYIgCIIgCIIgCIIgiA0GCUIEQRAEQRAEQRAEQRAbDBKECIIgCIIgCIIgCIIgNhgkCBEEQRAEQRAEQRAEQWwwSBAiCIIgCIIgCIIgCILYYJAgRBAEQRAEQRAEQRAEscEgQYggCIIgCIIgCIIgCGKD0TVBiDH2EsbYYcbYMcbYB7v1PARBEARBEARBEARBEERzdEUQYoypAP4KwEsBXA7g9Yyxy7vxXARBEARBEARBEARBEERzdMshdCOAY4ZhnDAMowDgMwAe7NJzEQRBEARBEARBEARBEE3QLUFoHMBZ2/fnxG0mjLF3MsYOMMYOzMzMdOkwCIIgCIIgCIIgCIIgCDfdEoSYx22G4xvD+KhhGPsNw9g/ODjYpcMgCIIgCIIgCIIgCIIg3HRLEDoHYJPt+wkAF7r0XARBEARBEARBEARBEEQTdEsQegzALsbYNsaYD8DrAHylS89FEARBEARBEARBEARBNAEzDGP5e7XywIzdD+DDAFQAHzcM4w/r3HcGwOmuHMjKMwBgdrUPgrikoHOGaBY6Z4hmoXOGaBY6Z4hWoPOGaBY6Z4hmoXOmebYYhuGZ09M1QWijwhg7YBjG/tU+DuLSgc4ZolnonCGahc4ZolnonCFagc4bolnonCGahc6ZztKtkjGCIAiCIAiCIAiCIAhijUKCEEEQBEEQBEEQBEEQxAaDBKHO89HVPgDikoPOGaJZ6JwhmoXOGaJZ6JwhWoHOG6JZ6JwhmoXOmQ5CGUIEQRAEQRAEQRAEQRAbDHIIEQRBEARBEARBEARBbDBIEOoQjLGXMMYOM8aOMcY+uNrHQ6wdGGMfZ4xNM8aetd3Wxxj7FmPsqPi/1/az3xLn0WHG2ItX56iJ1YIxtokx9j3G2EHG2HOMsfeJ2+mcIWrCGAswxh5ljD0lzps/ELfTeUPUhDGmMsaeYIx9TXxP5wtRF8bYKcbYM4yxJxljB8RtdN4QNWGM9TDGPscYOyTmNrfQOUPUgjG2R1xf5L8EY+z9dM50DxKEOgBjTAXwVwBeCuByAK9njF2+ukdFrCH+HsBLXLd9EMB3DMPYBeA74nuI8+Z1AK4Qv/MRcX4RG4cSgA8YhnEZgJsBvFucF3TOEPXIA7jbMIyrAVwD4CWMsZtB5w1Rn/cBOGj7ns4XohHuMgzjGlvbZzpviHr8BYBvGIaxF8DV4NccOmcITwzDOCyuL9cAuB5ABsAXQedM1yBBqDPcCOCYYRgnDMMoAPgMgAdX+ZiINYJhGD8EMO+6+UEAnxRffxLAK2y3f8YwjLxhGCcBHAM/v4gNgmEYk4ZhPC6+ToJPnMZB5wxRB4OTEt/q4p8BOm+IGjDGJgA8AODvbDfT+UK0Ap03hCeMsRiAOwB8DAAMwygYhrEIOmeIxrgHwHHDME6DzpmuQYJQZxgHcNb2/TlxG0HUYtgwjEmACwAAhsTtdC4RJoyxrQCuBfAI6JwhlkGU/zwJYBrAtwzDoPOGqMeHAfwGgIrtNjpfiOUwAPwHY+ynjLF3itvovCFqsR3ADIBPiPLUv2OMhUHnDNEYrwPwz+JrOme6BAlCnYF53Ebt24hWoHOJAAAwxiIAPg/g/YZhJOrd1eM2Omc2IIZhlIXFegLAjYyxfXXuTufNBoYx9jIA04Zh/LTRX/G4jc6XjclthmFcBx6T8G7G2B117kvnDaEBuA7AXxuGcS2ANESpTw3onCEAAIwxH4CfAfCvy93V4zY6Z5qABKHOcA7AJtv3EwAurNKxEJcGU4yxUQAQ/0+L2+lcIsAY08HFoE8ZhvEFcTOdM0RDCDv+98Fr6em8Iby4DcDPMMZOgZe5380Y+yfQ+UIsg2EYF8T/0+C5HjeCzhuiNucAnBOOVQD4HLhAROcMsRwvBfC4YRhT4ns6Z7oECUKd4TEAuxhj24Sa+ToAX1nlYyLWNl8B8Bbx9VsAfNl2++sYY37G2DYAuwA8ugrHR6wSjDEGXmt/0DCMP7P9iM4ZoiaMsUHGWI/4OgjgXgCHQOcN4YFhGL9lGMaEYRhbwecs3zUM442g84WoA2MszBiLyq8B3AfgWdB5Q9TAMIyLAM4yxvaIm+4B8DzonCGW5/WwysUAOme6hrbaB7AeMAyjxBh7D4BvAlABfNwwjOdW+bCINQJj7J8BvBDAAGPsHIAPAfhjAJ9ljL0dwBkArwEAwzCeY4x9FnywLAF4t2EY5VU5cGK1uA3AmwA8I/JgAOC/gs4Zoj6jAD4pOmsoAD5rGMbXGGM/AZ03ROPQdYaoxzCAL/J9C2gAPm0YxjcYY4+BzhuiNr8C4FNi0/wEgLdBjFN0zhBeMMZCAF4E4F22m2l86hLMMKjEjiAIgiAIgiAIgiAIYiNBJWMEQRAEQRAEQRAEQRAbDBKECIIgCIIgCIIgCIIgNhgkCBEEQRAEQRAEQRAEQWwwSBAiCIIgCIIgCIIgCILYYJAgRBAEQRAEQRAEQRAEscEgQYggCIIgCIIgCIIgCGKDQYIQQRAEQRAEQRAEQRDEBoMEIYIgCIIgCIIgCIIgiA3G/w/gDkT1O90UHwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(np.reshape(np.mean(y_pred * (train_max_dangjin - train_min_dangjin) + train_min_dangjin, axis = 2), [30 * 24]))\n",
    "plt.plot(np.reshape(val_y, [30 * 24]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x287f69e1ac0>]"
      ]
     },
     "execution_count": 1103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(y_pred_2)\n",
    "plt.plot(np.reshape(val_y, [30 * 24]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x287f5ea49d0>]"
      ]
     },
     "execution_count": 1102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAAJBCAYAAAA3J24LAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOz9d9gk6V3ei9/V1fGN84aJm3dmd6VVFisBEiCyJCOSj7FJvuAHNjaOhwMc4GDMsQ2/g20OGAwY88NkjGQhokBhkYSytKuwq807MzuzE9+ZeXPn6gq/P556KnRXVVd3V4fquj/XNVd1ertr3re66nnu5/7eX8WyLBBCCCGEEEIIIYSQ7JCb9g4QQgghhBBCCCGEkMlCQYgQQgghhBBCCCEkY1AQIoQQQgghhBBCCMkYFIQIIYQQQgghhBBCMgYFIUIIIYQQQgghhJCMQUGIEEIIIYQQQgghJGP0FYQURfktRVFuKorypOex/6woyrOKonxBUZQ/VRTliOe5n1AU5ZyiKM8pivLmMe03IYQQQgghhBBCCBmSOA6h3wHwlq7HHgbwcsuyXgngeQA/AQCKojwI4NsBvMz+mV9TFEVNbG8JIYQQQgghhBBCyMjk+73AsqyPKIpyd9dj7/fc/RSAv2ff/mYAb7csqw3ggqIo5wC8HsAnoz5jc3PTuvvuu6NeQgghhBBCCCGEEEIG4LOf/ey2ZVlHg57rKwjF4PsAvMO+fRuEQCS5Yj/Wg6IoPwDgBwDgzjvvxGc+85kEdoUQQgghhBBCCCGEAICiKC+GPTdSqLSiKD8JQAfwh/KhgJdZQT9rWdZvWJb1kGVZDx09GihWEUIIIYQQQgghhJAxMLRDSFGU7wHwNgBfY1mWFH2uALjD87LbAVwbfvcIIYQQQgghhBBCSNIM5RBSFOUtAH4MwDdZltXwPPUXAL5dUZSSoij3ALgPwCOj7yYhhBBCCCGEEEIISYq+DiFFUf4IwFcC2FQU5QqAn4boKlYC8LCiKADwKcuy/qllWU8pivK/ADwNUUr2zy3LMsa184QQQgghhBBCCCFkcBS32mt6PPTQQxZDpQkhhBBCCCGEEEKSQ1GUz1qW9VDQcyOFShNCCCGEEEIIIYSQ9EFBiBBCCCGEEEIIISRjUBAihBBCCCGEEEIIyRgUhAghhBBCCCGEEEIyBgUhQgghhBBCCCGEkIxBQYgQQgghhBBCCCEkY1AQIoQQQgghhBBCCMkYFIQIIYQQQgghhBBCMgYFIUIIIYQQQgghhJCMQUGIEEIIIYQQQgghJGNQECKEEEIIIYQQQgjJGBSECCGEEEIIIYQQQjIGBSFCCCGEEEIIIYSQjEFBiBBCCCGEEEIIISRjUBAihBBCCCGEEEIIyRgUhAghhBBCCCGEEEIyBgUhQgghhBBCCCGEkIxBQYgQQgghhBCSTZ78E+D9/2bae0EIIVOBghAhhBBCCCEkm5x9GPjCO6e9F4QQMhUoCBFCCCGEEEKyiaEBljHtvSCEkKlAQYgQQgghhBCSTQwNMPVp7wUhhEwFCkKEEEIIIYSQbGJ0ANOc9l7MD53mtPeAEDIAFIQIIYQQQggh2YQOoeQ49wHg5+4C6jvT3hNCSEwoCBFCCCGEEEKyCTOEkuPyI4DRBuq3pr0nhJCYUBAihBBCCCGEZBOjQ4dQUuycE1uzM939IITEhoIQIYQQQgghJJuYHcCkQygRds6KraFNdz8IIbGhIEQIIYQQQgjJJoYGwGKw9KhYFrBzXtw26LgiJC1QECKEEEIIIYRkE8Mub2KO0GjUbgBaTdymQ4iQ1EBBiBBCCCGEEJJNpHjBHKHR2D7r3maGECGpgYIQIYQQQgghJJtIhxBzhEZDBkoD7u+UEDLzUBAihBBCCCGEZBM6hJKBghAhqYSCECGEEEIIISSbSEHIYqj0SOycA9SiuM0MIUJSAwUhQgghhBBCSDZxSsboEBoaQwcufQo49Rpxn79LQlIDBSFCCCGEEEJINnFKxpghNDSXPw209oGXfqO4T4cQIamBghAhhBBCCCEke1gWM4SS4Pn3iHKx+94s7jNDiJDUQEGIEEIIIYQQkj28riCLDqGhee69wN1fBiysi/sUhAhJDRSECCGEEEIIIdnDW9rEkrHh2L8E7JwV7qBcXjxmUhAiJC1QECKEEEIIIYRkDwpCo1O7Kbbr97LLGCEphIIQIYQQQgghJHt4S5uYITQcWl1siwuAWhC3Df4uCUkLFIQIIYQQQggh2cPrZGGG0HB0GmJbWHBLxugQIiQ1UBAihBBCCCGEZA9fyRhdLUPhOIQWAUUBcgVmCBGSIigIEUIIIYQQQrKHr2TMnN5+pBmvQwgQZWPsMkZIaqAgRAghhBBCCMkedAiNjmYLQsVFsaUgREiqoCBECCGEEEIIyR7MEBqdjl0yJh1CLBkjJFVQECKEEEIIIYRkD3YZGx2tASg5IF8S99UiQ6UJSREUhAghhBBCCCHZw+tkMekQGopOAyjYgdIAoObZdp6QFEFBiBBCCCGEEJI9fBlCFISGQqsDxQX3Ph1ChKQKCkKEEEIIIYSQ7OEtGWOG0HB0Gm5+EMAMIUJSBgUhQgghhBBCSPZgl7HR0RpuhzGAXcYISRkUhAghhBBCCCHZgyVjo9PtEKIgREiqoCBECCGEEEIIyR7sMjYclgX80XcAZx+2BaGK+xwzhAhJFflp7wAhhBBCCCGETByvcGGZ09uPtNHcA577a2D9XlEytrDhPpfLU1wjJEXQIUQIIYQQQgjJHswQGo7qltg2doFOvatkjA4hQtIEBSFCCCGEEEJI9vCVjDFDKDY1WxBq7tqh0swQIiStUBAihBBCCCGEZA86hIbD5xBqAAV2GSMkrVAQIoQQQgghhGQPr3Bh0SEUG0cQ2gG0ut8hlCsAJgUhQtICBSFCCCGEEEJI9mDJ2HBIQai6JYQ0ZggRklooCBFCCCGEEEKyh69kjIJQbKrXxbZTF9uit2QsDxgsvyMkLVAQIoQQQgghhGQPZggNR+2G/z4dQoSkFgpChBBCCCGEkOxhdISAATBDaBCq10VWkMTrEGKGECGpgoIQIYQQQgghJHsYGpCviNt0CMXDsoDqDWDzfvexAtvOE5JWKAgRQgghhBBCsofRAQplcds0p7svaaG5Bxht4PiD7mNFCkKEpBUKQoQQQgghhJDsYWhAXgpCdAjFQuYHHXup+1jBGypdFCVjljXZ/SKEDAUFIUIIIYQQQkj2MDQgXwKUHDOE4iI7jB17mfuY1yEks4UosBGSCigIEUIIIYQQQrKHDJVWVAoYcaluie3mfUAuL253ZwgB7DRGSEqgIEQIIYQQQgjJHmZHCBi5PGDSIRSLdk1sSytAZV3c9nYZcwQh5ggRkgYoCBFCCCGEEEKyh6EJh1BOpSAUF1lal1OBBVsQ8jmEimJLQYiQVEBBiBBCCCGEEJI9ZMlYTmWGUFxMjyBUCRCEZBmZSUGIkDRAQYgQQgghhBCSPQxNlDgxQyg+UjhTbIdQvgLkPFNKZggRkiooCBFCCAnmvf8X8PbvmvZeEEIIySKWBfzSq4HH3z6+z3BKxpghFBuvQ2jpOFA54n/eKRmjwEZIGshPewcIIYTMKFc/AzT3p70XhBBCsojRAfYuADeeHO9nqAU7Q4gCRiy8DqGv+BHg1d/pf16WjNEhREgqoCBECCEkmOoWoNBISgghZApI4aF1OL7PMDQgZ3cZs8zxfc48Ydq/p5wKrJwS/7xIhxAzhAhJBRzpE0II6cWyhCDEFVNCCCHTQJYmtQ7G9xmyZEzJ8XoXF8chFDKNZNt5QlIFBSFCCCG9tPYBo03LNyGEkOkghYf2OB1CsmSMGUKxMQ0hBilK8PMUhAhJFRSECCGE9FLdElsO6AghhEwDc0IlY7LtPB1C8bAMkR8URo5dxghJExSECCGE9EJBiBBCyDSZSMmY7nYZs+gQioVpCAEtDGYIEZIqKAgRQgjpRQpCHNARQgiZBhMpGdNEiZOismQsLpYZ7RBSZZcxjh8ISQMUhAghhPRSvS62tHwTQgiZBpMMlc5REIqNqcdzCFEQIiQVUBAihBDSS+2G2FomB8mEEEImj3QI6S1AH8PihGmIz2CG0GDIUOkwvBlCpgF84D8Ah9cns2+EkIGhIEQIIaSXqmfwxlU+Qgghk8a7GDGOsjEpAOVUZggNgmWI31cYssuYqQPbzwMf/XngyT+ezL4RQgaGghAhhJBeqjfc28wRIoQQMmm8gtA4ysbkYgczhAajb6i0p+28XFzaOTf+/SKEDAUFIUIIIb3QIUQIIWSaWGMWhByHUIEZQoPQr+28kyGkuYtLO+fHv1+EkKGgIEQIIcSPZYkuY8UlcZ+CECGEkEkz9pIx+/1zeWYIDYJpRjuEcp6SMbm4tH12/PtFCBkKCkKEEEL8tA4Aow2s3i7us9MYIYSQSTMxhxAzhAbC6hMqrXpCpWWDitoW0K6Of98IIQNDQYgQQoifTlNsy0fElhlChBBCJo0vQ2gcDiH72pbL2xlCdAjFYpgMIYBlY4TMKH0FIUVRfktRlJuKojzpeWxdUZSHFUU5a2/XPM/9hKIo5xRFeU5RlDePa8cJIYSMCblKWiiLLUvGCCGETBprQl3G1IIQhUwz+c+YR2JnCHVE+fniUXGfwdKEzCRxHEK/A+AtXY/9OIAPWJZ1H4AP2PehKMqDAL4dwMvsn/k1RYk6YxBCCJk55KpsnoIQIYSQKTHuLmO+DKEcHUJx6ecQyqkAFOHAqm4Bd36JuE9BiJCZpK8gZFnWRwDsdj38zQB+1779uwC+xfP42y3LaluWdQHAOQCvT2ZXCSGETASrWxBihhAhhJAJM+6SMbnYwQyhwbDMaIcQIFxChiYEobV7gNU7KAgRMqMMmyF03LKs6wBgb4/Zj98G4LLndVfsxwghhKSFbocQV00JIYRMmkmVjDFDaDBMQziqoiguALsviAYVyyeA9XuA3QuT2T9CyEAkHSqtBDxmBb5QUX5AUZTPKIrymVu3biW8G4QQQobG7M4QokOIEELIhBl7yZgUhGSGEB1CseiXIQQAd70ReO694vbyCaC0DGj18e8bIWRghhWEbiiKchIA7O1N+/ErAO7wvO52ANeC3sCyrN+wLOshy7IeOnr06JC7QQghJHF6SsaYIUQIIWTCyGuRkptAhpBKQSguph6dIQQA97/Z7eK2fBIoLAB6c/z7RggZmGEFob8A8D327e8B8Oeex79dUZSSoij3ALgPwCOj7SIhhJCJwlBpQggh00Zei8pHxiQIeTOEVGYIxcWM4RC6z9Noeum4cBx3KAgRMovEaTv/RwA+CeABRVGuKIry/QB+DsDXKYpyFsDX2fdhWdZTAP4XgKcBvBfAP7csnl0JISRVOG3nK2JrUhAihBAyYaQgtLDODKFZwjL7O4SWjwO3fZF9+4RwCHVa4983QsjA5Pu9wLKs7wh56mtCXv+zAH52lJ0ihBAyRUxTbNlljBBCyLSQixNH7gQufBRoV0UWTVJIAUhlhtBAmIb4ffXjoe8TQlBxUSwwdRrj3zdCyMAkHSpNCCEk7fRkCHHVlBBCyISRAs39bxFO1fMfTPj9PQ4hZgjFxzJErlM/XvPdwPe+W9zOV8TfkOMJQmYOCkKEEEL8sMsYIYSQaSMXJ+78UqC86natSgopTuRUIQox5SIeptG/ZKwbWYLOYGlCZg4KQoQQQvx0O4SYIUQIIWTSeBscnPk64Oz7k3Xx+DKEcswQikuctvPdSEGIwdKEzBwUhAghhPhxBuElsWWXMUIIIZPGaQuvAg+8FWhsA1c/l+D7S0GowJKxQRjFIURBiJCZg4IQIYQQP45DyB7AURAihBAyaeS1SMkBx14qbh9eSe79fRlCeTqE4mKZdAgRMkdQECKEEOLH6TImHULMECKEEDJhvA4hdQyOVdOTIaSoACz3+kfCMQ0gN+AUMs8MIUJmFQpChBBC/MhVWbmixwwhQgghk8ZxCKmiNTyQ7AJFd9t572eScJghRMhcQUGIEEKIH7kqqxbFliVjhBBCJo23pEtej/T2eN5fOl6YI9SfkTKEGsnvDyFkJPLT3gFCCCEzhlwhlbkKFIQIIYRMGlm+lVMBRTqExlEylncdQswR6s9IDqFW8vtDCBkJOoQIIYT48eYqqEVmCBFCCJk83lDpcZSMGd6286r/M0k4pjmEQ2hBbFkyRsjMQUGIEEKIH9OT25ArcMWUEELI5AkMlR5XyZh0CFEQ6oupD+4QypfFlqHShMwcFIQIIYT4sTw2fbVAhxAhhJDJExgqPa6SMVvgoCDUH2uILmN0CBEys1AQIoQQ4se3KluYXIZQ6xC48NHJfBYhhJDZxivYKIpwrI4tVFr1P0bCMQ3XURWXgu0QoiBEyMxBQYgQQoif7lXZSQlCn/kt4Pe+GdDqk/k8Qgghs4s3VBoA8qXxOYSYIRSfYUKl82w7T8isQkGIEEKIH69DKFcAzAkJQgdXxEBTY1taQgjJPN7FCSD5EmZTF4HVuRy7jA3CMKHSuZzIEWLbeUJmDgpChBBC/PgcQhPsMla9LrYcMBJCCHEWJ+zpilpKPlRaCkHMEIrPMA4hQAhCOtvOEzJrUBAihBDix5chlHdb846b6pbYcsBICCGkW3hQi8mWjBkdjyBkb2VTBRKOOUSoNCCCpbngQ8jMQUGIEEKIHzkgnoRDqLEL/OX/DrRrQO2GeIwDRkIIIV4HDyBKxhINlfaEIys59zNJNMM6hAploMMFH0JmDQpChBBC/Hht+uPOELrwEeCzvy220iHE0ElCCCGm4c+qyZeSzxDqdgixZKw/3X+XuBQWeH0nZAahIEQIIcTPJLuMSRHoyiOu8MQBIyGEEMvsKhlL+HoUmCFEh1BfhnYIVegAJmQGoSBECCHEjy9DaNyCkB0kffFj7mMUhAghhHRn1SQeKh2UIUSHUCSmXVI+jEOIodKEzCQUhAghhPiZZJcxmRt07fPuYxwwEkIIGXeotC9DiF3GYuEdHwwKQ6UJmUkoCBFCCPHjXQHM5cdroZcOIe9ncMBICCGkO1Q6X0w4VFoXnTQBtp2PizdjcFAYKk3ITEJBiBBCiJ9JOoSqN3of44CREEJId3hx0tcjZggNzsgOIZaEEzJrUBAihBDiRw6Ic7nJZAgtnRC31ZLY0iFECCFk3KHSBjOEBsYZHwwZKq1TECJk1qAgRAghxI/pyW0YpyDUaQKtfeDuLxP31+5yHyeEEJJtxh4q7XEgKXQIxcIcwSGUr/D6TsgMQkGIEEKIH8sTtJkruO3gk0CrA7sviNsyUPquLwWgACun7C4kHDASQkjmGXuotC6ucYB7zZMZeiQYS2YM5qNfF4RsO29Zye4TIWQkKAgRQgjx4101TTqz4ZHfAH79K8RnVLfEY2t3A8dfBmw+IAQhriASQgiZRKh0T4bQGEuk54FRQ6Utc7xl6ISQgRlC3iWEEDLXeHMb1AJgJGihb+wCWhWob7uC0NIJ4Hv/SohBz/wlBSFCCCETDpXOu4+RcEYNlQaESyhfTG6fCCEjQUGIEEKIH29ug1pIdgAuVwar111BaPkkUDkibhfoECKEEIKAUOkxlIyp3SVjFIQicRxCQ4ZKA4DOTqKEzBIsGSOEEOLHm9sgM4SSqvmX4lLthhCFcgVgYd19nm1pCSGEAAGh0sWEQ6U9DiEpDCXpiJ1HRnEI5W1BiJ1ECZkpKAgRQgjx050hBCS3aioFoep1IQotnwAUxX2ebWkJIYQAwaHSpp5c8HNghhAFoUiScAhx0YeQmYKCECGEED/eQbhqD5aTsunLwXZ1C9i/DKzc5n+eodKEEEKA4FBpILngZ0P3d9RM8r3nFdllbCiHUElskwwGJ4SMDAUhQgghfkyz1yGUVI6Q4xDaAnbOAhtn/M+zZIwQQggQHCoNJCcoMFR6cEbpMiZ/x1ZCDi9CSCJQECKEEOKnO0MISL5kbOecKBnb7BaEKhSECCGEBIdKA8k6VpkhNBijZAgp9rSTohshMwUFIUIIIX66u4wBCTqE7IH85UfEtschREGIEEIIwh1CSQVLM0NocEbJEHJcWEZy+0MIGRkKQoQQQvz4MoSkIJRUZoMtLMkBfZAgxFBpQgghluG6SoDkS5hNZggNzCgOIYpuhMwkFIQIIYT4GWuXMe9gWwHW7/U/n6dDiBBCCGzBxiM8yFDiJEvG1K6SMYoV0cgOb6M4hCw6hAiZJSgIEUII8ePLEJJdxhIOlQaAI3e6A3yJLBmzrGQ+jxBCSDoxDX+XMSnajDNUmhlC0UjBbKgMIekQoiBEyCxBQYgQQoifIIdQ0iVjALB5X+/zhYoQpJL6PEIIIenEuzgBjKHrZccVghRFfBYdQtFYo3QZoyBEyCxCQYgQQogf05PbkHiGUAdYOi5ud+cHAUIQAoBOI5nPI4QQkk5MMyRUOqkMoS4HUi7PDKF+OKHS+ejXBcEMIUJmEgpChBBC/FieQXLiXcY0YP20EJyOPdj7vBSE9FYyn0cIISSdTDJUGhDXO7pXohkpVJoZQoTMIkPIu4QQQuYaX8mYDPFMKLPB6ACrtwNv/TBw7KW9z+fpECKEEIKIUOkxCUI5leXK/Ril7bxChxAhswgFIUIIIX68uQ35stgmFeJpdMQq78lXBj/vlIzRIUQIIZkmNFQ6AUHIskR5mE8QKlCs6IdldxkbxSEkO5URQmYClowRQgjx481tkCuyiQlCmjuoD6KwILZsPU8IIdlmnKHSUthghtBgmKOESts/Q9GNkJmCghAhhBA/3tyGsQhCxfDnC9KRREGIEEIyTU+odIIlY1KUUJkhNBDMECJk7qAgRAghxI83Q8gRhBIq4TI6dAgRQgjpT0+odIJNDqQgxAyhwWCGECFzBwUhQgghfoIyhBILle7jEJKfx1BpQgjJNuMMlZbCDzOEBiMJhxBdWITMFBSECCGE+PF1GbPFmyRKxmSIZ6RDiKHShBBCEBAqLa9HSTiEpNPFcz1ihlB/RnEIyZ+hIETITEFBiBBCiJ/ALmMJCDRyRTZWyRgdQoQQkml6QqXHUTLmff88xYp+jNRlzP4ZZggRMlNQECKEEOInsMtYEhZ9+z3ihEozQ4gQQrJNaKh0Ao7VwAyhPDOE+jFKlzFmCBEyk1AQIoQQ4scb5KkoQsBJxCEUQxAqLomtVh/98wghhKSX0FDpBEQbkxlCQ8EMIULmDgpChBBC/HgzhABRNpZEhpDT5jeiZEwtiLKx1v7on0cIISS9dF+L5AJFIiVjtiihdmcIURCKJKjULi45OoQImUUoCBFCCPHTnduQLyVj0Y/jEAKA0grQPhz98wghhKQXU/c7eADbsTrODCGKFZGYCTiEZA4RIWQmoCBECCHET3erX7WUjEMoriBUXgVaFIQIISTTdC9OAMLRk2ioNDOEBkKKOd1CXRxk+R9FN0JmCgpChBBC/Jimf7CXL02uyxgAlFeA1sHon0cIISSdmFJ46BaESskIQgYzhIZilLbziiIEPmYIETJTUBAihBDipzvIM6kMIZaMEUIIiUNYeHHSGUI5ZggNhPN3GXIKmVP5OyZkxqAgRAghxE9PqHSRJWOEEEImR1h783xSghAzhIZiFIcQIEQ3iw4hQmYJCkKEEEL89IRKl5MtGeuXPcCSMUIIyTZBGT+AHSqdYNdLZggNxiht5+XPsWSMkJmCghAhhBA/PQ6hpDIbWDJGyFS48TRFVpIuQkvGCsmINuaAGUKXH6VYBCTgEMpRECJkxqAgRAghxI9l+gfhalKh0gOUjOmtZFaBCck6lgX8j68HPv0b094TQuITJjyoRcBI0CGkxsgQ2j4H/I+vBZ79q9E/N+3ILmPDOoSY00TIzEFBiBBCiJ8gh1AiGUJxu4ytii1zhAgZHaMDaFW67ki6CBMecoVkHCZBglNYhtCtZ8S2sTP656adUR1CisoMIUJmDApChBBC/AR2GUuy7XyMkjGAE1hCkkBvii3LNEiaCAuVTir4ObDtfEiG0PZZse00R//ctGMZABTRQn4Y6BAiZOagIEQIIcRPYJexCWYIOQ4hZp4QMjJyEstJGEkTYaHSSQU/B4ZKh7iPds6Lbacx+uemne7xwaDkVMA0k9sfQsjIUBAihBDiZ9xdxvqWjNkOIQpChIyOFIRYpkHSRFiodFTw8yA4gpA3Q0h1w6a97JwTWwpCveODQcmpFKcJmTEoCBFCCHGxLJHdkOsWhJLIEBqgyxjAkjFCkoAOIZJGwrJqkio5CswQChGbdlgy5jCqQ4gZQoTMHBSECCGEuAQFeSbV1WXgkjEKQoSMjE5BiKSQsFDppDKEAtvOB5SjNXbdMGmtPvrnph1zVIcQM4QImTUoCBFCCHEJCvLMl8UAzhhxEMeSMUImT4eh0iSFRDmExpkhBMv/Xdl9wb1Nh5Bw93QHfQ9CTuW5iJAZg4IQIYQQl6DchnxJbEd1CTkOoT6CUHEZgMKSMUKSgCVjJI04gs2YM4TUrgwh73OA22GssMAMIcAuGcv3f10YFIQImTkoCBFCCHEJGoRLQWjUHKG4bedzOZEjxJIxQkaHghBJI6Gh0glnCCldGUKA34G0e1685ugDFISA0UOlmSFEyMxBQYgQQoiLY9P3rAAmJghpve8dRnmFJWOEJAFLxkgaCSsZSyxDKGDxQ16bvO/f3BO5dqUVQKMgNHrbeWYIETJrUBAihBDiEhTkmS+L7ait5w1NuIMUpf9rSyssGSMkCXQKQiSFRDmExpohBL9g0WmJcrHiIjOEADFGGLntPM9FhMwSFIQIIYS4BLbitUu8pMNn6PfW+5eLScqrdAgRkgQsGSNpxLQXJ8aWIRRwrQvKEOo0gEIZKFSADruMCYfQKKHSeXfhiRAyE1AQIoQILAs4uDLtvSDTxlmV7eoyBiTkEOoTKC1hyRghySBzTygIkTQRGiqtJnMsBzmQgjKE9JYQgwoLdAgBCWQI5XguImTGoCBECBG8+HHgF18O7F2c9p6QaRK0auoIQglkCMV1CJWWgXZ1tM8jhIiSF4CTMJIuwkrG1EJCJWMBeXlBGUKdhhCDCgvMEAISyhBiyRghswQFIUKIoH4LgAUcXp/2npBpEth23hZxkugyFlcQyhU4aCQkCRyHEL9PJEWEhUon3WXMW/4UmCHUFIsiRbadBzC6QygphxchJDEoCBFCBLKmW6tNdz/IdBm7QyhmyVgux9a0hCSBLPXk94mkidBQ6QIAa3SBM0jYCMwQaroOIbOTjDspzSThEOK5iJCZgoIQIURgUhAiCOkyJtvOJ9RlLA5sTUtIMjBUmqSR0FDpANFmqPfX/eViQHCGUKdph0ov2Pcz7hIatcuYwi5jhMwaFIQIIQK5YtOmIJRpAruM2YKQEeIQuvhx4Npj/d/b6MR3CHHQSEgyMFSapJGwUOkg0Wao9w9wugRmCEmHUMW9n2VG7jLGa/tAPPY/geb+tPeCzDkUhAghAnmBpkMo2wR2GZMOoRBB6H0/Afzt/9P/vQ3NzWjoR06lrZyQJGCoNEkjoSVjAaLNUO8f4HQJyhDSm26XMQDQMt56nhlCk+PwGvBnPwg8/WfT3hMy51AQIoQIZKkQHULZJjJDKKRkTGvEGyQPUjKmqG7JACFkeBgqTdJIaKh0gGgz1PvrAe6jEIeQDJWW97NM0O9tEJghFB/ZaTXrxxwZOxSECCECeYHW2Oo70wR2GZMOIS34Z4x2vFyFQUrG6BAiJBl0OoRICgl1CCWVIRRRMibL0SzLHyoNMEPINHqzlwZBoUMoNnKhbdSGHoT0gYIQIUTglIxl3A6ddQIdQn1CpfW2W5YSxUBt5zloJCQR6BAiaSTMIZRUhlBgl7Eu95HeBmAxVNrLqKHSuTzdv3GRxxoFITJmKAgRQgQsGSNAcJcxtU+GkN6K6RAatGSME1hCRoZdxkgacQShLjdKUhlCQV3Gut9bXte8odJaxgWhkUOlczwXxUUea6N2eCWkDxSECCECi23nCYI7u6h5IdCEdRnTtXg17iwZI2TyOKHS/D6RFBHU4ABIMEPI7J8hJCfihQpQXBS3M+8QGjVUmhlCsenYjn0jpFyfkIQYSRBSFOWHFEV5SlGUJxVF+SNFUcqKoqwrivKwoihn7e1aUjtLCBkjcrLQZoZQpgmz6efLwQ4hyxKDZj2OIDSgQ8gyxfsTQoaHbedJGgkNlU4oQ8gyAsSmrgwhudCRr3jazmdcEArKXhoEZgjFhw4hMiGGFoQURbkNwL8C8JBlWS8HoAL4dgA/DuADlmXdB+AD9n1CyKxjMUOIIDzIM18KHpQYHQDWAA6hATKEANe5RggZDoZKkzQSdi1KKkMosGSsy30kr2uFClBY9D+WVZJwCDFDKB4dCkJkMoxaMpYHUFEUJQ9gAcA1AN8M4Hft538XwLeM+BmEkEnAkjECRDiESsEOIVlGZmj9S1IMbbCSMYCTWEJGwbLoECLpJNQhlFSGUFCXsa7rjk8QkhlCGV80Cyq1GwQ2jIiP02WMJWNkvAwtCFmWdRXAzwO4BOA6gAPLst4P4LhlWdft11wHcCyJHSWEjBmnZIyCUKYJdQiVgwfCXpGo38rpIIKQ/HzmnhAyPN7vJ912JE04eXZ9XDzDEuR0UbsdQjJU2lsyRodQT6ndIDAfMD50CJEJMUrJ2BqEG+geAKcALCqK8t0D/PwPKIryGUVRPnPr1q1hd4MQkhROyRgzhDKNtHJ3rwAeuQPYv9T7eu9Apd+gRW8JYSkOTskYB46EDI2cUOQKXJUn6aJ1ILalFf/jSblHTSO8y5gsR/OGSiuK6DbGDCFmCE0KxyHEtvNkvIxSMva1AC5YlnXLsqwOgD8B8AYANxRFOQkA9vZm0A9blvUblmU9ZFnWQ0ePHh1hNwghiWB62s4zyDe7hHV22bgP2Dnbe2z4HEIRA2VZulJYiLcfdAgRMjrSzVBa5iSMpIvGLlBcBvJduXOJZQgFtE/vyRCyr2l52x1EQSihDCFe12Mhj7WwDq+EJMQogtAlAF+iKMqCoigKgK8B8AyAvwDwPfZrvgfAn4+2i4SQiSDLCSyDqxFZJiy3YeOMWLFt7Pgfj1syJl8nbff9YKg0IaMjHQ6lJQpCJF00d4GFgEbF4ywZ68kQ8jiEAFsQynjJ2KgOoZwKwGKwdBycLmMck5Pxku//kmAsy/q0oih/DOBzAHQAnwfwGwCWAPwvRVG+H0I0+rYkdpQQMma8pTlaDSjELO0h80VYhtDmfWK7cw5Y3HQf95aJRQ2UvVkMcZAOJU5iCRke+b0rrQhx1TR7XRGEzCKNHWBho/fxxEKlA7qMRWUIAUBxgaHSIzuEvOXgPBdF0pElY8wQIuNlaEEIACzL+mkAP931cBvCLUQISRNeC2+76p/0k+wQ6hA6LbbbZ4E7v8R93PB0v4gUhDzdWuLgDPppLSdkaKTDobgktpyEkbTQ2AUq672Pq+PsMtaVIdR93SpU6BBKIkMIEH+/uE0msorjEGKXMTJeOCoghAi6HUIkm8gSre4VwNU7hVV/55z/cV+odFTJmP26/KAlYxSECBkaxyFkC0IUWElaaO4CCwGCULdoMyyWGVAyJh1C9vdEXtNk9l1hkRlC5qhdxrjYExt2GSMTgoIQIUTgzWrJuiU6y4Q5hNQ8sH5vgCAUM0No4JIxhkoTMjLeUGmAJZgkPTT2gh1CSWUImXqAQ0hedzwOIUV1nSyFCgUhK6A72yAk1SUuC7DLGJkQFIQIIQJvwF+bDqHMEtZlDBDB0kMLQjKcM2aXMTqECBkd6XCQJWOchJE0YOhA+yDEIZRk2/kuQUhR7C5YMkOo6b9mFRfcMp6sklTJGBtG9IddxsiEoCBECBH4Ssaq09sPMl3CHEIAsHkG2H3B79oZ2CEUM6ycDiFCRsdxCK2ILb9PJA0098Q2MEMoobbzYeHIubw/Q8h7zWKXseRCpSlO94ddxsiEoCBECBH4QqXpEMoscpAWNOBbPilCpNuH7mNxu4zpXe17+5GjIETIyMiSA5aMkTTR2BHbqAyhcXQZA0RJmrzudJr+a1ah4nZ+yiqmmUDbefDaHgd2GSMTgoIQIUTgDVhkqHR2kU6xoIGyWhRbb8cLr5U5KlTacQixZIyQiSHP5ZUjYktBiKSB5q7YBgpCSWUIhQgbOdXNENK7SsboELIdQkmESvNc1BfpEDI0wLKmuy9krqEgRAgRWAZQtssKKAhlF5klFTRQzpfE1icCxS0Zs5/Ls2SMkInRronJm6/tPCEzTsMWhAJDpRMqOQoTNtSCP0Mo310y1vBnLmaNxDKEeC6KxOgIYbKwKO6zbIyMEQpChBCBaYiBj1pkyViWiQqVVm1ByOsQcqzMSnT3lU5X+95+0CFEyOhodSEGqQm5KgiZBFEOoaQyhEJLxrozhLpCpYFsl/CMnCHEtvOxkOW+lTWxzfIxR8YOBSFCiECWjBWX6BDKMlGh0nm7ZMznELLFodKK20ksCEcQokOIkImhVcU5nZMwkiYiHUIRJUcP/zTw7h+K9xlhTpeeDKEuhxCQ7dbzozqEspYh9PFfBv7g7w3+c/IYW7AFIUPzP290gF//MuD59/f+rGUBv/m1wJPvGvxzSSahIEQIEVgmkMuJsiBaU7OL4xAKGPA5DiGvINQSjxcXogfJ+pAOoawMGgkZB+0aUFpiZx+SLho7wq1cXOx9LipD6MpngIsfi/cZoV3GPBlC3Q6hrAtClgXAYpexQbj2eeDcw8DuhcF+TuYHSVG02yHU2AG2ngBuPNn7s0YHuPIocPVzg+8vySQUhAghAtOup88VsnOhJr3Ecgh5S8baQkTMl6MtzZ2mWNmVdv9+sGSMkNHRamJSzSBXkiaau8DCBqAovc9FCQqdhusu6odphDRP8IyB9IAuY4A7Wc8aUeODuGQtQ0i6o59/34A/110y1rVQ27K7vYZ9DwCgdTDYZ5LMQkGIECKQq2VqfvTafJJeBnUIGbYg1K/7SqcJ5GO2nPd+Ph1ChAxPu9ZVMkZBiKSAxl5wuRggRKJcyDhFbwkxKU7os2kIV3Q33RlC3lBp6VjKrEMoImMwLlk7F0l39PPvGeznpOgoc7R6BCFb7An7HnhfQ0gfKAgRQgSyLjxXcO3SJHtEdRlTwxxCZbFy2mkKW7QcyNx8xn2/TtdKaz/oECJkdLQ6UFr2CKwZ7o5E0kNzNzhQWpLLhzsjLBNoHwAHV6InxKElY3lPhlCjq2TMvoZltfV8Eg6hXMbORfJYufhx19UT6+ekQyhEEGrbx3bQeF0Klu0BPo9kGgpChBCBDJVWC4CRkZUb0kvUCqAsGevJECqKgXL7EPj1Lwc+/kvAznng174EePYvxeu6wzn7oWQsZ4CQceCESvP7RFJE7aYoGQsjrLRdNjZo7AK/8zbgb/9j+HuEdRlTC+6iR6fVFSqdcYeQ/J0zQyg+naZoumF2gKufif9zToZQSJcxKS4FOYTk92AQAYpkGgpChBCBZdoZQnk6hLKMHCQHZTfIkjFflzGPQ+jW82ICeuNJN+hwy97qzfiB0oDHVp6RVURCxoETKp2xMg2SXowOsP8isH5v+GtyaoggZLsx6reAvYtA9Xr4e5hmiBO2JAQhy7JLor2CkHQIZVQQspghNDCdJrB0zL0d++e6SsaMkJKxqO8BS8ZITCgIEUIEsp5eLfa2tyTZIWzVFPA4hEJCpaWFefsssHNO3JbbgUvG7MtTVgaNhIwDhkqTtLF/SRynG2fCX6MWQpwR9iT61nMALHH8hxFWMiY7rcpxUL7kPle0FzUyGyotS8pDxghxcM5FGbm2d5pAeVXcHqSDr9avZEw6hALG6ywZIwNCQYgQImDJGAHE3z5ssBfoEGq5odKS3ReEWwgAds6KLUOlCZkshi6+n8VlCkIkPchFhM37wl8TlCFk6K67+ebTYisn1UGYekg3zZL43sgSHdUjCGW+7XwSodIZKxnTPYLQIA1bOiOUjDFUmgwIBSFCiMCSodIsGcs0kQ4h2WXMsyJlaLYg5LHVmx3ghQ+J2zvnhfWeodKETBbpjvCVjPH7RGacbXsRIcohFJQhpHvKcW48Jbbtavh7yEYa3UiHkHRk5CkIOSQSKm2fi7Jybfc6hLrLvqLo6TLW5QSKLBmzf9bQ3DwhQiKgIEQIEZiGWPUJs2KTbBAlCDldxrodQmV3oCxXU2s3xO1OQ+Q4DCoIMVSakNGQglBxiSWYJD3snBOuiMguYwEZQt6JrxSEokrGTD2kZKwsrnGOIOTNEJKCUEa7jDkOoQQyhLIgTsvFMEcQGiCOQW+JsZg85rodQu0YodLe1xESAQUhQohA1tOz7Xy2ieUQ6gqVll3GAODeN7nPydvbZ+1Q6UEcQgyVJmQk2kEOIQqsZMbZOQdsRJSLAcELV17XTnNXbNshgpBlAbCCr3VRDiE1L653UaVo80yibeczIAjpbQDWcCVjZkeMx6Ug2Z0hJEvGotrOAywbI7GgIEQIEViWuFCreWYIZZlYDqHuUOmymw90xxe7g5/73yy2O+cYKk3IpHEcQswQIili51x0uRgQnCEU5NoJcwhFCRtqV4aQVxACxHWMDqHh3yNLGUJSmBkmVNo0hPDpLMR1ZwjZQk/QeN17fLL1PIkBBSFCiECWjNEhlG1MXYiCQSiKEIW6HUL5kiv2bN7nDubveZOwO0tBiKHShEwORxBaZIYQSQftmigx3jgd/bogQUgPEGk6jeBjXv5saIaQ5pZGe0vGAKCwCHSy6hCSXcaYIRQLKeIM4xAyOuL3LAWh7vyhdoRDyPtdaNMhRPpDQYgQIrCYIUQQ7RACxOqpzyHU8gtCG2eE3T+XB9buBtZPD+kQytAqIiHjwFcyxu8TSQG758V2FIdQ98JDUHlXlNMlX7YdQvYEXDpjJXQIjdZlLEuLPfI4KS4DUAYLlTZ1sUCby4vfd1jJWGCGkNchREGI9Cdi1E8IyRSy44Ya0L2DZId+glC+yyFkaGIA/ZJvAFr7wNGXAl/yg8BdbxDH0uYZ4OrnxEDI25q+Hwq7jBEyEr5QaZaMkRRQvSG2K7dFvy4wQ8ieBK/eDuycFdcQyxDfg/KK/7VRJWP5kv1zdrlPt0OouOA+lzWYITQY8pgsVMRxNUiotNmxxSDFFSm9RHYZY8kYGQw6hAghAst0Q6UHuWiR+cKI4xDq7jJWApZPAF/+wyL759SrgS/6HvH8xhlg/0Vxu1DuebtQWOJCyGjIltul5WytypP00tgR26gOY4DtEOo6lh1ByBaT1u4W26BgaadkLCRUGnBLbXoyhBay23aeGUKD4RWE1OKAodKGW76vFv1t503T02UsYLzeabodX+kQIjGgIEQIEVgehxBLxrJLLIeQPQAxDTtzqBT+eq/1fxCHkBw0WuwyRshQyFIZOoRIWpDdwWIJQl3jFOmgkO6iTbtTmVbt/Xl5XQkrGQPciTRDpV0ScQhlKUPIKwgVBguVNjru76rbIaTVAFju63o+twUsbopSM7adJzGgIEQIEZimJ1Sak4bMEitDyB7UBLXl7cbbPrjbeh+FzCigo4GQ4dBq4ntUqNBxR9JBY1ccs6XV6NcFZgjZrh0pCMnFiHZNiDumZ3HBETYCpkEyM0iW2gSGStMhNDRKVh1Cg5aM2RlCgB107hGTvK6fsLbzxUXhDmXJGIkBBSFCiMAJlc7TIZRlzE58h5DTljdC6PF2i2GoNCGTo10T7iBF4feJpIPmLlBZCxZqvERlCEkh6PjLxba6BfzCg8BTf+K+NrJkzL6eSWdFoEMoo4JQkg6hLIjT8jjJ2w6hgQUh6RDqKtV3XD9KeNv5fFkIqywZIzFgqDQhRGCZ4iLPtvPZxjSGcAgVw19fOQIsHgXqtxgqTcgk0apCEAJYMkbSQWMHqPQpFwOiu4y95BuAf/xB12V06xnhlrv5tPvayC5jXdkr3SXRDJUerctYpkKl7UWzoUKldTdDqMchZAtClbUQh1BTjLcsiyVjJBZ0CBFCBKan7bxl+u3VJDt4ByFB5EuuQ0gKQ/1KweSKLUOlCZkc7ZpoOQ9QECLpoLELLGz0f12UIFRYAG77IvfY3zknttUt97X9uowBnpKxoFDpjGYISSEtatGoH7kMLfZIh9AwodJRGUJSrFzYCG87X6iI7nosGSMxoCBECBFYht1lTE4c6BLKJH0zhIq9DiE1wiEEuGVjDJUmZHJodY9DKEOTMJJemnv9A6UBcY3qngjrdpmMLDeTx/52lCAU1WUsLENoAejU++/jPJJEyViWMoR0j0No0FBpb4aQWvJ3GZPH5uJm8O9RtwWh0gpLxkgsKAgRQgSm7DJmT+6ZI5RNjH4ZQh7rcpwMIcANlmaoNCGTQ/M4hNh2nswaFz8O7L7gf6yxG69kTC0Et533XmPkAoT8DK8gZEWUPnV3GVML/ucLC2ISnsUxUiJt5zPk/vVlCA0TKu0tGRvGIbQKtCkIkf5QECKECCxLXOTl4IcOoWzSN0Oo6A5q4nQZA4C7v0zkCK3eEX8/FEUM1rOwikjIONDq7qQ4l+P3icwOnRbwh98GfPBn3McsS2QILaz1//mc2jtG6TT8LtRcTriEpKO1et19LsrponpKxvJlcS3yUrQ/Q8ugS0hGCYwUKp0hcbrTdMfVg4ZKGx23fL87yLxdFduoDKF8RXQaa9eG33+SGSgIEUIEssuYFAOyuPpF+peMDeMQuv0h4EfPAYsxsiG8KCpLXAgZFlP3uxuCclcImQYXPybKrrafdx/rNIR4EytDqBCQIdTqzamTZWOA6GAmr12RXcY8JWNBix2yW2YWc4SSbDufhWt7pyVESkXxL6bFwTsWW1gX7jmJVhfj9dJytEMoyElHSAAUhAghAtMQK2pyAkFBKJv0zRDy2J69HTTGQS7PwQwhw2J03AwKgIIQmR2ef4/Y7pwXziDAnfDG7TIW1Ha+O6eutOS/X7shtpFdxjwlY0GLHYVF+/My2GnMcVaN0mUsB0DJxrmo03BFyoG7jHnO35V1IWjK70qnIY5DtRAtCPGcT2JCQYgQInBCpVkylmnMfhlCxQCHUJ+SsWHJqQyVJmRYDC3AIUSBlUwZywKee68Yb3QabilX0xaE4oRKBzkf9GavgFO0xZuKXYZWtQWhqNKnvJ2j2D7sbTkPeBxCGRSEknAIAdk5F+kt93hRC/5g6H7IXE9AfCcMzS1T1OqidDFX6B2rW5YbKp1TKQiRWFAQIoQILNMOlZYOIV5EMknfDKGSuyLlCEJjcggpajYGjYSMA2+XGsDOEOL3iUyZm08Dh1eAl32rff8Z4M//BXD+Q+J+LIeQnSH0N/8OuPBR8Zh0RXgpLovtyVeLrRSfnJKxCIcQELzY4WQIZVAQSqLLmPz5LAgVnYY7Pho0VNrouONx+Z1o7LjvW1gQz1umK3AC/s5mdAiRmFAQIoQIzK4MITqEsompu0GGQeS9befH7RBiCC4hQ+OdUACcHJDZYPeC2L7874rt5/8A+PzvAx/7BXE/Vtt5u4X3x34BeOKd4rHuUGnALRk79WqxlZ3GIkvGPNezwJKxBffzskZSDiElI+5fr0ipFgeLYujOEAJcF53WEO63oPG6zLbK24KQZbilZoSEQEGIECKwTH+XMWYIZZM4GUJ6Wwwwxp0hxFBpQobHpCBEZhC5oLB+r5i0Pv3n4r63lXY/1AIAe5Irc4GiQqWPv1xcT2q2IBSnyxjglo95cQShDIZKJ9FlDMjOucgnCBXcYz8OXoen/E7InK1O3XUIAf7xujwupUMIoDOU9IWCECFE4JSM2QMgOoSyidGvy1gRgCUGK2N3CGUkZ4CQcWB0lYzx+0RmAZlBV6gAG2eE6C+DmgE37ycK7zVKloFFhUqvnAKWT7gOoThdxgA6hLpxHEIjTh9zGSlf9QpCA4dK667wJkvGmntiqzXcDCEg2CFUWHB/PgviGxkJCkKEEEF3yRgzhLJJHIcQIAb1484QytEhRMjQmB1/+WdWcjvIbCOvG2oJ2Dgtbn/ZDwkHT2nF72oLwycI2Q6hwFBpWxBaPgEsHY9XMpbzNNeIyhDKoiCUWIZQRhxCesuTITRgqLS35FeWjDkOIU+XMcA/XtelIFT2CEYZ+F2TkaAgRAgRWLYg5FxgBrhwkfmhnyAkB8iGJgY7uXx05tAoKKo/LJEQEp+etvMUhMgMICfF+RJw9AFx+5V/H7jrDcDi0Xjv4b1G1W+KCXGQQ6hyRIxrlk4Ayyc9odJ9Sp/kdS6wy1iWQ6Xt80ciXcYycC7qNDwlY8M4hOzjvHxEbGWotNNlLCJDyFcyloHfNRmJMY3iCSGpQ7a4ZNv5bNPXIWSXFOptkdkQZKlPCoZKEzIcpilEfmYIkVnDcZaWgdf/E+D21wFrdwHf+EtuSUw/vMe1ZQL1W8Fdxr7o+4DbHhKT57W7gfMfFN+NqC5jgBCEtFqwQ4glY9FjhDgUF8Xvd97ptPyh0pbhbycfhTdDSM0D5VU3VNrpMmaPx7xCk69kjBlCJB4UhAghgp5QaU4cModliQFLLIdQO9iinyQMlSZkOKSg7/0uy44zhEwTmSGULwmh5r6vE/dl+Vgc5HG9chtweBU4uGxnEXVdjxY3gNNfJW5vnhHXrOq1/t2y5HUt6PqWLwFQsikIJVUyVloBWoej78+s43MIedz3uRhl9t4MIUAESzc8XcZ8odKe8brTZazMDCESG5aMEULslpSW7RBi2/nMIgcNUSVgjkNIEwP7sTqEGIJLyFDIrjNqd8kYv09kyshS41FEBTlOufvLxFa2su8uGfOycUZsd871FzbkdS6oy5iiiM/JYpcx2Sp+1JKx8irQzoIg1BUqDcQvGzO6ukRW1oVDyLJEl7HQkjFbqPQ5hCgIkWgoCBFC3MGRL0OIglDmiOq8IvE6hDrN3hXZJGGoNCHD4TiEWDJGZgxDG30hoVsQ2rMFoaj3lYLQ9tn+17oohxAgJuNaPf7+zguOkDbi9LG8ArQORt+fWUWrA0/9mRgn5T0lY0C8YOkgt/bCunAI6W0hzIW1nZclmYUyBSESGwpChBB/K1Gn7TwvIJnDCCgz6cbpMjYBhxBDpQkZDllCwAwhMmvoLXecMSwrp8S1596vAqAAVz8nHq8cCf+Z5ZOiM9PO+f5OF7nwEZQhBAjXRyYdQn1K7eJSXp3vkrHP/yHwzu8Rt1dOim1Q3k8YjmDZ5RBq7LoOoOJidNv5PEOlSXyYIUQIcQdH3pIxOoSyRyyHkBzUTCBDiKHShAyHGVAyprDLGJkB9ASaEZz+auBHzwGlZdGZ7NzDABTg7q8I/xlFETlFO+eAk68Sj4U5XaK6jAFCWOpk2SGUQIbQPJeMSffTv/iM60wbShDyZgjZJWPSmVZYcMv7vRlCcuyeL3oyhOi0JtHQIUQICS4ZY4ZQ9jBjdBBxHELtyTiEWDJGyOAYYSVj/D6RKaNr4c6buCiKEIMAYPm4WNS6/SFgqU/b+o0zwE6ckjHpEAq5vtEhNNr7lFeF02VeFx71pji2Nu8TxyrgD5XuR1AG3MK66MzW2hf3wxxC8v3VIh1CJDYUhAgh/ot8jhlCmWUgh5A2gQwhTmAJGQozqGSModJkBkjCIeRl2S7Juf8t/V+7eR+wf8nNWenbZSxEuCouik5PWcP0uMlHobwqtvNaNha0WDZIqHRYyRgAHFwV27AMIQpCZAgoCBFC/DZghkpnl6BW1d1M0iHEUGlChiMoD4wZQmQW0NvB3buGZfmE2D7w1v6v3Tgj3EQ758T9vl3GojKEMigIJeUQKq2IrXS7zBudgHL6QUKlw0rGAODgstgWFzwOoYCSsVyeghCJDTOECCF223nYDiG2nc8sA3UZ08afIcRQaUKGw1klZqg0mTGMhBcS7n+LyFU59mD/167cJrb79qS6b5exMEFoIZuCUJJdxoD5zREKWiwbpGQsyOG5sCm2exfFtrAY/J6GJoQiRfGM57mwRqKhIEQI8az6KHQIZRk5aPAOQrpxVrkm4RDKxVtNI4T4CW07z4kBmTJ6e/QMIS8v+QbxLw7FBbHVqmKrhIVK92k7X1jIbobQqO4gIAMlYwHl9OoAJWNBDk9ZGrl7QWzlsex9vXx/OU5zQqW5EECiYckYIcRfMhZkQSXZIMim3I3jEGqPP0OIodKEDIfTdt5bMsaufWQG0Fvh3bvGTWFRbNu2IBR2rZMlbWpIaVsxww6hUfODAE/J2MHo7zWLBDqERmw7v3xcbHfPi20homRMLuqxZIzEhIIQIaQrVFoFoNAhlEWCVqW68dbBTyJDiI4GQgbHaTvvmdCyZIzMAkl0GRsW6apwBKF+JWMRXcayGCqdtENoXkvGgjKE8iO2nS8tA8Ulj0No0dN2PswhREGIxIOCECFEhCwC4uIjy8aYITR/mCbw+98KPPHHIc8PkCGkt8afIZTL0yFEyDCEtZ3n94lMm6S7jA1CwRaEZKlSaJexkn/b8z6L4vqXtYy7pBxCMkNobkvGAo5xb7l9P4IyhAARoG7YP+9zCHnG62YnQBDieZ9EQ0GIEOJeLGQ9fa5Ah9A8cv0x4PwHgeffG/y8UzoYkSFUWBCD6MaOEBIZKk3I7BHYdp4OITIDJJ0hNAjFmCVjaj9BqCK2esZyhFgyFg+9FZAhJB1CMcbWYW7tpRPu7dC2896SMWYIkXhQECKEuA4huVqmcuIwl0ghSLbc7SZOhpCiiPan1evi/jgzhJh5QshwBLadZwkmmQH01vQEIbUoxjlSyOnrEAq5vklhKWvB0kmVjOVUoLg8xyVjEQ6hWCVjIYtzy7YglK+I8VFghhBLxsjgUBAihPhDpQE6hOaV594jttvnAMvqfd6MkSEEAJV14PCauD1uhxBLXAgZHCdDiA4hMmMY2vRKxhTFFXOghLdP79t23nYIafVEd2/mScohBIiysSyWjBlxSsbkWKzrdy0FIZmFFZghFFQyxvM+iYaCECHE4xCyTwlqId4qBkkPB1eBrS8Aq3eKlru1m72viZMhBAiH0OFVcZuh0oTMHkEZQorKiQGZPnorvHvXJJA5QpHdNGWXsTBByH4POoSGp7QCtPaTea9ZI0gQynsacsgFtTCiMoQAt1uePL97x+uGxi5jZGAoCBFCPF3GPBlCvIDMFxc+Irav/8diG1Q2JsWX7kFIN5V14NAuGWOoNCGzhxSEfG3n6RAiU8Y0p+sQAlx3RdTCx+IxIXxU1oKfdwShrDmEzAQdQqvzWzIWlSH0+B8Bv/QqoLEb/vP9MoQch5D9nj0lY8wQIoNBQYgQ0lsypuZZMjZvHF4R2/vfIrY7Z3tfEydDCAAW1jydLhgqTcjMYQY4hNQCYHBiQKaIdDJMK0MIcN0VUU6Xl3wD8C8eBZaOBj9fpENoZMor8xsqHZUhtPWE+B5E/d/7ZQh1u9xYMkZGhIIQISQgVLrItvPzRnULKB8BNk4LG3yQQyhsVaqbyrp7O19JbBd7YKg0IcNhBGQIsRSYTBu9JbbTFISKMUrGcqq4VoYhJ+RaI7n9SgOmEZ67NCiljGUI5fIAFAB2fmPUomtohtBJsZU5WIpiO/q9ghBLxsjgUBAihLhlOb5QaV5A5orqlhhM5FRg/V5g53zvawbJEJKMc2DPUGlChsPJoPBktciJQ1CgPCGTQLedpVN1CMUQhPq+h70Q0smYIJSoQ2hOS8aMjvg9dbunFcV/Po4Klw7NEDoutvIYlq8xugUhOoTIYFAQIoS4ZTlOqHReTBwef0d0nTNJD9UtdzCxeQbYDioZC7Epd7Ow4d4ujNMhxFBpQoYiyO0XlDdByCSRk+CpZgjFKBnrh5MhlDFBKPEuYwfzJ1A7LriAY9wnCEW4NcPc2qVloLjkutyA3sxPoxPgEOI4ikRDQYgQEhwqvX8J+NMfAD73u9PbL5Ic0iEEABtngL0LvS6wMJtyN5UJOYQYKk3IcAS1nQ9qUUzIJNFnQBBKxCGUUUEoSYfQwqYQMpp7ybzfrNCJEITyHkFIjxCEohbnznwtcNtD7v3uzE+fQ4ih0iQefeoCCCGZQGYIOaHSBWDvRXF7OyBrhqQL0wRqN9xAwo37xABh/0V/TsJQJWNjdAgpdAgRMhRS7PWFStuTBEMDsNDzI4SMHememGbb+ThdxuK+R9ZCpZPsMrZxRmx3zvvHFGknCYdQ1OLc3+9apA3MEGLJGBkMOoQIIe6k23EI5QHdHugEhQ+TdNHcFQMG2bLUGYh1/W3D6ta7mZhDiIIQIUMhJxveCYUUhzg5INNCuiKm6hBKsGQsa6HSluGOE0clbBySdqQgFFRO7xOEokKlY47F5Gu8bm9Dd39O5TmfxIOCECHEUzLmcQhJ5u1inUWqW2K73E8QkjblARxC48wQUnIsGSNkGMyOEIAUxX1MntdZMkamxUx1GRthCpRTRbfOrJWMJZkhtHaXGGvsBOQZppmoYzxuqHTcjq/yNV63UaBDiOMoEg0FIUKIRwjwdBmTNLbnr8Y7a3QLQosbQGWtN1jaiJshtObepkOIkNnDGywqcQQhtp4nU2IWBKFCAiVjgFgMyZwgpCeXIaQWgLW752/R0ckQCnEIlVbF7ciSsZgNPuR7+krGOq4gJN1cdAiRPlAQIoS4XR6CHEJAcItykh5qXYIQIFxCYSVj/QbKasEd1IwzQ4ih0oQMh6n3TibYZYxMm1loO59ElzFAXE8Pr42+P2nCMkYX0rxsnJm/8WWU6PnGfwW86Uft1w2ZIdRNT8mY5v6NFEXc5jmf9IGCECGkt8uYFITkpH/eVnCyRvW62C55BaH7egdiZkAQbRgLa2JArY6xN4GiisDzeWtLS8i4MTq93005SaBDiEyLWWg7n0SXMSB4UWXeSTJUGnAFIdNM7j2nTVSG0Ku+HXjwm8XtSIfQABlCuXx4qLTzPAUhEg0FIUKIx57qaTsPAHe8TkzKu0uLSLqobgHlI0DBMwjfOA1UrwHtmvtY3AwhQARLjzM/CPC0TKVLiJCBMDu9nZycLmPMECJTQjqEZqLL2KiC0Glg94VsXZ+SDJUGhCCkN4HDq8m957TpVxap2o9HCUKDZAipBff1piH+Rj2CUIaOUTIUFIQIIQGh0vZFaPUOEfzXbxWMF5vZproFLJ/0PyaDpXc9LqFBbMoL6+O3/cuBJ8vGCBkMI6hkjKHSZMpEteSeFEl0GQPENdTQgP1Lo+9TWkgyVBqYz05jURlCQLwst0EyhHIF1wEkz+1eZ1FOpUOI9IWCECFElOUAvaHSyyeAdXsVLIy9i8DPngCuf2Gsu0hGYP+SPz8I8AzEvIKQHRjp7UwUxvIJoLya3D4GQYcQIcNhBpSMOS2IKQiRKTELbecTcwjdJ7bzJGb0wzKSC5UG5lMQ0ptiG+oQkk7NfhlCSrxOeGreFYLke7JkjAwIBSFCiDvh7s4QWj4BlJajO2ncfFZchPYujnUXyZDUbgJbTwB3vcH/uGwd3zpwHzP1eDXrAPBV/wb4+7+fzD6GIe3SdAgRMhiG1ru6nGOXMTJlHIfQFEvGpENo1HDkeRQz+pG0Q2jpuBCYZM7hPCDLIsNK6qVQFBUqHdQlMoxcwRX5HYcQBSEyGGNMAyWEpAbpEFK6HEJLJ8SFJWoCIS/kcqBHZouz7wdgAfe/xf94cUlsta4MobiD5JWT4t84kccjBzOEDIYRIO4yQ4hMG30GQqWlQ2hUp8vipmi8kSVBKGmHUC4nRKHqjeTec9p0+jiE4oT7m3r8sZg3Q8hxCHlLxigIkf7QIUQI8dQrd2UILZ/wX2yCqNotzSkIzSbPvQdYuQ048Qr/47L1rjdU2ugku/o3Kk7J2Bx1ICFkEpid3gmFPK9TECLTwmgLJ3KSrcsHJakuY4oCbJ7JVtONpLuMAWKcOY8OobAMIUURwdJ9BaG4DqF+JWMqy+5JXygIEUI8DiFZMmZfTJZP2g6hiAlEzRaEOhSEZo5OCzj/IeD+N/fmAuVUMTD2OYQGWJWaBAyVJmQ4gkoO5Hnd7IhcOG9+GCGTQG+JyXCcnLpxIRdDkhA2ZNv0rJB0lzFAjDPlwuI8oDeFi6o7w81LP+e9qcc/PtUiS8bIyFAQIoR4uozZp4QjdwHLp4Qlup8gRIfQ7HLzaaBTB+55U/DzxSWgXXXvD7IqNQkYKk3IcAR9l70ZQn/1I8Bf/R+T3y+SbfT2+LtT9qOQUMkYIMZKh1eyc41KOkMIAJaPuwuL84DeDs8PkqiF/m3n42YI+drOB3UZoyBE+jNDS8GEkKnRXTL22n8IvPq7RH13vwsXBaHZRbp/ZIB0N6UlQKu79wfJEJoEDJUmZDiMTm9wr9PuWPeHyRMyKfT2dPODAHuyriQjbJTsLL5O0709zySdIQQIh1BjR4QsTzNsPCk6zf7HeL7klpYFMchYzLtoywwhMiR0CBFCPA4hz4U+5ykfoyCUTjS7O5zsqtJNcamrZGzGMoQYKk3IcJgdf9kA4BGENJHlwm5jZNLo7elP+hVFuISSWPyQOTEySHjeGYtD6ITY1uYkWDqO6NkvmzMoAy70vYrifA6ElIwxQ4j0h4IQIcTNEAq60KsFIRgFXVBMA6jfFLeZITR7dGz3j+yq0k1p2R8qPWsZQiwZI2Q4jE5vyZg3Q0hvU2glk0dvTd8hBIhrYhJZOLI0SM+IIGSZyTuElmxBaF5yhPQmUOgnCMUJlaZDiEwOCkKEELeLU9AAyVlVDljNqN9yxSQ6hGYPxyEUIggVFwGtK0Mobt36JJADT4tdxggZCKPTG2qa85zL9RYdQvPA9jnggz8LWNa09yQes5AhBNgOoQSEjULWHEK66x5PCukQSlOnsU/+KnDho8HPxXII9XHeD5IhlPe8V2CXMQpCpD8UhAghvaHSXuSFJeji5b2AUxCaPTq2IFSMKBnzOYRmLUPIPh7pECJkMMwgh5BXEGqz/fw88PSfAR/5T+nJhJJdxqbNa/8h8JJvHP19MicIjWGMkMaSsY/8Z+Bvfy74uTgZQv2yOQfNENLbQhRmlzEyJDM08ieETI3uUGkvjiAUMHmoei7gFIRmDxkYHeYQ6g6VNmYsQ4ih0oQMR2DbeU+GkN5OvvSDTB6ZAZcWt1ecDkyT4Ct+NJn3yZogNI5Q6YVN8Z5pcgjpGnDpk0BzD6isdT0XwyGU71cyNmCGECwxjg8tGeMYikQzkkNIUZQjiqL8saIozyqK8oyiKF+qKMq6oigPK4py1t6u9X8nQshUseKUjEU4hCprzBCaRToNAEr4ALy43BUqPWMZQgyVJmQ4otrOm7qdIUSHUOqRgn5Ux6JZQo/hnkgT+YxlCI0jVDqXEy6haoocQoYmxLGzf9P7XKwMoaIQlcIYNENI7lNgyZjKMRTpy6glY78E4L2WZb0EwKsAPAPgxwF8wLKs+wB8wL5PCJllgrqMSSJLxrYAKMCRO7MzIEoTWkO4gxQl+PmS3WVMZkgFTSKnCUOlCRmOwAwhFYBiO4RaLBmbB9opdAjNQoZQUmTOITSGUGkAWDqeHoeQZbli+vPv7X1+0hlCzhi9HV4yxnM96cPQgpCiKCsAvgLA/wAAy7I0y7L2AXwzgN+1X/a7AL5ltF0khIydOCVjQSsMtRvAwoZwmqRlhTJLdOrhHcYAN1tIdiObVYcQQ6UJGYygDCFFEZOMThOAxUnCPCCbAqTl+ttpzkbJWFJkTRAah0MIAJZPpidDyHvePPewG+h+81ng/7kDuPFkeJm+xNsqPohBMoTynlgHdhkjQzKKQ+heALcA/LaiKJ9XFOU3FUVZBHDcsqzrAGBvjwX9sKIoP6AoymcURfnMrVu3RtgNQsjIyAtaoEMoomRMqwuXSaGcnQFRmpAOoTCKS2IrV5lNfcYyhBgqTchQGLp/lViiFoG2LSKwZCz9OA6hlAhCdAilG8sIjhYYlYU1kceTBuRYuLwqwtylQHT500D7EPiSfwa88V9Fv4daiBbkB84Qgt0oIKzLGMdQJJpRvtV5AK8F8N8sy3oNgDoGKA+zLOs3LMt6yLKsh44ePTrCbhBCRmbYLmOGJp7Pl9OzQpklOo3wDmMAUFoWW21GHUIMlSZkOAytt2QMEN8pKQgZWnralZNgZAZcVB7JLKE33dydeUAuuGRFEBqXQ6i0CrQOk3/fceAVhAC3m+vOOdFB7+t/Bjjxiuj36BsqrQ9RMqa5IpPXHcoMIRKDUQShKwCuWJb1afv+H0MIRDcURTkJAPb25mi7SAgZO07JWJQgFLCaYXQ8glBGBkRpohPTISTLDgYZhEwChkoTMhxBJWOAOF/7guQptqYaKebTITQdZFZMVsY/4+gyBgDlFTEOScP5SI6FS7YgJDvs7pwD1u+NJ5j1C5U2hgmV7ngyhFgyRgZjaEHIsqwtAJcVRXnAfuhrADwN4C8AfI/92PcA+POR9pAQMn6iLvLyohToEGrTITTLaI3oDKFSV8nYIIOQSTBPodKmAWyfm/ZekCxgmiJ3K0jcVQvu9x1ITxgxCaadIoeQZTFDKM1YljivjMMhJN027RS4hKIcQptn4r1Hv1DpobqMRZWMZUsQsiwLrc4cjBsnyKiFoP8SwB8qivIFAK8G8P8F8HMAvk5RlLMAvs6+TwiZZaIu8nFKxpghNJt06kAhomRMlpNps5ohZA+I5kEQ+tSvAf/tS91yHULGhcwGCppQqAXXEeh9LUkn8m+ZBoeQ0QFgzVfb+ZwqxkBSFJhnZHOHcTiESitim4aysR5BqCUW03YvABuDCEJRodIDZAhJx12kQ2gOxlAD8P/76Av4sv/4QXQMNiSJy0hLwZZlPQbgoYCnvmaU9yWETBgzIigwqmRM10SHAzqEZpN+DqGinSHkC5WeoZIxRxCag9WtZ/5SDCQ7TTe7iZBxEDQpkOS6HUIUhFKN4xBKwfVXllXNkyAECJdQpzXtvRg/UdECo1KWgtBB8u+dND2CUBPYf1GIOLEFoX6h0v3L9y3Lwm99/CK+adnEUcANlVZU/8JexhxClmXhHY9exnZNw+XdBu49ujTtXUoFY/hWE0JSh2WGr/pEdRnzhUo3GVA6a/TLEJIlYz6H0AyVjEUde2mivg1cfkTc5gScjBszIFhU0p0hxOMxveia+7dOwzlSilaFeROEFjLiEJLNR1gyBsBfMrZzXtzeuC/ee/QLlY5Rvr9T1/Af3v00Pnbh0N0vOSb3kjFB6JnrVZy/JbLV5Jb0h4IQISS6c0RkyVjHLRmzzExddFKB1qfLWHHWBSH72Et7WcvZ9wOwxVJ+R8i4MexjLDBDKO8vW0yDkECC8Qp7aXAIdebUIZQvu8HC84zjEBpnyVgaHEL2eES6mvQWsHNW3B6kZMzURd5bEDHGYts18Z2v66q7X3JM7iVjgtC7v3ANOUXcPn+rFv1i4kBBiBBiO4SGKBnzhkoDzBGaNTr1Pl3GbLGoPeMZQml3MTz/Xvd2hgZmZEpEZggV/ZNXHo/pJW3CnhStZkgQspJwNRcWsjH2keeKcXUZA1KaIdQQgdLlI8DCerz36Od+jpEhtFMTP1vTbfVDhkp3LwRkLEPovU9t4Y1nNnF0uYTzNykIxYWCECHE7jIWJgjFLBkD0rFKmRV0TQzgogShnCqelyvNWh8BadJEiZFp4sbTAOxBGyfgZNwEdZqRdJeRpUFIIMGkzSE0YxlC73tqC6/9Dw+P3o2oUM5IyZjtZhmHi7h8RGxTWTLWAg6vAUfuABQl3nuoMgg65Hsb5PTpQjqEanrO3a/AkjE1M+OOVsfAhe06HrprHaePLtIhNAAUhAghMUvG+oRKA+6Aj0yfjl07HRUqDYiysXZV/NNqwPKJ8e9bXOYlQ8jU3e9I2sUtMvtElox1C0I8HlOL5snHSEOXsRnLELq4Xcdeo4Od+ojXl8JCxkKlx1EyZjdaSFPJmCxz6zSEy1rej0O/xa5OQ4SVR7BtO4SqtiD014+9iE6nHeIQyoYgdGm3AcsC7t5cwOmjSzh/q56MCzADUBAihNgOoSEEIaftvH3hSsMqZVbQ7BXLfo6f0pKYWFRviPvLJ8e7X4PgZAilfDBjGm5r2LTnIZHZp1/beS8UhNKLt2RMT4FoPmMZQm1dOF7q7RGvL4VKRhxCMlR6DFNHtSDGKmkQhOQ419tlTKu6mYxxyPfJ5jT1GIKQ2I9qR7iSPvzMNWzv1zItCF3YFiL53RuLOH10CQfNDnZHFXwzAgUhQoiwAoc6hKJKxmxbq5zsZqGOPi3IAWpUqDQgBjFaDaheF/eXj493vwbByRBK+QXdO7jLUC0/mRJRbee7ywkoUKYXX7e4FCzGyOyqfPREd1JotiBUbY04Wc54qPRvf/wC/vHvfWb09y+vprNkTG/aDqEBBCF5Hg5aRJXj6D6C0I4tCB1q4u9RgA5NawWHSsMKD7CeI17csQWhzUWcPib+Huw0Fg8KQoQQcaHoGyodJAjJUGk6hGYOWU7Q1yG0LFaaq1vi/iw6hNLuYjB1VzRN+/+FzD5Rbee7XUNpF1uzwPPvB375tcB/fQi4/Kj7eNubIZSCv6MjCJWmux82bV0IHKM7hLLbdt6yLPzeJ1/Ex89tj/7+pZV0OISckrFlAIrtEKr1X3zzEhnFYH9PYpaMHdhf/RI60NpBJWP23ysDLqEL2w2sLxaxWing3s1F+zHmCMWBghAhJGaodETJmBzgMUNodnAcQn0EoeWTwMEVoGYLQksz5BCKOvbShKm7omkGBmVkysiVfDWky5iXtH+3ssDFjwJ7F0Rr64sfdR93HEJKOhxCnXgT3UmhJVYyVs5shtD5WzVc2K6joRnQjREdKOWVdHUZU4tuhzmtDhSX47+HIwgFOYTssVsfJ510CB3YJWMF6NA7QaHS9nUgA2OPi9t13L0hxrwrFTF+rLXpyo4DBSFCSHSodE4VYlH3SrKhi1KzfIkZQrOIkyHUZ9Vq4wywfwnYe1EMQKQNehaQx17ay1pMww1STfv/hcw+cuDPDKH5QKsBlTXhoJBOTvk4IJ5Lw7V35hxCdslYIg6hDCyGyS5jHofQ+5++4dyujfp7TFvJmFoU13WtLr6Lw5SMBTk0Ywqn0iG033YFIaPTzrYgtFPH3RtizFvKC4lDOgFJNBSECCHiQh8VFKgWAwQheVEsuCGRWRgUpYW4XcY2zgCwgEufFPlBcdumTopcIf1lLT6HEAcnZMzIgX9Qo4BuQYgC5ezTromst+UTbtabfDyXF6UraThHzmiGEEOlYxLgEHr/U64gNHIWU9pKxmQQdmNH3B8qVDrg/CuPpQhByLIst+18x4KJHIqKDlPXgkOlgbkXhJqagesHLdy92SUIdeY/OykJKAgRkgX62XCjuowBtiDUdeHyrpI4bedTsEqZFeJ2Gds8I7Y3npyt/CCJWnTbaKcVZgiRSRLlEOrOFUqDkJB1tJoQfZZPALUb/seLi+LckoZr74w6hGojh0pXxBhq3s/tXV3GTNPC41f2ce9RMQE/bI34/5clY1oj+ndpWf4Oe5PG5xCqAPVb4v4EQ6VrbR1t3cRCURXlekoBBeiAocHKdTuEZIbQfC9GvbjrBkoDgKIoKKo5aKOWMmYECkKEzDs754H/dA9w+ZHw10SVjAFixSHUIVR0y2GYITQ7OA6hPiVj66fd28snxrc/w6Lm0z9p9XUZS7m4RWYf2U0msGSsO0OIx+PMo9kOoaUAh1BxGVBL6ThHylKYGWs7X9MScAgB8+8S6nIIdUwTlgWcWhX//5EdQuVV4RD67bcC7/mx8Ned+xvgP58B6jujfd6wyNwfuRhauynuD+IQigyVtsfREU66Hbtc7M51seDXQR4ldFBAB5rVNZbPiEPo4rb4/t2z4Y55S/kcHUIxoSBEyLxz/TFxIdg+G/4ay4zhEIoQhOgQmj3iOoTKK26Q9NIsCkLFdJe1WJZYWZWr4mn+v5B04DiEgkrG2GUsdbRtJ9DyCaB6Q5xTADe3JF9Mx7VXb4nJaVDY+RRIrsuYLJmf82Dpri5jHUMch2uLQtxIpGTMaIsx697F8NfdeFIcS9Vro33esHSXjNXtDmtDCULDOYRkudhdG64gVICORbTQQJcDLyuCkN1y/q5Nd8xbKuSYIRQTCkKEzDs758W2EbGaYpnR2TFqofdiIicS+RIzhGYRp8tYjFaoG/eJ7Sw6hHKFdFvx5aoqM4TIpIhTMibD5ilQzj5S+Fk+ISaQzT338eJSehxCemtm8oMAN0No5JIxueiSNYeQ/fvbcAShUUvGPA0torKEqjf6v2acGJo4jyqKEAPb9n4kHiodvpgnA6Xvst0wLSuPpYKFRaWFqtXlwMuKILRdx8ZiEStltyy6qOac7zmJhoIQIfOOdAY1d8Nf07dkLMAhpAeESutzvkKWJrS6mChE/V0lG3bZ2CwKQmo+5YKQPQhjhhCZFJFdxuyJiJy88HicfWRpmDw/y05j7RQ6hGYkPwjwlIyN2pbaKRmb8wUxs8shZJemriflEPIKQlHdxmTZ5LRa1Bsd9zj2ijYDhUpHjAecUOnw0krpELrDLhlrmyo2yhYW0cKBEeYQmu/FqAvbdSc/SFIqqM73nERDQYiQlHPjsIXzt2rhL9g5J7aNLkHo4Arwif8KfPyXgb0Lo5WMqXlx0aEgNDt0Gv07jEk27GDpmRSEAo69NCEn58wQIpMiTslYkYJQatDqtkPIDv2v2YKQzyGUAkGo0+rbSnuSOA6h9ojfAel6mvcMRavLIdRTMjbi77G04t6OdAht9X/NODE8nby8x3NpOf57yJ+PDJUOH7/dqrahKG6GkIYCjhR0lJUOdvVuQUiGSuvi8555d/z9TBHelvOSUp4lY3GhIERIyvnZv3oG/+wPPhf8pGW5glC3Q+iTvwq8/98AD/+UeM36PeEfogaU7TiCkH3xyZfnv4Y+TXSa/fODJHe9EaisAUdfMt59GoZcQLlimuh2CLFEh4wbp7QjyiFkT154PM42lgVoVVH6K7Pe5IS4sQNUjtgOoRSI5jPnEJIZQnQIxcKbnQO3ZGyxqKKYz6Ha0vFHj1zCuz57Zbj337xPuIROf3W0+0cKolEuonFiaO551FsCGac8XxJVMuaESoc7hG4ctrCxWMJqxf5bII8VU3Re29a6zvvekrFn3w2847vcKIk5oaHpuHHYxj2b/jGvEIToEIrDbCS7EUKG5tp+E9cPQgYi9VvuRbOx1/vckbuAH/yEuB91MctFdRmzVzryZTqEZolOI74gdPsXAT92cay7MzRBYmSaYIYQmTRdK/k+ZIaQFITS/N3KAp2myPgrLnlKxq6LCXPthugSeeOpdDiEZi1DyJAOoaS6jM35+Efzdy7V7ZKxgprDSjmPw5aO3/74BRypFPG/fdHtg7//xmngx14EPvLzwPkPCpEz39UV0bIcQfT3//YJqLiE7/ziO4f+Lw2F0XEFHa9DKKkuY53+gtDWYQsnVktYLIpzvAYVx0wx1t9qRQhCzX1xW4uoKkghL+6IMru7uhxCxTwzhOJChxAhKWe71sZhSw8+6cn8oOJSb6h0YxdY3BRW9NJSn1DpYrhDyKmlrlAQmiU6rcga9NSgBoiRaYIZQmTSRGYIyVKHBQAKj8dZR07cSstiIl5aEaG6u/YK/8YZcW6hQ2hgZDvq5AShOQ+VlsdiUYjJmi5KxgpqDsvlAqqtDq4ftFDXRvh9KoqbJRTkAGodOOPMZnUXz9+oDv9Zw+IrGfOMsZLsMpavALnwKfrWQQsnVspYLIlzvIYCFnTx+7raiBCE5DE6Z+LlxW0hVt7TnSGUZ4ZQXCgIEZJyduxuA7v1gAGhLBe7/aHekrHmLlBZj/chQZNy3ZMhBNiD0vm6yKSaQRxCs4xanI+SMWYIkUkRRxDKl9Ivto6Zxy/v4y3/5SM4HDUbZRTa9oRXTjaXTwiH0LZ9bd+8z/47psAhNGsZQrZDaPS28/Z1dt7HP/JYtAPpO4Z0CClYLudx47CFaksf/fdZtrOEgjKCZLkkgGU0ppMPo7c9DiH7b19YjBRweojsMtbsu5h347CF4ytlLBbFOb5j5VHu7AMArjVVtDqe34s3Q0izBaE5O1Yv2C3ne0KlmSEUGwpChKSYVsdA1b747tQDBoQ750TGz4lXCkeQZbnPNXaAhbiCUFSotJxgVOZu1SHV6K1Iy3FqyOXTPWmVGS3MECKTIk6GUL6cfrF1zHzu0h6e3arimWtTyioB3DKdklcQ2rIXexRg7R5xjU+NQ2h2rknSIdTQDBim1efVEcj/k/xbzSuOQ0gci96SseVyHs/fEM+P3LVNhksHOYRkhzEAy0oDrY7H/fG53wd+523A279LdOAbF0anN1R6kJbzgCdU2vO9/fwfAp//g775j62Ogb1GBydWylgoyZKxPHKWOJfXrQqu7HliJHwOIfsYnTNB6OJ2HZtLJSyV/Ne8Yj7nfM9JNBSECEkxsvUk4DqFfNRuAMvHRWmY2fHXDTf2BnAIBZWM2Z/thEoX5+4ik2rmySGU5rIWJ0Oo7L9PyLiQIo8SMMSTGUL5YvrF1jGz1xDnnQvbU5zoO5Nwe+X72IPA1heArSeAI3cKJ0E+JZ0YZ6xkTDNMlAviOzJSmZM8t6fhbzAKbf+x6CsZKxVw0BTfl8Yov0vALRkLcgjVbgAA9NIaVtDwO2Ee+5/AxY+K4OTt50fbhygMzTPutQWhQQKlAVEaV1jwlxl++teBR/+HCJWOEE5vHoqx9/HVMgpqDsV8Dh1PJHADZVzZ87yvVxCaU4fQ1f0m7ljvdR+W8jnHCUiioSBESIrxikCBDiGtLuq9FzbEfdl6XtdE55LYDqGgUGl/xwnR+nbOB0RpYsbs+UOT+lBpe3CsFsQEPc3/F5IOYpWMldMvto6Z/Ya4nr0wTUGo7c9twf1vFpO5598r8oOA9LSd12fnmqQbJgzTwsaimNjXWiOIGKr9PZv375JWEyKG03beXzImaWgGzFEcV07JWLhDqLFyGitKw58P0z4UpVvAeAUPb5cxeTwPkh8kKa/6Ra/qlnDu93EI3aiK/9uJFSEaLRZVaB5BqIYyLgc4hM7fOMDu/r54bM7c/LWWjpVyoefxUl6lQygmFIQISTF9HULtqrCySieQDJZu2h3HkigZy3sdQikYlGaFTnNmBt8joRbSXWblnZznCizRIeMnsmTMKwilXGwdM9Ih9MKtaTqE/LktuOvLhDhkGa4glC+JTmTGjJ9bOrPjEJKugfVFMbEfKfcmKg9mntBqPuHDXzLmn4yP5LiKLBnbAorLqJeOYbnbIdQ6AJaO2Ts3TkHIWzJmCzeya+MglFZcQcjQReff5l7fDKGtA/F/Oy4FoVIeGtzfv5ZbCHQIvf1TL+DZS3YG05w5hGptvadcDLBLxpghFAsKQoSkGJ8gFBQqLS/gUviRwdJyO1DJWNcFXoo/cjCUllXKrNBpzIcglEt58K1PEMpTECLjJ9Ih5GkCkHaxdcxIh9CF7Sm2aHZafdsT8XwROPPV4vbmfWIb1bFolpihtvPSNSAFoZE6jckyzHk/t7drvqwcf5cx/7mmPkqOUFTJWHULWD6BRm6x1yHUOnQFoXE6YHwOIVu4GcohtOKKXvWbACxxv12NHLvdOOx2COXRsdzf/+qR9a4MIeHoqrfasOY0Q6jeNrBo5yl5KbHtfGwoCBGSYrZtV9CRhQJ2agGDQXkBdxxCtjNIOoWSLBnLF9MRbJkVZizAc2iCxMg04Z2cqxSEyASIcgjJx9RS+sXWMbNnC0KXdhvQp5VDIUvGvKG1979VbL0OIWD2HbozlCEkHUIbiQhCKgBl/r9LWs2XlRNWMgaM6hCy3TZBJWO1G8DyCdSx4HcImaYQUybmEOoqGRs0VBqwS8bs/6OnexoOr0WWjG0dtFAu5LBSEb/zhZKnZEzJ4ejaKq7sehxC9hi91W5D1W2haO4EIR2LAQ6hUiHHtvMxoSBESIrZrrWxXMrj1GoluGRMqwc7hBrDOIS6BaGuUGk6hGYHy5qjUOmUB986k3PVDvGlI4OMGVMHoAS3QfY5hJghFMVevYOCqqBjWP4V90nS1dkJAPCKvwf83d8E7nmTuJ+GkiXLmqkMoW6H0EglY4qSjfJLmUlp4y0Zk/kt+ZwCYMTfZ04VnxNUMtbcAypHcIgFlJUOzI495tSqACxg6bi9c+MUhNr+7rrA4KHSgL9kzCsI1bYiF/O2Dls4sVKGoojf9VIpD1O61IpLuH19wX++svct16mjAvv3NUcZQpZloa4Fl4yV8ip005qeoJ8iKAgRkmK2axo2lorYWCqGlIxVxUCyfASA4gpBUhgayCHU3WVMOoQ8E4x5HxClBblSPCOD75FQi+kua2GGEJk0pu6UCfTgyxCiQBnFXkPDy06J8pWpdRprV8Vii+rJaFELwCu/zRX80uAQMjoi52hmHEJCqF+zBaHqKKHSgH2dmvNzu8yktOnIkrG8WzJ296YQH0ZyXAG9gcuS1iFQXsWBJRa71M6h+zgwIUEoKFR6iAwhb8lYzSMIWWZ0qPRhy8kPAoCFogpF7k9xCbevLWCnrrminJ3JtIIGFqQgNEcOoWbHgGkh0CFUzItzJDuN9YeCECEpZrvaxuZSCRuLxd4uY5blloypeXGBlaViAzuEgkrGNNE1SXbYUBkqPTPIVqbzIAjlUr7yygwhMmlMPbhcDPCX+KZdbB0jbd1AQzPw2jvXAADnb00pR0ir9S9HkS7dWXYIyQnojGQItWyH0OZSAg4hwHZ/zvDvPwm6QqU70iGUU5xQ6TNHxfONUTKEACGWBApCB0BpFfuGEEQKnZr7ODChDKGOOH8CnlDpBEvGgMhQ6RuHbZ8g9PJTq1hbXXb24/7j4vaTV+3fiS0ILaOBijJ/gpDsEBhYMiYFIZaN9YWCECEpZrvWth1Cpd6SMb0lOpHIC/jCuqdkbEesEBdjlhTJiYPlaSWqt91VEsB2CFEQmgk6tl14HgShtFvxmSFEJo1lhgtCOY9DKO1i6xjZtzuM3Xt0EYtFFdf2pzSBkmXfUcjJ6eE1YPeF8e/TMDiC0Kw4hMQEcW3BFoS0EQWMLJRfdoVKd3RPyZidZ3P6mHAIjZQhBAgRo7tkzNCBTh0or2DHEGObomELQu1pOYRGCJUurYgxc6cFVK+LBVZJiEPIsizcqrZxfMX9Hv3Lr7kP3/iau5z9eOguIWI/etEe76t5GPlFLCsNLMD+vXSmVAI7BqQbbSkwVFo8xhyh/lAQIiTF7NQ1bC6VsL5YREMz0PQOatpd2QOLR4HaTXG7uQcsbMT/ILmq7B3weIP1ANshNOcrZGlBDobmIkMo5cG33oBfZgiRSRBVMrZ4VJyrV29Pv9g6RmSg9NpCESuVAqqtKf2e2rX+La2lQ+g9Pwb84beNf5+GQTogykemuhsSmSEkc0c6o5aUZOG71CVOdgyxQJhXFbz05Ar+2Veexje/+jYAYyoZk6JPeRXbuhBiKrp0CNnPLU4iVNojCFXWgcIisHb34O8ju6m1D4HqDWD9Xve5kMW8umag2TFwdLlLWHVKxhaxtljE/ceX8OjFPefpTmGpq2RsfhZvZUe7xWJ4yZj8vpNwKAgRklJ0w8ReQwhC0vbsKxuTYZRyRWf9Xnf1sLEbv1wMCA6t9F4UATqEZglZMjYvXcYsQ3QRSSOOQ0hlhhCZDFElY8vHgR89B9z95ekXW8fIbl0KQgUsl/OjT3CHRav2D6yVDqFbzwqX0Cxy9v1ie8+XT3c/bKRDqFRQkVMA3bD6/EQf1MJ8l19aVnjJmJpDQc3h/3zLS3DqiBAykikZ63IItdwSqJuaEETKZh2mabnPlVeFQDr2LmMFdz9/+Fngpd8Iy7Lw6Rd2YFkxjyUpCLUOhUNo/V5X3A0Zu92qijF2qCBki8evu3sdn3txD4Yp9qWlLmNVqaOs2MeoPo8OoYiSMWPE4zEDUBAiJKUcNDuwLNFyfmNRXBx8ZWPd3Uk2TgOHV8UqT3MXWFiL/2GBglBXyZhaEqUKaW4RPi905sghJCe2aR1sM0OITJooQQgQExFFsQXKlH6vxowsGVtbLGK5XBg9dHhY2rX+5ShyEgm7u+QsdhB6/r3AqdcAyyemvScAgLbdrryUzyGfy0E3RxSEcnMurmp1AFZwqLTqTiUXCsKZOLKAWgrIEHIcQq4gtKw0RDmQ5zkUymPOEOpaDC2vAIqCT72wi3/wG5/CY5f3472Pne2D1gFQuyG+G7LRS8jYzRGElroEIylQ2eeK19+zjmpbxzPXxe+lmVvEccV1DM2XQ6h/hlCLDqG+UBAiJKXImthKQcW67RDa9XYaa3c5hDbOiO3O+SEcQiElY3mvQ0iKRvNzoUktTqj0nDiEgPTa8ZkhRCaNqQNKSMmYlyyUuQyJt2RsqZSfXsmYVu8fWNudyyOzAmeF2i3gymeA+9867T1xcBxC+RzyqjJ6W+p5zxDqXmCEKLPLKYBqt5oHgFxOwUJRHT2ku7wqRB6v26blloxdb4lxwQrqaHUMn3sI+fL4HEKmKc6vXkHI5lZNjH1j542VbUGouSfiHJZOuFEOIWO3UIeQPAfY54rX3S3G9zJHqK4s+AWhOcoQknlVS+UAQajADKG4UBAiJKW07BWuckHFuh2MKAexAAIcQveJ7c45ESodt+U84F78vKvJ3aHSagpa32YFJ0NoTkKlgemtvj7/PuD8B4f/eWYIkUljGtEOIQkFoVCkQ+iIXTI2NYeQVuvf0rp7ctqYIUHok78G/Mk/AmABD7xl2nvjIDNFSnkVak4Z3SGkzvm5XauLbVfJmNcdJFks5UcPlS6vCOFFLm4BjuhjFJex1c7DhIIVpSkm+60DMQYtlMcrCMlxiByXeDhsir9/T8ffMGTJ2M45AJZwCFVs536oQ0j8v8IzhMTf59SRCk6slPG47VY6xCKOKq7jypxFF+GQRJWMFe3js62zZKwfMUYMhJBZRCrepXwOa4sBDqFuQUgG1l34sFhBXLsn/ocFlox1hUrnA15DpoPjEJqDkjE58JqWs+Zvf05keJz+6uF+nhlCZNKYRniotJd5dzWMwF5dQ6WgolxQsVwu4HBaglCn0V/Yn1WHkK4B7/83wrVw5muBE6+c9h45SIdQMS/yb/RRM+pkJ9Z5pV0V266SsWKAILRUyjtBv0NzxO6adeMp4I7X2/sgHEJ1ZQkWcqgpS1hDVSyOtg9dgWUiglCvQ0iKxtvVmIKQLBm78YTYrt7uKRkL/s7fqrWRzyk4UukSpLpKxgDg5bet4gm79fyhWUYe7t+k025gNvr9jU5kyViBbefjQocQISlFOoRKhRxWynmoOcXvEOouGSsuACu3A4+/Xdy//83xPyywZEyjQ2hWkXbgeQiVzk3ZIdSujmav9mUIqRSEyPjplyEkyeXnexI7ArsNDWsL4tyzUp5iyZiu9W/V3uMQ2hnb7rQ6Bn7m3U/Hy4jZuygaArz1PwHf/S6RWzUjeDOE1JzihO8OTW7O3XYhJWN5tfdvulhKoGTs9FeJstfn3uM+ZpeMVS0hlhzmN3BM2bcdQoduCdY4M4Tk39ge77Z1A//odz+DJ68e4NA+R9yqxRyryP29+jmx3TjjRjnkQwShahubSyXkcl2/d9VfMgYAr7x9FS9s11Fr69gx3PdrWQVY4wzdnjA1W3yU+VVeZIYQS8b6Q0GIkJQiT3DlvApFUbC2UMBu3TMgCbiAY/OMWDlZuwfYvD/+h8UJlZaDVjqEpo8UMObJITStwbZWS04QUukQIhMgriCkFnm+DmG/0cERuxR7uZxHWzens8psaIHlKT7ktVfmj4yxZOyxy/v4zY9dwCfObfd/8c45sZXl6jOEzyGUU5wW6kMz7yVj3QuMAPSQkrGFYgJd+SprwF1vECXbErtkbM8UC12N4iaOK3tuhpB03OQrEysZO3+zjr955gY+fm7bLRmrxVwULS4DUER3wFxeuKL6OYSq7d5yMaCnZAwAXnHbKiwLeOrqAXZ1d3FwD8tQ5qhkrN7WsVhUe0UyUBAaBApChKQUp2TMtkSuLRSxFxQq7RWEZLD0A28dbLUuyKXhbb0JuBckOoSmjyMIzYFDyMmvmmKXn1FatHZ3GZvnSQOZDQbKEKJAGcR+Q8Paori+LZfFduIuIcsSDi61n0PIfv52u7RmjCVjTdtZIzOWInEEoXvHtj/D4mYI5aCqCTiE5l1cdRYY3TwrTbcCBaGlUh4NLYHMlvvfAtx8Cti/JO63D4HCIqqaGLtqC8dxTNlzu4w5JWNjbDvfVTL24o7IVtprdJyy0u24glAuJ0QsyxSLtGredQhFlIwFCkIysqHkLxkDgCeuHuBWx/2ZPWt5rpq/1Fp6YLkYIDLCAJaMxYGCECEpxSkZs094a4tF7HaHSqtFfycwKQgNUi4GuO/xe98K/Kd7gV//cjFR9lrZHYfQ/FxoUos+Rw4hObGdxmDbshJwCHlDpQvufULGhamLyUY/VLadD6PVMVGxSxCW7e41Ew+Wjgiw9SGvvccfBAqLQGMv+vUj0LIn+r7y9DB2zgILm25Q7gyh2R2y8moOhaTazs/zd8kRhBadhzqGiUJgyVh+9JIxQAhCAHD2/WLbOgDKK05plrV0HEexj5bW6SoZq4yvi5ZTMmYLQrsir3GvrjmC8XbckjHA3edN20W3uCm2EW3njy4FCUL24p9HsDu6XMKp1TIeu7yPLc3jELKWkJunkjFNDwyUBrwOIY67+sFQaUJSilMyZjuE1heKeGG75r5Aq/ndQQDwir8vJgt3f/lgH3bHFwNv/Nei08Tei8C5h8Wq5JE73Nc4DqE5XiVLC52mW6KUdqbZdr7TAGD5O50Mii9UWp3vSQOZDWJnCBXm29UwAm3dQNGeTLgOoSkJQv0yhEpLwNv+C3Df1wFfeOdYHUItXQpCcRxC592J7ozR1k1nMU3NJdF2fs4zhAYoGVssqk7J2FPXDvDpF3bxfV82QBMTycZpMc7ce1Hct8vCDuxjT109iaJiwKjvdJWMlcbnVJcLnvbY6sUdMTbYbWiDl4wBwtV0cFn8XwHggb8DfP3PAEdf0vNS07SwXdOCHUK3fRHwdf8euOcrfA+//LZVfOzcNl5tuY6jPSxDmaOF23q7v0NIOgJJOHQIEZJSAh1C3gyhds138QYALG4Ab/iX8TrQeCkuiovNN/y/wFf/pHgsNENofi40qaXTDA0lTB3TzBCSg+BR6u2ZIUQmzSAZQqYunHDEh2a4goHrEJrwOUgP72jUw0P/H7tL0dpYQ6WbmphY+crTw9g+6050ZwxNNx3BL68m4BCad0EoIJNS0y3kQ9rOy5Kxdzx6Gf/+3U8PV7KjKCIXSwqcdlnY1qG4Hi9tigXJXG2rq2SsMlqZdxRdJWOXdkXJ2H5Dc0rG6pqBZtySOSliSfd+ecUeo/f+XvcaGgzTCskQKohF266YgO99490wTAtVy3Uc7VlLUI3W3Jz3hSAUPKcpMkMoNhSECEkp3RlC64sF7DU0WPIkr9V89tHEWPcM8AK7jHHFeep0mv1bFacFp+38FAbbchBstIcv9XIEoQIzhMhksMyYgpAsx+Qx2Y2mm05LbSkITbz1fNySMS+V9bGGSssMob4lY60DoH7TnejOGG3dcMpJ8ok4hIrz/T1qV0UZk2cxsWOYKIaVjGk6LMty8nRuVodcVFlYd0sg7ZKx6wctbCwWUVo7BQBQq1eFi9eXITQuh1BXyZh0CNklY7KELnaOkCwZixG8fst+z0BBKIQ3nN7E3/wfb8L/9oYHncd2sQwF1twcr7W2EVoyJgUhZgj1h4IQISlFtk0t2zkHawtFGKblDlrbVV+9d2KUV4Cl4+K2zyEkS3voEBqJxq4rqh1eH24VZ54EoWm2nW9X3dvD1tz3ZAjRIUTGjKnHc4E6ge3zMTFIEq+DZGVaodKOIBR/AoiF9fGWjMUVhHbOi+0MdhgDxIKa6xBSEsgQys/390ir94wno0rGLAtoaAa2q+I4uXE45PWz4nG8tQ6B0gpuHLZwfKUMdeUkAGDhwA4vl4JQoTLGtvOyjLMITTdxbV84kfYaHRw2ddy1IX5H8QUhe59jCKe3quI9N4MyhCI4vlLGd37FKwAAlpLDoXQLjctFNWGiSsbUnIKCqjBDKAYUhAhJKY5DKO92GQM8Vm6t3lsylhRykJcPcghREBqJ//4VwMd/CahuAf/l5cAzfzn4e+hzJAg5GUJTEFK0unt72JBKUwegCAt4TqUgRMbPIBlCAHOEAvAKQtMPlY5RMiYZt0NIi5kh5HQYm1WHkNnlEGKXsUhqN4HyEd9DHd1CPsQhBIiJuhRGtg6GHBd6BU67LOz6QQsnV8soHBGC0JH9p8XzMrx8Ql3Gru43YVrAydUy9hoamh0D92xKQSjmsbB8Elg8Biwd6/vSHfs9N5YGOB9IHLFsAW3MV0fgKEEIAIpqjiVjMaAgREhKaXcMKAocW/v6ojjJO53GgkKlk0LmAgQ6hOZ4UDQJajeA7eeA3QtiYnf9scHfY54cQk5ZyxSOK1kyBowmCMnJ+bznTJDZwNQBJY5DSApCFCm78TpI5GRjeqHSA0wAFzZEac2Yuhk6DqF+GUI75wAlB6wPESY8AYTgJ74j+Vwugbbzhfn9HukacOEjwF1v8D2sGcEOIbfEsuOUOV0/GPL66RU47ZKxG4ctnFgto1xZwJ61hDtv/a14Xu5fvmKXeY9BBHBKxgpOy/lX33HEMXLfuzmgQ+grfgT4xx8QeUl92LG/c5uLgzmEAAh3l6ICxUW0YZ/3x9WJbcLU2jqWIwShUkGlQygGFIQISSkte4VLsS8ka7YgtC8FoXYNKI0hQwhwO4cEZgjNx6rD1DA6wh1UvS7uy5XWQZirUOkplrV4S8aSEIRyebadJ+Mndqg0HUJBmKYF3bQcB0lBzaFSUKcQKi07Gg0iCK0DsIDm/jj2yMkQ2m923LzCIHbOAUfu7N8hbUr4HEKqgs6o4oE6xx37XvwYoFWBB97qe1g33ZwtL7cdEWOPF27VHRF16JKxhQ2guSeuv4aGTmEZu3UNJ1bKKKo53LSOIG9pwIlXiFB1YLwNTjwOoUt2y/lX3XHEeVo6hGJ3Gisti+9JDHZqbeRzClYqQzQIVxTxWYUFtObIIaQbJtq6GekQKuVzzBCKAQUhQlJKu2M4XVAA0XYegNtpTBtThhDg2sADu4zN6aBoEpgmAEsIQrUb4rHtIQWheXEI5abYZcznEBqy9bzRLQjRIUTGjGkwQ2gENDtgWDqEAOF6mLxDyHUjxKayLrZj6jQmBSFfXmEQ22dntlwMADTdcDOEcsroDqFcYX6/R8+9F8iXgXve5Hs4rGTs9jWRUfPY5X3nsesHI4RKWwZwcAUAULXEmPbEahmKomBbscvE7veIVXLsMw4HjEcQunnYRk4BHjjhLrweXS5huZyPXzI2ALt1DWuLRWcReGDKq1CKizBzcvE2/Q6helucjyJLxvIsGYsDBSFCUkpbN1EuuF/htUUxaNyrayKIWKuPsWQsQBBS52fVYWrIAaXXIbR7Xri9Pvs78d0l8yQIyclQ7Sbw+NvFsb19TgxSAeDyI8CVz47ns70ZQkOHSnsCftl2nkwC0xgwQ2hOJ7JDIicPXvfDcjmPajsNodL2BHlMwdKyZAyIKBuzLBEqPaOB0oDfIaTmcugkkSFk6nPTytvBsoDn3yvEoOKC76lOSMnYseUSCqriE4SGD5W2Bc7dC2JjiO/CiVXRXn1HsZ+//y3uz+RjuNXr28ATfzz430s2/FALaHYMlAuqsxgLACuVAjYWi9jtV1I5BDt1DRuLQ+QHScorQGEBpmq3pp+Dsbo8Jy+FtJ0HhEOo3aEg1A8KQoSklFaXQ2iplEdBVUSGUGtfDE5kyF7SrN0NnHglcOLl7mPjtOlmBSkWaFW3S4veAj78H4G//NfA2ffHe5+5CpW2J62P/SHwp/8EuPY54OGfAt7x3SJT4F3fD7znR8fz2e0EHELdJWOcfJNxM2jJ2BxMDJJE5k2UfA6hguMQurrfxOXdIc8Hg2AMUTLmOITGIwjJUGkgotNYdQvo1N2swRlE8whCBVWBMXLJmMy6m7Pze/U6sP8icPqre57qhJSM5XIKbjtSwReuHAAQuTojOYQA4NazAICbhljkPGkLQk+oD+LFysuAU69xf0aWy0c5YB5/uxg73HxmsP3xOIRaHQOVgurkdwJCOK4U82hoyZeG79TawwVKS+56I3DH62HJsfocZAhd2BaLdidXw8e7pbzquD5JOBSECEkp3Q4hRVGwtlAUq3ZOy9cxWbbVAvBPPwq85Bvcx3J5AIq7gkIGxzuYvP64O6n77O+I7XPvifc+c+UQsgdAey+K7VN/Bpz/kHBTfeq/AfuXhGNoHCuzmjdDaBSHkBSECgCs8YRdEiKJKwjJcwQFIR+a08HTXXBZLuedEqmf/vOn8MPvfHz8OyKvB4OGSgNjdAi5YduhgtDOWbGd4ZIx4RASf181qS5jwPyVjckMw6MP9DwVVjIGiLKxWlt8X1522ypuHrZhDlOWJwXOK48AAC5aorPYCVsAeF/pzfjFu35VdPGUxHEINffE9vmYYyqJx7XX6pgoF1QcWXBLOlfKBSwUVTQ7yTuBd+sa1ocJlJa89T8Cb/5ZWI5DaEyd2CbI5y/tQ1GAV995JPQ1pXyOodIxoCBESIrwBqN1O4QA4NhKCdcOWu5FfHOClm1FERdiOoSGx1sSdnAZOPVacbt9KLbPvy+e8DFPodJyYivFmUd+w135+9gvim37AKjfSv6zE3EIecp3ZOnYvE0ayGwRN0PImTilf2KQJPI6680QWikXnFDpg6Y2fAnMIAwdKo1EHUKGaeFH3vk4vnBlH82O4bgz9uoh57FpjD8GRPN0kSuoOehJZAgB85ehKP+WAeKebgaXjAHA7Wvu+OPlp1agGabbAXcQ5PF8+RFALeFs+wiWSnks2Zkx5UIOre5yoDgZQnJMJUvP4+LJ9WrpBkqFnOPOB0TJ2EJRTcwhZJgWfvrPn8SLO/XRS8Ykhfk573/+0h7OHF3CSjk8Z63IkrFYUBAiJCV84vw2Xv5/vw9nb4iJsbcGXnL/sWU8t3UoAh0VFThy12R3Ui3SITQK3ULBqVe7OVCv+W6gthWvDf08OoQkekv8Th78FnFbDsSH6cbWD63mijkjdRnzZAjJxwgZF95jLoo4pRUZpF+odKtj9m+7ngTO5HOASWBxSZwTEwyVvlVt448/ewUffu4WWh0DJ1ZsQShsgr99Thxby6cS24ekaeuGJ0NIgR5RUtLqGLi23+c74nTsm7Nzu/xbrtzW85Sm9xeElst53LUhgqC3hikbk4JQ7Qawfi+2qh0nPwgAykEtxeM4hFq2IHTlUaA2wGKSt2RMM1DOq447P6cAi0UVlYLqK60chcu7DfzuJ1/Euz57BdWWnoggZMnz/rCu5xnBsix8/vI+XhPhDgKkQ4iCUD8oCBGSEv74s1eg6Sb+5PNXAYhBSrngH/S/5OQybhy2od18Hli7azCreRKoRTqERqFbKFg+IVbmykeAr/4pAIpwCUW+hyn+BnMjCHlWfjZt2/rprwIe/CZx+xV/T2x3zgF//X8Cz8fMWYqDVgcWj4rbI4VKezKEgPnLmSCzRdySsTgTpwyiBYRKL5XyqNmCUFs3cNjSI0WERPBMPmOjKGIS3a9kbOe8yGGTwflGB3jXPwJuPdfz0m27hfZBs4Nmx8CxlTLUnBJRMnZO5AflZneK4XcIKZEOoZ/4kyfwTb/yseg3VOfYIRTyt+wYluOM6UZ2Gju6VHIEnKEEodIqoNifvXEaNw5bOLbslk2V8gEOoThCd+sAKCwAsIBzD8ffH49I29INJ7ZhbaGI5XIBiqKgUlSdbnyjIr9jn74gvs/ro2QI2Sj5+SgZu7Bdx36jg9feGZ2Vulwu4NJuAzer6f7/jpvZPVsTQhzauoGHnxJtyN/9hWuwLCvQIfTAiRUAQOfm2el0+MiX6BAahW6hYOkE8MZ/DXz9zwhx6OhLRLZQFHIQNC+CUM4jCN3zFcCX/wjwxv9dtJl96PuBr/pJ0YXn7PuBR/478NxfJffZ7SqwuCluJxIqLR1CrGcnY8SK2WVsnO2ZU4xcTS55MvoqRRUt3YBlWc4ENLLtehIMEyoNiNyVfiVjn/0d4Jm/BG48Le7vXwKeeCdw4SM9L71lC0KHrQ5aHQOLRRVHKgXsNUKE7YMrwJE7B9vnCePvMhYuCD23VcWfPXYV2zXNycQJZMoZQh3DxNX9pq8LXCLsnA3NgopTMra5VMKmLWLs1IcQnnM5tznK5n1oaIZTLgYIh1BrGIdQ+xA4+Wpxe+9i/P0xNAAKkFOdDCFAdPldqYj9SrJkbL8pjqfP2x3bknAIKU52XLoFks9f2gcAvKaPIPSDX3kabd3Av/ifnx+/iJ9iKAjNOH/yuSv4tl//xLR3g0yZj53dRrWt4xtecRKXd5t4/MqBHSrtdwi99MQyFJgoHVyYTqAjHUKj0S0ULJ8AXv53gdf+Q3F/43T/0ig5CMqXo183Jm5V23jfU1v49AsJlSzkcqL8ERC/j6/5KeD2h0QL3Lf9AnDkDmD9XuCZd4vXSCt4Emg11yGUSKg0M4TIBIjbdp4OoUCCHELlggrLEuVkskQl1CGTFE6o9IBBsgsbbmhuGM/b2Sm1LbFtiY5QQcfCdtUWhJo6mprhBOmGls1VrwPLJwfb5wnjdQjlc7nQieIvPvy8E9t3Myo3yskQms65/d//5dN44899EK/8v9+P57aq/X8gDrommjkEjCUty0LHsJAPFYSEQ2hzuYiFojgX9Th54iKDpTfOiM5eRXfcG9hSPI7Q3ToQQlNh0Z8V2A+jLca5iuJz6b/qjiN45e1HxO4W8omVjB3Yoqs8J20sjRAqbZMrpNMhdLPawk7NPT89de0QlYKKM8eWIn/upSdX8G++4UE8cmHXEdZILxSEZpwnrx7i0Yt7TEjPOO95cgsr5Tz+3Te/DEU1h/c8ed0OlfZ/hY8ul/BApYq82QI2pyAI5UucXIxCt1CwfMJ/f/M+YPdCdE6BHARNQRCyLAtf/4sfxj/5/c/in/zBZ5N7Y7n6GjbJ2DgNwB61y4lNErRrQGlFOJBGCpVmhhCZIMwQGomgUGl5rW11TGdiuz92QUiWjIUHpgaysBbtENo5D2w/L25XuwWh3mNhuyb246DZcVwRq5UCDlsB4ofeFuVq3deuGcIwLeim5TTlyIc4hCzLwgeevYEHji8DAG4cRoxt1OkKQo9e3MX6YhGaYeLS7pDXqm72XxRuwwBBqGN3ZSuGlIwdWy6hlM/h2HIZFVs0GbqMSnbO2ziDpt3qXVIKdAhJwaNPhlB5BSgt+buJ9sPoOOORlmdffuKtL8WvfqdoAiIcQjqsBDqfdp9j1hNwCKnFdGYI/es/egw/+adPOvevHzRx8ogoX+3Hq+84AkB0aiPBUBCacTRDnOj2w6y5ZDaxkm0tfWmngZeeXMHmUgm3r1dwZbcpLM9dDiFFUfDl6/viztQcQjzhBmKa/TuESaEgTADZOCNEo/0Xw8uO5KrPFAShw6aOvUYHC0UVB81OIgMiAO5ge/l48PPebjbthB1CpSWgUB4xVJoZQmSCmLrrqouCDqFA2gGCkHQCtDuG6xAK67KVFE6XsQFdAZU+GULSHQRFuHkA97wZ5BCyV+X3Gho0w0SloGK5XHBCtn3URGn7LAtC3YJfPqTLWF0z0DEsvOqOVQCIziCZYoZQq2Pg7M0aXne3KJ1JbAF5+6zYBnSL0+3xbVjJWC6n4Le+93X4ga+41xFTh3bNyGDpjfsch5ok0CHkCEJRXcYOxGJPcWlAh5Dm/K1bHdNXViqpFFWYlhtOPwrdZZlJlIwVCgXoUFPnELpx2PKJnTcOW07AfT9WK+JvdsC5dCgUhGYceaIbuzWZJMtj/xP4fx9IbKB92Oo4J7T1hSL2GlqgQwgAXrUgBoLm2r2JfPZA0CEUzh98K/C+/yv6NVIoWLtbWJkrXbXRMhfq8iPAf7oHeOrPet9DXuQLkxeEZNbEXRuLsCwkVkfvCkIhDqGjLxHbldsTLhmrA8VlET45rIuCGUJk0sQNlfaWVnzmt4FffEV/0ToDyAl1KUAQanYMxyE0sZKxgR1C66LLWNjf8oW/BTbvF+fTqi3gyPNmgPAtBaGbdulYpZjDSqWAw2bA5Eo6jpZmVxDq/vvmQ7qMHdj/v/uOCYfQrWqUQ0hmCE3e/fncVhWGaTnhukOXZnVz6xmx3Tjd81RHF8dWWMkYALzxzCZOHakgl1Ps9vBDXveWjguX0MI6Wh3TVzIW2GWs0MchZJq2Q2jVdggNKAjZQnpb723sAsB1RCUw/jlodjyljUpke/W4lAo5tFBMnSBUbevOuQgQjr24gtCRBVsQCjpnEQAUhGYeqTDT5pYyLn8KqN8U5T0JcNjsYMUWhI4sFLFb12yHUO9X+FRFHCu3jIVEPnsg1BIdQkGYJnDpU8CNp/q8zh5AfPkPA9/zF6JjjBfp+vrUrwmL/+VHet9jig4hebG+e0Mce5EhnIMghZSwScbLvhX4rncBZ746uZIxy3IdQvmkHELMECJjxrIAy4wnCKlFAIqYOG2fBQ4uMWAaroNElhQBcLoJHTbdc9rYJxdGW5z7uq8D/aisi/NOO6QUprkHrN4uXDzSIRSVIWSf1+U4VDiE8sEOISkIpcohpMC0ALPLJSTdBHesV1DK53AjMkNIuj8nP/556poQ877oroQdQuc+ABx/ee/CFNy5SVjJWDflwgidt970Y8B3/wl003Icas775tWALmP22CfsXKbVAFiiZKy45Hbai4PR8TmEyvleQWjBFqySWBDbb2g4sVLGiZUy1haLyMUoj+pHKa9CQyF1glCtpWOnrsE0LZimhRuHLRxfjTfOXSrloeYUCkIRUBCacdpOrToP4lSxbQf/7pxN5O0OW7qzMrC+WBDWbT34YrSS02BaCnZaMUoGkiZfpEMoiMMr4uLbrxWwFAqWT4jg5G4W1kUL+q0viPtBx1dneoLQjp01cdfGIoAEBSG1ICZG0jreTb4E3Pe1wgKeVMlYpyEm1sUl4RAaWhBihhCZIFJUjiMIKYo4T+hNNyMryQyulOJMdr0OIfta651QTMQhNGigNOBmroRdb/SW+Lsvn3BLvJySsQCHUNX//ywXVKyURYZQT1mwIwjNbqh0u0vwy9uT7O6yMfm3XqkUcHyl7DikApEOoSmUAz957QAr5bwTrttTQjUMjV2xiHX/WwKf7lcy1k2loA7vmFk5CZx6NVr2380nCAU5j/plCMlj3SkZGyRDSHP+1s2O23beSyVBQWiv0cGRhQJeenIZJ2OKH/0oFXJoWsVUZQjpholmx4BhWthvdrBT16CbVmyHkKIoWCnnsd/kgnUYFIRmnCQdQpZl4fc+eRHve2pr5PcifZCdoPp1hIqBYVqotXWnpeXaYtGxLgc5hBZzGpooYmcaZYZqiV3GgpDHQaNP5xcpFIRN5hTFX88fdHzNkEOo7hGELMvCr37oHB650EcUC0ItiAlGv5Xy8hExsU1iUC5zBYqLorSGGUIkDTjnkJgLArLMVwpCSWZwpZSwLmMAfBOK0LbrSeHJKxkIKZyHBUvrdqckn0Oof4aQpGw7hDqG5YgrDtXr4jwnRakZRDpovBlCgBhreTmw/9arlQKOLZeiHUJTDJV+6tohHjy14hyjPSHLw3DuAyJQ+oG3Bj4dp2TMS6WgOoLOsEhBqdxVMqabFjrekj9FEWPRsDJvKXoPWzKmFtExTBimFVgyJruqJVEytt8UcRE/862vwH/5B68e+f0AIYS2rAKsFDmE6m33d7ldazvfxeMxBSFAfI8PbIenZVn4xYefx7Nbh7AsC49e3O1xCGYNCkIzjrxwjdrNwrIs/PA7H8e//fOn8FsfS6aMiYTQOhDlYkAiglDNtmUv2w6htYUi5Hkr0K6KNhooTafMMF8UrUqJn53zYtvo04pdDiZzEZMAWTZ2/BWiJWz373uKGULbtTZyCnDHul0y5ikp+IvHr+E/v++54c4/uUJ4oLSX8orYJpEjJAeJpeUEBSFmCJEx009U7kYe27JsIskMrpQS1GVMOgG8DqGxdxnT24MHSgNum27pELr6OX8ber1tO4ROimuSrrmT5K7znG6Y2G1oOOVxJ1QKKlbK4vhyOo3VbgLXHxeOo6XjQG52pxeuQ8jNZgGATlcjEPm3Xq0UcGylFO0Qkt+3CZcD64aJZ68f4mWnVp3/TyIOoeffAyweBU69NvBpuVhdGKRkbESBRDqBvA4hebvHJVQohzuE5DlOlowNEiqtC5E2aF+692noEjkPBw0NawtF3HakgnuPRrdXj0u5kEMbRZhaesqDq233e7VdbWPrQIxzTwzgmlpdKDrf6XM3a/jIB/8a//Ydn8IffvoSvu3XP4m/euJ6sjudMmb3jE0AuAOT3RG7WTxzvYo/+dxV5BRRfkTGiCMCKW7p2AjIAZccgK0vuF0GAjscoI2mVXJaxU4UOoSCkd069Ga0sBCn3OP214mB2uu+X6zg7V30Pz9Vh5CG9cWiU94oS8Z26xr+3V8+DQB44uoQJSlrdwEnXtn/dSVbEGonUPYiJ0ilFTFpTiRUmhlCZMwM7BAq+x1CLBnrEQwAj0PI4woae5cxT4vrgfA6hEwD+O2/Azzym+7zels4w5Zskb12I7TL2G5Dg2UBp4+5k9FKUXUyDZ1MpY/8PPBbbxW5iUsxxPsp0t1FTgpChhFcMiYcQmXcimw7L0vGJjvuevr6Idq6iVfdcQSKoqCYzyXjELr0aeCeN4UKe7JkrBjXIVRUhw+VtmkGiDBSqO3JEaqsAQdXgt/IKRlbFQs+A2UICYeQ/LzokrHR51r7zY4TiJwUpbyKNgowU1Qy5o0fuFVr40ZVOoTiC+arlQIObBH/U89dxTuK/x6vvPln+Om/ENmeWa+eoSA048gL16grUVJUOLZcDu4MQZJDukHu+OJEHELeOnYAvotDkEOoYDbRRBm79SkIM3QIBeM9DsJs/IArFKgRgtBD3wf80NOuQNKdIzTFDKHtWhsbiyUslsRxWbcHRB95/hZ26xr+zitO4Op+s6cEoS/f8Q7g7/zn/q8ri/bAibgcnPbJx0cMlWaGEJkgg2QIAW6GkCZLxigIabqJnOIvh5GCkBw/5ZRJZAi1hysZq3gEodaB/ff15KToLSEIyZyf6pYnVNo/SZT5QfduLjqPyZIxAKhKh1D9FtCpA5c+OdP5QYA3NFz8fVX77xzkEFJzCpZKeRxbKaHa1sMn+VMqGXv0onB+yZbz5aA27MPQ2o8U9oYpGRvVMSMdRpVi7/eyR2y69ytFN72g8ai3ZKy4KI5bM+bvzBZp5eeVAkvGhu8ytlfX8AsPP++UpB00OzhSSVYQKhdyaFlFWClqIOB1m2/XNNw4aCGnAEeXBhSE7PP3589dQlEx8MCyhnxOwZed2cSHn7vlnBuyCAWhGcdxCI048JAXsROrZdfiOyQfPXsLT1+jrTyU7bOAkhMht41tv1V7CFyHkAyVjnYIKZ0GNLXsBPxOFDqEgtk5J4KJgehg6TjlHooihLeNe9339iKdLFMShDaXi1iyJwvyIi4FoG9+9W0AhnAJ5XLxHA9OyVgCk1qZrbF0YsRQaWYIkQkyqENIllZ0WDIm0QzTVy4GuE4A6RA6ulyaQJcxbbhQ6coRAIq41sgFCMMjZMj3lWW4tS2PQ6hLELLP3d5ylYodKg14HOdO9pQ10x3GgF4HWEE6hAJCpVfKeSiKguPL4np6M8wlNCVB6DMXd3H7WgUnVysAhEAxcpcxQxcl0/J6GsDgJWO5kUvGpKBUzvszhIAAQej+t4r/w4sf630jRxCyS8aA+DlCtkNI/o6DM4SGD5X+yNlb+OUPnMXjl/dRbXVgWaLUKUmkQ8hKkUOo2vYKQm1sHbawuVSKLUgCwBFbENINE8++KMZ3b3vJMv7sn78R3/uGu1Ft6/j0hT6xDnMMBaEZR164Rg0vlCemk6tl1Nr6SOFZP/EnT+BXPzS682Vu2TkHHLkTOPYy+/75kd5OWrJlqPQRz8UhyCEErQFdrWBnKhlCJTqEuum0gP1LwG1fJO5HOYTiZAhJKmvAwqZbjiaRlv8pZAjt1DRsLpWwVLIFITsIcKcuVmHecHoDigI8cWVMLgSnZCyBSW31BgAFWDrGDCGSHgbNEJLuN40lYxJNN3tKYeTET4pAJ1Yrk+kyNoxDKKcKUaix6y5ASPepZXm6jAU4hDrBgtBpjyBULuScTEPHIeQ9bmZcENK6uoypsstYT8mY7oy3jtmlKaE5Qs65fXKCkAzDfd3dbvfNciEBh5C3C1cIujFYyVi5oI5cyiZFH2+odGhez71vAvIV4Ln39r6R9/9XGk4QckrG8uElY8M4ouSc7/ytmiM+ryVeMpZDC8Xhy+CngLdByXa1ja3D9kD5QYDrEHr8ygEU++9dsVp46ckVvPHMJsqFHP7m6RuJ7neaoCA042gJlYw17InZidUyLMuvtg6CZVm4WW0n1056Htk5B2zc54b/dk/YB2RQhxA6dZj5BewMWpaTBGpROIQ+8vPAtc9P/vNnkb0LACzgjteL+5EOIVnuEXN1f/O+XodQZ7oOoY3FEioFFTnFvYjv2tlCy+UC7tlcHC5HKA5JloxVr4usJrVgZwgNuZrGDCEySaxhSsbYZcxLWzd6SkG6u4ydWCmh1TFHzkWJZNhQaUCUjfkcQvY5x9QByxTvu7AJKKo417WCHULSaXzvUbdkTGQIyZIxeyzYOnRFkRkXhLq7jMnW6UFt52WpvuxmdHW/EfymU8gQurjTwHZN8wlCpfzowotzDpDX0wA6xhBdxsYRKh1WnlWoCFHo+fcEvNGBOP4LZaC4LB6LGyxti7SOOBUVKj3E/9cVhOqO4Jx0hlC5IBxCoaHbM4h0m28sFkWXsYPWQB3GACEImRbw4eduYgH2ec4upa0UVbzs1CqevzFAwPicQUFoxpEXLtkxyrKsoSb6TsmY/QUaNkfosKVD081E2inOJZYlHEEbZ4CVU+Kx2miKsxxwyYHJaqXgdN8uhTiEUFiYnkPI0IAP/gfgiT+e/OfPIofXxFZm/kR1GnMyhGIOAFZO9R5fehuAMlwY6Qg0NB0NzcDmchGKomCxlHeE45265giZr7xtFV+4sj+enUi0ZGzLLakoVNwJ86CYhjs5Z4YQGTfDOIS8GUIsGUM7yCGUl13G/GOpsbqEhg2VBoSYXbvZ6xCSk8B8SZTirtwmHKwhJWP7TQ1qTsGJlbIz7qgUVMch5Iwl24fAA28RpTp3f/lw+zwhejKEnJKx3gyhVXvcde/mItYWCvjwc7eC39QpGZvcuf0Ru7xF5gcBCTmEvF24QugMWDJWKSaQIRQVKh2U/XL768Sx3V0a1Tp0/28jOoQqxaCSMXHuHaZkTB6b52/WsO+EmiddMiYyhEytiXd/4Vqi7z0u5Fjy7s1F3Kq1ce2gOVCgNACs2sLaoxf3cGpBlrq6f/e1heL4XZ8zDAWhGUeqxdWWjo5h4pPnd/DQz/4N3vvkYO3x6prrEAIwdI6QtA/XE0jPn0uq10UWw8ZpMYkEhncW2Bw2O1AUYNkuw1FzijNICepwgE4DSnERu1PJEPJcuNrV8NdlCTnQXrtbbBsRmVJOyVjMyVxQy1S9KY49Jd5ALSlk+OimHfK35BOE2thYEsfG6aNLuHHYHk94X5IlY7Utt6QiXxET7WHyIUzddQYxQ4iMm0FDpXsyhOavZOwT57bxg3/wWVhWvFJ5TTd9HcYA4YTI5xSnS80xWxDaH7GcP5JhQ6UBIWbXbrgLEPK4cAQhe3V98wxw/QuukNg1Xjls6litFJDLKc4YpFxQsVgULlDXIXQAHLkL+M63A+v3DLfPE6K7y5gUNTpdJWOHHkEor+bwdQ8exweeuRmc0eMIQpMbd733yS2cWi37yvkScQh5O2yG4ApCkwyV7hVhylFuHLn/3WJP+9B9rrgY/JowjDagFgPzjCRqTnR7a3QGnyfJY+v8rRoOxlQyJh1CWquBH3rHY4m+97iQ55k71xfw1LVDVFs6Xn/PxkDvIb/Lj13ex70r9ndd8wpCBQpCZHZp6yYWi26700cv7sGygB971xO4th+//rOpGb5EdqdV6IDcsuun6RAKQZbvbN4nJoFqcfjsEZvDVgdLpTxyOXeCL1vPhzmEcqVFVNv66OGCg+INwByklec8IwdXi5tCwIkVKh1zAFBa7h3IyJbCE2bb7mp31CMI1T1t59cXxeNHbKfQqGWwgeRUYQFPyiG05HEIAcN9l4NCpZkhRMaFPIcoMYd3+bIQ7+XPzWHJ2MPP3MB7ntxyhIB+aHpvqDQgJlLdXT/lxHgsDBsqDQgxu7rVWzImBZ+8vXizcQbYft5+rNLjppDByoBYYVcU4TBQFAXL5YJYXDQ6wkEZISDMEr0ZQuJvHRQqvVpxhdW3vPwEqm0dnzgX4PKdcIbQXl3DR89u4xtfdco3Nkw0QyhGyVhcQahUUNHqmCPllzYDyrTk7cCxrnT/dC9Otg5ch5AMlR66ZCz4/79QVNFoG/j59z2HszfiL47KY/PSbgM37dbqRxIPlRYZQgVLQ8ewnDyoWabW1kW3v+USLEssPL7lZYOVpkpBqNkxcNeS/X/2OoQWi9hrdGIvHMwbFIRmGMuyoOkmjq/KlSgNT147wNHlEjqGiV98+PnY71XXdCwW884gZliHkBSE6BByOWx5TiAyL0jmB40SRivfv6k7+UESWVMc7BCqo1AWF7ndSZeNefMO4q64zDstz+Cqst6n7fyAHYKKS2Ig7hUYOk0xsJ8w2/a5QTqBvCVjuzUNG7YQJFe7Rg3KD6W8MnrZi6GLNsrSIZS4IESHEBkTw5SMectY57Bk7Oqe+N5qMSc+mtHrEALE9Va6raVbpttVkijDhkoDQsxuHwKHV8V9ec4xuhxCG2cA2P+HpWM9QbOHLdcls1IuoJxXodju0+VyXqzct/oLCElwdb+JN/7cB/HM9dGO0e4MobzjEHKPD8uyfCVjAPDGM5tYLuXxniCH/oS7jP31k9ehmxa+8VWnfI8n6hBKsmTMEW6GFx8CM4SiHEKO+6drcbJ16B6rJTtDaOCSsfAMIblfF3fq+JUPncN7n9yK995wfz+mBXz07DYUBY4gmxSlQg5tFFCGBsAKLrebMWotIQhJB/p3vv6OQNE+Cu93+bYF+3jxHBtrC0URiTLOXLgZhoLQDCMHL7JWfbeu4elrh/iSezfwlQ8cxcfPbcdWMpuagYWS6nwhhm2XKgWhYWpj08rl3Qbe/IsfCeyMtF1r4/U/+zd431N2jsvOedGietm+SOcr/gHWH38f8B+OAv/llbEnl4etDpa7Lggyj6XHIaRrgKmjuCAEoYm3npcT58Ji/BWXead9KFbri0vAwrrrEHr0N4G3f5f/tXIyF3cS4NS/ewY8U3IIXdwR+yDPV7JkrK0bqLZ1jyAktmOz5pZWgPaIDqH6LRG8utztEBoiR4gZQiQOv/tNwBfeOfr7DCMIectc5rBk7Krtpu7EnPi0O8EOIe/1dtEWhMa6uj5KqLQUs288LbYy28abIQS4i1eAEJFM3ZeD4w1WXq0UfOU6K+WCyBBq9xcQkuA9T1zH1f0mnt0aTRDqzhDKB7Sdr7V1GKblm0SW8ioeunsNT1wN+PycKq7zExKE3v34ddx7dBEvO+X/nSeaIVSKcggNWjJmZ/2MMNluagbUnOIToULbzgPhLeV9JWODZgiJXC8pogQ2doEoa3vedgbVB5gveUvpP3p2G29+8MRArdXjUM6raFlF5BQLBRjjDcZPiFpbx1I5j1fevorbjlTwnV9818Dv4Q3nPl6yz3Ga694a+2LljENBaIaRJwY5wbqwXcfV/SZefmoFX3p6E9cOWri0G2+CUtcMLBTzjtNk2FBpmSHU0IzM2Op+8eHn8dyNKt7+6KWe5569XkWrY+JxGZK7cxZYPy3CGoFeh9DFj4ng6f0XReBjDA49AzKJtJD2OITsHIhSRax6TDxY+qVvA77pV4C73uA70Waa1oFYhVIUIQjJ1fhLnwZe+Fv/a4fJEAL8gxmZITRh/vqJLTx4csXJ1pAlY3t18X9at51DcoA9lpIxQKz8jTqprdkrenJSJVcRh8nFYoYQ6YeuARc+DFx/bPT3ksG4g2QISXKFuSwZk4LQIA6h4JIx9zFZyt9dZpQoo4RKSzF7+zmxNbtKxtQgQeiY/zXwC0Ir5YLPndHjEBpzydjfPCMW3mTHoWFp6yYUxRWC8vZ4zev2OnACff1jrxOrFdyqhuRCqsWJuT+funaAN57edNxakmS7jEU5hAYrGRulFbuk2TFQKai+/7Pbdj7gu+1ct7vEnsYuULGDuEuDloxpQL6Idh+H0EJRxY1Du6JigK7Mbd3Agv27Khdy+KlvfDD2z8ZFOoQAoAxtJNfWpKjaJWNffO8GPv7jXz1wy3nA/13eKMowfPfvLudVe9NoyDMDUBCaYeSX9K6NRag5Bb/ziYsAgJedWsWX3ivCtD5xPqJjkYempmOhqGLJdpocDnlBlQ4hw7RScRIZlee2qvjTx66iqObwvqe2egZ/L2yLk8nFbduhsXNOBEpLvIKQoQsRaP1ecT9mxs5hq7dkLNQhZHeKWVgSF/KJt56vrAGv/YfiQkyHkMBrT/aWjGl1IeR4y72cQNiYDqGg+vcpOIQu7zbw2OV9vO1VJ53HFkt51Fq6IyI7DiEnQ2iGS8aqtiC0ZNeojxJWbXrKPpghRIKQrsEk2gAPWnaa9wysl0/OXclYva0755qOHj9UurvLGOBO/gqq4jgDOmMVhNpu1s+gSDFbur+cDCH7vrxGrN7hikMyM81zHHpL1r/lNafwXV9yp/PcSsXOEHJKjMZXMnZgZ2gCw49fJTI0XAoLsmTMO74LE4SOLZewXdOCs6NyhYmI/dVWB4ctHbet9S78JOMQOhBO9winsuxcXAkRRHr3KxlBqFuAkS6vaIeQZyHHssT5dmFd3C8MGiqtoWXm3ZKxoBxPAAsFV5AfJGJD002sVgr4pledwk+97UHcdiT5xb1yXkUL9hwCnXQ4hOws1VGoFFQUVAXL5TwWLHteZnac852cV2U1WJqC0AwjHULHV0r4ztffiWe3xEntZadWcProIo4tl/DJmIJQvS1UZ9XuFDGsQ+iWR2DIQrD0Hz1yCaV8Dj/9TQ9iu6bh0Yv+/JcXbglR58J2XQy09l4UgdISryBUvwXAclfkYl6Aqq0OVir+E+FDd63hi+5a68056EhByHYITaPTGCBWXRgqLWgfutZrb8mYHKR4RQa5uhh3MlcKGPB0ZQgNmxc2CH/1hMhUeNsr3DyDpZKKWlt3cqxkqPTYbbmlFZitQ3zHb3wKT14d0ilUtTMilm1ByGlnP+Bk2bKYIZRSPv3CznjdH16c4N8EztfDlIxJlk+I85E5P4s9Vz3NN2I7hEJCpeXkt5RXHVfJWEvG7LySoZDijqS7i5gUhHI5dxHLcQiJ35llWb5OW295+Un8s690HUWOQ6iPo+Sxy/v45Q+cHe7/YfO3z990vo/VBBxCXsFPOoU6nuO+Ozxcctx2wG4HLbapkxGErh+Iv+GpALGglFdHn+C3Dvq6vW7V2iiquZ6xaRiRWT9xd0szUCn6v5e5nCJCkgMFIVvs8S6YyQD9yrp8g/gRB6YBWCb+20cv4dzNWk/5mhdvaWWjHf//3LbPPb/8Ha/Bdw1RFhUHn0NI0UYXECeADJUeBUVRsFop4syxJSje+Zf9t2fJGJlZ2p4a1X/1NfdhsajitiMVrC0WoSgKvvT0Bj5xfidW6VajI0rGAM+qzhB4L4JZCJa+cdjC7WsL+JZX34ZSPof3POEPEzx/q4YHlYs4tfMpWE++C7AMvwW7sOAKQnKSuWk/H7P85LDZ6XEIff3LTuBdP/gGX3cJAI4IU1lYxnIpH7ukMHGKAd2v5pHdF8LdHnsXxeDQ29Gisi7uG7o7APGWN0nxIG7LeGcFLDhD6NJOA6/59w/jM11CZtJ84JkbeMVtq7hzY8F5bKmc9wlCMmy6UlBRzOfGWjJmNvfxyRd28MiFIf/f1RsAFHeCJFe+g0rRTBO49Cng/IfEv5vPus9ZXeU7zBBKBU9dO8A/+I1P4eGnb0zmA5vjEISGcAitnARgzVW5rwyUBvz5HFG0dSOwg6d0J5QLOaj2tVef1ZKxypo/f8gRhLpCpYEAQUi8pq2b0AwzdNJ/pKRgpXW5r0Por75wDb/4N8+PFDPw6MVdLJfzOLJQQHXERY62bqLkcZpIcc/wlIwdRjiEADjlQD7UwkTazssOw7cd6S2bKRVyo7v324d93V63qm1sLhV7StbCiMz6iYksGQt678D3dQKjPeMjea6VDiHAXsAMOedpDeDADma3/7ZtS8UXrhyg7HGZdePdz7qmY6+u4dt+/RO4shc9JpfutXFSyqtoW9IhpI1eYjgBai3dqXAZhTec3sDXvvS4f35i35YlY2Mbm844FIRmGDl4Kaoqji6X8Av/4NX48be+xHn+gRPL2K61Y538G23dqUtdqRRGajsv3ycLDqGduob1xSIWS3m86vYjeLqru0X15ot4d/En8Vvqz0L5s38qHjz+MvcF+bIbKi3LUAZwCJmmhWpb71mlCsV2CCnFRZw5voRzN6ckypSW7HKo2V95GJraLeBXXgc8++7e59o14Fe/GHjsD/0lY3IQ0tp3//5e14nRib+yDwTXv3syhF7crcMwLXwhIBA9SbYOWzh9dNH32GIpD9NyV+hlyZiiKFhbKIzPllteQU6rArCwP6QTErUtYGHDFXCkwyuoZOyFDwG/9Wbg979F/PvvX+46Pron57IUkBlCM80FuwT4/K0JnT9lrtg0HEKFrpIxYK7Kxq54HEJxW8SHt50Xj5XyqpOdoo+zy5jeHl4QUhTX4Qi45xyny5hHLDr5arFYIV0T9iJWWNmU5HW1D+HPrR+CtX1OPBDiKml2DFjWaB2mqi3RmGC1UnC6Vw5LWzf8DiFVinu9DqHu/7t0CN08DMgRUosTEfuv7YvPPrka7BBq6+ZoGZ/eRawQtmsaji7HL02XjpnWCG6UMEGoUlCDS9GCSsbkuXZhw/+6EEf7/sP/Ea1f/0oAQLUuXtNBHhd36qH5QQCceRIgylaf2TrEoxf38NkX90J/BnAdQuNEzSno5Owc0pSUjFUTcAgBwC9/x2vwz7/qTIggJL7rE+/OPCNQEJphZGtMqRa/+WUnfC0m5QUtziCnoXkcQuX8UA4h07SwXdNw14aY+A2SnJ9WdusaNm1nw1I57+uu1tQMrFbPIadY+MnO9+GJN78D+KcfB068wn0Db8lYrVsQ6l9SVdN0WNYAbSftDCEUF3HfsSWcnZYgJK26nTkuG6vfEoO/oHDw1r6w5u+cEx1Y5EDZ6zSRIo6vZMyInx8ECCcW0BUq7TqEZHaG7AA2LvbrHWd1RSIv3pd2GlBzis/ltrZQHGvJWM7soIQODoYVnRo7/gFjVMmYbOv8938P+Jb/Jib15/5GPNY9OVfz4u87TLcyMjEu74pz9qWdCf2dEi0ZkzlkQ5aMAXPVaczrEIotCIWESpeckrFcoIiQKJZl548NKQgBfkHICZW2BSGve+gN/xL4Z59ymxHYr5EumW6HsuSosYWiYsC49GnxQIggJEWAURYRRexB3i1TGwFNN33dofIBbi8pCHVf146v2A6haoBDKJefmENIzSmOW8mLFC1Hcgm14jmEBhKEEsgQanUMn7PLee+iGiw05Yvi++NdMGvYgkylyyEUUjL29HPPody8CV1r4aPPXgMAaBCLXVGCUMUnCBnOIvytoOPGg3AIxXR3jkC+KL7rpRSESluWhVpb7+m2PBLtGqCo7m2IgPTlcn58+ZYzDgWhGcZxCIWoxQVHEIpRMqZ1O4QGP+D3GhoM08Jd6wvOe847u7ZDCBAneO+A5sJ2HXcrQuR5n/E6PJF7EDjxcv8bFCru5K+6BUAB1u4R92PULPcbkPUgBZjCAu47JhxkU0nMDwo7njekCOPtIidxygRv2Ktt9uBKDphbB64g6CsZ68Qv9QA8NfLeDKGWkyEkra8Xxzix7Rgmqm3daScvkYLQi7t1rC0UfeWNRxYK4+0yBmAFdWdQPzCNPb8gpBZE+WdrP+C19mT+9FcDr/x2YPEY8Nx7xGNBbo3igivckpnksm3rf3F3QoK2EyqdwHfCkoLQMKHS9oLTHHUa82UIxS4ZCwmVtidqpYLqigjjcghJR8+wodKAKwgpqqftfFeGkLy9fNw9FvR4DqEVS1x3cluPi2u+Gjxhkw6ExghigBzDLpXyvpKxtu7vePuBZ270LfXsyRAKcHsdNDtQc4rTTU6ysVRCTgFuhTmEJuD+vLbfxImVcmA7cikmjJQLEydDaEBBKJlQaTPQIVTK58Lft7jkXzALKhnrfo1NxzBRPRQC0tbWNXz4GbH4c2RJjLvCWs4DrkOooCqoa7pzzN7q0+il2702Ln7kba8CAJSUjtMxbVYRXa2RiEPIQau5OWu+1vNFhkqT2cPJEOorCPU/8dc1AwslWxAqF4ZaYdm2A4rvsnNCBglKSyOGaWGvoTlhuItF1ecQemG7hnuVazAKyzjMHwl2YRQqYoIOCEFo8ShQOSLux8hpkAOpSjHm4N5xCC3gzHEhypybVNmDl6Da7XlDijBBgpD8f1evi9eVuxxC7UP37+91nZh6ZGePHpxQaa9DqNXjEHpxjA4h+Rlri/79XrQv3pd3m065mGSsDiEpCCmN4UvGvF1IJKWV4Ilyc1dMBIpLIqDy/q8Hzn1ATAyC3BqFxfl2zs0BV/bS7BAaMVQamKuSsat7Dcc1MUiodNBkzy0Zy7kiwrgcQrK0axSHkOySuHg0OkNI4ghCYswineRhJeurUhDq1CMFhCQcQg3NwEIpj2V7/Hp1v4nv/s1P48F/+z785kcvABA5Q//k9z+L//rB6ABrrSdDqNchtN8QYdrdGTFqTsHmUikiQ2j8gtDV/SZOBeQHAV6H0Ajj8/ZhZMmYYVrYrbexuTREydioodKhDqEIQcjnELLPtZUuQSgg0/NzL+6hZIhrwbXr13D+uvjZFVsQCuswJvZJnH/PHFtGva07nfFiOYQihKakuOuYWPAqQRupjO+dn7mMH/5fjye1W4HIEtEkMoQc2jX3eueZp4g4AzqEyIzR3yGk+F4Xhm6Y0HQTi06o9HBdxq4fiBOjLBkbZbUnDew1NFiWm32yUMz7grTP36zjHmULyuZ9uHtj0cmd8OELld4SJ6B8WazYxXDPyBN1lDXVh+MQEiVjAHD2xhQEoaDa7XnDcQgFTBrlYzvnRbCwUzJmb2s33cBhr8gwaIaQ0zK1jh995+P4zY++IAbztvVfXtiu7DVjl0sMinT6dFvrl21B6Op+E6eP+fOFjiwUx+cQsn/Xy2gOb/1t7IpQVi9h7ewbu2JwKScO979VlAm++InggF86hGaeK3YY//XD1mgTq7g07TKGmckQmo+SsVbHwLmbNdy7Ka5HcdzUlmWJ0OGItvPlQg4F2Zlq3A6hJErGlo71lowFOY/ksWAvYvU4hK49Bjz7V87LFw3P+TCixEhO1kcThHQsFlWnZOxDz97Ex85tw7QsXNypo6kZ+ME/+Bx00+qbiSJCwwMyhDzXyANPd7Vujq2UcLMa5BAqTKSD5PWDVmCHMcB1CI0yye9XMrZb12BaGMwhZP++R207H7Q4Wo7qrFYKcggp7sKs8xoxdn5xp+6Edn/ouVtYUsTtF69cxl5VvGZ1WYxnohZqpbPspSeWUdcMZ87VTxAKcycmji3+ltHpvcY9/RfA1hOx3uavnriOP/38ldjuy2GQBobEHULyeueZi60tFqdTVTEDUBCaYdwMoeCTjhSK+k30pHDjlIyVC6i29YFb6krB42WnxISrMWKw36zjtssOLhl7/Mo+7s/fQG7zDB44sYLPX9rv/Z36QqWviwGaovRepEKQF89y3BUDj0Po1GoFC0UVZ29OQZQJCjueN+T/TQ8YGMq/Q1XUnPeUjB1ccV/rKxkbMEMolwOKS2jXD/Cuz13Bh5+/Zbedlw4hcQwbpuXL0kgS+T2RLTsl0iG0UFTx4295qe+5tYUC9hud0YIvw3AcQkOWjFlWsEOovBo8UW7u+V9775vE9vIjwZPzwgIzhGYY07RwZa+Jo8slWJabJzRWEg2Vtq9RSsxFBOkKUUvueWpOOkS+49HLOGzp+I4vvhNAvJIxKfD0C5WWXcYGHUfFRk/AIXT3lwGnXgus3xtQMtbfIXTQkCXr9vnrk78CvOsfOYJRWfecDyMcJY4gNIIYUG8LMWDZLhm7VW1DUYCTK2U0NANX9hrYrrWRzyl9M1G6OzkFdYw7aHZCnVHHl8vBDqHc+LuMmaaF6wfNwEBpIAGHUKcl3GkRji8pahwdwiE0qiAUtDhaKYaESgO95WCNHXGe8y7SFBYArQ7LsvC9v/0o/u2fPwUA+NvnbuJoUXwHnj3/IgoQn3FkSVRJRI3Lv/nVt+Hn/u4rcM/mIjTddMqQ4jmExp8hJL/rPQ6hdg141/cDn/iVWG9z/lYNpoWxdjR2HEJJCUKWZQtCsmTMIwixZIzMIu2EMoSkiOFtOw+INn6DcP5WDSvlPO50MoTm2yG0U/O3y14sqtBNC5puwjQtPHlxC8esW8Dmffg7Lz+B7Vobnzz//2fvv8NkOesrcfxU7Orck8PNWdJVDgQJBRAgokkGB3BYe83a3q9xXNv78+P12sYGR8x6jXECewFjcMDYBBGUEBLK8Uo35zB5pqdz5d8f7/tW6qrqqp6Zq6t75zzPfebOTE93dVfVG87nnPNZ8D+JlCObQlMHGjNuxU4uJrJTdRxCKKlCqOW8Ls9z2Dn6EnUaY9k2F8nGIhTs/IUqhALnNmgZq51zf7eSDCEAkAuYXViAZQMLtRZ5DpYh1NbBonuOJ7SN/euTZ/C6P74fVsKNDlMhBTOEJsoKJIHDb7z1cl87evZYg3bQW3UoXoVQHxO71iCL+myAEIqyjLUWAgGVRaC0gQSKh2YI5S9uK+XLHHMNFZpp4TU7hwEAp85HjtCaWMZSEkJyzrWrnodOSWsNzbDwVw8cxY1bBnDLDmKPSKKSZLayUEJIdBVCYgrLfl9g18JKCKFNrwA+eB8Zk5hyxXnekM18l2WMXAcOMaK3yXx34kHyFJ1F92/jLGOUnFhJ7mRbN5GXiWWsoRqYrasYyMkoZSU0VcPZNA7m5QQKIT8hJPEsQ8g9l7WeCqEwy5jsEm9rhPmGCt20Q1vOA6ugEGJzXIxCiOXgpFMIrbztfJRlTJH46PcbDIxuLfrzAQFy3Zsqjsw2cHy+iZlaB6Zl4+BMHWWB3C/N5TlIoNdYqeB7T2EYLyv4wVdsdgpjU8vknrpgFEJUDahwgS5jx+4nY0RYXmIAHd107NWhDolVAhs32B52xdDbRKHPLLUeu2CFFisvRaz4quM4TuA47mmO475Cvx/kOO5bHMcdpl8Hej3HOsKxWhlCTZXdTEwhRG6qtNXzY3NN7BgtOFlEF3uo9EKTDNxDNEOIeYLbmomjcw0MqGfAwwaGduC1l42imBHx5WfO+p+ESbDVOrEJsQFIzod6loNgk1zYJBgKrUkmN7oZ2DVaxIvnamtXxYwC6351MSuEmB1Oj1EIMbDFMstW8hJCvi5jKTOEAEDOY2mJLMxrDfp5U4XQUkvD7jHymicTTtgvnKvh2HwzMVnjWsb8xz1aUvDcb92F979yS9ffsMdWm6s/8dr0My5yLSy39cTElgO2Oe9SCMVYxoKPHdoJLBxeVwi9DHGaVjpvpiTCyfORI7SaodI9LGPVlobX/+kD2HeWEtGMBJDyLvlwHjolrTUeObaAc8sdfPC27Q65kyRDSHPWXWEbT8H5nSR0q0pWFU6odPJNdyS82TZGhyhZ+JB1ZVAh1NaRkwVnrenY32loPtdaQg1UDRxrGVuNLmMGchliGSOKhCZGChnkM6T7KytQDublRAohL+EnhJzLWMtYUcFCU/URSOSJ1r7LGAtJj7KMrVghxApUMedznpIaaTKEeJ6LD39OAGIZC7dyRl5bYaHSwflazACGim/tJ2Hki03NiYzIWGT8H0ADAxlyvodKRed1eyFP90szNIR8saXF7tnU85Qh5FUI+e6XQ7QhRoIcuaNzDTCR94m1JIRUv8tlxWDXQ26QzJOe62MwJ6OhGmtqgbtQsRpX3c8D2O/5/tcB3GPb9i4A99Dv19EHtJ6EEM0Q6mUZ0/w3E6v2pG09f3SOePFlgYfAcxe9QihoGWOfX1Mz8PiJJWzj3DbyiiTgrivHcfe+aT/bztq4Vk8CsF2FUELLWCetZUxvkQ0nxWsvG8FCU8OjxxZi/mgNEBZ2fLGBkV2JFEIV8pUXCFlW8xCH3ok3bYYQAGQKaNarAIBmi2VIketuuaVjx2gBhYyYuNNYtU2u+6TqmiiFEBDtsWePXQtpbs0m6rSNCsk5aKQlrp0uJIEqYqRlLIoQOuJWi9e7jL1swCqe122uICcL54cQOo9t5w9O13FktoFH2JwgeRVCFw8hxNY324bzLiGUYJHPNtJxljFF4iGGqEpWFTRU+nsnai551y940R8qHWYXA7oyhLpUMszGdugbZK5Sl3FIpnbgGMsY26z3SwaYFsl1yklEIQQAx+eaGClmkJMFNDwKoaFCUoWQOzc5CqEuQij8HhotETspa7TigF/7DCGmXI8iY1asEGLrkTjLWB8KIYCGP/e5b9BNC4ZlRyiEhGgCLCxUOqj+FRXAUPHtF11CiH3OskkJIa6OHYPk/Y5UyPo2CXHDVC3nquSesm13bxGG89VljI0BOa9CyLKAQ9+kB5KEEHLXucfWkhCix8fItRWDFeMzRUoYusdeofu9Ncu4vICxoquO47iNAN4K4G89P34HgH+g//8HAO9cyWtcylBjKlUAnEFD77HIaQUtY3RCTRMsXe/omKmp2DGaB8dxyAU6bq0l7tk/g08+cHRlT/L43wH3fYT8/xu/ATz7Tz3/hE0ILBuFEUItzcQTJxdxZWaWPHBwBwDgDVeMoa4aeHHKM5AycmaRdMFwLWN0ktr3r8BXfsl9/Nwh4LPvcTaMbAEVdQ10QWu5di0Ad142hrws4D+ePRfzR2sA+RIghNh7i8sQYvAulpWyqxDihJAMoXSEUIfPgdeb2DVaQMamk5hHITSQk7BlKIejCbvNsdyIpJ0Wqi0NssCnqt6wjmRrQQjNdAQYNo9NebJBWE4r/w3rQgKEW8Zsm2QIBR87tJOc1wYljX15Betdxi5UPHh4zmlZvXEgh82DuTXNRgBAFuFMnt8vEXP6MeCf3k8IyB4KoWlaqWZKKGYvheSxjJ2HTklrDbYhzoiCu1ZKoRAKbTvvUQiFdaZaVdBr4XNPTOGzj5xc2XPxUoAQitjIhyiE2HqR/JwqhGpnHNvY2cKV5GcxBILqWMb6WzMyNXo+Izidhs4tdzBSzKCQEdHSDEcJP5TPQDWs2Hw6LWDLCeZB2baNWseIVAgx1fh8sIW4IAMzLwCfvBWoz/TxTnujV8elFSmEvvsx4AsfoE8UnyGUkwXHDpUUWSkm66cH2jHxCdk4hVBXqPRSuELINvHc6QWUFBFt3cS5ahsCTAgWOccDqGPbALke8rksKjnJf29EgOXezDdUx74/G5Y/RXG+uoyxez0vGC55OPUM0Jwl6/cEjQWOzDbAc8CVG0o4Pr92a/02vf+zq2EZ+8ZvAA//Ofm/XCCkkIcwHC+Rz4XNk5cSVnrV/RmAXwXgnWXHbNueAgD6dTTsDzmO+yDHcU9wHPfE3NzcCg/j4kTPLmNOqHT8gsTxX7K287TqkUYhxPyhrFsHIYTOj2XsM4+cJN2TVoKDXwee+wL5/zP/CBz8Ws8/WWxqqOQkJysg57GMPXVyCVcUW0T5QdUwwzRryEe0sQXW8mnyNT9CvmZohtD+/wSe/HvXKnDiO8CRb1NFEaD2kyHkUQhlZQF37R3H156fOj/dchgYKXUxW8YchVBI6GxQNeRdLCslMukChCD0WcbSK4RmVQl5dPD9N2xEhmM2gywsy8ZyW8dATsbeyRL2nV1OFOLMWrUnJWuWWuQ+CbbnjQPrSLYWXu3ZuoYGsphUmNIp5Wuwjk9hljGj41bJAXLuLKP7scO7yNe5g+TrukLogsc/P3EaP/J3j+Grz09hy1AOiiRg+0hE98jVRKfqdhzslxA69gBw4CtkXOmhEJqmWRanWcg8IwfkPGl4cB6Ccc8H2HynSHxiez0Qv+5yCSEePM+B5wBjrbqM0TXBss6nVnN3QRA9lrEYQkiQAXC+tvNdCqERqgg6dj8AQC1uxR/hx4Brfijy5dmGkykR6h0df3j3gcS2DEYkZWmXMQaiEBLRVE2HEBrMyyQzNtaWY/o23aLTMY78TYM2XYkihFjxo0uJdNNPAFtuAaafA+YOJHpvacEIoWIEGdO3QsiygO/9BRkHbvwJYPK6yIfO1dXU6iCAWrv6VC51PNdA9/Py6ESQgLZcgKU28JGvvohvvDDdnfkHOPeDbOu4fQ/Zsh6ZbSAPlxSocA1sKZPrgRMz+If/8gr8zB07eh63t1DG8lfnGuFkQ1yHw1WHIAK8iDzv6TK2dIJ8nbwumWVstoFNgznsGSut6TzZZJax1QjbfvbzZM8FkGtdLvi6IU/SbC7Wae5SQt9XHcdxbwMwa9v2k/38vW3bf23b9o22bd84MjLS72Fc1IiTLgPJM4TYZMrazrNJrtZOTugwdcFO2j46L4tonieF0PH55so7EhkdYu1g1dgEg91iU3NazgN+y9jZahvjUsu3EWRS5oY3e4WRM0wRwmwobBCqTwO26Q7ELboZpRtGJ0MoqfpCb7k2NYq3XzOJWsfAY8cXI/5oDcALtHPDRUwIxbWdZ1lOLLjT68f3kkOlSf+12EeG0KkGjwFRxU3bBqHAVQjVOwYsm5AvV2+sYKmlO3aYODCpbBrLWJhdLA6D9PELa9Dec7beQc3OYUQiiy5mgUuMKIUQs/15zxfrDtWlEKILRbYpWM8QuqCx7+wy/n9feh6v2TmMe375dvzbz9wMgNiNTi221jZPgF1vSrl/IkZddp/LUQiFrxu6FEKSRyEE0LyZlz8h5FMIpbCMMfIlypri/SoKPHRrbUOldYip1mqh8FqZjE40IcRx1D7DFEKGU0AkB9MGRnaT8ez04wCATGkIf9G5C52BXZEvz4gTthZ9+OgCPnH/UTx7ppro8BnZk5dFt+MZQDOESHGSrUdZYS6OEAkqhBi5xxRCLF+zFyHUpXbZ+Xrgzt8k/w9TDq8C2PoySp3Tt0Lo3FNAcw64/deAt32sax3pxXxDTZUf5B5bjJKnB9hnHXZfZiUBpmWHFsfPNHnwtoG/f/AgPvzvT5G5t0shREgAGTouGyf5QIdn6z5C6IYRG6/eRjMgBRnXbKpgrBRhvfTAe562j5DicVSwNDv+89JlDABEBTneoxBixcnKFlrsih/bjs41sHOkgO0jeczUVOc+XW2wc59bqWXM0OiajV4nmWJX6PgGms2VZK18sWElNOQtAL6P47gTAP4JwOs4jvssgBmO4yYAgH6dXfFRXqLQDAsizzly1iDOZ4bQ0dkmBJ7D5kFCCAVbsK8VVMPE6cUWDMtemUXNUIkEsr1IqrEJ5JDzDdWRBgPu57fQ0KCbNopWzbcRZJWrurd7G/PkszbjWZqxLufJIFSnlpKFI+Qryy+hlhInQyiCFOxCwDIGANtHyPdxMtU1gVxIFJz9soVDCIUs/JhSqzhGqq6SZ+HgJYdKG/zXommkUgjNN1ScbnKoCCpGChlkQO9pKesofCpZCddsrABAogU4WwwvJQx8rlKFUBqUsxIEnsNic/Wvydm6ijpyGOApIZTaMsZInkA/BEbkeRVdjMAN5g2VN5NN2GwIISTnyfWxVhvJdaTGI8cWoJs2/uR912DHSAFDdLOzfbgA07LX1jbGxvziRP+h0mwMaS/2toxRhdCZpTYpsjBViOwlhF7+ljG2Ic5IvKMA0RKoeR6lhZNrNlW6fue2nSdfRZ6DuVYKIUoIaba4Cgohiax7LItkE0VlCAFkrvJkCBWVgEJILgIDW4FzTwMAsmWiqIje5FqOrY5t7NjaMamd17uG9R7PcFH2KYR4DijTYkMcIRIW3CsKvLMh70UIMUIwdA3MLJhrRPo3VQMcFx2w27dC6ODXiYV95509H7rQ8BdLkyIr8X0r1dn7CVPLs591Qp77sXPkXP7ibZPQ6nRuDxJCNDstA91pwnFktoE8R0kBjscg14BM286n6fznI4SGyVo86l5xRADnQyEEUEJIdz83VuyqbAJg+5QzQbQ1E8fmSaOhbfR9nUjYyTYtmqoBgedW/rk0AjZOudAVOl7OSsjJgpP5dCmh70/Xtu3/adv2Rtu2twL4QQD32rb9AQD/AeDH6MN+DMCXV3yUlyiCrTGDSOqLd1v2kUGzIIvguIC1SWsCMQqc4wtNbBzIOpW2vCyuGRvsxamFFphFv5qyK5oPNKARi9R6liAwbbGpOYHSgGsZm1omk0TeXPZtBJlXuO5dvDkKobMAx7sqA+ZrDhJCrFrsyRASec6xrfWE3vRZxgCgkqX2nJV8fv0g4w9re9nBMuOtPbSqYGhNnFkKPI4Rc8WJ7m4dSkAhFOwyloIQ+taLM2jYWWTtNkaKGY9CSHHO90Bewp7xImSBx3Nn4olQ27YdAiXp9dKPQojnOQzmZSenazWx2NTQ4HLI2uTaq7b1dNbF9iKQKRNJtRfsvHkJPCeAOrjAFIHB7cAc7bfgyxCi96dx6VWgLlR4OxR5wcj0YwnztyJh29HXIBvzi+P9K3PYQr6VgBCiCqG2bpJQXKYKkWghQZAvMoUQD44jm4m4tdL3ji5guaXjoSPzuGy8GGqJ6VII8dyaZwhpEFPlPYaCjT+WQUiduA2tmCXqFrWBpmY46xoAZMySFJKRRsevwiAhhGbr4Rsor62KESjsfkva6dabg+k9npGCgkJGgGZaqLZ05GXRKZ6pIYTIvrPLuO/ALAzLhiz4iQWR52BSkp4RVaUIQigbpRACXGVNmJV8FdBQDbqGDy8UhymEZmodPHmyWyH+7NGzmF2ma7RDdwObX9U9l4Wg3tEjP5s4ZCOyR08ttHruY+KUUQ4hFHjuakvDY+fI2v+6EQt7+RP0QMIVQgXBcMiNI7MNjCt0LC1tJHM9GxdTqLjzHuJuuJhBSRExG0EIOY2EzkeGEACICrKc7t4rnWWyT2FZpzFOiq8+PwXNsPDaPaOOFe704tpc8y3NRE4WUsUShILttzj6+WYKZJ3u2adwHIfJSnbdMrZK+CiAN3AcdxjAG+j36+gDwdaYQaS1jDFCg+c5FDMiakzJ0lwA/nA7cPTeyOdYaKgY9SyQsnL/4XBp4E2xX1HqO8v9mD9Mvia0jA0Wui1jU7TCqhjLvskzT4k2v0KILg6WzxIyiMn45SKZXNimcIEeF1MnOAohK3l+EEAGNtlPCBUVclzL5zs1P9ju8+WGB/4Q+MtXRys56HtrNhr4gb96xN9thhFzlS1APhCjxpQmokKuH28uTcoMoYePLoDPFMAbbSgCnLaoEBVHIVTOypBFHpdPFPHs6Wrs8zU109ngJL3fqi3NCYlOg6G83N2lZRXQUA20+QJEjdzjyvRTwEc3AwsJg+nD2sgDLrHnJYSi7GUAMLLHvZ/ZZhtwFXzrOUIXDFoa6ewiBYh3JvFfcQeVff8K/MllQHM+5MXpNVIYJ/d/P8oxRiq3F4kFGYhVCDHi6zQjsrMD7jV/kRBCqmE6ZBBArPdRljHNsPAjf/cofv4LT+PxE0t4zc7h0McpVH3BNmxSD5JpRaBzgg4Ry20dlmXjo18/4Fr90oCn47OlU8tYjEJIzJBMqo9uxpB61r8BZx3KhnY6PxoYmgAAzEQokL1KFVacZF+TEkJNTw5mWIYQQAipXEZw1kthSpT/e+8RfOifiLKpSyHEc10KIVZMC4LZlkK7ma01IdQxIgOlgXCF0J99+xDe91eP4PETHlLINDD6mduw/4u/BTTmgJl9wK43JjsGNUAUJsRoUcHZgBWn3tHx+o89gC89dTbir9zHAQh9Xfd8+O/Frzw3hWWTXOvXP/IL+JT8x+QXjPBgoBbK0RznKJ9qHQMTCr0+K5tItiA7p30qhEqKhJFixmlBH4Tao7P0qkNSoHCeDCG1RtanrHAdUzj/x0dPYvtIHq/aPuick7XKlW1TQmjFYE0+dr+ZqOGUMg2V9iuhJitZnFteJ4T6gm3b99u2/Tb6/wXbtu+0bXsX/Xoeg0suLpAFTfRN4IRKGz1CpanE1Nu6vJSV3KpTY5osEmI2TEtN3Vc9zWeE86IQOuZJrmeT9FxdxScfOAorTWWO+bmZEqeHZcy2bSy1NCfrBHAJISa5z2jLvo0gz3MoZEQ/IcTkw81Z/yaTtWVnYJ89UxywDCHDTEcItZe6rC48z6GkSIkXX6uGQHr/yw7VkyTb6dxT4b+n7020OjhbbeObL3rkqFqLEHNv/DDwA5/x/x0jFuQCUaIALkGZMkOo1tbBZaivXWtiVKH3hKQ4VU7WJe/qjRXsO7vs5CSEwUsCJekyxhRFlZQKIYC0zV1YA8tYUzXQEQrg1TpysoBc9SDZJLOA514IayMPhFvGohRCAPCmjwLv/lvgh/4J2Hij+3OmEFrvNHbBoK0ZoTlt5ayE4YK8coXQ8hkivz/8ze7fMRl7ZRP52k/bajaftRbcUGmu+/2Ylo3Zuoobt5A5wiEXfvTfgVt/mfx/lSxjK8r8WwWoul9hLQlcJHnTUA0Ylo37D85BMyzcsiuCEGJt5+m6TOC52PF0RaCbzxYyqHUMnF5q4ZMPHHW64KWCt3ucoUVnCAGE0Fg+Bdgmhq0Fn8IBettPCAkZjAxWAACzEZtcn0KIbtjbKRVCbU8OJiu8AYQQYq2oZ+sq8hnROedhlqnltu6sz4L2E1HguzOEIqzQ2TjL2BoTQk3NiO3uxd6/lxA7NNOAadn40Oefdm16Zx7DBOYx0DhKzjcADO/u+fq2bfdNCO2dLGG61vF1Z1tq6tAMyym0RoGdt1IIGcbWyPvOLePAtDs/H5ltwKLFGGnhAL6D6/DZbR8FNr7C/wT0fhjLk70RS+kYzdDPsLKZWC4ZoZ+CEPJmHhUVEdtHCjgyGz6f9GoktOoQFWQ5za8QUkrhamgPDkzX8NSpKn74FZudrtNA/10Ee6GpGQ7xuyIwhdCbPgL85LdohlB399gNFWVdIbSOCwu9FULJMoSamomc5JfblRTJ9aWzSnUMSbIQsE9lJTF1hlBHN8MrKjE45lEIsYnsa89P4aNfP4DDEYNqKFg2AyOETNXfLajrWC1Ytp/dZwPSueU2ZOgQjCaQ85Mvvs8V8AfzeXNGZA8hNLC12zKms1Bp00fkxYK1wA7mmQCo5KRVtYxphoVb//Be/GdcO3s5H+tBvuDBZKQHvx7xe/LeMja5jj790HH3d3qLqEKKY27AMAObbOW8+382IaXMEGprJkymPtEaGM7SzYlHIcTImhu3DqCpmfjKc9HnzJu3k0QhVKcbqYGUGUIAMFRYG8tYUzWgCqRtajkrQWQd3Vh1qBdai+GKH2eRFAyV5rptgQBQ3gBc/V5gz5sDljE6JqwrhC4YtGIqkNuHCyvvoMIUN2FjSX2aEMPsGupHneNYxpYIqczxoaHS8w0VpmXjpq3k+naCM0f2rKpCyDAtfODvHsUvffGZFT3PSqAGiilxah6vzVsSOLxyW7htZuNADq/ePoRrN1c8z7lWhBC55tq2AtOyHTtGo59CnKMQMuJDpQHf7zKc5q6BTIMQ615CKDeIwXwGGZHHqQi7iN8yRhVCejpCiBUfc7LgFN5EnkMlK7kKoZqKQkZ07UMha8266r5emELIYJaxHhlCjDxuhSqE1tYSXO/EkzE8zVphhJht2zgy28Bl40VMLXfwwGHa1ZmORXltHqhTkjGonAlB2No4Ka6YJHPoC+fcOZStl3vlZDFCqBjS6j0rk3P5C194Br/xpX3Oz+fqKuSca9F/qPIO/Ef72u6xkV7zIwohedmaaVim42BlM/nK1hApinY8zzmkaikr4YqJEo7NN0PVNK5C6PyFSisIZAgpnrkowknxnUPkGnrndRsAeCyUa0QIrZpCqD5NCiXljcDGG8jPlDJ5nx5l7oZKFvMNLfV+9eWOdULoAsbqZQiZyAbY1VLW07mCVarVcEKIqWW8OSH5jODrMjZT6+A1f3AvDs9EEwC/9MVn8PNUrpsUx+Ya2DJEJlg2SS/Q6kKqRbqjEPKooGJsY8HcJYBUBzkOmKp2UAElowIbx6IihlvGgo/1Bj9vfQ2pEndqHoWQGyqdWCHEWmCHbGYrWWlVW3yfXGji9GLbV43pglx4eSuEWCjkobvDf0/PkQgTOcHC4yeWXCVBiHXPAZtsM8VuG1LKDKGWbjgVMKgNDPksYzo4zl3Uvu3qSVy3uYL/9eUXIqu57B7Ly0KitvNVGjzdj0JoKJ9x7uXVRL1jQBeLgFpDRRGQ6VBCqJ6CEEpjGcsO+AmfXmD3/nqnsQsGsYTQSN5XmOgLbP45em93IaI+RTZirOrcT7C01zJmGaHqIMC1O28bzmO4IIfbjwS5L4XQ4Zm6Q1Z84v6jeOjIAh44OPeSKYU6uj84mFjGwo+FzdkfvG07fu+dV0VWo7OygM9/8FVO8KwouCTCqoPlCIJcF8epWrovQojloZl6fNt5wFU1A1CgueQDIzgkBRimHcWyg+B5DpdPlPDCufD1o1epEwyVTpqN5HQZovdoMSNiuJAhm22qEJqrqyRDyLGMdZ8X79qsSyHEczA8ljHBs5EPglgRuzNrABCygBPWTiGUQJ2T8YQ3LzQ1LLd1vPYyYl1nc7xN1zUlY56MQQDJPOwBRqrF2daisHeCzKHea4VdA72uhUbM6zLFnmZYWPR0Lp2pdaDkmUU/i/amW3Fwpt49JlEL5TB1UrLi96AUIIQYcZZCIQQAOXq+ioqIKyZLsG3g4HT3XslRCJ3HUOkMPMSHWiPFCaZcj7CMnV1qo6iITqc5Nl6ulUIobn5Ohfo0UBjzr9eUEkiAtrtXmaSdxnqp1i42rBNCFzBWK0Ooo3ffTD4LkaMQCr/5ax0DpmX7FUKBLmP7zi7jzFI7VrXz5MklnE0pwzs+38T1m4kKhylcWKvqdIQQC5X2EkLRiig2sHltBBzHIScJmK13MMDRwTwXRghFKYS8lrGi+/+tt5KvcwfdY9LbQH0Gm+vPJFcIsSyKkM1sKbu6ljGW7eQjv4J4uYdKs/tiZh/w4J8A08+7vzM0UkWn9rzdQ2RCdLpHsC5jYWDWI7ng/t8hhNJlCLU0EzZTm2l1DMguIbTc0lBSJKdLocBz+OP3XoOGauCzj5wMfT5GGm4dzifqMsZaulf6CJgcKshoamZsVcm2bdy9byqVLaOpGTDkAgAb41mDVEABshhoL8VmpQEgm+owhZBcBMB1W8YShHD6wK6Ll/O9cZGhFSNJ3z6Sx0JTW50MO60BnHzI/7vGDO1GyGw9/SiEAm3ne3QYGy8r2DiQC2+t26dl7B1/8RDe9RcP4WPfOoSP33OYhMY3tchsmbWGapjORhEgm6woNTUjWe7YPYL33bQp8WsIEaHSc3UV7//bR3zWmNTQGSFENl0sxyp2zo2CN0OIdhl77kwVN/3et30baAB+hRB0t9Uzu4ZFhWyq5IIz9l25oYQXztVCbfxMfcBz7roqdYaQ6s/BLCoShotkPZqnP9NMK2AZ655XGp7PLtjaWxR451wut3WUs1JkiC3HcchKMTmaUi68++gqoKEaDgkWhYwoOEQcsyddR7vm1Ts6sHAU3Pwh1OwsSsYCLZZwQH6k5+uzc1HoowV4OSdh02A2oBAy6HHFX9f1DukiF0bSKZ6feYml2bqKQqlCvtl+B3ZODmO5rXeNSSZPFUHUcs+iIgYE+rguhVA6QshRCClEIQQAL05177e8nRHPCyQFMnSXPE1oGTtbbTvt2QEyDsoij5a+NjEicfNzKjSmyVzrRUgUACOELjXb2DohdAGjl0LIJYR6ZAhpRjchlPVYm/R4y9gSXTD4MoRkEZppOWQUu3GiGOJahwzCaVphtjQDSy3SBlIWeGezuugQQmksYx3/VyBSEUVe2/Wse5GVRVg2MMjR1w7Ys4qKFMgQ8oQ3erN92CZeLgAT15L/n3nc/b3eAh75BH5p+tdQEBNuhlkL7DCFUE5eVUKIZTt5J9+7903j4aOe0FS5+PIOldabwPAecg7v+R3gG7/h/o6+L5suoCbzZOHoSMhZl7EwOAqhgnv9MG96ygyhtmbCzFTIN61FDAvkXm5AcRa1XuwYKWAgJ2MuwqrFCJ6tw/lklrEYGXcvjNDqUlyO0LNnlvHTn30K3zu6kPh5m6oJUyaT/JiskgooQBa9j/4V8Nn3RNu19A45t/lu2yV4niwe2lX3Z/WZ0EW0N7+hK8iWKcfWFUIXDIiKNnyDs2ecXEv7zvZuRBAJQ3XH/NOP+39XnyKVeYFuxM2UJIKhuvNae5FkCEUSQmSeHi8rGClmwgmLPixjpmWjpZk4PNvAx+85jDdeMYaP/cC1AEix6KVAUCEkCTz0iFBpRhSkVT1IPO9vJkCxf6qGh44s9Azxj4XWhM7JsOgy/bhDCPUxj7PrwekylsGhmQbm6mpXyC9GLgNG9wIAFK9ljCleRIV0ptt2GzBxDQDgqg1lNFQDJ0MUZ4yYqeTkFXQZ8+dgXre54tgevdalvC9Uug+FUIAQikM8IaSsYdt5E4VM/LEpHoUQI4T2bihDEjjiDDj5MADgK+ariOV9/hBQGO3urBkC517pcQxR2DtRxgueMSGNZayQCe+u5iV+l9s6bNuGbduYrXeglMdJY49rfhA7R8kY7M3wOTHfxEKHPCdrysGaZJQFFQDnEkLVU0T9lUYRDPcaLSkiNg5kUVREvHiuez55SRRCtkchxCxjwUJlAGeW/IQQQNR7a2UZW1WFUFAFF6L8Zu8trYDh5Y51QugCRuIMoYhFDkM7pFNVSfGESrNKdYQ8kClyBnwt2MnzMW/32arbyjYMbABO48lkVbuCIvoULux4TswnnHCZ9z2IWIVQt2XM+/1khg4UvSxjHOdKsMNCpYvjwOA2kvlw+lH391oTaM1Dho5N3FzMm/MgJuCWWMZWL6+FWShYdaejm/gf//ws/s89h90HZWiXsbWS1K81tBYwdgXwayeBnW9wP1/A6Upg5SghlCMLSWdCZF3GwuANlR7YCoBzlWumkWqx0VQNtApbyDcLRzGincG0PYBlU0a9Y/g6sjCUsmLk4ouRrtuG8mhqZs+xhd2jYa/TC0O0g19cjhBbfDbU5Jughmo4C5pBoYMBi563xjQwd4CEQwa6Srh/TCuAhYgshdyA/zpYONKVEdXWTNz44W/jC4+fwlOnlnDlb30Dz5/xjDVO5tO6QuhCQTtERctwLa2sP3Vqqf8XMDrkmsyUXSUnQHLf6jNEccGqzmnVOcFMKyt6DJmuqZAEDoM5GQM5KdwW2odljBWG3nfjRvztj96IT7z/ety0dQAcR4JeXwp0KYTE6AwhZ62RMhdFFFybkRfsdVaqEFI5t6B0ghJC/VnGmPrMzRBia7VmMMvkzR8lIeMgCiGnKMZIR1bk+qHPA3f9HgDgyg1kTns+hPxjc+JATuqyjKVpO5/3tFr/6Huuxm+9nZBW3vs2TiHU0U1oprum7soQEjxt59u926orkoC2FjE/Stk1s4zVO3pPdU5G5J2g4KNzDeRkARMlBSVFogqhw7B5CY9Zl5M/mHqGjEEJ4LZ/72+DvneyhBMLLYfYZPuQJAqhqMITW38M5WUYlo22bqKuGujoFgYHysCvHAL2vtNtj067Kz5/Zhl3/ukD+MR3zwAAKjJVCNG9ToGnRH55ExkXm3Op1UGAW1guUdXZFRMln0qKwckQStNIZiUQFUjQ3EK9ukzmKUkhBYqIPeG5ahsbBgKEkCSsqWUsqmCTCvWp7us8JBtyrKSA49YVQuu4gNCryxjHcbGdMxg6mulLugdIrkhTM0l1S4+3jDGF0JCHEBotkUXBLLXIMCY11FMN4MgMI4RSKIRUptIRUMlJWKbqBaYQStwKOFhxzXQPAEG0QyxjgLv4mJDoZ9bLMga4trGwDKHCOJFoVzZ3K4To8W2yY4KbvWCB1CGh0mVKqKXqzBYDlpXD3us9+2dRVw3MeqW4TlZK8o1vQzVC28W+JGDB0BJtD++9XqhCSFfIZz2WI9e1MyGyLmNh8FrGJIV0F5qnRJpluPL+BGjrJqzcMNloLhzGQPskjlsTqHd01Dp6KFFT9nYYDGC5rUOReIyVyf3NFENRaDqLw34Iod4KIbaoj6zERh0T9cAP8C0M2lXyi/q0G94epVxzwjUjshSyg+591lkm3QM9LZgBUumsdwz8/cMn8dlHTkIzLXzjBU9+0bpC6IJDUzW61KAM5ayE3WOFFRJCNLclN+gnFNtLZH4qTgAiI4RSEvds0Z4pUctYtEJoua2hkpPB8xwG8jKWmnp3noYgpT4GtgbZOVrA668Yo51nROwYKaxMWbUCdCuEuEjLWN1TfEoDUeChh8ypLiG0giKM1kKbU5ycjtNUydPoyzLGFEKsy5jirNVCW0VT0icDzd34M0JI6m5Zv2uUqLjD1GAduskdzMvO/NhOGSrdiugCCPjnHm+odFAhxAgHRvBmAioMgXcDwmsdI7SblRdZWUA7yiIj5dYkVNq2bTQ1s+d1OlZSsH+q5gRKbx/Jg+c5t2C5cBRmZRumQdekSycS5QcBniJQnwqha+jn/9hxMg6y89JbIRS+ngGATYM5fPwHr8XP3EGKM7W2uxYdLVJFG4CJchYiz+H0Ygu6aeFX//U5mJaN+46Q67Yiu9cqABTQIYVNXgAGt5MX64cQygiQBM4hK6+YLOHAdK3LCq++BAohyVLJmtuyqEKIrk+VUmjRnKwtjS6FUDBGZDXR0qLn58QwNFIwCV7nmW6FkCzyyElCf2PtyxjrhNAq4ouPn8bfPngs9d8dmK7h354iDLVl2c5iQu2hEALiO2cwtPVudrWUJTdXvWO4leoIxcwirSJ6Q6XHKSHEQrcYkxq1cTs8SyryapqNnaPSER1CAyCEEMeR6luvSQRAd4jnwFbyNYL9BtyNfZRCaEykn1mXQohYxnyLbEYI+bqM0Qwh1tVhaCdQO+v+Xms652Oj6fl5HNhGI9B2HiBdxiwbaIQt/lLCtm0nQ4gFk3/paXKM07WO+96ZRSJFsPT7/+YR/MHXE7YHX2toTffcKWX//cFCv2Vy/kdpd6+WZpANmam6SpAg2ITLVGJDO12iIkWGkG5a0E2beKuHdgALR1BonsRxexy1toF6x0AppKLmUwcGUG1pqGRlJxOoVxB5cwXVQkYwx22a2AIpKZFsUesKlyWT/IQ1BREmoFRIdY+FykcSQixcM6Ja6t3Qs+cKEEKMxNo/VcN/PEPI3O8c9qj8HIXQOiF0oaDdowJ5/eYBPH2q2j+hbnoIoZaHEGJB575Q6ZSqEjYuDWwl/zfVyDGk3jFQpBvowZwMzbS6q7p8ekKIqWTEQPeeKyejw4bXGkGFkCTwkYpHtvAPGy/jIPKuqsQLjX4eTqZcP9CbaNsZbBokcxDbPK5MIaRThZDsKoTUkDWZQwjprmpKDyiEPJBFHpdNFMMJIZ0phGQPCZW2y5gZGfDss4zJ0QohVrx6x7WT+O+v3YHrt/jXSZLAOZ9xkuDmrBSzARaVNVEIdXQLpmX3LMC898aNODbfxENHFnB0toEdI2StUWRdcBeOQK9sx4zt+Qyi5rwAVjLnA8Crtg+hkpPw73RuZGv4ZAqh6Pf9jms3YKJM7pXlto7ZOrleR4tuJpbAc5isZHF6qY0vPXUW+6dqeOW2QbQsquCR3GsVALJ2213Hsnk+haWfIZcRUVLcTKq9k2V0dAtH5/zrkJciQ0iyiULI1uoAbFfBzrpvBcCK/10KIVkMJ5dXAatiGWtEdNJj7zewHySE7wVSnD5PWCeEVhH3HJjBFx4/nfrvPvXd4/ilLz6Lf3rsFN788QfxM599EkBvyxiQrO1pWHWFLXxqHd2tVEcQJGEZQhNUQTCTkBByLGMp1B9sss1nBKdLlmmRjmd7aJePE0lUQsEF9uA28jXOMqZHEUJUmspTS1CgWlZURBiW7d/AOoRQhGUM8G8qC2PknNDzMWmeiTxO/0EvEOuZUun6FfPDL69Cp7FF2rUCIIuspaaG+w/OopgR0dJMd8HKgrNTWGOOzjUdOe9LDt2j8smUiM3ItoH7fh848FUAQJsSQiOKZ6HL3m+vLmPOQmMXIYRsm5BJCRccvuDz4V3A2achqUs4ak+g1tYjJdZxAePVlo5KTnIWREvBwNEAGk7A5NpYxtgCKWnliZHIYq4CABjXSHi2PXEtsYo5Y10UIcQ26AkUQozEG9oVOGb33jcsG3fsGcHzZ5fd8FZHIbRuGbtQ0IqxjAGEEFpu68lVqUEwhVA2oBBqeAkhz6Y9Ddg8NrgNgA00FyItY03VcDaT7B7vChXuI1Rap6QIs7EzXLmhjKnlzsqsU31CDekyFm0Z0yHyXGxmYxhEngtdf7GsohW9b62Fpp3BpgH/PLKiUGlTI0UHUekKePZBkGCBh8Jpbphr0DIWwBUTpdDOSaqHEGrpJmzbdsZz1bASxQiQDWFE5zeP+t2bIRQsIrDPbayo4H/cdVlXjILAu2r7dszrOa8bt2GUcmtCCLnqnPhje8tVExjKy/i5zz+Fc8sd3EjzlkpZEc22Ciweg17ZgVm74v5RQoVQv2o6Blnk8darJvCtF6fRUA1XIdQOUSt60EhA0rFCd62jO2QsczMwbBrM4vRiC0+dWkIlJ+G337EXKsj9URDI+bxx6yCu3FBCDm1/4Q7oSyF0x+4RvP2aSef7azeRNWAwY+ylyBASLfI5qU16LEzBnimF7glZ5liYQmgtLGOmZUM1rJWHSnuLL15EBGgrcRlhFynWCaFVxHAhIqSxB9iC7Nf/7XkcnKnj2/tncWC61jNUGqBVr55dxqwuyxjzR9faRs8uY4tNDRmR9y2YR0uEdZ9a7kA3LczQNtZRGzfWfUw37cQdg5qOSkdEOUcIoWpLg20DN9DqTqJOY2whw0I7y5sAcPFt51VXneQF+wwG+UaoNYtN1HVv5kmYZUxUgFf9LHDFO8n3XkKovJGcE3p8Y1pSQmiRkEF89zXD2oKvRrA02xRtH8mj1jFwYLoOw7Lx5qvIQMuuBXi6XyVBRydk0gUh0zQNsnhmag6lRHKotAbpOPa9/wsAaIrkOhyQPJYxRjpEZQhJOXLu97yFfD+0kzxvY4ZsxBJmCLU99weGdjoh6cftCdTVOMuY6GQ/BVGlYZqVHBkflhIohHgOXeNLEuRkETlZiB0z2aI+KZHMqt12aQMgKti59CAAQB+72v/AKIVQY5psnsK6jAHknm9T69DCEQCcSzBTsOyGybKCqzeW8aE7d8G2ge8eoeHWokL+bo0yJtaRHr0yCq7fUgEAPHWyT9uY0SHnPTfozxDyKYT6DJVmi3amfD31PTcENQDvpoplAnapAPsIlWYKISmwkbl6YwUA8MypaqrnWw100nQZ6xgoKOGBtXGQhPBQ6dXKEGpYMoYKsm987S9Umv49K1aIGYeIaYQphDgOJi9D8SqEHMtYtvvxIEqMpZbWtb5jm6qBvAzTsqGbtq8bUZLW82GNURgEnnM+n4InQyhoPXcbIIRvLCWedxVCWu9OXiRUOipDaG0UQo2EFu2MKOAHX7EJSy0dP37zVnzglWQ8KGYkKK1zgKmhXdqGJrJoghImCTOEmiu0jAHAu67bgI5u4ZsvTDvn31tInV7udK1ViWUs/jW9hU+2DmV7FYaNFdJdcf9UDZePl7BnrIihEileZkBe89pNFXzl526FaLTcdewwLfz0oRB6742b8L+/b6/z/fbhAgoZEc+eqfoe52YInaetuVKGZHUgQ4fOCCHHMlYOLZo7CqGwUOk1IFCi8lxT48xj5OvIZf6fRwRoK5KQKvP2YsA6IbSKGC5ksNTSQxcIcVhsatg+nMe1myr40/ddA0Xi8fcPnUhECMkCF9k5g6Gtd2cIMX80UQjRRYLRJj7LkOMbzMu+xVJGFDCUlzFd62Cm1gFbA4TdQC3NwJmltjMRJ73JXFJGcHJPGHl23WYSWJmMEKKLshKtgOSHI9lv95jjLWMVux5qzWITlr/TWIhCiOOAN30E2HQT+d5bfciPknNCB6hhLaHqLKYFdjmhBSgJmPf72k0VNFTDkeZeRYMlnZaerLKS0DLGzm1fkvjVhh5Q+TBVz/JZkvNj0aqWUAEAFHiNSsg9FsyoLmPs3G+8gXw/TM/9wpFUGUK+idITbHzcnkC1paOhGqHBmMwyFlaNW2YKIWez2EshZPjCPtNiqCBjIWbTxBb1UdlkYccDAEouD2y7HZUWUQi1hwOEUFSodH2aLIxDSFUA5P5Sa2ScnD9MNt6if8HJyKvff/dV+NefuRnXbKygnJXw0GFKCHEcuTbWLWOrBsO08KY/+w7+/qHjff2tZlixGQXbhwsYzMv+LoqpXkQjY3t20O0GCbgWxYLHMpY2Q6gTIIQ6VWD3XaEPbaims5kcpJ10FoP3+AoIIbGLECpD5LmV5S/1iaBCiHQZCy9G1ROoD8Ig8FxogWs1MoQsrYm6JaOclRzlA0DGuDglRfiB0nmAEeFCxu34FTHf6nwGCqc5nb1chVAm9PEDeRmW3U3wsE0+u97amom2Zrqb9wSEUFMzkYs5P4y8yWVE8DwHWeBDFELkdaJIBYF3A8JbagKFkCREz0trpBBiZEySa/VDd+7C5/7rK/Fbb7/CmZ9LWRFDnVMAgE6ZFDLmQdexSTOEaPt3ZQWkxQ1bBjBSzOC7h+d9sQ/s/z/+6cfw3k8+7Csw97KMAX7nw2xNhSLxXWqqTYNZzDdU7J+u4/KJEjiOw/fdsBUAwAXJeLXRbRmLuP7TgOc5XL2xjGdP+0kIphDKCOcpVJqqZUa5KgyHEGKWsVK4ZWypDVngnWwzhtwaKYR8SviV4ODXgdErgIEt/p9HBGjHWkIvUqwTQquIYepV7ZJg98BSS8cVkyX8+3+/Be++fiPedd0G/MuTZ7DYVHtKB6UYGTRDVNt5gE7e3o1JCEmy1NJ8+UEM42UF08ttX9vSMIaYdQO7fIIwsUkJIaYQyssiKlmZhBZTGehEWUE5KyX7rNkgzya83FBkYFrwfQQHoSxdJBTtWij5wiYsHyEUphAKglUfsoOEhNBasNUaNFtAUZ+PVTM5aC2GqpYAOIqPXiHBvfDPT5zGH3/zIG7dNYwr6Plk5/eKSUYIMYUQy0pJRggx69AFQQhpAZUPqyIs+TecVa4CAMhxJHyzmUQhFARbaMwfTpUh5CMtqW3J5kWctkcwtdyBbSM0GLOUlWDQrB0vbNvGfENFJSs7f9fLntBUjb6l4wAwlM84XQPD4CqEkpHsvgWzZ1NcG9jrf2CUjbE+3S0p9oKRwO0lQuCx+9YDphDKySIkgYfAc9g+kseZqmeclXLrlrFVxH0H53Bguo5Hjy/2fnAAUfZgL3iew+suG8U9B2Z7dt4LhaMQGiKKSVZ4qc+QUEs55wmV7tMyNuBRqu1+EwDgy8+cxb0HZpwfN1RXNViJsoWuomVMkQTsnSzhyX6VVStAR/c35YizjLGW1mlBmnp0kzMsQ2glCiFLbaKFDCGE6EZ3rJSBZacL2QfgFhk8CiG3y1j4cxmcjAJvuGS/kyEUrhBikQKMYHz61BLe9GffwWy9A5HnHCKmrZtoaaYTO5CEEGprBnIxKlRGcrLuWxlP23UGZnWKIhVEgYNhWdBNC5pp9VQkxFvGsmsSKs3m4yTXakYUcMvOYV+xpqhIGKUFxmaBjBezLEcobt7zgKkM+y0CAaQhztahHM5W2741Rq2tQzMsHJ5t4NBMA//7P15wfldPsNbw7mtm6ypGi0rXcW6incY0w8LlE0QZ9It3XUHukWC8hFb3WMaYQii9ZSwM126qYP9UzbcfOu8KIbonGsUS9CadR1jIcpRlrNrGZEUBz/s/16wkrgmBwtap/WZWAQDaVaKcpfNiF0LIr6wkpGqCdDFgnRBaRQzTCXEu5SKAKXAYfvaOnXj7NZN481UTeMd1G2L/tleGkEVlmF1t57Muk+7rdhNCkgSPj2G8pGC6puLcMpn4MiIfOiAwieHOUTKwJt3cOQqIjIAyrZAxRdBgXvYFTcfCCBBC2UEy2MVZxjQDAq00ecGCDfNmLZTgcRVCAcuYXHQX/GEoTpKFVm6IbBbbi+BMDfttymaztuRxaC9Gkk6VFNW4KFiWjd//2n7ctGUQf/OjNzrX0PH5BgSew55xMrlOO4RQugyhedptqq+MhNUGuycYqcVktIt+QmiRI5OnwmlulwVGJkVlCAVR2kg2i/OHyPcJJcltZyMrOgohbmArREl27rmoLmNAd1ePJ04uYaGp4catA1T14y6io0Ck9SshhOQeodIpM4S8kno6+S/aBSzLYwA4oEytNJGh0j0IIUYCtxZIqHQgUBpwCW+vunO4kMF83fM+Kem7jtXBFx4nVe8TC+k/06iOkkG8ae846h0DjxxbiH1cKJwuYx5CESAKIXa99Rsq7VjG6FxR2eLI4v/y/qP49EMnnIc2VdNZWA8yQmg1FUIhyrrrNg/guTPLPQtXqw3V6FYIBTtPMTQSqA/CIPI8jJBQafZeqy091fvu6CZ+7vNPk3WORkKlKznJmWu3DJH5iM2Rn3nkJO47MNv7idmcwpSRouLMH1FBsBonIy94ftdLIRTIpPr8Y6dwYLqOZ05XkZUER6Xe1Ay0dRPjKQihpmoiF7MhZGoepvLLiN2buXqP4HCR53yFkl6EkBLXZnuNQqWbK8zvKSkSNlrnYGdK6MhkLJqxKQGQkhBaKSYrWZxbbqPW0Z39Ra1j4MRCE6ZlY/twHl944jRm6x2ohgnNsHqGvrNC1nKbKNe9gdIMGz2ZXKxIDYBc196x19T9CqHcIIlk6MMyFoZrNlVgWLav/fx5zxCiNsFRrgqLzUlBy1jANXKWtZw3dd/vsjK/JqHS7Dmz0gquuSPfJur7KEIo0y0QUNZDpdexEjCFUBqZsGFaWG7rPgXOpsEcPvYD1+Ivfvh6XL+525bkRa8MIbYA6g6VppaxtuHfsIcQQkstPZwQogqhc1WyUNg2nA+9gc7SkGDW6SBSITR/BPijXc6mu+VVCNHPhxFCQ3nZCZruCbaQqWwiX/Mjkf5YhqZKQkaD1QW2SMga1eQKoUyR2NTiwPNEbZAfJiQEHZyfs2iry4UEhFAr2jJWWgXL2NG5BpZaOr7/xo1QJMG5ho7PNzGYl1HIiCgqott63rGMJcsQWnQUQiu3ta0Y7J5gKh8W1L10gnwd3AEIGSyZ5PcZW0NOol0W9MDf9gLPk5amcwfo98kqIWxxmJUFcs2UNwHDu1FSJEe1FxoqrYSTg//yxBnkZAFvuWoCPM+hIIs985y8FpR+UM5FdzwDPAqhhBNzw6sQKm9AY2Avpu0htAyOLHgnryUPjAyVnuqhEKL31+yL5DyHEEJszPWS8F35clJ+ve38KmF6uYN7D8xCFnicXGimttMk3QC+ZtcwcrKAb7wwnf4gWZcxdv2wYOnGjNvdR1iBQihTIvMaOGDPm502y23ddMYJgGbl0OyPUlYCx4UphOT0CiG6BhGFbtXADVsG0NZNHJhKNg/ce2AGn+7D+ueF/Y3fwIfxiYBCiIsJle7TMiYQEiEIZuP/pPQxqN/83cTPd3y+if989hw+872TgN7yKITIsW0dInMKW1/8+T2H8Ztf3te7+x1TnTIi3JMhFNplDIAKGTnecx30yBByFEJNDYZp4VsvEmXa0dkmMpLgrEFZDiRTCCVZk/RqO+0U6ug5VCS+q6MtK9JFKQ1EgYdh2s4GtNe8lo3LGFkry1jCY4tCURGxlZuGObDDKSSfsYZg8yKJKkgAlre1UkyUs5he7qDa0p08mlpHx1GaN/qeGzYCAE4ttHrmPzGIAo+8LBDLWF3FWCBQGoDTtU/kOewaK3j+OONe48ceAD48BrTmXQsVxwHDu5Ov63rg2k0VAMAznmBp1TAhCVyX+mbNQIvkY9wSzDYlptj7zQ6QNcqHR4Hn/wWYPQD8wTaUlg/iDfYjwO+OAB8eAZ79JwCsy9gFqhA6eh+ZezfeGP57pdylhlJEfj1DaB39g3kq4zIxgqjSzVAY4ZIEshC9yAE81qeAQigvi+A5uinUW26gpeemaGsm9k/VsNBQQ49voqxgqaXjwHQdg3kZg3k5tJJ/brmDjMhjQ4UMztGE0CGgOQuceRwA8bZz1KtcppanY7RN40BeRjknO59fLBiLvfvNwHv+Dtj0CsKCqzGWsYg2h1lZRAkNZPQaqcQG4BJCnuO6438C7/7r3sf5fX8O3PX7vgnntD1C/pOEVGkthuYaAWRzqkj8ihRCj58gJNVNrGOFws5J07n2x0oKppeDodIJLWNUIdTRrdQ5XKsOPaDycSxjJ8jXt38c+MF/RNUg51u0Om6XBbYQTLNwKIwBNdKGNWmGUDu4kX3P3wFv+B2UshLOUEIotO181kMGUyw1NXz1+Sm89aoJV36viD0DTEl73v4napZnFAVHIZTYZupfMJ++/U/wP/WfJD///k8Bb/htUr0NCzrXOyR/JYlC6DQNKAwlhLoVQiMFGYstzb2u5Vyq7nvriMb3js3DsoF3X78BLc1MndviZnHFbzYUScAde0bw7f0zsY8LhaG6odKA26muveSO2Q4hlLbtfI2MT5ki8IOfA277VedX3q6PqmFCMy3nfhV4DpWsFJIh1EfbeYuFSndvZFh776Q5Qp+47yh+/2v7V9QR05p6DtfwR305J7IQ12XMQCFly3kAkDy5M16w17mSPw7++P2Jn49di994YRqc3kIbCs0Q8iuEWI7QUkvDmaU2Hjg8F//EjBBiqmgpG99lDIQQynIpFEJ514L46PFFpyFBWzehSLyzBmXWcLZZT7Im6dV2OudYxphCiKjB2prpnIt6h0QnBHOuGIhCyEpMELMQ3VACWsquCSHkECN9EkKlrIQRbhladtS5Z//OeDO09/0TICR7zpWqghk2VBTopo16x3AIoXrHcDoS376brH1PLbacwlQS0rZEC8Xnqm1HhebFSCGDjMhjx0jBRxhDVNyxd/EoaSJy668Ar/gp9zFv+xjJf1wFjJUUbB7M4XueXDrNsM6fOggAckOwOBGj3BLsTpX8jK11r/sR4A2/Q0ij574I7PtXoL2IWzsP4FWNbwOFUYATHGV7VhKgGlbipkFJkfR+jEVzjihoo4qtIREi623n17EisDbKaXzjLLR1oE9CSIpZ5AAeuV3gZuJ5DoN5WrXWWu4myGOj+n/fO4E3f/xB1DpGaIYQm9Dv3jeFW3YO064LYQqhNjZUspHtQB2wTTht59zUTOQkotIZoYTDs2eWUVJINkclK2G5R+gtAHchI+eAq76fMP1KOd4ypoeHCuYzArZztEIcshkMDZUe2kFIqF6YvBYYv9JnNZpnct5eC3S9TTzrEQohAKhk5Z4hwXF44sQihgsZp0rpvFfVwDC99sdLCmbqgQyhhKHS3iyZqKrleYOjEApYxliG0NheYNfrsaTR+0pvI5+hhJBjGYsIlQ5DboioBYD+MoQAYPMrgeFdKCmiMwbFWsboQvx3v/Iirv/wt9BQDbzvpk3O4woZsWeeU6MTX7nthXJWQl01IhcRrkIoGUHIOuawapIwcSWetXeipZrAlpuJEksuhJMxrAV4IY4QohldZ6IJIXasXoXQSDED2/YE+Eq5dYXQKoERm4yoPrmQjmhLs+DcNVrETE1Nv+g1On6FEOs01qm5Fdl+Q6VVz3Nc9lYg7+bIdTTTGUvZV++maiAvd3cSFGSSZZYCjOgMs4xNlhUMF2Tsn+qdg6cZFp47uwzdtPGt/TP44uOn8WAvsiMEtq6ixLV8Gz5J4CPzn/rNEBIjuoyxDKEsVEjVY4mfj52jqWoTgqWhjQw2VHIOsb+VEUIdA7WO4ag8PvfIqfgndixjjBDKOQWFqDG+Y0vIcp5rsVeGELOMtTTcvW8aWUnAAC3kKZLg3F/MUpaUEGqqBlTDilWHdCuEiHrnXZ94CB/5GlHe1iO6bjKIAk8sY6rHih2DrCw4XdO6IGUJuWCt7jrGZ4nuA0VFxABXhypVHGfBHAbQ3nx74ufo914JYqLsXkcbB6hCqK3jyFwDGypZ7BwtgOOA04ttj0KoN2lbzko4OFNDR7ccV4IXHMfhmo0VvHpHIG9TkF3LGFNIvvq/k66/DONXAhPXpHiX8bh99wgePrrgFJGIzfU8BUoDAM/DyI5gjKuSuUjIkJBlgChXb/l54Ip3AMfuB178MgDgtfaj2FF/HLj87WSNS4lPdn+vNonCQu9XZBnTW5HjFoDQCJFYBeBFinVCaBVRzIiQRT5VhXKxSRVCIYRLEsR1zgBcNU5YW+iJsoKp5Q6xPrB8HQ9LemapDUngIAluPoz/78kNpps23nntZKTn8gz1nLINUlDK64Bt0uYPA6Bh2HTi2TtZwhUTJSw2NQxRcqiSkxIqhNhCxlMtCPGMetHWjNDPLCsJ2MbRzjAhgbJsooxq650IkkskzIMu9Nl7iAKrOEeESgNkolyJZezxk4u4aeuAr2MFA1MIjZYymGEKIV4gG1+tgT/6xgF89OsHYp9/wXPf1F9q21hQIcQ2XEsnAXDO9w3VRAcyoLeRlahkNq1lDCBEHvNwJ/SoszDcINnrXTSFLYC9ljHLsvGvT53BTVsH8c8//WpnU83+tichtMI8AVb5jlIiOV3GkiqEAl1Y2CKl6a2Cy/lwkrJOCbm4bitsQz/9PFlglLoz3sIUQuz+cHKELvEuY1PL7VWrJLJrdO8GGnKfMkcoDSHE7qdeVsouGCpZbDPCnlnG1JpbkWXKi34sY4yw9sC2bbR0VyEUtpkcyMnhljHLAEKycaKgO13GuhVCHMdh02AOp5d6n5f9UzWHtPnE/Ufwa//2nC8DKSlso4MiWj6FEGnAEX7NecO204DlzgTBinRZaJC0KtBMljvFzlEOZA69fscGjJcVDBVkSAKHzYPMMqY7522yrODeAzM+a2AXHIUQXfPIeWdMjbJ5tG0JChewjHFCpJIkKxMV8lJTwxMnl/CKbYPYNkzWMllJcNZ/rPBTyIgoZsSehBBTll21sRL5GHZNs0JARuTR0kwcnm3g7n1TsG2bdqmKnltFqvZyLGMJMoSAiA0ws9X1WrelRIOq5vtVSxQzAgbQQEss+ZRtUdlaYWiuYoYQw4YBVyF0dK6B7SN5KJKA8ZKCU4stT4e4BAohRcJ+ak/dPhJelPvHn3olfvNtV/h/KCru+WLE0CrlBUXh9t0jaGkmHjm2iK89P4V6Rz+/CiEARn4Mo1iixYnueQR73kTIzfmDMMubsYOfgmR1iONCyjprZXZNrnaO0KpYxvR2pNUVQLhlbL3L2DpWAqZkCVMInV5s4bkz1a6fs2rJQL6/gUcS4zOE2hpdmISQGyQDqONXCHluisWmhs2DOez/nTfhrr1joX8PAAM5CbftHolsw9mlEDIibrKgQkg1nUmZ4zj8wusJAcPsaxUaKt3TP88qrl6ps1IiNqyIvAmWIRTEzTuH8ZbJBmxOCLWMCTyHQqa31SYWyyQifAAA3WZJREFUYQqhXkGjbIMR08msqIj+jXEKTC93cHqxjRt9hIF7zXoVQrN1FZZlQzctWFIe0Bq4Z/9sz5bN3o5xL3mnMcf2RRcUokKsXKYKZCuO9LShGlA5EiCZk1nb+ZSh0oD/vCXMEGpHWF28rebDFsDeUOkD03VUWzp+4MZNPjIIAAqK1LvL2Arl465aKcK2kDJDqKmSlrhsvGPqJV9r5Uyx28Y4fwQ4+FXy/zjLmJwj14JlEOVfiCKCKYS8gbZuvhy9jy/hLmNnq23c9of34ev7plbl+eodA7LAY/twATwHnEqpEGqnCK0sRQSy9wQLlXYUQouE+NFbHoWQ5D42CSwLOPxtYPmMSyp5oJs2TMt27EVhORwDObm7Uyfb8KdQCTECRIrYzGwayOH0Ym8LDdv8v/XqCRyba8K2o8niONh6B3lOhcK787tM8xaDFh/dtNDRrT4VQtGEUEbkoIB+tnRNE4mpZ4EX/wPiHOmqdMUwOZZbriAh+D/26q34x596ldMttK4aDrFy/ZYBWHYPZTq7thghJOXcLmMRc23LlpCB59owOvGbKpDC5kJTw8mFJrYN550AX0XinfUUK/zkZAGlbLxlGCBWdZ4Drt9ciXxMXhZ8474iCZiudWBaNs4td3BkttGzbbnAczA9odK9QuazjuI9ZG5iaoQ425ipk8JCCjRUAwW5/w5fZdFAhtPR4Es+Z4GaopvS6oVKuwXa0aICSeBQbWs4Ott0GtCQcaPlNLdIZhkTnWJDFCEk0u6f/h9m3HgJtmcQwu2Rq4VX7xiCLPD4pS88g5/93FP48rPnzl+HMQorP4ZRrgpeq4XOI9h8s/PzmVt+GwBgCDlg62toeDoh0VgH5rZmYq7ef3fFIKIKn6nQa+wKyZRV1ruMrWOlGC6Ed835w28cxPv/5tEuxpF1+FjzDKGQm2myrJAOYXo71DK20FQxlM9AFPjQCWiirIDngLddPQlJ4EMtYx3dxHxDxWQl61TrIm8yphBaOArYZGLOeja7b7hiDDduGXDUSuWcTBeMPcgDxvp7B/dMiXiEI3I8WrrpqJO82FDJ4g2jdXADWyO7hpWz0oryD7wKoSW7CJvjEyiEaAUyxjLmZNz0gQPT5Lq4emPZ+Zl3ccVUW+NlBYZl40tPn8V7P/k9nG2JgNrAdK3Tk+RZaKhOBkXqCvxqg10XjNThOLd64lFhNToGDE52LGNNzXTznliGUhJ4z1vCDCFn4RrsIOg5L2EL4KLTiUN3Oia9KiifBlE8JsoQWkHAZMlzLGFImyHUUAlBxcYr1pnG11pZLvgzuWwb+Oy7gIc+TtQRXol4GNimnnZ2izpmr13FUQixTdsl3GXs4SPz0E3bCT5fKRqqjoJC1LkbBrJ9K4SSVCCZui4VIWTbNFRaoYRilhD4bK7t1zJ2/H7gc+8hNtaQa5atNUzLhmpYoYG0g/kQ1Wgf1jXWaUuMCEPdNJjFuWpvVdjTp6oYLyn42Tt2ICPyGC8p/XWdpPNlAe78LlPFXlAlFFQVpoHIh1v2ddPCiALwHH2tOELIsoBPvRn44o/gjoc+gAw0/N/37iHPr5A5ZCAv46atgz6FGiPydo2S9dBCkNjzgg8QQnLO02UsQiFkSZARUAhF5AcxDORlHJltoKWZ2DKUcwJ8FUlwyNRztANmVhYSdYp9/PgiLp8oxap7XrV9CG++csIZ9xVJ8I0vDxyaQ12NVwjlZAFNzUgc3JyVyfUU+vlJCQihF78M/NVtrjI1ARqdlRVgKiDzXp0v+gmhqCJt2DGoq5MhVM5KDklYyoooKhIOTdfR1k2XEKLKwl4d4rxg11kxIzpRE4ngDZVmKs01VgjlMyJu2jaAhaYGWeRh2+exwxiFXRzHGLeETPNcePMbUSZW5JHLcW7kdrxgbcHixjuJtcxjfWfn8j+fPYebP3oPppZXZ35nxbxeFs5Y6K14QihTIo/xqHOzkgDNvADyTM8j1gmhVcZQIYP5EHb0zBJhub/2vL8q6iiEVmIZ6yNDCADGy1nUOzpsvUk2SXLRx5JGtZtnyGdEfOYnX4lfuWuP8xrBjRub/DdUslDEmIoK4CqE9CZQn6KdJdzj5jgOX/hvr8bvvfNKAG4r9Wq7x8KVVVy9ixlm54kgWtqagVyUl3fhSGh2CMOGgWwieXwkPANXDTlYQqZ31bjVWyGUXYEEkhGXw54JlpGA3p+/9aoJXDFRwi//87N45nQVy1YGamsZ1ZbuePOjMN/QnIpir3bnaw52LXptX073BfczrqsGdEEBDGIZa2smyaLJDpLOHUnhUwgl+7u2RsI6g5UutuiVRd6XY8PgdOJoG/jesQVsHsw5oY5e9MoQUg0TummvqFpYDlFcmJaND/zto3j4yHzqLmNBObss8BB5zi9jzhT8CqGZfUD1FPC63wR+/lmiAIsDI++Gui2jAJHfSwLnOy9MQedUznp0GbNtG5955GR6JcrLAI8cI2PVSgLuvWh4Mi22DOb7zhBKUoEshXWR7AVn/qFzaW4QaC2RAHPArcqmJWJmqQX3v9wNvOmjXb/2zsUN1QgNZh3IkbBzn2qmj25njGSJUwgZlt1zk/DUqSVcv6WCvZNlvPDbd+GWncM9FSShoJ9h3nbvMVZsCK6XknYwCoNIVSVBaIaNgrdl+8Lh6CdpL5I1z/bXQjLbuIXfhxLr7hWwHbONeEM1sEibMLBOSV3WPy+6QqXzzlogyuLRMEVk7ECGUFwOB0hhk2VFbRnKeRRCAobyMhSJx6FZQkrkZLEnIaSbFp4+vdSlXg3izVdN4C/ef73zfcajnBd5jhBCPTKEKlSt5Nj2EiqEQtdUSQih1iJgW6SzZUIQRe4KmjjY5Nwso+QjRpNaxmzbRlONV1olBcdxTqe5kkI66T12nMwNl42TMXHzYA7TtY7TqCepZQwg6qBUSipv23lTJSRqn0qsNPjF1+/Gz9+5C//zzZcBwHlXCPHFcQxwDQwsPQdsvyP8QW/7M+Anv4mltoH3af8Ls6/9E/JzSXGucTZ/PnO6Ct20E2XGJUFU4TMV9I4/MiQItrb3FAoZ4dtJYad8uWOdEFplDBdkp1uSF1O0NfsXHj/t+/lSU0NOFkI3bklACKH+MoQmKwoy0MHZFqlcBnyUCw0Ng4V4ouqWncPOpi5LJXZeC9dZRgh5MoQiq/3eivn8YRIqHdhsCjznDPJMPu1dUDx9agnX/c43/fJpZ0HuGRCcCTt8UxbZ1cKyiIIphhDaOpRLXaX2gapSbPBoQoGdhBBilrEYhVAuIuMpCaKyrliOENvwDhUy+LefvRm/8sbd+MnXbEMTChq1KoBoabr7GpqTkZBEIbTY1Bzl0qojLBiabdw8n3FD1WHwrmWspRmw69MwC+N41UfuwTeTtqj2nreEVammZoRWTdg5KcUsnspZCdW2hseOL+LV28NzpwpKfNt5FoDaK2shDqya572Hqy0N3z0yjydOLnkyhJJNyk3V9FUvOY4jlV81oBDyKgMP3U2+XvcBoDTZ+0VYV6iIMaCjmw75zVDIiMiIfEAh1Iy0rB6ZbeA3/30f7t7XR4vzCxyPHieqtFUjhDwk4JahHE4uplUIJa9AlgKB7IlgBuaf7CBRdLK5likPOY7aUhMSQguHAaUCbH5VqFrVu9FvdIxQ28VAXoZmWP55gY0/aRRCMRlCAKn0A4i1jdU7Os4stXHlhjJ9Lh6lrNiXQoij82XOdu9zRlYFCSFGevdFCNFW5UHopoWi4LlG4hRCjBC49v3Q+BxeLzyNjE0/p4DtmBVh6h3dmZOZmiJWIcRsgPSaM8WsQwKENXAwLRstS4ToJYSSKIRysrMe3TyYd8KCFdocZONADifmyTnJJVAI7Tu7jI5u9SSEgvCup1932SgePbaIuZoa252rkpNh2SC5mkDPZgmORSY2QyjOMkbHBbZ2S4Cmaq6oAJMzSMF30c77lA9JFUJt3YRl9x9qHQTLESoqRCHU1ExsH8k79sDNQ1nYNnBwmmzUk6iR2X5ke0igdCy8XcZMvee1vlq4cesgfvENu/H2ayYh8Nx5VwhJFbLm4WEBu++KeJACKCVUWxqayKJcopmyUs4pqrMC+rE5cn8fnV0dSzzrUthl8UsDvRWf6cnmYFakQQ9L6EWKdUJolTFcyGChoflIEcO0MFvvoJKT8NiJRRyfd2+UxZbWtzoIiO+cAUS3nQdI3ksWnoq1p/WeZZGWpkMprGyMIWYLjb+47wg++8hJAEQh5N5gUV3GmiS0EMBzzz2JlmrEbjbZwO+VvO87u4yllu4MSgAiFELxFRxiVwt57fo5MskPRxNCW4bymKurPQmQSFDLmC4VAHD+sLsotGggcZxCaAWWsaWmBoHnuhbNTI3iVQ4pkoD/73W78H3XTKJpK9BaZBHa1IzwFq0gm5e2bjodzJJkCP2few7jB//6kcjnXBH0JtmceckZNml4PuNGx4AlEEIoKwuwbMCuTaMmDmGmpuLIXLIOa37LWDKCpaWZofc1q5DFyatLWQkPH1nAclvHzTvDCSGSOWVG2jxW2vEE6O54BrgV+4ZqpFYIhcnZ8xnRXwWXC/5Q6YN3A5PXx2cHecEsgxGEEOkU4p9aOY7DcCHj2omlHLGsRmy65yhxtJKugBcizlbbOEOtHKtFCNU7rm1xuJBBtaWnCqxOU4F0LWP9KIToGJkbCLeMAUSdk1SZw5SqEVXsoELIsUb5MoTI+/EG+q/EMhanEAIQq5xlY753PVRU4rsQRoGjG7us2W0ZC66X6o5yqo+28wIHPSR8Wzct5HnP57dwNPpJmGVoYAuOlF6BO/mnwQW7XHpQoGH/i00VisQ76s6uLCgvApaxDsi1yIpEwc+3pRnoQIZkeQtrCTKE6HqR44hN0FEI0c9+00AW7KWyUjJCCACui8kPCoM30P9Dd+6CblnUMhZHCHVb2uIQu2FMohBi40IrOSFEVMH9F2CEDlknzlvFvjKE0rR/T4JJ2pimlJWcQtaPvXqrU/Rl48YL52pQJD5yfPGCkfbbh1N0eQX8XcYMdc3tYkEMFzJ493UbHEL8fIERQg1pCJi4LvaxbK/F7hV/qDQ5f6doQeZo0rVvDzTV8MJnKiQJlQZ8kSlKnALwIsU6IbTKGCpkYFi2b5Kba6iwbGKnAYBDM64sbamHLasXZDE+QyhODj9RziIHT8Xa03mr2tZh2emyjbIeBZBp2fijbxzEN16YAc+RbJmMkyEUrRCyypvQsjOYOvo8Ven0nsC9ncaYJcMXamZ0iGTau9HuSQgZ4Qoh2gEtXiFEJqKT/aqEaFVQEykLL8i9F+ftRWL5i8g1AuBamvoAIS4l8AGWvuTZiAWxYSCLJhRYdPNt2dFkINuQbKafXRIy7cxSG9WWnqqrX2Jore5QaDZpUPLGtklgqyVmSYYQvV7sxjSmrAoA9LTJOfBZxpItRNoRKjbHQx+z+C0pEqZrHcgCj9deNhr6GLboiwoib6wgeyN4rN7xkj1vQzX6yhAqBCT1JBvC8/dey1hjFjj7JLDnzckP2rGMhWcIdXTTlx/EMFz0NBxgyrOIDDN2P6wWaXKh4FGaWZWku1BSNFTDGYecjJUUZHyU9TIMRccyluLYgxl2uSGyCWT2bG+Qpyj3VoMyLBwN7XTJ4B3rmx7LmJcwZeqSR497NqUrsYyFhKwDwESF5A2eiVFvhXV7K/VxPgGAt8j9k7XcTQnbTAabcDRoR8t+stBEnuR+BAkVQgiR553ix8m5impBzhRChTHsy78aY9wicOoR8rOQxgQk242ESg/lM8jJAjIiH08Isc2t1gBEBW16KGzeDtrGmqoJFRLEICGUQCEEABMlBRlRcIKD2fqTKcUAqhDKxRNCS3QDGra+iAPbzBUzIq7cUMZbriRr77gMIXbs56odCDznI5XCEGsZc0KlY9aAbE3HuosmQFuPUK4nfgLyWrNGri/L2ErUdGHYNpJHRuRRUiRUcjIKGRHvucHNQ2OK8YMzdQzlk10DbMzYMdqHQsjJENLWPFA6DH/03mvwO++48ry+JkcLYQdLN4c2yfCi2tYg0sY5AAKh0uS6ZCH7q0UIqYbVn11s4Sjw+N8RV4ep9s4QAnyRKcq6QmgdKwWzzngtS+eoXWzvJNlQeifuxZaOgRUQQr0yhNoxhNBYOYMs5+l647GMMX96P4RQSzOciv9rdg7jF1+/G5LAIyPy4LiYtvN6Cx1OwQF7E7a09kWTMhTlLDm2ZU8VnVXW5+oeRY2pdftHYwghy7LR0a1wMoot3mKCZ7dQlUvaLAv32CghJJBNIyclUQgtkspzDFg1sB9FTTVCycYWWGHXyVBeRpvLQTTczyFqYc/k7m5b3d4bAHaOT/T7OcdBb3ZXZzN+Qkg1LOimTTqpqXXkZBEcLPCNGRzrEDIvsSLLpxBKttiKsjUWnc1xvEIIAG7fMxKpJCr2yEtZDYVQXhYg8JwvK4e9XlM1nIVqJ+F121SNLql/PiP6u4zJlBCybUIGwQa23Zb8oHfcCex9V6Q9M0whBAAjhYwnQ4hujCI2DAuOQujiIoS+e2QelZyEazdXVlchlPETQmkIm16FBy/Y80d1xQsF61zD5qDcMNCc67aMAcnIf4AQibWzkaQkEJIhxO5Xz3u9fvMAtg7l8M9PeKzsfVnGaF5LhGVMEnhMlLM4HRMkzshz77lwFFlprhXLBE87pGW8CiHHMuYfR+orUD2w92sEVEKaaTuE0DF+M9mQNCLCgxvUFlocx7PyteT/xx8gX0MUQkVHIUSKiRzHYSgv+1VeQXiLDFLOWRey9WpwnmpqBjq2DN42AJNe64kyhMjrbKZroIwo4EdfvQV37BkBAMdCBrgZQqphRW666h0disQ76q6kYGTOSIls6v+/1+0EzwFjpehNPiswnq0S+3ev/BmWMRJrGdNj1m19KIRaETbx5E9AXmtGz/UVKh02hqwEP/bqrfjKz70Gssjjl9+wG//wEzf57sORYgZvvWoCP3DjJvztj92Y6Dl3jBYgCzyuSqu0ERVPlzHdJcYvdgztxFPcXjxUemvPhy61dFRykntvhIRKMxydW511uUYzGVPjmX8EvvpLgMo6K8YRQpQ89GRLZntFnFyEWJ27eh0OGIvtJX2mlxkhVOr63VJTw7ahFO2pA1hJhlBGFDCZMwETpGKtlID5QwDcCnVSVh4AFNllVNkxveeGDXjXdYQ84ThSdYkM6dKaqJky7jWvwq/w/4yssYBcZlPk64VZxubq5Lh9qhGj0z24s4VNiMebDQChZBSzmoS1Z6Rgi6G+c4SoeqAjkEGKE5UEodILsXYxgJCCpmVDM61QBUMcFpvhhFApK6GclUIXbBzHgVeKyKvuoohUIruvqarTbU/qGWbMMFMjn8mJ+WbqjIGeCFUI+S1j7BhNpQLUDiIrCxhCHZxtYl+NbP6iAju7IBfIot3S3byHHmhH2BrZJipWIUTl2W+7eiLyMcxCEZUj1FgFQojjOJQUMVwh1DGc8cuykei6DWuJG6oQsi2ykGHZHsO7kx/05W8j/yKg6uHHOVKU8czpKvnGUQhFEEJ0jqheRAohy7LxwME53L57BLbtSstXioan0x0jQdMoSpqakbgC6QSy96MQYuqK4jjJKmjMku99lrFMMmUOsyDFKFW9m3xGCOUoAcvAcRy+/4aN+ONvHsKphRaZu/qwjOlWfIYQQMiA0zHn3Onu5FUIZVcQ4g0gY7hq7CjL2IoyhOhnaZg2vMOObljIc+Q8nrLHcAsA1KfDM8rq0ySXTMzgnDmANhRkp/eR34VsYgoKUQgZpuUUYgYLslPECwXPA+AA2ICcd8ZV1h10ua1DFninONlUDaigJJLRAYQCWSspldjPg/39lkGXyPIqHpgFCCCt6L2ZXGFWqFrbSNRZKogMfa7RInl/l0+U8K1fut33+kFU6PrmbLXtWCnjEGsp6UH4A3DvL9YhNgFWahlDexFNLoeqajtKDiC5QugAzfKZDGlC0Q+ysoBdY6R4Fpb5w3GcLyw8Ca7fPIB9v31XahKRqDOZQkiNVdtfVJBz+NXiR7Bb7K2oqrY05z4B4AuV9u6XKjkJi00NS01tRYIHgKgtU59LwA2Ibs6Tr3FktnO/uvvBrLOfXQ+VXkefCAs6Zp01tg7lkZeFLkJopQqhoATai7ZuQuS5SO/tRjZvM4UQlcyxY+zLMqZZzga/kvX/vSIJsV3GFjQR91hkAniN/WRsJUIWyeK8GrDnASGWsRQKoaYTMhoy8WqspXi0P7mkSBjKyzi1uDKFUNshhBKGSscESgMez7uWfoBbauoYyHcvkt557SQ+eNv2yL+TsgUUuA44kNeM2qixa0KRBEII9dgAWJbtqPDWRiEUEkIXsIyxtrZCfhhoLSIn8RjliCT7uErIo8QKIY5zs2mSKoT08Gph2QmVjl7UjpcU5GUBr798LPIxrv0mfIO6WvLxclbyKS7Y6zU8CiGg98Tc0U0st/TuDCE5JEMIICqL+cPkc+9x76SBahALUhDDhQwWmyqxlzgLkPBrlxHayxeRQui5s8tYaGp43WWjidpNJwXpMkaudUYGJgmlZ4iyXkahqEgpLWOBDCGWVcXsx97igiC5waZxYF2rYggh7zzbVM2uDnwM775+IzgO+D/3HiYqvD4sY0whFGUZA9wW0lFwwr09x8gIvlSft+fzk4xuy1hQUc3WCpUEJEAQIn3OYLC0YVnI8eR5j5lEHYN6REB8fRooEmK+qVuYFje440KIZWwwn8G5ahsLnriBwXwm3jIGuMovyW05zxRCf/btQ7jjj+9HSzPw0JF5fPKBo+iAXgfeXJVeGUJ0s7g5osjJLGNZGjJdDrEMe1FX4zuDRYGNv6NFd923Y6QQu7FkJJBmWIkUMLEKAom+bpyym32uKUKlV2wZay2iyZfQ1k0fMZo0Q+ie/TOYKCu4fKLY/zGcB/RFIHgLr6Z26SiEQIp6jQTxBtWW7nR3BkBDpbszt27ZQdrXH5tfuW2MKIT6OJ/eWAAgfuwK2Q/2bIJ0EWKdEFplOKoVHyHUQVYSUMqKGMjLTnvQZ05XUVcNbBmMrlr0giyQDKHosN7w4FmG8RydCOQ8WZiqNcC2nQr1cI8uY154J0im2ikHFlmKGE0I2VoTMx0ep+XtOGsP4U7+6Z6TXyUn+xRC8yxDyNdlTOv2vscQQq7NLmRRoNHg67gWhiC2sRPzK1MItTjiryaWsQRt5xmhEAE2YLf09GHXi63wrKs7Lx/Df39t9KZEzhESpSyQ6ymKIGEbf0USnNDMXsfDKlwr6ugWBa3ZTQhl/Aqh585UAQCDI+OAqaLA6w4hNGdXkJWE5AohwCUlEmYIRVnGkiiEfuaOHfjKh26NVfcUzoNlDCAqM59CiFnGNKIQYpvYSKspxcfvOYy6auCNe/0kVy4j+rOcGCGk1nt2DOwHRCEUYhkrZmDZ1A7GNnpRCiFmGWtfPKHS9x2YBc8Bt+0aoSSg7mu+0A9Uw4RmWs613uuaDUMrpJtlHEpZMZ1lzIwihA5SZaDnHk5qGWMKocFoy5hfIaSjHkEITVay+G+37cC/PHkGv/OVFz2WsTSEUG+F0FUbypipqXjyZHhmCjten0JoJSHeACTdDQlltoNgAe3sUhujxUxq1SzgUQiFWMZyHDmPh3Wa0daII4TINdFUDczKHlV0iGXsldsGMbXcwdlq25mTh/JyfJcxwJ1X5JzzWTMF+IOH57Hc1nHfgTn8+r89R7Ifg52y9HbPDKENA1lwHHDFRLiCmlnG2LzVixCqtQ1HRZQG7FyOFJMr3IuK5OSz5xK0ds/FdhnrVhx0gY0LqSxjKyWEFtAUSujolu+aTWIZ6+gmHjw8jzsvH03Xzv3lAjHjnhNDO++h0i8lChkhUW4nsYx5FUJZ5xqXBTeH75adhBBajU5jmrlCQqg55x5rFBzHiEvgMlJ5PVR6HX2DESBez/v0cgcTFcX1etOJ+0++eRADOQnff2O0LaoXJCE81JCho0d0y6IYV+jFLuWIJcYyAL3tWMbSqJfY67R109nIVAKTuSLxkZV+vUMsY2/cO457zOtxK/88CkL8zUgqzeS1bNt2iCB/2/mQMMQYQihsYepAbRDLSY8JcetQvv8MIZ4QTktWlixoxEzvDKH2Yk/LGFtIpO00Zts2UbL10Q0vV6gAAP4g9zn8uviPiRVC9R6T00yNfB4Cz5E2tvd/FHjgD1MfXyT0uFBpQrw9c3oZwwUZ5UGy4C/aNYxxVQDAsjiMyyeK6T5rdv6SKoTU6FBpnou/d4uKhG09unCwFr1Rm2tWUSqsME+gnJX8GUIey5hqWM6mIa5Sc2C6hr964Cjed+NG3LprxPe7vCz4rzuvX3zhMDAUHczbDzpGuKyfdVQ5W227G72oDKHmxRcqff/BWVy3eQADeRnlrATLBhppCNMQBLvesEDRXuOHF23NdFrmJkFJkfq0jNEiQoESQnOH/HYxgNoWYjb2ehv45GuAB/8EKG0MVZAwtH2EEFUIRZDEv/amPXjP9Rvx6YdOQLPpZ5HKMkbm9MwLXwT+9b+GPua9N27EYF7Gx+85HPp7J0PIpxBaQYg3AFHvbRk7t9zGBk+2DVqLwN/cGd8ZjD2/kyEUCJU2LGSZZcwahg2OED9P/j3w5f9OHvTN3wTu/wPyc3pNtDQTi9nN5Pe8GGpbuY2Ob7an6cdgXvYphHwKaQZmRZbyzlg6RAt+bIz/428exOnFNv74vVfjf7/7BvJ4r0KoR4bQlqE87v+VO5zMoCDKWQnFjOisFXsqhDp6X5YxVyGUnBASeFexlCSnh5H+4aHS9F6Ps4yx+zxOIfRvHwSe/QIAoopWDSudZcy2gc//EHDga85rtcQKVE+sA5DMMvbIsQW0NBN3xqiKX9YQMmTMs6yXLFT6pUJeFhMRQsstza+kFLP0MzPBcZwzj960dQCywK9KsLRm9GsZS0EIOftB935lAoeGamB6ueOoYC9mrBNCq4yCLILn/Lk2U8ttTJTJBDFAJ+4nTy7iwcPz+Jk7dqyoS48khgclMkTljDCURXKctpT1tN5bxmJTRUkRUzGz3q4LbnvC5JYxU22iZWfwlisncK91HXKcii31J2Jfs5KTnNeqdQxnsee3jKkhhFB0BSeuMxu0Bunm1QNbh/M4t9zpLeOOwtv/D74kvIl4tdlEFQXTIFa/hJaxtIx3XTVgWHZf3fCK5QoA4C79HvyY8E10WuEkGSMJFZEnoZk9NgCz9PzunSzhxHwT9qFvAEe+nfr4IqGFWMYuewvwht8FRi4DQBRCV2+sgKMEUcFcxihI9XtwfBMKiuTPrukFFgqeMEMoKmBSkQR86sdvwg+9YnPy1w5BoUeHH1chtIKKJegGO0QhtNTSYduulSPOMvbgoXlYNvA/7rqs63c5WfQTc0whVJ8mQa8xwbz9IEohxDadZ6ttj0IoqsvYxRUqbds29k/XcT1tH+1sBFf4/oKd7nrlXgXR0U3MN9WUljGxv0wbZkGg9iBo9e4sul4KobmDwPTzJAT9jb8b+7Js0y8LvNNlLMoKw3EcXrmNzB9LjE9J02XMoAqhg18B9v0b2VQFkJNFfPC27fjOoTlHXemFY9X2bHi9GTOJ4SHUBM1DCEVYxs4utf2ZKHMHgLNPAGce7/lSzCIXfE7dtJAFOY66nYWdGybjzYtfBl78T/Kgg18DHv1LMgZ5FELL2S30ycMJ+81DOWylliwvIdTSTHR0E0+cWMQrfv/beOJEgGjwKIQ6Tqi0uy6SBR7H55soZETctXfcXTOxNZLRWyEEEFIoSkHCcRw2DuaSK4Q68a3io8AUQqMxIdJhYEWvJOMBz3O0wNlnqLSTIRRDCL34ZeDovQB6ZFtGQW+R64w+B1qL6EhlmvPpzlNJCKF7D8wiJwt49fZ4JfrLFuzaNtVLK1QaSJzbudTS/flagcI62zNNVrKYqChkrbNC6KbljN2pkEYhFCIQYO/l8Gwdr/rIPfjyM+fSH8PLDOuE0CqDp1WG5YBlbLxELjhWyfneURIk98Ov3LKi14tqpcrQyzKWp13GWlDcxalaIy1NU7b6dEO4XEKoFJjMM5IQGSrN6S0YQhav2jGE71lXoGlnsHH2O7GvWaFtS23bdkigDZUs5huqa6Mz1W6LF/s+LFTaaX8bshBR67H5QQx37SULvH958nSPR0bgmh/A480RTJaV3goh1rY0Qag0kN4TyyyOQXIvCcoVt/NZltNQOPtQ6OPYoiojCcjLvSenORoo/Yqtg2hqJsxOHbraxm//5wur0yZSb3af5+wAcMuHAJ5HQzVwZK6BazZWHCIuZ9Ywxi1h0S5g9+QQ8rKAdhoFREqFUDtG/XfHntG+CDwvnIDeGMtYRuSdHI1+QSxj3gwh8n82hjJCKO66PTRTx3AhE2oRyGcENDXDHQ8ylNA99wz5GtO6ux+oRnjbeYcQWmr3DB1lGUIsPLYf2LaNrz0/dUFUthoqIevZ+Sn12AgmhdMhqssy1vt5Z2sdvO6P78exuSZu2pY8Q6qUTasQYpYx1mVs0N2cK0FCqEeoNAtBf/1vA1e+O/Zl25oJgedQyUlodAxf+HYYxmjRaqHD5s0UXcYoAcQtHgFsE2jNhz7uHdeSUOXnzy53/c5pO+8hmHt1Ogw/GHeu5DxthMMyhCzLxrlqBxu9hFCH2swSWHmYRSKs7bxCLWMqZBi5MUIILRwhXW9Mgzx/e4k0EvAQQo3CVvIkMeqv23YTBY7XMgYQZeE/PnoKtg3sn677/yg0Q8gdL3/oFUSp/tarJsjax7FRJM8QSoJXbR/ElbTjbiKFUB+WsbAMoSRgx5O0i1ZOFrHUCrlPeIHcy4lCpSOuM0Mj1zJVEMUWKqPAnpt1x20vQZXK6BgWdNOi3dR627EB4MmTS7h+88DKQq0vZDh7AvXSCpUGmTd7KYQ6uom2bnZbxgBfsHRJEZHPiJgoK5ha7uFsSADdtFdHIRSnbuQFQgB6CSF6nZ+ikRRjpXRjycsR64TQGqCclZwMIdOyMVtXHYXQYI4QQicXWhgtZlakDgJIhhDQXaFiaOvxXQlylBBqQvYohGpOS9M08GYILbd1lBSxa7OoiBEVFduGZHWQL5RQyIiQlRy+a12F0an7iOw1AuWsjMOzDVz+v+7GV58jk97lE0Xopu0uMgy1m+3vO1S66VpOYrBnvIibtg7g84+d7isnw7RsTC93SOWyV5cxJjnuoRDq1zK2RMm9wZBQ6V7YNEYWrpaooGlnMDx1f+jjvAqhgtI7VJpZxthGzuo00Gw28OmHTuA7h+ZSH2cXwhRCHjx/Zhm2DVy9qewQOYq+jDGuihl7AFdMlpCVBTQTBPU5cEKle3/Oukla3qexuqRFTiKLxSj7TVhHr35Qyoq+DXbw3LNg+jii79BsA7vHwu/LnCzCtj0KI0b0TT1Dvq5yhlBHt0JDpUuKhKIiUoUQ6zLWrRDq6CYaquGQJ6nyUzx4/uwyfvZzT+HBw+Gb8/MJt0kBeU/lfpQfIQgGm+fpBidJtfPr+6ZxbrmDT//4Tfjp25OrxEqK1J9CiFWgOc7NEQpaxnqFSi8cAcABg9FB/gysGFRQRDQ0o+f9Ok4XvHMtep+ksYyZNhTBArd4nPyAbUADYGuEoG0LIGSIyHO+arAk8MhKabu6kc/PtDmSiUgRZhmbb6rQTMuvEGJ/kyDsV3TWX0FCyIYCchxtZKDlRoGlE0CVFohaC6TTHENxHJZlo6Wb6JS2kZ/FzD/MtsO6ZrG12sn5Jr62j3z2XR3dWKFBzneFSgPAf711O3785q346TvovcCu1xQZQknwW2/fiz/9gWsBuAXDuAyhfhRCl42XsGMkjz3j6cKPmfohqQrn5h1D+Prz0+HXp6QkC5XW6uE2UdVPTMZ1DI4Eu4br04RoVmvQZGIZM0wbksAjI/I9FUId3cTB6Tqu3piylfvLCYwAMtRLNFQ6fk4LFugAuPsoJ1hadMbSyXIWU6ugEOq77TxThyYJlWa/DwmVPuEQQhe/hXCdEFoDlHOyc/OcXmzBtGxsGqQKoYKMtm7i0EwdW1bQbp4hqnMGQ6dHVwKHEDLlgGVsBYSQZna3J6RQJCG0GmHqHQiwUKEWo4mygm9b1yPTmgJm9kW+5vtu3IgfvIlUtj776EkApMUo4LGNhXUZC2GEGdo9LWO9CSEAeP8rt+D4fBMPH03eVpRhvqHCsGxKCMnxhFArGSEU2yY1Bkwh1E+GkJyjFfBtd+BB62psmnsAOPd01wJINUg3PFHgE8lXZ+sqylkJl7EFn9aATeXZD6wGIaS3YpVgzPJAFEKEyMnoVYxwS5izK7hiooS8LKZTY+WSK4T6qhamBM9zKMjR5Nz0csfJoFgJylkJmmE5C94gAVXuoRCybRtHZurYNRp+XzJLGyN6nfv37FNIurlOgyiFEEDUi70UQiw/aMcIuf6qYRXoBGAqzQshmJopntj10ksZkBTs2ixSqxjHcSSDLAFh89CReWwcyOK1l42mes2iIqJGVamJEMwQAoACzeFIaxlbOAJUNrldjGLAFISFDKn+RnUZY2AL3pkWUwil6zK2mV8gahcAqM+EPk6OsaiwwNyg3Si1RY8Saktc2VX7wKumds8b6xS5wacQoqqiBAoh9pzdodIWFKiwOQE6BLQywyREHPS1l04AtudvihPoGCZsGxDzFSA/GqsQun33CO7/lTtwxSS5fth99amHTjiEdCQhJGWdNQBb41VyEjYOZPG/v2+vmy3nbPY6RNFkmz0zhNKCzfdh40BHJ4Hx/WQI7Rwt4J5fvsOngEqCNJYxAPjp23egrhr43COnun8p5dzxvblAPkMvvPd5Y6b7emPXYUAhlCTfyAF7zsaMoyQ3MhV0DMsJ682IQk9CaP9UDYZlX+SEkKcz3CUXKi1CN+3YcHG2nvDtA5ysLDKO7h4rkDUxgImKgpm6GplvmxSk7XyKdS6be1ixjbWdjyHYAZCxzeMYYXbKUzQLNq3a8OWIdUJoDVDOSlimi/gDVLZ72TiZuFlbzv1TdacF50rgEEJGRIaQHm8Zy9odtOwMmprlsYxRQiglAaDIvPOa1bYe2sY1KlT65DTZxA8NEIvReDmL+81ryC+PPxj5mtdtHsBH33M1XrV9yCGArugihEK6jAFdjDAA/OOjp/BH3zgIwA3V9UFtuJaTHnjTleMoZyX8cx+2Mea9nawoyRVCPUOlWVeMdIoDt7rfx+Y/TzZb/BVvx732TShos8Bf3wHc//u+h5FFLLlOi7TLWNyGa7bewVgpg00DOSgSB9FogjNcQijqb0/MN3vnOllWeNt5D6aWOyhmRPKZZMk1K6pLmOAWMYMB7BkvIicn69zgoLwJ4PhuG0kIGEnQj40vDQqKGGq/sW0bz51dxpUbVr5AdDoJ0U1Bt0KI/D5K1n622kZTM7FrLPy+ZNe902ksWyGdAhvTJD9oFareXkQphADSZYeESkd3GWP5QTtGCHHVL2nCrr0k7WTXGuyeG2YKodwqEUIsQ8ijIkii4DEtG48cW3Da46ZBKSvBsOzkZC/b+HmvM0chFLjXe4VKzx9OrGhraway1IJbbemo98hjKWclZES+L4WQYdnYKXhUQREKIab+CVMItTQjtGNh+swmMg8scRV3U+15bd3z2ueq5LG+UOnARjwOzDIWbDuvmxYUaLAEBQCHBQTm5gUarL3xFWTML29yruW8LADjVzpzZxS2epoCMOXdt/fP4NpNFbxy2xBOLwXGFq9ljJILpawEWeBx2XixO/fHyRDqEAs1kIiITAuyXu4eB5jqJhg7sJZg41LSroNXbijj1l3D+NRDx7uV4FKWjO+GBvyf64BnPuv/vXdN95VfIOsiLwLEJBtvsnKKbZtXIUSVEkZmEKZlo6ObkASOKoTix7LnzpBjuZpu9i9KMHLD1C7BUGlaNItZK7A5vKvtPOAQnx//wevwB99/NQBgopylDpmV2cbUNAqho/cBf3oZIdy7QqV7jF2B/SDHcchKApqaiYzIo5Q9f+PQS4V1QmgNUPFkCB2croPjgN10s8I21ZppYfNqEEJMBh2TIaTEKYSMGqrIk8UIW5x2apGEThxkgQfPEQXKUkt3qsBeKJKATsjkc/g0YXXHh8nCaaKkYAlM/dG7W9draJtDkeewkyoFnNbzYV3GgC5GGAA+cf8RyCKPP3zP1RgN84xqyTKEAPJe337NBL7xwnS6LikAzjmEULZ3hlBChVD/lrH0HeccVDYBP/0QcM0P417pNvzDjo+RhW7Nv2EgnZnItVzIiLDs+MyYmZqK0aICnudw5agMHhYES4Us8Diz1Mbx+e5rxrZt/MBffw8f+dr++GNmi98Ya2BT9WxeBBHIlMEtn8YYV0Utuwk5WUROFqEaVvIKyeVvB37mYXezGAPWRW94FRQ6cWDkXBDTtQ7m6iquXgVCKKgWCb5erwyhw7Nk4t8dQQg5ix2mEMoUgZ+6F/ihLwDv/+eVHXwAtm0nUwjxPFmA6t3XKevwyAihap+kibdb20sNRnINrrJCiI2rXuULURjGP+++s8uodQzcvDN9QCojMBOTFI5CKIwQClrGYhRCtk06XyXsitem6uB8RsSLtMIfZ6HhOA7jZQVTjX4sYxa2c5626o1whZAo8BB5LnQD2oxogNFvZlOVr4RbxjxrpbNVspEJtYy1eit7pZguY7KtkmYdAM6ZFf8fzlNC6LZfAX76u0BpwiGs8xkReNdfAe/8y56vz8AUQpsHc/jrH7kBmwazOL0YUD87odLEMibyHCSBx8bBLF6xNWTt4G3F3KCbqh4kVT8oBTI3Gdj91U+GUL9g6ofQDrMReMtVE5irqzizFPi85TxZu6o1khu1fMb/e9PTte3It8nvvYUsdh12qoBpoEXnr6zUh0LI0p2Q9HaB5JbWOwZRCEk81JiGDQAhhIYLGSf64qIEs4gZnUsuVJqtZeMKmM6a05vTGBOePlkh1woj3fuFN/y8J849RZSXC0dd67VDCPXYb4cIBNh8NFrKRAblX0xYJ4TWAN4MoQPTNWwZzDkXltdisRqWsV4ZQp0eLXUzxjKW7CIZCOjiVG9VoRlW6omY4zjkqE1mOcoyJoZ3GTt2jty0I4NMIaTAAD1uq/dikLWaHi5kHGmfqxAKCZUGugYAw7QwtdzBW6+awPuoDa0LanLLGAC85/qN6OgWvvZ8eMU0ClN0EHW7jKnRWUps4dpDIdSvZWyxqUHkuXDFVBKMXwnwPDKZDJ7NXA/kh90OABQd3d1EM+Iq7jjn6qrTUvaqYfJ42dbwtmtIB58w29jx+SZmaqpDIESCEZAx57mpGf7uWrkB4DRZcHE0pNgl4BJuHHkBGL080UOZBSetJD4tgva9xaaGh4/OOxXDq1ahYsjGRBZA2FD9SgY3Qyh8jDs8Q1SYURlCrOrrU4ZNXgvseROOGKO4+SP34EQIgdgPDMuGZSNyAbNhIIu6apANkJQLVQixhdcOSmz324mLLe5SqdTWCMwGx8Jv87IAgedWTggFMoQAohbqZTn97hEiI7+5D4UQe63E+UdhljFGCHVZxmJCpRszpCCRUCHU0kh+YFERHUXOdZsGYv9mrKhgqkHH3VSWMRtbuSlAqZB5KEIhBBBiJlQhpIZ3QSsqUuIcLd208JnvHgIA1IQBQmrRzQojb7yvfXapjWJG9BevHGXGUs/XE2mXsWBwu27akG3NOecndELE6TadM1g4eG4YGNsLwJtdKAKFUaCYvL13SZHw5z90Hf7pg6/CaEnBpoEcltu6n0hz2s7nfA0Jvvpzt+JDd4aQjE6GUMc9nwmKFWlRzoZbxtj91Y9lrF9UnAyh5GsdRrIenAmEeMtFss5R6c+DY72h+T9P2/SrhjzqNnSqnmYnfYRKA8CJ7wIA1PJWAIQQEhNaxkhH1fLFvSm+lEOlM/EdZQFvETKMEOpexzCSfWp5ZTlCzNqYCAtHyddljyuDEathe0AvwgghumcauwTsYsA6IbQmqORIG2XLsnFwuu6rynn9l6uiEArJEJqtdZxNRFwnIgCQtSqW7AJpjy3lAE6A2iALoTCFTy8okuBaxkL+PisLoRu7mQVCaggK2QS949pJfOh1u2DzUqKF6e6xAkaLpMtQKStCFnhXIWSGtJ0HqMfbHQCmax2Ylo2NXvl4EAlDpRmu3VTB9uE8vvT02cR/AxAbTCEjksWQ0w4zomLbXiTVjB7KpSRESxiWKLm30sUAy7IglTM/KaPqFjJUIcSIqzAlk2Fa+MT9RzC13HZk/pcNkr/LcDpu3zWMDZUsnjjRvZh/4iT52algtkIQTGoaQwg1VNOfx5EdpBkRwNtfdxsAt1tO2s87CUIn5zVAwWO/OTBdw9v//Lv44b95FP/w8AkIPIe9k73tbb1w1YYyeM49P/WO4atEOhlCEZ/joZkGRoqZSPscC149G6zgAviXJ8/g3HKnN0mYEIzsjgry31DxHIucD80wW60MIaYMShKwvNZYaGjIy4LzuXBcdzfOftDokCBiLwHXy2L02PFFfOK+I7hucyW0K10vOK3Qk6pWDA0A588GY63n04RKMxJhOBkh1HEUQuQzH8zLTpZhFMbKCqbq5Bp+6ni4yicMumVhK84Rsqo4EZkhBCAyxLaphecdlhQR9YTXyZmlNp4+RpRK2QH6GdONdT5k03O22vGrgwA3d6jPUGnbtqGZFjK26lSlj7TIXPKCTdQZcydfJA/2qHqbjkKov1y4t18z6bwXtrb05Qg5odI5dDxRAllZCO8U6W28UafqL3bdriIqWTlWIdRPqHTfx5IyQwhwlamHugghus5ha52gGtRUuz9P77rIk3+F1qLHMtZHqDRACKHCOPgsGXMaqgE5gWWso5s4MtfAVaugBr6g4RCgl2aoNNBbISTyXMAy5lERBjBRpoTQShVCRhpCiM6RSye7f9czVDrXtR5je5JLocMYsE4IrQnKWQmWTTpYnFhoYs+4u2kayrsL0M2DyaxHcRBDCKGf+syT+F//QYKYe2UISeoSqqAKIY4DlBKMVtV5H2mRlXm0aAU8zHKWkcK7jDUbdPKjC6jtIwX80hv3gBOkRAohjuPw62++DD/5mm3gOA6jpQymWctDQw33A0uKbwBgkt+NAxFEnamTSVxO3rmC4zjctHUQx+bSKRDOVduO5NIXdheG1iIJNu5B2EhUrp+27fxsTV0Va1I+IxCSRy64pAuFaphQRHeBCoR3lfp/3zuJP7z7IN5wxRj+yy2kG8vOivv7nYMSrt5YDm1r/CQliRabWvxmjnUnSGoZA3wL+5HNROWTc6xKa0AI1f0hvWuF0WIGpxdbsG0bP/PZp6CbFgbzMh4+uoDdY8VVaUFbVCRcMVnC48fJ4rWh6r4JmC1AwqymALHlRqmDAKI25DngTCBTw7ZtfPX5c85rrgbYRjcTkSHktJ5nOUKhljEVisQ7XZ+W2/0ROg3tAiKEmiqGAuTlqhBCtJW6l6wuZKKD0JfbOn7i7x/HeFnBJz9wQ1+v6SiE0ljGRMU/PhdSWsYOfA14hFqIUiiEspLgjFPXJKjwj5cyOFMn7+uJo8kJIcO0sdlmhNB4XwqhtmZGZAglVwi1NRMZjlxTN19N1Za0QqxIAnKy4DRJAMiYsCFYAAp0d4oDUwh5bcHMPibbHfAyee4X6/SrtRWaLaLUoiHEXkLIqxBaITY5hJBng8MsY1Ie7Qh7ng/eDXKDEULJVUtJETUOOBlC59Uyli5DCCDjzcaBrJMX6iBD1zlsrdNLIQS4aiLAZ3dEe9FtJJFmzm0tuue9MQ0M7XTm7HpHpwohP0E731Dxe1990Vl/LTY12DaZRy9qeBVxxqVJCMWtFebqKoYKMnjeM4eIHtI4gJIiIi8LOLdChVCqtvPMilsNhLwLMlHgx0FUuiJE2L3WT+Ho5Yh1QmgNwIiUJ08swbLhdkICWUwKPAmrWo1NtiuDdhckc7UOXjhXg2FavrDeMPCdJaIQYgOBUoa5EkJIEjBbV2Hb4X+vUHlqMICv1aATYVDlwkvd3Rki8O7rN+Kd120AQLI6WA5PZIZQgBF2CaEIJlntTRSEoZKXUG2l6EoDYp9hDLs7UUUoBeYPAaUNiZ43KwupM4T2T9VSt28Ng9PaMlMIsYy5QbxOt7oQQuifnzyDazaW8Vc/cqOTx7Wt6H6uW8oCrtxQxqnFVpfV5omTi57OATEqoQQKoW5CiGaRlDc53WGcMOOklrEUmG+oqOSk5JWTPnHd5goWmhoePrqA4/NN/MwdO/CztC3xauQHMdy0dRBPn15CWzPR0S2HDAHcDUEn5LpVDRMHpmux4daSQMiVM4EWqM+fXXY2TKuVs+MohGIyhADg7FKLXCchlrFqS8dAToYo8ChmxL67hDkKoQsgQ2ixqXWRl6WshEeOLeD1f/pAd0ekhGiEBCUXFamrUx3Dg4fn0FAN/MF7ru676hcMQe8JI0ShOraXjBXULuSgvJF0Azr9mP/n//7TwIGvAIM7gNLGRC/L1MHM6nttD7sYQCqhDZ0WmbSYRgYB8EYTo/YCUS8VxyMzhABEWlSamhGuEMqKidVYHcOEDHruCzTvxqO0GMzLjnVUNUwcnWt0Z48xq47RDt3oeOEohDxdxlhxTrJUcHIOHAe8UM9iv7UZR0uvwBIKyHAGTE7wWQZZhlBcJ7ikYKpI333FQqXlnEMWxsLJEKIKISnXbXFcBZRz8RlC51MhtHkwB54LdJ1LgD1jRRwKEkJyIaAQCoxxpkoI4cnrgJ2vJz/zKYQ8Ra3WYnz32yi0F4Hh3e73Qzug0DVQo2PQUGnBlyH0J988iL958DieOkUKaOzc9LMfeFnBW3i9xBRCBUchFL03mG9o3Yr0GMsYx3GYqGRXpBBiastE69zWoquI81rGvMcZhzjL2LpCaB39gg2cj9KKt3czzfMcBnIyNg/mVsWPK4cohJqaiZMLTRylqpRIa5plgetUsYSCywxnSrDoAqqfCaCSk7F/ivx9WJtyRk55F4QtzYDNcluCwV+CmEghFMSGARreattkcA/zjwYY4TNLLXAcaZcYCjZZJwyVZhjIydBMK5Uyx68Q8lQugmjOk80DW1D0QE4WUlmYFhoqzi13cOXkyjf/eVkki1652BUU3tFN59rIRmQd7Z+qYf9UDe++3r8hGhDdjUuB1x1p875z7oJqqanh6FwTb9xLKnIn4wghdmwxxF8j2MKZ5TcN7XB+1G+IdxIsNFUnj2UtceMW8r7+8n7izX7FtkG8/5VbcOuuYbz16tWzD9y0dRAd3cIjx4h11GsZUySBdCcM2UQemm5AN21cvaES+/wbB3K+0M8Xz9XwB3cfcLoERREIadFLITRckMFzNANKyocupKptN5C/nAvvwJMETobQGhCSaTHf0Lqu18GchPmGhiOzjdSWWoa6aqCQ8c9TxYjOeABw34E5VHISrtvcmxyJAtugJlZehVmWSxPAL+7rzgy76b8Scv+rvwxYdNzQmmRzeOf/An7uSRJIngDtoEJoU+8xfKykwAIP0+ZgmlqoSjMMgx0amOsohKZJt8YQRGcIRVnGJGiGlehYOrqJDCiBykh6zyZ7MC9jkXWAnaqTsSPYSjtg1YmD5GQIuUUJ1vFVslRwUhZ5WYRhC/hh8U8gX/0uNATyei2h5FONsfs1VUZMBMo5CUVF9NujnbbzJFS6p7pTkEgHNEMliq/CWE8Vcj+o5CSohtVlV3kpMoS2DOXx+G+8HjdsSTc+7Bkv4uhcw39dZ4qkuMSuv2BzFNb99oP3A6/6WfIzr3Ladx0uOOvH1BlCpQmS7QUAw7uc897UTDdUmqpvj8018MUnyL3MMjhfivPwksDp/Nkke45LiBBiNtVelrFuQoh1GQsnfSbKyooyhJgVN1GoNLOLAa5CiDlDegVKA7Gh0mOldYXQOvoE8yHff3AWhYyIrUN+AmHjQBa7V0FxAYRnCLU0A7pp41svEpnvZRMRr9WpgrMtNPmSTyHE0YmoH6nu26+ewBLdwES1nQf8dqDp5Q5yHN3Uy4Ebl5dSdTth2FDJYrrWga7RGzwsIC4wAJxZamO0mInsEJREORIGZnlZSrixM0wLC03NCcf2hd0FcfibAGxgz5sSPXeWZjwlxQvnyLWwd8PKK4O5jOAqhFR/NY10GSOfO+uKFzzOLz19FiLP4e3XTPp+znmrakbHIYS8trH7D5GWq++5niipTizEWPgc4i/6Hm1pZiBUmhFCbjinqxBaG8vYWucHAcCu0QJKiojvHplHSRFx2XgJWVnAZ37ylbht98iqvc5NtMvNvQfIeRrzEUI8uW5DPsfnzlYBoHtTF8BGRhCDbOTf+8mH8fSpKv7HXXsgCdyqqWhYpTVqAcNxHAoZSljIudAOisst125byUl9dxljhEWqlt1rhMWm6rNLA8CvvukyfPrHb8Irtg7iq8+lC91naHQMFAKZK4WMiI5udTVasCwbDxyaxW27RhwisB8kyVvwIUwhFIVMAXjjh4Hp54AnPkV+5uS3TKbakLMuY1dtKOOy8SKuT7DJZZVQHSJkmE6eVS8MqbQiO7SL5KLYJtCaD31sVGYJUQiFt50Hkl3Hqm4hA3q/sDHZMz8M5FyF0HN0fujKRlFr7ga6R6cxdh2ZHvKLdTETbdJFim3gB/MyfvWuPdi+iTSsqME/vzDiNsw21w+umCjhHx87hV/+4rPE0uZRCC00tN5dZDmOdkJsk0yoNcgPAoBtdH0ctNXXOwYEnlsVgiwNgtbWJNgzXoRh2f7upkwhxNY6QbWZqbrnJBPSUdd7HXosY1Hq01C0FkixilnTPJYxgOwfvJaxv7jvKER6Tc/WyHrzklEIsb0HU2ath0r7MFdXu61TrJV7SGELACbLWWKP7xNsLE3Udp4RQplSdwh+r0BpIJQQYnvB0fVQ6XX0CzZwnlho4aatA12Lz7/+kRvwu+/YG/anqREkhDTDcljVrzw3BcHThr0LbSIJbYkVNJhUUCmD1/pXCL3jug0O6RNOCNF8GMNPCGVByQ4poL4RklvGvNhQycKygZlFNriHdRnL+QayM0ut6PwgwKMcSUfmMYJwKeHimhFHjsWCVSrCwkYP3U0WahPXJnrurCymIiiYymbvKiiEChmR2KdY2KLHQtfR3daSUeHXDx6ex6t3DDlWMQfeRZTRwUBexsaBrEMI2baNv/7OcewcLeC2XSMYLmR6WMZ6WwMbQctYlm62PPkejkJoDTJc5huqv/3nGoHnOWcjedPWwRVtpOMwUsxg+3Ae395PrCZDedlZBGREEkYcphB4/swyKjkpPggehBCaWm5DNy2cXWqjqZn4yLuvwk/fvqOrk9pKwMa1TEz1vciCugPjD0O1rTmd1QZycuJNeRDsPb3UXcZs28ZCQ3NazjNcPlHCay8bxVuvnsDBmTqOzNYjniEay229q3LtKHgCBMK+c8uYb2h47WUrIzJZ185GjLzeB5YhlBR73wVsux2493eJAtQhhNLlt7Q0E4os4Matg7j7F25LVOFnyjyTkyDBwHw9ZM4JwahGCaHB7URJArjHHYAcEipt2zbNEOq+b/IprLcd3YTMGbB50d1MqwGFEL2fnj9TxSCdK/xPsgwMbCX/7xEsLYWESjuWMbMDSFlnszWUJ62LOUpUzVv++YXNy/2GSgfx5z98Hd505Tj+9akzxD5PFUKGkMWRMKtcGETFVQitQYcxAM769Mice/+fXmyh1tFRDOSDXahgLoAXPKpkoiS3gQYpcvjy4mzbn23JioyaZwzsLAOlSVIUbS1SFTXvz3DphfYSUco5hNAuZ30OgAbyEwunZlj45gvTeMe1k1AkHjM1ovpg+V2l7Pmz7r0kYCoSui+6tBRC8YQQm8O7ipCOrTRcIXTlhhLmGxpePFcL/X0v6HSekJNYxuYPkzFu4hr3Z4zETqIQEtcVQuuE0BrAS4S8avtQ1+9HS0pkR5y0kEWaIUQXJN5N9IHpOnaM5KMVL1QOrUpld7GVKUHUyaRU6sO7XVIkvO1qouAoZ8MsY0wh5C4Ip5Y7yCFKIdS/ZQzwEEJhg7ukuFLH9hJ+evp/Y28hptsQm6xTKoRYUGHSANWFJvksnIp6VKi0qQNH7gV2vTFx5Tgr8WjryTeIL5ytYfNgblWqQzlZJB5luQBYhk/xpBohlrEAAbDU1HxWIveP/QohgFR991FC6IFDc9g/VcMHb9sOnuewdSiXUCEUbg3UTbJ4Knir2Y5CyCWE8muoEJprqBg5DwohALiREkKv3D7Y45Erwy07h53W84WM5GykHIVQCCH03JllXLWhd1juhgFCEE8vdxwJM+vIU1CiQ4jTopdCCCDKy1pHp8RoeIYQm0Mmy9nQ7mhJwBZ3L3WodK1twLDsSIvjm68cB8cB//ksqep968WZxJ3Vlj32Ooaoauejx8h8d+uulRFCPM8hLwspFEJaeFODKHAc8JY/IkT3vR/2BPomV2iYlg3NsJCT0s3hmwZz+KPvvxpSJgMJhjMX9cKYfhpz/CiZv9lxRgRLh3UZ00wLhmWHKoSSBJ4ytHUTGeiwBTl0kz2Yl53CTOjYYeqEpGWEUA/LGGvqYYRkCIlWB5AUp9ukU8igc8WMkfNlKTZV0jEv0eYnAUaLCt5yJTkXLc10CKGzTQ6aYWFPUkKIdRlbI0Joy1AeAs/hCO30ePe+Kdz6h/fh7n3TLxub0s6RAjZUsviH7510syJZQYnlaXnHessAYLvKQfZYn2VsmWQM5QapQihcQRcJUycqo9wguSd5ERjY4lcIiVQhpJt49PgC6qqBN1wxjrGSgtmAZeziVwjR9V67Sr5eQoQQU4pFzWm1tgHNtLpzb3mezG0RCqG3XT0JSeDwr0+d6eu4HIVQUsvYwFY3Ow5wiyhSQoVQV6g0ed11hdA6+oZ34AwjhFYTjkKILrCCeRGXjcdYfagcWpMrPsuYbDRQyIjhrUgT4P977U584FWbsXWom5XNSt3VvumaxzImBqp1QrK280GwUMC5xSr5QRhD7AmVNk89hjusR3Cnfl/0k6rxREEUHIVQwk3OYoM8zllAert9eLFwlCx2t9yS+FhyspgqQ2jfuWVcuQp2MQAoZASy8JfYQt1d/CQJla62tXAi1WsZowTf3skSTi600FANfP6xUxgtZvDOa4ldbPNQzslW+Mz3TuB//tvz/ufrYQ1k94pPIbTtDuDGnwC2vNr5UdbJEFrdDblqmKh3jPOSIQQAd+wZRUbk8do9o70fvALcumvY+X9BEZ3PlymEgtdtRzdxaKbe0y4GuJ0Dzyy1nconC64uZKJDiNOCKYTi8jmKikiqriFdxmzb9mUIbRrMYr6hprpnGVhA5EtNCDFSIcriOFpScPOOIfzLk2fw5MlF/NT/ewKf+u7xRM9da+td1uYoi9FyWwfPYVXum3xGTEEIRTQ1iMPIHmDPW4Bj97tKm0JyhZDbojr9HP7eGzeBFzNUIdQ9Z335mbP46NcP+H42rp/FtEQbG4zsJpvPU4+EPr8sCl0ZQixQOcwexAi+JMR6R7dIhpCghG6yB/MympqJakvD4dlGdH7QIOlg2UshxOw1RohCSDBJ23m2iXcUcjRvbtEqYKbuFnmOzTUxUsysqiKGqY0aquHYk44skWNN1ChiaAdw4kEyTq0RISSLPLYO5XBktgHdtPAHdx8EAMzW1fMaKL0SiAKPD925E8+erjq2Z8dyzohR76aZreUY6UDXGp++fx8Os/b1ao3YX7KDQGsxWRC4F0zpkh0ArvsA8LrfBATJZzmTeI5mCFn41oszUCQer9k5jNFiBrP02mSFzOLLhJzrG4IMcMIlqRACEKuUnmuQayG021aI1YphIC/jdZeN4svPnO2ycCeBlkYh1Jglirqsp3CZRiEk5QhR69lv5jMispJw8avjKNYJoTWAIgmQRR6FjIi9k6vflcGLoGUsuPm8fCLm9elix8wMoKEa+MwjJ/HkjAHZbKKi9C9b3jqcx4ffeVUoocQ2Ot6g1OnlDiqiTm7IYGAmL9FqSjqw6v/CEh3cg8ojwBcqXZsjDPYV9Yejn5QRDym7jDGFUDVhhhCziDhsfCQhRD2zw8naEAPpuozVOzpOLrRWxS4GuJk6Gk9JPx8hZDpKNiXEMtbRSfep0CqVN4+Ins9dtPp5ZLaBF87V8MrtQ07ryi2DeUwtd9DRTXxr/yz+89lz/g5wWoNei+H3AJs0faHS+SHgbR/zkYVsMb7aCqEFShieD8sYAFy5oYwDv/sm5zNdK7xqx5BjSStkRBQyIiSBg8BzRMUTWKw8d2YZhmXj6o2Vns/NbCFnllqOConlpRRj2pSnRSKFkCISsiKky1hHJ+qzco4RQozISt+FixEiTdVI1eFwtcHGsy6rpwcfeOUWnK228aHPPwMAeOLkUs/nNS0bddXosiazjUswWLqtkw3Vamy482lshoaazjLGMLIHqJ4EqqdJFZbZUhPA7UjU30KWF2XInIH5EIXQN16Yxt88eMx9/7aNSfMMZiQa9q+Ugc2vJnbmEIQphJz8nJDjzXlJjR7o6LTLmJihmwCuK0MIAB46sgDTskPyg6ii2FEIxV+HrMuY4VH6sI6vgtkOWMb8CqEqik7Qfb2j476Ds7hr7+qSLvmMpwBH248fWDTiowS82P0mcg0CQGFtCCGA2MaOzDbwhcdP4/h8E3fsISq+l4tCCCBdbjcP5vBXDxwjP2DrxHqIQojlYrK1HSWEFhYW8D3aWIEohEpUIbSEDu0amBhM3ZYbBLa+BnjNLwCAzzJGlCECmpqBb704g1t3jSArCxgtehRCHR3FjLhmdvELBhxH1m+dKvn+EiOE4oocc7QwEKpKjyGEAOA912/EfEPDQ0fCM+XiwBRCidrOqzVXUQeQQPzcsHuMveDkIbnv5Sdu2YZP/sgNLwvb6mpgnRBaIwzmZNy0daBvlU1SdBNCZCHImNzIQGnAmTDM7ACaqokvPn4a3ztrgIeNUaW/INNeGMh3ByxPLXcwJBvhLK4g9qUQUiQBwwUZ1eUq+UEwmwjwMcLLsySVfnjpWZLbEAaWVRMTNhyGskMIJVMILTTIRNxbIUQJoaEUhFCKUGnWZWIyqutaSrCFcZujg7OncqvqVpdlzJsZw6pUoUGYvlBpcsy76GL3mVNLOLPUxp4xd/Hr2AlrHcwsd9BQDb+dT2v0aDnPsh7iN1usEtdcZUJovhGvuFgLnI8JsaRIuG5TBQBReRQyokMSFkM24N89PAeeS6bCnChnwXHA2Wob08sdDBcyziIjjGzqFywsN9KmC/I+6x2djEmm6naTApwW8yxDiCmbTvdBCDVVAzwHWHa32u58YiGoeAzB668Yw2gxg7PVNhSJx7OnqzB6VBSjrAxRlrGWZvZNkASRz6SwjJlqfwGlQzsB2wJOfY9I39MESjNCKI2iwANelKHwpnPuvGioJkzLxuO0iyqa8yjYTczJm90H7XkzMPsisHSy6+9JlzH/9cjWLbmQ/BxHIaSaOL3YwsNHozcWHcNEhtPJnMlxNNjXVeGxa/DxE90dYMkTUIVQfoT8bY9QadHpMua3jHGwIFhaV6g0eZNkvFqyCw7R+60XZ6AaFt5+zeoGNzOCrakaZC0FYN+cga1Dud5dxgBCCDGskUIIIITQyYUW/vL+o7h+cwV//kPXoZARnfXiywGSwON1l43ihXPLhIBnxSGm8POqQYMKIVGGxUvIcx2nYIGOZ4PbWkBLC+/CFwl27XoVE/Dn20kij0pWQke3MLXcwdto59CRYsYXKt1Pg5mXJaScaxlLq+p8mYMUOcLXCc6aM6VCCIDT0fP0Yvo1DNvXJlIIdZaBTNm93uWiS8omDZUGfO9l02AOt69i85QLHeuE0BrhT953DX7jrVes+eswFULNqQaTG/r6zRXwHOk0EYn2IsAJ4JUymqqBc9U2TrfJwD+e6S/ItBcGQ+xT07U2BiQ9XMUjyPEZQrbtCyf2YkMli1qNVvzCntszADCFEAebdu4KQYKw4TBkRAE5WUisEFpsauA512oWmSG0cBjIj5JFQ0KkaTvPSLuBVcq7KlD5dxN+hZBp2dBMN1RaEniIPOfbxLLPrhKSS+ULlaaD+ebBHGSBx9eeJ4uxPR7rJMshOlftOJJ9b0tyqI2egdJA7/BPnnZIaa+yZcwlhC6+CtZrLyP2tJIiIZ8RnWpmGGnzwOF5XLupkijbQBZ5TJQUnFwgCqHxsruwSaX26AGmEFIi2s4D1DLW9ox3nus3SHxuGiT3yunFdDlCpmWjrZsOabhaCqh+UOv0zqCQBB4/+uotyEoCfvH1u9HUTBycqUc+HojuftNlGessA815dDSjLwtVGPIsDy0J0oZKMzCif/q51B2e+mpR7YUgoyBaWKh3X3eMCHOUDLQwMZfZ5D6IEQkhKqEwhZATqBymEJLdlsh/+cBR/PinHneCoYNgljGOVXsDHS29hJAs8N1NJFiHIWbVSWoZs/yWMQX0+Gjbee9rO5YxFHGG3tf/+ew5bKhkcd2mdO3Oe8FtJ00zhHgRL8524qMEvBje6V6Ha9RlDCCEkGHZOFtt47/dvgNFRcI//MQr8Etv2LNmr7kW2DGSR1MzMVNT3cIhywCzDJInBrgNQjykgy7mkQcpUsG2/Zax5jz4TjWlZcyjEPLApxDiOfyX12zDP/7XV+LBX30t3kFt9aOlDBqqgZZmoNY2Lh1CSM55LGOXyHumKMQUOWKLkJ7ojTCw+bjWxxpEp2pLKREhVHMVdQAZ+1lhN2moNBCZh3QpYJ0QWiPcsnO4W5K7eAz48Dgw8+KqvU5OFjFRVnCUBvIxy9hPvmY7vvSztzi2iFC0FoHcIAqKhPmGioWmhmWL3DhjUnhq/ErBSA6vWmZ6uYOyoIerePgeGUIPfRz45K2hv9owkEWjQSt+oRlCrkTQqJ7DcX4zyWk4em/4a2kNIkPsY3E/kJMTt51faGoYyMmuRJcFkpqBRfDC0VTqIAChWSxRYOGbq0UIMdXagk6fjyqEmE/YW7EMWtvY9VLJSWSx9PFrgCc+7T4PG/hp5U0UeGwfyePxk7QS7LE7MULoxELTIZp8lhytEZsT1QyzjEUgJwtroBBilsKLr4L1U7dux9d+/lZkZcGnECoEbF3VlobnzlRxW4rqzeUTJew7u4yZWgfjJVdCTNrAnz+FUFGR0FAN2GxM8ixAXOKTLEZHChkoEp+6usYIrnF6rb+UOUJJ75efuWMnvvtrr8VbriIbz6d62MaiCSGPZezEQ8BHNwN/tAN3Tf9V34qZIAoZsSuvLxJ6fIaQapjhcvqhHeSrbaVWZ5ytkuulb8uNIGGvfRh/cOjNwKI/z8khhI5SQmhuPwBgQfEohIZ2kBb0B7/e9dQZkQ/JECLPGZch1FANVFsaNNPCl54+G3rYHd1EljPBea04HgXpIFWc7J+qYdtwvtsGo9L1AttY9FIIMcuYJ0NIMy1kvYRQJkAI0aBTXRnG6aUWTMvGQ0cW8Ma9Y+k6SCVAztuhTS7AVio4tdhKlh/EsOfNZN2zlgqhEXI8W4dyeP3l5PO5YctAMlvbBYTtI+R4j815ikredRtTCTFiyBM2r/E55Lk2pmsdMidYBin2FUaB1jw+NfNe3K4/mPxgmGUsoBCSBd4RG0oCiba4eeewY08GgDEaojtbU0lO28sky2nFkC5dy1gwQ+jBw3P40U89BtOyMVdXIfCcsy7xwRO9EQZFEpAR+cRNdbzQTLKe6hkqbZkkTzXjIYTkvHsPJg2VBiI7pl0KWCeEzifmDpIbZ2bfqj7tztECDjuEELmBBvMSrqH2i0i0FoDsIHKy6LC3HZAbfkBOHwCWBLLIIy8LDjmiGibmGxqKghahEBLjM4ROPkwWpCEqoQ2VLFoN1hkswjIGwNZbkNqz0HJjQHljdGcRtUGqPn3YZ8pZKYVlTPPbKxzLWGCgmj+cKj8IIAvulm4myhRhKq44q0casBDfWZUuLuhCnVnDvJWrbKDNeNW7+VPrwNIJYOYF+jx1IE+9wp6JaddYEbZN3rO3tfBEmfz/2dNV52c+BQY7zxEIDZWOQNoQ7yR4KSxj5wuyyGMHXVS/76ZN+OBt2wEQhZA3+PmhIwuw7XQdo67cUMbRuQZOLbZ83eqKioiGujoW2U4ChVApK8KyAZWjx+BRCDFCiNlMOY7DxoFcassYu0ZZQeBCIIR63S8Cz2GokMHGgSxGihk8daoa+/goQoh9X23pwAv/Rsb5wR3Y3H5xFS1jKUKlm3NulkEIPvXdE3j/3z5KWoN7kR1w/y5lfsu/PXUWlZyEm7b1qTjhJQxbC8jYKilkecCupRfOLZNzcPjbmOGGUctM+p9jz5uAE991bVgUrM21F4w0D+ui5CU1am3y2v/02KnQOayjm8jyuqedd95nTWbFDcsGdoyGrAnYsSplUhxiHaIi4Fj2fV3GbL9CKNhlbOJa4Ie+gDODr8aZpTbm6io003LGvdWES6aZwM0fwom7Pg3bRjqi5bZfBX7kS4QkWyPsHC1goqzg51+/62WdVbN9hFxTR+eb4bZzliPkKITctZXKZ1FAhxBCHQ8x+Yr/Brz1TzHPDeLm9v3JD4Zdu96uSyBzCrOzR0VajNI227N1FbVOdyfHixY+hdClRQiVs5JjWQfIGus7h+Yw31Ax31AxXJDDCeseljGAdlbthxCiCqGeljHVM247lrGCu45PGioNrCuE1nGewIgG5ileJewaLeLIbAOWZTsKoUQL3/YSUQh5rC8qyCBYWSNCCCAqIaY+YWqHHNTwm5aXupUxXiwcIYRRyE08UsxAsuhAFfbcVOlzZnYRQ/Yi5PJEvPxRi7cSxWEgLzmkRi8sNjUMee1AjmXMkyHUXgJa86kVQjlZgGnZ0M3khFBobk8fYAqhqXaAEArpzJQNWNtYCHklJ7lSaPZVbbgbJ89ntJsueneNFX0TWVYWUMlJeNqz4exSCIWc59laB7/31Red85hYIbTKm/H5uoa8LKQLmHwZ4vbdI/ixm7cCIBlCmmE5CpxHjy+gkBFxTYIOYwxXbyzDsglpPu4hhAoZER3d6qsLRhCMxOylEAKAFuim1TN2LbMMIY8qb9NANrVlzFEIXQCEUF01IAt8smBIkA3L9ZsreMZD2IahGkEIySKPrCRguaUBB+8Gtr8W2PwqjOtnnDayK0Vc3oIPeptUnGPUFV9+hqhdQrtQDu8iX1OoM6otDd98YQbvvHZD7HUYC+9miNmoKJqqgZ2jBVg28MyxaeDYffgud2P35nL3m4ndO6C4lcMUQnTdEpYhJIs8ZIFHQzVR6+gQeA6HZxt49sxy12M7ugmFMzztvIs+hVAlJzv1nFACxmsZK465gcARYOSF6e0yZljIerqmMkJrKE+PieOAPW/C5CAJlT5LiUDWGXU1oUg8eI5+vsUxnM5eDgAYTdOQQCkB2+9Y9WPzIisLePjXX4d3XbdxTV9nrTFeUpCTBb9CyAs21ocohFpcFnmQjDvbex0WRoCbfhLf4V+By1tPOp1Ue6I+TTbHIepEVrCQhXDyjbXZnql1Lr0MIVZ4vcQIoUpORrXp7lFY4XFquYPpmhrtNklACJWzkmMdTwM3VLoHSdwJKDsBcv+lyhBijpF1hdA6zgfaa0QIjRXQ1k2crbbdwNskm8XWIpAd9FVuVZsM/CVp7QihgbzkLH5ZgHLG7kSESsdYxgyNKEWAriokQBZgOdCFWYxC6PCZGYxgGaXRzfHyxx5hw3Go5OTEbefnm6q7eATcKpKXEFqgVduhXamOg5EuSVQrSy0dIs8lIj6SvvZATsKZFr02VaYQ6lZVBMOvq96NMiNW2Vet4SqEdK9CiJwrb6A0w3hJwaHZuvO6vgyhiPP8rf0z+JsHjzthqskUQslDvJNivqGetw5jFwrYNcjGt+PzTWwfyacK7fd2FBov+Qkh8twrJ03qqoGMGE9+ME9906bnUIu2jAEk2DCtQqjLMvYSZgg1VcPJD0uKPWNFnFxoOgRgGKIUQgAhjnPVA0DtDFGqDO3AoLWAAaG7a1Y/iMtb8IFV6SPyVw7P1HFgmoxDoZlEzDaWghD68jPnoJkW3nvjCjbXnvwMKzC3NlUTN20li+7GgfsAvYX7cUP3vbjplYBSAQ59w/djkiEUHiodliEEkCwcohDSneD5/VPdc35Ht2ioNL2/A5Yxr+0hlBBileZMiZyz5hxgRp9nliGkd2UI0TWLlMUb947hp2/fgbGSf8zeOJDFuWrbKUZMrgEhxHEc8rJrBWGNIkLbR7/EuBg6+XAch23DeRyba/ojEJQK+crUoCEKoaadRZ5T0dJMtOqL/r8DcK99PVknn0hoG6tPR447bB0YqRAqehRC7UtJIeQ5Z5dYqPRATkZdNZzCGNubTS93cK7ajiaskyiEFNFRd6aB7rSd77Gf9Y7b3lDpNBlCjkIoXfHtYsI6IXQ+4SiEpqIfM3cQePpzpLKZEKyj0pHZhltpS6QQWgRyA87GlueA8UEiCy6Ka9eVxpunw1oSy1Yn3DLGx1jGqicBmx6nGkIIFWSXEAprO0h/durEIUiciYGxTfGDW4+w4ThUspKjcumFaIWQh7leOEy+plYI0U5fCUiKpaaGgby8qgu1sZKC0006uGtkI0RUFTYmFx93rH+KJKCtu6RktaVjJz+NfHvKJVZZvoPWdDq3+BRCNDcoLEBzoqw4LsNrN1UShUqzrhsv0o1Ir1BpgHzeq60QWmiqbgvjSwQFqqphxMbpxZYv8yAJRkuKs9D1WsYKwRBiirm6imt/55vYd7ZbiRCFJItnluvStOg59HSfqbZ1SALny1LZVJFxpfasf/w4+XBsJYt9TqyqlzjvJinq08DsAfL/+SOkNXoEmqqZ6F7xYvsIUaCcXIgmwpgEPax6Xc5K2L74XfLNrrsc4nwLVqcYk8+IaOuk21YsWPGH5sYE8Z/PuWuBUNuiE+ibnBB64uQSNlSy2DuZXD3XBU91vF1fJGPimSegGRY008JkWcFkWUH59LcBKY9HrCsgBdUGggjseiNw+Bu+TnqywMOy/Z252BiZywhAbYqsgzzIUVKj1iHqJJ4DpoIWO5B5TYHuUQgVfJYxABigYyez9/jQqZFNhCDSz9wGmrORHxPHcRB5zvdeNNOC4ll37Bgp4NfffFnXPLppMAfDsp2srNXq5hlELiOgRcnGi9lufKFg+0gBx+Yb5BpiQbXMtuUohFiXMfc81O0M8iDXdHWRZop5bHoP6pdD4xU3qH12f3xxuT4VOW4wQigqrLeSkyALPKaqbTQ1s/8sspcbvMTBJRYqzZwArNDC9mbTy22cq7ajCeseodIAtYytQCEk9VQI0TWaUiaqUF6kodJ0jE/Sdp7ts9YtY+s4L2Ab2Thf+hd+BPjyzwKf/4GuMMcoMD/4oZk6WpoJSeCSyfPbS0B2wKmQj5UUjA+SReRaEkKVnOzk6bC2tqLZDg+VjlMIzR92/9/p3rQN5TPIcipscOGSQTpIzJ4goZh8aSKeENKayZjmEAzkZFTbes/sHsO0UG3p/tweIUQhtHgcAAcMbE11HG7if+/BeamlYWCV7GIM42UF5+omeU90oa4aFl7Nv4hXPvjjwLmnAdAMIY+Kaaml42PyX4K7+9ddYpV5vdUGmQSEjE/dtX2kgE9+4Ab8wE2e7jcUE3Ryy8kCLp8o4cxSyz03WniG0CztSHZktgFJ4BLZMXKBcOzVwHxdu+QW9GyMqqs6TMvGmaU2NqckhABiGwPgs4wVI9qUn15qodrSQ5UIUah1esvrnXvQoufQs2Gttgih5N083qA+hs/Lv4epw0+SHzQXgE+/Bfjen0e+RjNoGVtthdB9vwd8/gfJ///1J4Gv/nLkQxuqEan8iMIObzhrBJbbOhSJD22fXcpK2NJ6Dhi7kpAxlFjZYJ1LdRxRcFRlvYg2VvyJqNR/68UZh6QMtaBteiUZK4d3Jz62aktbuYKwvBELQzfAtDm061XgqX8APnUXWnUy5uYzIvaMF7Gh9iyw5Wa0LNFpwe7DzjsJcT9/yPlRhipBvTlCT5xYwlBeRkEWgXt/F/in9/uepkAzm+odHQN5GaNFBWer3YRoR/e0nQe6FEKA2+l0e5hCqL3kdu1kuU1xBTyQYGl/lzEbZY6SvJnoLDqWa/fo8UUUFdGxkq428rIbgD5XV5GThUTq1nX0h+3DeZxZapNCFyssFSgh7GQIUbW4R4VSsxQUOXJN16uMECLXomXZWNYFnCnfCBz/Dvnd594HfPM3ow+kMRNJCLkdXcM32hzHYaKiYN85sq4uZy+R68VblL7kLGMse8+/NzswTfaV0YRQ1lfUCkNJkfoKlU7cdt5rGeM4YPRyYHAHkB8hregHt/V+Mba3Ww+VXsd5AVM0RC0wFo4C8weBbbf7H98DlZyMkWIGh2cbaGlmMnWQoZILX6k4i4MNlSxGBysAgIKwlgohyVEILTYJySEYrQiFkBTddp62uwUQbhmjCiFDyIYGQduUJNopzpEfFHsQQka7b0KokpNgWnbP1ouLdDD2KUA4jpAdpocQqk+RwU5MN2kxookN9nFYaumr1mGMYayokNBEOe/Ipzu6iXH4VT9ZWUBLdz+r5baGQa4OVE/5LWO2TZRGcoF4gL2kGYA3XTkeuvidoBvlsZKC/3977x0ex3Xe+3/P9o4FFp1gBQk2UaQoqlK9S1ZcZce+jh332HFNbMclvr7JjfMkv3sTJ3ESp7lfO45L3CJbkiXZsS1ZVqO6KPZO9Lq9zu+P95yZ2d3ZigVBct/P8/ABsAAWw90zM+d8z/f9vis7fYhn8lSuUyjQcbn82DcWxU+eM87VcekQyhW0uifUQ50+HJ6KU8ejFtGOJWNKRImlchidTyJX0JoShHau7oTbYdODxQHDIVQqCKld9UYmMvN1dGRRC79ZTS4WlLAJGuelDqN1DjonTh+VronYOAANeOknFf9GVC8ZqyI2LIbkLDB/gs6XueN6pykr4ulcw2Wna1U462TlieZ8orIbq8PrRCA3awgxXWtRgMCK/MmGjqMS/nrLDFUGjUUodCKTw76xBVy3kYLRLUW71VcCHz9BzQ7qZD6Zte4G0wgv+ywO3PoNxOBFNj4DLJwGCjmkZuj1C7gd2Ngfgj8/h0JwANmCZr24DMvOY6Y5j5rcqxyh6VgaD+wdx6t3rqCst8Q0jSnT5onPbcd0LINsXkPI48RA2IPR+fL7dDpbgBPmkjF/mUOoO+BGf8hjPSZjY8YiWn2sUeLvsNmKuozl8gWsEfJ971pX8fdUy/t949ElyQ9SmAPQKRy2ve4dZ5p1PX5oyt2oSlZ0h5DqMqYcQsb8ai7nQtBGjyfm5JxUlr+onMX54HraDEzOAfNVrruFQnVBqIZDCAC2D4XxxFG6N7VPhpBpU9reXudJp94BmjaulZvwSelgXFHJwegO0fqrymZ3R9Oh0tIhVFMQMmVuAcA7fw5c81ESZD96ENh4R+0/plxE7BBizggJOfGPjlufPKrWfofcHbNwvVRig+w0Fk/nLFu3lmHqpqHs/INhLwZkyZhviUvGFlK00z8dz9AEMZuokiFUYdJtFoTS5a9Vl98FL1LI2qwnW+NJmsBeFpa/G+irbn/MpZuuK1YhsR/+9jP4kx+9UHGROSNtmpHSSZujROyIjVcsQ6iGEoTqyTOajWdaLwh1eDAVS0Mz7dymsnl0CjlpT1MZWWmo9FwiC59I0+RcOe2ycQps1Qp04Xd46q7/VQ6hvpBb36k9MZuQNwMNcAfwuZ8dwB9++2ndOaQcQkDlrItS7tw+gEyugHufb02pSi5fwEyifR1CsXQOx2UL9mYEobftXosff+DqokBu/blLFuSq/LYRQWghmatdMiZ3W6eVIGQS/ucS2aJAaQDoyNH3p8eO0wNq/J/eUzH0Vi0AI3437DbRsi5qOtkUlfJGT9PxzJ2oWMIWS+cadiQE3A70hzw4VMMhVOm1DnudCOQXjIBJpxentW70ZiuXtjVC/YLQKG1qqOMw8dzJeRQ0YPf67qLn0jQND7w4bnRZrKdlrgkaQ4tcwNlsiHQEsKD5kUvM66Jldo6EHb/bgU19AYQRxRwCyOULegv2IixEFbUYVQ6h7z91CrmChtftkk7OTJw2P0xCacDtwOg8ja+Q14HBDq/+tZlULg+3ljUW2u4gbeSY5hAfunkDPvu67db/7+iYId7VKwjZBXJFXcYKWCdOo+AJG6XMFgyGPRCCpoJLkR+k8Lnsehe3yVj6rMwPOp9Q96WTs2ZBqLZDaDbngldLAtCQjUqHkJe6BKq5UCK0ljZID/+cvj99iMSfUhLTdH2u0J3QIx1Clues5OLVnbrzrX0yhNq3ZEzN9WcTWcQzef36rDpYV7xGeUI0Jqs4a0Je6mRdT3djM6pkzF2r4kXvMhamj3YnoByrDld9naF1QYgdQsyZwLyQlQvfIvbfA/RsBgYupK8bEIRWR3w4NZuQDqF6BCFDUVWL28GwF1duWkGf+5cu4K/T54Sm0YR+OpZBr98GUchaBz/baziEwqvpc4vXyuO0I2TPIiWsJ0B7J2mS2JNVtv7+6qHS2WR9tagWqNKrB/aO42uPHMWdf/+rorbqAPD13xzDX91H1vqyVu8Od/EFNzpasQyhGrpDKG4tCKWyebz8Hx7Cv/7yEDmEWpxV0x+i7J6cw6+fA6lsAWEhzwfpGqK288UZQh4tTSGfMVOmw5xcJLsC5aJZFVSGTH/Io2fRHJ9JGOUFrgD2nl5AKlvAhAziVA4hoL4OYwBw0cowVnX58KNnWlOqMpvIQtOA7kB72ZmDJhfPiUUIQh6nvazlsnruaKlDKNO4Q6iekjGVxzCbcdCYVfcFWLs7hCwxTk5Ld0vC+HkcKA7sBYDnT83rYzbgccDvslsHFi8GJbyOPiMf0MrakytiTYRKA7TTfriaQ6iKINThdSKkRfUd9kJBw+FCP7rTrRGEVGfOms4rtUtvMSFVXdSUIKTG3y/2T+IdX3sC973QnIg8l8gs3iEEctJE4UMhuaCPudw8Xcf8bjs2R2xwiTxGM14UtAq7uBZlV6UOoe8/dQo7VoaxQWa+6Tu0JiHG73JgfEEKQh4nBsMenJ5Lli0wUtk8nMgUh0oDRWVjm/pDuFK+5mVETQ4hfy8AUVMQ8jnteGksioJcPGfyGtaKMRQ6h6suRNwOO/pkN6elyg8CjHI7QJUbt9e940yj3KdjCymjZMxPLsBKDqFMroDZnBt25NHnBfKJGSp1sdN1U3VUzIdlyLzKGM0mrCsOoqY5rQW1MoQAEoQU7eMQMs0p2ixUWm0izCYyeqC0uct8ZUFIlthaVGkoQh6qkGg0PiFbt0PIVDLWLOwQYkGo5STngPv+mGzK4y8CP/uM4QZKzBgXnNJJRmqegkJHbjVsbxZByZXoC3kwFctgPpmtbzdWOWo8HfpkfUXYg54wndwurb6OWM2gRIaZeAYz8QwGfXLhX7HtfBVBaMXF9HmFi1GHI4MkrCdbz4zT/9EZP007MQ43HUMhZ/03F+EQGu4JoMPrxP95zYX481dtw4mZpO50AIB8QcP/vW8fHthLi7+yXTyH22hVCsidzMYdQmoXYKZCydjf/+wAnj05jwf3TmBuCTKEVKeVtN2nT9LTuTw6ISfs8rHSLmPziQx12IBWHDhaJgjV6RCSglBfh0cXFo5NJ4zOZzYfjkzH9cdz+QKmY2m9q0y9IblCCLxixyAePjhV5DBqlnYNBQ3o2VfkELLbRFEw9KKe210cWK1Qk5e5OsPgAVUyVv2ccTtscNoFhVh7uwznqPxbHaXnnJzcO5ITWEhlEZuTgqgrUNZ8IJ3L41Wffxj//ItD8u/YEPQ4ywKzF406z2TmF4Bix6aJeDpH2TANMtwTwKHJGPIFrSi0VzFXRRDqdAN+kULOQ4JQOlfAYW0AXcnjVa3t9aI2UepyCFVYlD19Yg6runzoDrilaEfP9fXf0DVtqo6y3lJUWXJHC5ydHV4novDClp7XRUttgeYtAbcDa/10fEcSdB5aTtpdPlrYmpxsbqcNN9uegOvF7wIATs4msX3IFICtXBQxY47kc9t1t0LQ48BAhxfpXEEvPVcks3k4tJJQacDo7lSNXJr+n+r9sjtoIR+rLgi9+7phPHZkBv/ySxJEs/kC1tpG62r4oNypS+oQcjv0a9kkl4wtOd0BF2yCujNVdgipLmP0XswlM4jJeeraEGCTDV8Uqjucu19miZk3AlSDETN6mH2lLmPVM4QAYFN/UN9cbh+HkLlkrL2EU3OGkLr3qM0zl8NWuZGJWwlClQ0MSlBsNFjaaDtfQao49STwyD9SpYDDuzhXl9pEmDoA3P+/ihohtAssCLWaow8Bj/wD8OIPgV9/Dvjl/6VdVE2jyUbvZvq50knG9EESIlZeZqicVRTXUlR46JGpeIMlYyGs6/bjE7dvwm9tHzROinx9TotmCOu1qhlMxzPo98rJvlWGkN1p3WUstUC7r/3bKFG+wsUoZMsgAesJ0BPjOTzuvASiZyNwoQxIVfZ8q9KjXNLoGtEga7r9ePrTN+N1l6zUu1+dMnVJee7UPOaTWXz01o3429/egXXdJW4ps0MonyOnTBMOIZfDhqDHYVkydngyhn/5xWE4bAJPn5hDrqCVO5UWiep6lBI+U9t5c8mYFIRKSsYSyThskONk4gXjCSdkDb2/xzJDqBKDYS9WhL3YMUQZWt0BN45PJ/TOZycTdn3deGw6jul4BgUN2CpblzdSAnPNSA8KGvDCqfrP50q0qyAUNIk2x2eoBWojLeerYWQIFU9WGi0Z0zStri5jQgiEPE7KlfJ16YvtiYUUpmLp8jJNObnvxSxe+0+P4Av3yXDp4euBseeKfjSeziOb16BphovN77YvQcmYEoSeNh6rKAjlmwqxXdfjRzSVw+V/8SD+6LvPln1/IVnZjdXrJAEg6aB7aSKTw6gWgSsfb8kOoL9CEHkZZsdJCc+cmMN22ULd73Yglsrh5GwCP3uJxJNmQjhVTkMrhHybTSBlD8KejepljULOW/xuB1wZEjL3R2m8OmwVFpfB/mKHkE3gU46vI/zk51AoaOWuOguHkNmRGfI6dUfN6ZJOY6lMnjazzKHSQFmwtCWq2Yf5/Qr213QIveny1XjZtgH89U/34cRMAlo6jkExA9FdWxBS7tSlzBAKuElszOYLmE1kuGRsiXHYbegJukkQ0kOlS7uMyfmXzKmZS2QR12gMrPDn4crMFZUbKkGos3uAymKSs0bejdV1V60vKsQK1OMQctht2CGvT9xl7Pwn4HbAYROYS2R1h5DqVLki7K3cbdhT28Cg5kTqnvaT50axb8yiSqaErMxmqzhO93yNDBjxScOp1CxC0PrumW8CD/9t3U2dzidYEGo1auKx7yfAgZ/S5/vvlXXxGaB3Cz1W5hCSJ5M3TJMYYWuoZEx1zTk1l6wv38RUMiaEwO9dO0xCjd1Bf7vOhXUzdOrWRLrw6IKQVZcxm8OotzajboLdG8hRVeFi5LdlECuUixqapuGZUzF8f8vfAO99FLj9L+UxKNuglSDUvEMIgH5BVZM/82T2l/snIQTwhktX4ZUXrSi/+JrLoeKTlJvTQCtiMxG/y7Jk7Of7JpEraHjPdcN6/XBpnsliUeM0pnn0Xdt0roBOqJIx+uiRDiFN05DJFVDImN6P1DwQkiGrJx6lj93r6WJeZ4aQx2nHwx+/AbdvI1FtTcSHo9Nx/ZiOmIbTsemEXq5wibRRNxKSq0S1ZhZ4pRiCUHvtXnmcNj0L5/hMoqlysUr4nHYIUcUhVOf7Fs/kUdCMjKBqBD1UUw9fF5CYRiKTw9u/+gTsNoG7Li4JEJaT+z4xi33jUfjy8yjYPRRYGxsrcrwoEevK4Qju2kXPs647gD3H5yxdNk2jFjajT9NHh9dyYVIoaIhncnqJVSNs6CXhfCaewY+eOa2PfQWV11mfBxEbncdxO01Wk9m8sTGQaZ0gVNshNGaZ4zGxkMLp+ZS+4Ap4HIhlcvj+nlPQQGVVzYRwKqF/0RlCkqwzAGcuppeM2RMkmgTcDl0kOp6g17WiQBvsK+qs2pk8itW2CdjTs4hlctC0kgWnhSBkbpQR8jj1spxSQSiv7pGlglC6DkFI/T3z+xUcqCkICSHwqTs3wyYE/vkXhxCIHwMA2Lo31PyTZ8Qh5KKSsZl4RpYbsyC01PR3eGXzDDn+PB0k/iinmu4QkrktccMh1OvKwJef18tdAdN9P+gxnGcrL6E58/Sh8gPQx3IFQUh2SLXsDGjisrURuOy2ll1PznqKMoTa6zwRQiDsc9G6TK4Ptg7S/bNqSaunDoeQvL4vJHO4/8Vx/P439uC9/74H+UJ1t25aLxmrIEZFxwBoZLpYTLmYwumh5wOKSvnbBRaEWo0ShF76MU2Y7C4ShNTgqigImVLShagqclhhbqPsrcchpIdwWaiqDs+Stt4zwsuoZKzHIyfVlRxCVuVb6iYYWU8XggpuKr9IYyFfvmg4Np1ANJXDhStK/v9668ESYUHT6DVpMkPITE/QDYdN4NRssSC0bUVHZUeO3WVMIvTdn+YEoU6/S+/uZua5k3MY6PDg+k29xs+2eCLQ5XNRuUzBXSFU2igZo+8VMJ/MwoeS41W7rycfp9emY2V5zlIDrIr4qIRP/v39s7SrsbLLi2MzCUzI/KBda2iS1ojjQeV5zNUR5F0L1R2uLHT8PEcIgYB0UZyYSeg7663AZhMIuByVM4TqfN+U4FfPbmpQOYS8XUBiBvc+P4bnTs3js6/bjs0DpolNNqnfG4acC7j9gn50IoqUM0wL13ymKHxX5ZK9/tJV+MTt5EZ95UWDmIym8fCh+rpWVuLF0wv49A+fp6wUFbwYnyTRfvAiS0Eokc2TW6mJDKErhyP4u9fvwLd/73LkChq+v+eU/r1cvoBYunKAd6fMJFsQUhDK5JFUglCNFrn1oEpGzYLQsek4vv6bY8YPZZNkZbe4Th+UYdmb+kn0UmP76HQCAyEP+jrcTV0vlHhZSShrlIIrBG8+Sv8PAK4ElSv63Q691NEoGavkEBoocgj1jlIgrj01hwX5fyx6HzNWDiFjThPyOnQBpTRYWsuqbJbSkrHau9FGmY1ZEOqrKQgBlBtz164hfOeJkyhMUQmPqEMQ2tQfgstuw5qIxWZYi/C77Ehk8/o9jB1CS09/yF1cMuYKAC4fcuk4/uRHLyCVlHM/OU5nE1kkpCDU48oiWFgoCqKfjFK5etjrNASh7hEgMkwlLqVEx+jeUmEDU5WMuRzVs0J/79p1+P57r9QdRec9RV3G2kQEMxH2OalyQwqQW6QgVNXBqCJOqpaM0f3/0GQMH/3uM+jyu3BwIoa7n62erZnNF+Cy2yq7k9S1eXKfcRyLwewQS7AgxCwWfSdKo4nyZe+mnIXxF+nhztU06EonGaUCTRWRwwpVMgbU2QGpWghXaV5Ni1G7DaNzKSQyeURcclJdKUNIy5fnPkwfACBol9zTUfFi5NHSmM859cBHxbOn6Oe3DZUIQqpkrtRpUrrzuAjsNoEBGYoJ0ELyqRNzuGZDT+VfMjuErCauDRDxuzATLxfZnj01j20rOrCpP6hnYbY6VNpmExjq9GE666waKq3KHpPZPOaTGfhEidCjJkWpeRoDNjuJdU0KQqu7/BidTyGTpPPihekCtgyEsCbix/HpOMZl/s+FQx1wO2wNWajVYqdep4kVJ2YS+N0vPYZ9Y1G47Laarc3PRwJuB07NpTATz2B1pHWCECAdGovsMqYcHfXkLYS8Dsr1kSVjY9KBdu1Ib/EPqnM9NITOwhz+/rcvRJctjgVbyLILkhKxfKYJ/PWbetHhdeJ7exbXcv3eF8bwtUeOUbaW+foY6AN6RiwFISWYNFMyZrMJvGLHCly8ugsXrQrj20+c0EOEF+R71VHBjdWh0fVkDiS4JLN5JLTWOYSMrndGWetn79+PT/3geaMzmlUJkmRMChkqB0sF/07H04gE3OjwOptyFM7LTJ2yHKpmcXcgoMXJkQrAm1KCkF3f5DqRov9DRbdBQIoq8r2LnPoZAMCm5RBdoOfQXXWaZjiETGX15vET8jgR8bvgsttw2tR6Pl/QYMu3wCFUJAgNkOhZqdOpifdcO4xMvoDZ43KuV6XlvOKObf341ceuX1KRxu92QNNkF02wQ+hMMKAcQkqQdPkBpx/Ts7P4yq+P4vikFPHtxmZRXKPzKOzIIKTFUPAWZwh1B9yw2YSxGRZZT/+sSsaiY1UjBZTAU8sh5HHa9bKhtkBtStvr7Ex1ntHpc2JWZggFPQ6slkJ1VQdjHSVjar78vT0nMZfI4v+9/VJs6g/i7x48ULXzWCZXqJpzZcx9tMWXjAHFG/6JxW2gnYuwINRqMjEAshZx1RXAdplN88w36aO3iy7Uj/4T8Jk+4M8Hgef/s1ygqSJyWNHhdeqt+Xz12PNT83ScrmD59+zSafHSj4Ev3Wbd1rJenvgS8OWX0UTv3k8A93xcr1VVE2ddELLsMiYngqUuoemDQHgVTfyquKncWgpxzV0WZvbAi+Po8Dr1PB8dJUqV5kwox1CTGUKlDHZ4cXqOFgXfffIk8gUNt2ytEhLtcBuLMCtrewN0WTiEoqksDk/GceFQB3wuB9bKDKNWt50HgJG+AE4lHcUOIYtQaYAWcrOJLLylDqFgv7Gbo8Qhh7vplpFKYJiZoZvAsxM5XLAihFVdPhybSWB8IQ0hgN6gG196yyV4x9Vr635uh92GoNuxqJKxhw9O4Rf7J/GDp0+hO+CqvGNyHhP0OPDMyTkAwPqeQPUfbpCQx1kWUGvuMlYqKFuhBKF6OrIE3U76eW8XkJyFd+xJ/NT9MXi1kuuOOtcHdwBaAY7UNAZcCUzl/SZBaBT41puAz/Rhw7euhRuZIpeo22HHnRcO4L4XxhY1BiekaLVvLFrkoJy1d+GEbQVNoP58AHjmW8bf/tn/wscd/95QiaUVd108hAMTMb0FrnLP6MKHpgFfuRN4/IsAQDvsAKY1ukYkM6aSsRZkCHmddtiEIXjl/99d6HnxK3Ajg46vXAcceACYl44mi+u0EgCVs9fvdiCWzmE6Rl2gmhWE5pKyZKxFIbA2r2nDyN8Db2YKTjuNKbWDOg96jSu2sA4OkJPt158D/nwAgfHHcVKjLl/JOWqvrQvsWWq7DaCsyxhApXQepx02m0B/hwejc8b1PpXNww35mumh0vL+nonRhsq/XAMc+rlxbN9/N/Dfslw8NgYIO+AzdSAL9NHxxE2dLSuwssuHbSs6sBKjGEPE2vFcghBCz9VbKnzy3DsqmyT0skNoyekLeRBN5ZB2yPuUOwi4fMgkZCONVJLm2fI+PpvIIgaaW3bbYgiKJLlAJVOxNLqDci4Wkc4zJQjNHSuPeIiOVswPAgB3HRlCbYmaU7ZZoLQi7HNhLpGl8RZwYyDkwTuuWouXbauSV1pHlzG1SfbU8TmEfU5sGQjh9ZesxOHJuH4vtCKbL+Ct9p/Q/AYAfvJHwIP/mz4v5Iuvy60oGXP5gY5V9DmXjDGLJh2jXam7vgTc9hdUItaxijKFANoRvu0vgCvfD1z2exSYfPKJcoHG3dFQyZgQRteduhxC6QUSUqx2CBxuusGcfAI4/sjiJtBPfBk49hCV9jz5FeDQgxBCYDDsxWNH6ITrcNRwCAHlreenDlB+ECDFM+vXyllIIQl3UceW+UQW974whlfuGCy/Ieqh0iUXqRY6hACyYJ6aSyKbL+CLvzqMS9d24cKhcOVfkFkjAOREWRhBhQ3S6XdhNp4tUuafl4HH2+QxbJFlK11LIAht7AtiLCFkN7cccukEvEK+P9I15FEOoUwe07FMecmYt8uwVOuCUPMOoVVSELr/Kdpt27ByEO+4eh1WR3yYS2RxcCKK7oAbDrsNu9d3N5z50OFz6rv3zaACyLN5Dd1tOqEPuB16uOZwb2sFofW9AewbL76GKIdQQQNimdoOgUZKxkJeBznGfF2AVsC6ifsxIk4AcyVt0ZVLYmAHfYyOotsWx2jGWywIHbgfcAXgjR7FGjFWVjb8O5evRjpXwOf/2zr4uR5Ujta+0zNFuW6PT7nwwRdHoF39EZpIHzYW3J5jP8MVthfruydV4doRck8+fJAEhEflvUMX9MeeBY7+iu4xAHx5ei+ncjTBT2TzSMod+Lo6TtVACAG/y4HDUzH89Tfvhv3Q/bha24PtnnF0xw8Ae74KHPkF5fENXlT2+2PzKYQ8Dj0bJ6gLQotzCKmOeK0S8h1+w6WA3i1wFVLoc8n3PjmDtCOIPNTispIgJBemD/8d4O/GzMUfwN/nXgUASEcnAZhEVPNcwywISVHDnM811EnlvIpUNo+QkF+rRYraZMrE6DwZfQY49KDxNw7cTyJioWB07jTPiVS78PiU9f+thGtGuhFGHLM4e1wVqtzu2BQ7hM4U/R30Go+ufiXwqn+l67zTh2xa5iamk0VzyblEBlN2GmuDCeqiqvLPAOoO16Pet423A3f8FbD2WpoDawVg9qjxxzUNmDkMdK6peHz1dBlrS3SHUPuViwG0kUCh0hlE/C7YbAKfunMLNpRunJupI/M2KB3tuYKGbSs6IITAiCyXPjhR2b2ZzeXxOu0+4Mgv6YGjvwJekmtplaWqaEXJ2C2fobW7sHPJGNMCMlGyiW66gzpgCQFsvM2YQPsi1Fr+5v9N/wJ9NPBKBZoGS8YAo4NTfQ6hhcqKqsNDeTVqclZPhw4r5k/RRB0Afvopej45yXvZhQO6MtzhkBNfS4eQvDCbHUKaRhlCSgio5KbSNDjySSTgxowpRPlHz5xCJlfAa3etLP8d3SFUUjKmvm5BhhBAFsyxhRR++PRpnJ5P4d3X1rCXq3BLTaOJrb+76ZtWxO9CRmZwKJ47NQcA2CYzla7b2IvhHr9+IW8lG/tDSGpywZJLwpEyXXhLHEKpbB7T8TR8QgpCqvOGrwtQlmqzQ6hJQUhlOMzNTqEAG770ruvQF/JgVRc9/sih6UXtrHZ4nYsqGTPnTVVs/3meo3JoXHYbVna2NoR164oQTswki0S7hKnLXT1inlHGVPu8XNXlw2Q0jbRTdvGIyW5hpdcxs0NIfh3SFjCW9WGsEKbHTj1Jjp0tLwcArBOjZZ0mNw+E8OqLhvDlh4/ixExzAv+4zCA5NErCdE7QOHR2rsCeaSde2PQBYODCokwLe3wCIcSbKhkzM9Tpw+qITxeE7n72NNZ2+3XhGvvupY9jzwLzp+DJziOpuTCTob+barFDCCCR4ifPjSH5PE1Q19vH8PZNUkQ8+CCw97+AoUsBf6Tsd8fmU3owsnquWDqHqVgGkYALHV4X5pO1RchSlCBUj0utHtyBYkEIAFY6ZXlvYhpZt/H9iuUnqnQlMQ3seCPiuz+BA4UVAIBslMaSfs4osc4XKSozU3Mas9i6sT+IA+NR3b2XyhX07Cg9kNdcMqYm+FNSFM1ngcQU7TKffsq6I5zadKhzt/jakV74kEZaLK3rpxGU6HhoMoaA21FfxiSzKPpDdG6fygaA7b9ND7r80KQglE2nilwo+8ajiHR1A/5e9M4/AwCIihBS2Txy+QImo2mjrNDhBi59J7nnI8P0mDlHKDFDmV/KSWSBCpVmh1AJav7fZoHSik6/C7OJjCxdrnOeWUfmrcNug19ed9QaQ7W0ryYIdSSOYhXGaF2gaXQdnzlM7iCVS+eXG+OtKBlbew2FtZu6v7YTfDVoNZm4MQlRjNxmfO4JF3/P10kDr1SgabBkDDDs5756AuBS85UVVYeLHDFqclZP/b0V++UkPThgdINKLwCZOF6zc4X+YyG7FGusHELqpmluPR8do2BQJQRUuhjlMxAaZUdMmzrUfHfPKWweCOkJ+kWoDKHSUGndIdSaid6KTi/yBQ1/+8B+DPf4cV1pdkgpgT46pvQCZVM0mR8EAF1+utmZRbJnT85jqNOrh1rfdfEQHvzwdVSz3mI29geRhpzY59Kwp+foc5tDH3PmkrGZWMYoGeuSEyBfxBCHlFNsERlCnT4ngm4Hgkig4A5CyMXN5gHKU1pI5XDNSJWMpxqosL5mOTmbxOaBELxOO/o7WiuGnCuosqM13b6WtZxXXCBzEl4YNa65CVM+TD1uDaNkrLb4MSxL3kazJDiuzshFaul1LDpG18DezfKPnIY7t4BZBHDD5x5DXPiBow/R9zbcCgBYK0bhc5Yfw0duHUG+oOFbj58o+149TEh31vFxWsSf0Oh8uPzCLXDaBX7w1ClahEwfADQN+05OwJmZQ1AkWyIs717fjd8cnsHYfAqPHJrGnRcOGKWT++8xhIf998KemsU8gvr7VtxlbPEOIcAIln6VjzY9BjGJS3w0SbVl48DEi7QZZMHYQgp9pkYQAY8Dc4ksMvkCuv3KIZSpmq9gxXwyi5DHAXuLrtveYNj4ok8JQvIcScyg4DGCbyu6DcydjkZug8thw6zMdsrHaSwZJWNSrOtaR5tSMjBdnftBk9C1qT+IRCavZ+NQ6bEUhJSQ4/IDELSgUBN8lbli6nyG/fdYC0JKWKpzt/iiVWEEbGmkbWePIKTcec+enNdDzJmlRc3Fx8yh506fPr5zmZTuECoUNDx1fA4Xr+4EIusRmKUMqjkE8LLP/Qp/ff9+WUpqIVKoObA5R0h9rr5ngZ4hxA6hYtSmdNuWjDmRzhVwcCKmCzZ1UYeBQYn+F8rc1p6AGyGPo6ogtGnh1/RJISfXpFG6L8yfAKLy+r1mt3EMrcLbxRlCTAtIx4wgOcWaq0gk8nQYmTgK2WWmTKBxh4B0A4JQagHrvHSz6cR8bXdReqGyoqq6jOkOoTo6dFix/16yrV7ydvpalX9Fx7C+N4jt8sLgV+4Pq5p7m0WG0LTcDdEdQiEqNSrNOpIT/yTcmJSC0Gw8g2dPzuH2C/qtc1gqOYT0DKHWTPRUydHJ2STecOmq2sKLWuxEx2R9eJWa3hp0+el9MAtCL55esBbIloA1ER9yNrVbn4QzIwMWO4aMLmMuujQlMnlMxzPocsn3XwV1WpaMNZ8hJITAxWs6sTUCOLzGebE64sevP34Dnv+TW/Gx2zY19dwAdf1ZlENoLolN/UH8x7suxwdvrN295nxEiQrDLc4PAoz2qi+cMq6biWwOQbkQnavLIUQ/E6yjZExNto7Jlt1OSMHbyiEU6JeLagFM7oPQCojaQsjkChjXOoGp/fSzA9sRd/dinW0MXiTLGhcMdHjRE3DrpV+NkM0XMB1Pw+u0Y2aOjvFwnkRsb9cKXDvSi/969jQKXcNAah4vHjqKt//jj+n1QELfHVwMu4e7EUvn8InvPYuCBtx54SB9IzpGDo9L3k73m/33AokZLNhCeqZOIpNHUmutQyjgdiCEGDbnXgQ610BAQ+epX2BCCxvXt5EKgtB8CgOm7BhzxlJEZghl8xqS2bzVr1dkLpFBuIVlvsEOU55O71YAwCXac1TamJyBMHVCquwQkiJLcAAY2A63w4ZZTZ7DiWkIYZzbeuC3Ev6laKMcb+Yw/Y39dM6+NKaaE5i6VSohRwiae6Vjelc0zB6h+YQ6P2xOcnMtnKzuEMokgIXqXXGcdht6PHnrza1lQgmXmXwB21eGl/dg2gTV5KUoH8Xlgz83h51iPwpZwyF0eCqO+WQWO1d1ApFh2GQ8wmjGh0OTcXxvz0nkCpp18LingxwS0wdpzh8dM82Physen5pfudghVIw6bx3tKQipUmOfy4G37a4/JxPu2gYG5Vq9QDqEhBBY3xuoKghtjT5sfJGJGeaEqYOGQ2jNVcYxtApfl3G/aCP4atBqMrFyh5DDTRPD8Kryn1fWtFKBppLIUYl7PobfOfAhAMB1j78HuO+T1X8+NV+9ZCyXMSZnzTqEjj4MrL8J2PRbAARwwWvocTnJe89163H9xh64C/Km6axWMmZyV4w9Tx+7R+ijOwRAK99dlxP/tPDoOzWPHpmGpgG715fb+OkYvEW/q6McQs7WCEIrwvQ8LrsNr945VPsXzB2FFk631CGUyORwZDpe3O56CXHYbegMyZ3KXBr5qNx9Da/SxUevdDgkpSDUrYLHB3fQRCo4AIRXA8FBwynk8NLuQYO76oovv+US7OqzlQmlAx3eRdvsO3xO3UHSKLl8AWMLKawIe7F9ZVjffWw31KJ5KQShSMCNgQ4PXjhd7BAakOdpPQ6h+WQWQXd97ozVET/sNoED0ZKJZ+mkKjZOGSx2J53zp54AAHzwzsvx+9cNY7SgslICQLAfc95VWCdOI/zzTwBfe0XZ3+3yuzAdb9ypNhVLQ9OAK4YjcIN+PxqWAmlkA1550SDGF9J4KUdukKefegy9mAMAuEUOfnvzYqjiyuEIbAL4+b5J3LS5FyN9chwck5PG9TcDI7cDh38BLJxE3B7Sz7lUkUOoNYJQ0OPEdb4jsGl54NJ3AQDE+HM4IFZjf+gKckv1lIvI2XwBk7F0sUOoSBBy67upjeYIzSayehfPVhAMkyBSEHagZyOycOC1iW9Rs4nEDOwBkyBUyW3g8tN1evPLASHgctiwAD80CNiSswi4HcaGSFa6t9RiVk761etjLhkb6QtACBlyDnqPw6o5gUmogjtIcwPlECrkgLnjhiB0wauByZfo3OssWQTpDqFZ4OG/Bf75qppzsj5PHrs21HFPP0OYyzV3sCB0RvC67OjwOoscQpq/F/3aBL7n/hNcnHlcdwjtOUYLz52rw4bbGcBzs/S+qVLditlPqtPY3X8AfOEm2iCwOWl+VIHrRnrxgRvWY90S3EvPaZxeAKJtHUKd8t7x7mvXIdJI1pinduZtyONEl99V1MJ+fW/A6MpZSmIGw6kXMGmTzvzkrJElO33QyFJddz1l/nS08Jrr5ZIxphWkLQQhAPitvwPe9IPyx3WH0Fx5yZhWqD+/Z+xZdMYPwY0MgvP7KXCrGtVKxuwu6RCSk7NmLPb5LP1+oB/o3QR8YA+w+wP0PTnJu+2Cfnz5rZdCZBP0N0vdU4ApVNpUMnbgPhKDOmTZmVrAl16Q5MTf6Q3qN+ZfH5qGz2WvHOCsC0Ilu+jZ1juEhKDXoKueTBglAE3J97aOlraVUBk0amH40lgUmoYzJggBQE+Y3rNsOo6FGTkxD6+i80fTdAEmlc1T0KpL7pTveCPw/j2Uy3HNR4F3/bfRHlSFNDZZNiaEgEhHW7vTIFFhfY2WgAC0y5gvaFjR4tyccw3lvBnutRCOW8DWwRBeOG1yCGXyes6LcppUYyGZqzu7xeWwYXWXD3vnS655pdewxLQheK69hvKCAAQ6e9HX4SGHEEALaCEw7V6FYXEajgP3GDtoJiKB5gShCbkouWZDt16+ef0NtwMffAZYfQVu3NQHv8uO/zpB783pw8+jTxg7bAEsXoTp9LvwH++6Avd88Gp84XcvMRyeqpwntILy+fJpYOw5pBwdurMrmckjqWcItaZk7MO3jOB9V8pS31WX64+PO1bgKz0fBd56j2Xr4okoiWsDFQQh1WUMaFwQmktmW+oQCnfSZDzlCAHuAN7p/3v8V9dbyE0zfwKuoOEgquo2eOfPgJv/VP+5AmxIOUKwp2eLM7d0h5C8v8myAKtQaZ/LgVVdPpMgVECXiCLv8Bc3fwj0krBqLgGYOmCcHzd+GnjbT4G33Qdc9u7i43a4aD6XmKZFSGIaiFZ3CYlsAnb30lyjmoEFoeVhRdirlzMCwPQVn8Dr0v8TcwgggCQ0KTrsOU7nwLruQFGZ15OTxdcOS4cQQNf+yZeA/fdRKc0LPwC61lrPpyWdfhf+8JaNLSstPW8QglxCbRoqffWGHvzxHZvxjqsbXF/UUTL2sgsH8NYr1xRVZqzvDWAqlrGOUzj4AGwo4CHPtfS12fE8fZAabvi7afx/4KmKbtym8HVxqDTTAlSodCnuAA3eUnwREmeSc8XOBCXW1NNprFAApg/BpuXxuq5DsGm58jaUpdQsGUsbk7NmQqVltyj9tehaV1z2ZCabqGyxLm07n1og51FRLlPI+F7R88o8Gl8Qp+dJ0Pn1oWlcsqarcpheLYdQiwQhn8uBf3rjTvzxyzbX9wtKEFJ5IVUCA2vRKQWhWbkw3DtKr9uWMygIDfXSQvaRfacQkC2i0bEK0PJALlWcIRTPIKwHjweAsAwDd/mKW6uq965JQQhA9bD1RRD2OZEraIhnGisBAaisEEDRzko7ohbN63uWJgdj62AHDk7G8NHvPIPj0wnEMzkMWjiEMrmCfu6YWUhlG8rKWdcTwPPTGjRhuhaVOoQSM4ZLwXzN83ahO+DGhBamr+VCYty9Eh0iAZFe0MVVMxG/qyhPzcyx6XhFAUKVme1c3Yk37iQRpCMU0jvZeF123HpBP755QINmc8IXPYpBu/F/8eZbI8JcurarXLhWr5knBKzerd87bf4u7B1dQDZfQCKbR8HuAuXJtMYhdNGqTox0yffb36tn5Ux5VmE05QQC1pljanPC7PTzFwlCJodQg50J5xOZlrWcBwCXPwwAiNvoNd2f68PjPa8GQJN6h79bLwesmusVGtCvzw67DXabQNIRgiszV9yVT4l1XdKpI0UblYNT2sFvY18Qe8fo/pHK5hEWUeQ9nUU/g2A/CUuJGWPnf/ogiUTCRvOSVZeRqGdVKqJc3GreYs5rsSKTqKvl/JlCvT/dAReG2nxT4UyytsePI1PGde90wo7HtM14wXcpACAnaCzvOT6Li1aFySUnr+NJuPDsGF2nlWZTURDq3kDuCRXtMHesan4QUwOXr21Dpf1uB955zTo9Y6pu3KGaJWO/e+UavL8k7qBqsPS+ezBnC+Mlzw76ukgQOmCU0wNA52rrjtnNoq75TVYbnKuwINRqrEKlq+HrAqABC6eKHTu6yFFHjlD0tJ5x82ebZWBoNUFI02p0GXMXdxlT4k4jKBHJ/Fp4O+lCWyoIZRLWHcaA8rbzh35Gn5sXR+4Kr5Wc+PuC5BCaiKZwcCKGK4crlIsBplDp0rbzrXUIAcBtFwzoneFq4g5SSZ0qj1jEDd/vssPnsmPfOL2ve0cXEPQ4zuhk8aJ1JA5++5GD6BQxFFwBo2tYJm4IQpk8pmIZdDgyVBJW7aKvdoWbzBECIEspW+8QUgu8ZoKlVYexdncIXb4ugpu39GGkf2ls7nddPIRbtvThu3tO4puPH0cyk0enzwW3w1a0MP+3Xx3GzX/zS727kWI+ma2rw5hifW8Ah6eTyLnCSGsOZF3hclE7OWOUv6y/0chU83WiJ+jGhO4QoonWmN1km5biqplIoLjjoiJf0PDKf3wYf/vAfstjHZeB0v0hD95wkdzYKOm4+IodKzCX0nAc/VgnRnH9CkP8FPVsbDRLap7uKw43LeiHbwAAdPcOIJ7JY8+xWSQzeXicDrrPtChDCICp+6RPfw8WfKurZk7pgpDp2m8WEjt9Lr3sq9HcMXIItXB32+lBBg7MyRDoWDoHm78bWEmLWvg69Q2GRgJq3Q4bEvYOeLLzxSHsSqzz99B9XZaXe5w2XDvSg0vWdBU9z6aBEI5OxZHK5pHKFtCJGAqWgtAonUsdQySwTkuHkL8XsNVY/CgXt3IUVROECgWaK1iVvy8TqsvYjpVh69xEZkkY7vbjxEwC6RxdB0/P0bViZgVdnzJw4vBkDPvHY7h8nZyTdq4FhA1REUQ6V4BNQP9e1ZIxgOamA9uLH2Max+lr25KxpvF0NJZ5K9nQS/eVp47PFX8jnwUOPognXZcg45DzPXX9dfqoy7RVE4BW4e2imJJmO2yfo7Ag1GqsQqWroXZ/tUJ5yRhQX+t5c8vJ/ffRx2ouiUycFgsVu4zJ9t2qVEydFLkM8Mjni8Wmp79J7eVLUblD5tdCCHJ0lDmE4lUcQiVt5/ffS53aVl5m/EylkjE58Q8GOzA6n8KTR6mE4bJ1VQQhIUh4KF00KJGhRRlCTRHsp3IxYTN2UJtACIHX7BzCfz1zGidnE9g7GsXm/tAZnSx2y5KxWDyKQVcSNl+XMVbSUQQ8DrgcNozOJzGbyCBkz9bedXW0wCGUrlJKuQg6vDTBqCecuJRTc+wQAoAtgyH825t3we1YmrbJK7t8+Jc37cJghxcnZ5PIFTT43Q50yHI/xaHJGKZiad11qFhIZhtq9z3c40c2ryFu78AxrY8WsuZrWFYG+ytByNMBrL6SPvdFKCBaF4RoAXDSNlj8R0ry3yIBFxKZPBKZ4pbme0cXMJvIVmxJP7GQgk2QoGSIIMXjcfdwBNuHOnBcDGCHbwojPpMrqMGOmQ1R6nbdeDsAYMXgEOw2gV8emEQyk6dgYqevZV3GABS/FjL3Jhlaaym6KVTQ7ICFQ6jD64TLYWuqZKxQ0DCfzLbUIQQAKVsAk3k/NI0cjn633diQ8UX0kmdnAzu0LocNcXsHfLn5YhFV3XedfkPIAd2zvvq2S3HTlr6i59m2ogMFDTj2i6/BMUubC5q3RBAK9FN7+dgEzbci6xtbUOgOIdnVZspCEJo7ATz7beP4zyKHkMthw/ahDty6dYkWT4wl63oCKGjA8WkaE6fm6LwPbL0NWc2OtObA//vNMTjtNB8DQIJ2eDVidrqe9Yc8uOviIVy0KlwUqF6EEn/WXQdsfVXxY0zjuPxtGyrdNI1m3kqGOr24bG0XPvezA8XNLo79GkjP4xHHJSiotaFaN/Zvo9LI6UNLJwipOdfxR4Hnv7c0f+MshAWhVpLP0e5QQw4h0+SlqGSsgshhhdqxsrsMFTVfxYmgnrNiyZibRB/dISQXFcd/Ddz3CeCF79PX8WngB+8GnvxK+XOoSberpLwj0E+1n0U/W8ViXZohdOJRytIw10eHZJbQxF7LYwh3hJHOFfDrQ9OwCdRuver0WnQZkxerFjqEGkaV3IVXFWckNMF7rqPFy/+5dx/2jUWxeeAMt6OVwpobWazwZmgsqvMmE4PdJrC+J4DHjs4iX9AQsKVr77p6w/Sx2XaRhcKSlowBjWeCAOQQ6g64G7fxMk3RG3LjqLT6e512hH3OovdtOkbX1lKb80IyW1bSUo0NfXTOPWbfgXsLl0B4SmzXKtTQa3JF7HobsOoKwB1CT9CNZ7RhzPjW6Rk2p0QvXrRtBDa+jH6+ZIdLzw+LFd8fHj1Cf0u1li9lYiGN7oCbMifUtbBExHfYbfjh+67C1buvQ3/mOLrihxDT5PVySR1CJefsyK1A/zZ41lyGnavC+NWBKSSzeXIdunxL4xByeIANtwCrroDoGKrqBBybT8JtEn0AoxwyEqD3RwmLjQTRR9M5aBoaEiXr4UjnlfhZehMSmTzyUiTFBa8BujcC/RfqnWkadQjFbEEECgvF54w+b/BRCV7p5lEJu9dHMOCMYcNDf4B1B76ETkSLOp8BMBYNky/RRL9vK3D6aRJx6unW6e2iEGpVzmblEHr0n4HvvZNKd4CzqssYAPzwfVfhtbtWLvdhtBVru2m+cmiSxs3puSR8LjvWDA3iO/lrcDywHd998iTu2DZQXA625RXY59sFgLImX71zCN///d2VN+y61gGDO4GL3wJsfTXla6rOS0zjrLsOWHXlch/FuYU71FjmrUQIgb949TZkcgV85sem9dvpPQCAJ2zbkFMOIbVu3Hg7VRMIQSXiS4Gac939IeB776K1fRvAglArsSqTqoV5st9sydj0QfqbgxcZj1VzSSjXUdUuYxYZQurrfffIvyudSRbhpXo9c2kpWLC/QoZQhcW+OUMolwFmjwE9G0uesw/ov9BwR5mfF0BnRxgA8PN9E1jb7a+9sHZ6y8uOzgpBSO6OtmD3ZzDsxRsvW40fPXMasXRObwV5xpCvo1dk0OPO0fjVHUI03jb2B/H8KRr/fpGpveuqWhVPH2rumDIxANqSlIwtRhA6PZ/Uu9IxS09f0KMLQn63HWGvC7OmBf6UzOApFYRmEhm9S0c9bB0MIeRx4D3Tr8Nnc6+D3RcudoSqUEPzAnfrq4C33QsIAY/TjnnXAD636et6rlYsC3ys87PA9tfTz5cJQsUdBhWPS0GoUkv68WjKKG9Vgkqla+GGWwAtD8f4Mzhhk2L9UjqEShskeDuBdz8ErLwEV2/owXOn5nFqLknXfae/ZRlCAOi1cHiolHXzncDb7kVnwIt4Jo9UhZbxk9E0ekPuogWeEoS65fsTdDsgRGPXCyUeNVK2WA/PXvKX+EL2Vjx8cAoAsCbip8yG9z0GRIYNh1ADgpDLYUPUFkJIixYLWNkEAEGvaXCgpiDkcznwrv6DsEFDIHYUnSIKUZrVqESf+CRlNm64heYnU/uKM+gq/pEuo0mHzWnMe8wokUgdb6USeKZtWNdDY0DlCO05PosNfUH0Bt34ZO6d+ODozYimcnjzFSXdwG7+Uzww9D4ANE+rid0JvOvntFDuXA287/GqLeeZGtz2F8C1H13uozi3qFSlUQfregJ45Y4V+NUBUyOk6BjgCmIu70VBXUuVQ3P9zcDHjgKfOAHseMPijrsSqpHH/AmKKJk7tjR/5yyDBaFWkrEok6qFz1S+ZFkyVqcgFBkuDhquliGknrNSNyW9y1iJIKS+PvggiTNqEiTr/IuwKhkDrCd5mXgdDqEsMHuUSt2sBJGNtwMnHyPXkvl5AUS6wgAonHdTPcHJTouSsbNCEJIT20UESpv59J1b8KP37caX33IJXrFjRUues27k6/iJW9ahz5OnHVXlJpPjbaQviLzMafFoqdq7rp1rqP2k1YS9HtTNbAlKxsKLKBmbimUq5wcwLac35EY0TTtCXpcDXX5XkYCi3DVq5xcAEpkcdTkK1G81d9ptuGakB/mCBq/TDru3pHWrcrp5u6yfABQ0OmUKiU5k8tShr0RcVSgHynTc+B1N0/D4URKEpmIZ/Zwzf//kbBJ9oZKMrkrn44qLKQMGgOgZocfqKX1ulioNEq7f2AtNo8WYz6UcQi0sGculyu4Jev5PhXN9JpFFl7/4fA7IcpDuIL0/NptAyONsTBBK0c+22iG0JkLv80+eo42frYPF10fdIdRAyZjbYcccAvCJNLrcpjIDlSdoLi+vEex5i+MpAEBg4RA6RAJ2f6lDyCT6eLvIAaDes3ocQuY52tAucguVzq90QciUc8G0NUGPEz1BNw5PxjAZTePpE3O4cVMv/G4HfC47jk0ncPWGbuxc1Vn2u2pjod1zA5lzhEqNfepkQ18Ac4ms0axDlvNm8xoKpRlCZ0JsL3WZNrvJfI7BglAr0e3OjYZKS5rtMjZ1gESSbpNQUk0Qqlky5pECiJyIqUWFssdnohRuPFXNIVTBLRXso79vznGo2mVMLrDyOWOhbyWIjNxGlsWD9xc/L4DeLmNCt7lWuRhAWTSlDqvsWSAIBZRDqDW7PzabwIVDYVy/qRcuxxm+FMjXsc+rQWSTtFBTF3o5dsylfW4tVftG4HDRDlmtLjCVMHcrajFGSGzjodIz8bS+C88sPeagd7/LXtSqXdM0XUw5ZHIIKZEo0uD7dONm6tgVCbhk61aLkrHSyYmJ7qAbk6Yyr1RWZuWYyi/NKIeQuWTs0GQc0/EMtg6GkC9oZe6hv3ngAA5OxHD1Btk1S895qXAttNmADbcCADZt3UmZZ2eyZMzEBStCWBH2QtOoExplCLXYIVRy7+qSAslshbKxmXgaXSVOMp90rUZMQlGHt0FBKEkiZiNli/WwJkLX3Qf2TiDgdmBlZ8n/109/r5GSMZfdhrEsPW+PzTRGzXmCwQFqbpGaq/xEuTQGp3+NjOZAsEDnjt1fkhFoFn18nXSvWStbGQfqcAiZBdk1V9E8Y/ao8Vg+a3zNDiHGxNpuPw5PxfHzlyagacb1vjdI5befvnOLZSmYmi/U5RBimOWmUmOfOlH3mCPTcl0oBaF0rgC7y03GAHVtdZ+BeAt1zTd3pWwDWBBqJborpoEB6woYLhizY8fpocFY6wTLpWnHKrLBcM4EB+tzCFXrMmZGD5VWIomg8qxSm7SZSq+FVev5al3G9JIxkyMpsq785wZ2UD7R/nuLnxdAd1eYsi8AbOpfhEPI7m5ta8NG0R1C50FgoFpM5lJyEeAvczWMmAQhV6EOhxAgA0ObFYRqCKWLwOO0l3WrqgdNowV6hB1CZ4xeU56D12VHJODGbIKcMwvJHLJ5DTYBHJw0FrJKRCl1ftTi2pFeCmv2u+j6b1kyVjkEvyfoxmSpQ8hZRRCSDqHo3DTwhZuBv9+Fnq/uxvdcn8art9D5Zi4b+/XBKXzuwQN43a4hvHloHPj2mw0x31FlsbJRhg4H++ke0OhEcc/XgJ/+z/p+trRkzIQQQg/Tpdel1V3GUmXCWFgJQhWCpWfj5Q4hm03gLVeuKQr+DfucDTkKDYdQhfDZJhkMe+G0C8TSOWwZCFF7bBPregLwOG0NOZPcThtOpWn8vOzJtwNPfYO+Yc4TVNk/lcrGfvF/gH+4BCITx9Twq/SHRen54u8hURIwJvrm8VkLX4kgBBQ38pg9ZmQcRk/TR3YIMaDGAYcmY7jn+VEMdniwRTrUX3XRED5660Y9R64UdQ0ZYkGIORfwhOmj1cZPJgF86Xbg73cBP/tzy19fK8srVak+YsohVIDLbqO1QbYJw0WzqMYEG26h/1uzVQfnGCwItZJKuTnVEMLURaZkUuvpqG3BmzkCQKOF8PANwJXvp/KpahlCccoCgK/b+vulglC6pGRszVXA/nuMhXd8yugCpqj0WqgdOXOZWbUuY+aSsemDdMylXUQAEmpW7CyeqMmFgt1uR59c5G0erFcQsgiVXk53EABsuAnY/UEKlT3XUa9lNmUsAkoWsYMdHgRltoYjn6yvc4vqINNgtwMAppKxpclTKu1WVQ8LKRIgGnWeMM1T7BByoDvggqaR42NKuoO2DIYwE8/oQpAhCDX2PnX5XbhuYy8J1Z4OuhaqAEOrUOkSegLFDqFkjZIxn4uEycipB6nENrIek4UO7LQdxJVhCsQ1P9/n//sQ+kJu/NkrL4A49DPgxR8CM4dri+MbbgF2fwgYub1c6KqFpgEP/Q11baqHKiVjAHDbBVIQcjmWpstYqUPIrxxCFUrG4hndVWPmT16+FVdtMO7JvUEPjkzFodUomVKoDKFWO4TsNoGVXfR/3GJx/7z9gn785hM3NvR3XXYbHkhuwLdz18KViwL7fkLfMOcJBmoIQnt/RPOOS96BwZs/YDzuK5kf2OzUXh4w5loX3EVzpTVX1z5YNd9w+oC+C+jzBVNnVfMGhO4QYkGIoQ3IuUQWP983iRs29+puoA/etAHvvray03tVlw82AQz3nIHFL8MslmolY7NHqCHR7FHgBeuOXSs7abwfmYrT/V86hDK5AlUvqDgJm2PRDXXqwu4AbvkMcO0fLW6T+RyDBaFWoibfjSqYasJfOql1h2pb7fUyqmESX275DO0o59OVa++joyS0VCpFKBU+9AwhKZJsfSWd3JP75DFr1NK16HfilOdS+ly6Q8hUZlaty5i57fzUQaC7Sn5OaVeS5Iw+mevv8CDocWCwow5Rp5IgtJwt5wH6v9z8v5f/OFqB3UnjQ2VVOX2Gm0yeR0IIjPQHEfI4IKoFj5uJrKfnsypjrMUSlowBlLVRqYykEkpoiDSQTcMsDrMg5HPZ9QX+dCyDKSmWXL6WXAiHpEtIlZQ1I9x94c278Jev2WaMO3XNT8zSvaRKC9yeoBvRVE4PME5kclVLxoQQ6A64sXr6l3S9fP2/47P51wEAuh20iaAcQs+fmsdDB6fwtt1r4XbYDYFq9khZy/kyHG7g5j8FAj10j2ikZGzqAIlO9fxOPkvnexVB6OLVnRjs8JDzq9VdxnLJstdC5X/MWJzryUweyWwenXWMk5s29+L4TAIvnK7vtVtIyZKxFmcIAYal30oQEkLojoZ6cTvtGM368Ue530Oie5tx3zbnCdZyCKUWgLVXAy/7a2o0UeoCMqOey2vafLvlM/XlPap5UrCfft/mLL6/mHeP9QwhLhljgDdetgpffdul+OQdm/De6+t3dl+9oRu/+tgNWBVhYZE5B9Azb+fKv6eyEHs2GsHQJbgcNqzs8pEglJqjdUGAHEJOuzCu0ypf7kxw5fuBge205uQMIaZh9FDpBmsc1YSj1PZemilhhV5GZbrZKAW1Uut5qb5WPLHMCqwrUCwI2d206wsA0Iy2f6Wt5NMxOolL/0bpJK9QkJPqChMom7S/F3JGeHYlggNAYooCrwG6EMnX9uYt/XjNzqHKrTvNWAlC2dSZUabbCYeHXuesLBm0O2l8mRaxN27uxZXD3dWDx82o86AZi6cuCC2NQygScJXls9RiWpYDcYbQmcNcMuZzO0y5O2ld+Ll0LV1XVI7QjHQONRIqrbDZBF2XSuvwkzNV3UEAOYQAo/NZIpOHz+UoE1fN9PkFNkYfA0Zuxcn5FA5FKb8mbKdrnmo9/7VHjiLgduANl62iX1QTu5kjjZXEeEKNOYRU2W82Ue48LaWOMk+7TeBH778KH7ll4xJ0GUtahErLAHmLc10Jwl11CCi3bO2H3Sb0MOdaKIeQ6ljWSlbLhWlpoHSz3Lq1D5es6cQbLl0Jf2TImA+YM5nUXKF0bqFILxjnjMMNhOU4tSqxVM9VpfyyIuocDPSTKy7QV7ywmT5ojAF2CDEmHHYbrh3pwbuuGcZAR/3lX0IIrOByMeZcoVrmrSp9791ClSMWcxKA8raOTMX1a2vC3YNcQYPLbtrgcp2B/KBSIsPkCG2ls/gshQWhVtJM23mARAubo3zXtZ6SsamDNEExuxrU5KS0bExNhGV9ZkXsJuHD31McKu30AB0rqM07YNTUl3UOi1mfvN5OykZS3UOm9tPjlXaclUMoMQPEJ6p32FLdROITxu/Iydx7rhvGn7x8a+XfNWMVKp1LVc/MYBrH6QGSs/JzOYF2+WmXVT7++9etxz+/6eLqweNmlIOsGYvnEnYZA4BIwK0LCvViOE9YjDxThH1OqlsHhf12S5FnKp7RhZcLh8Jw2ASOz9A1dTqegdMu9BLHpiht3ZqYLi9/KaFHilcT0TQKBQ3pXIGycnRxNUoCuSpDA3CZfR+8WgIYuQ2PH51BVKPzypmJotPn1B1Chybj2LaiwygFUhO75ExjLkV3HRsbmTi5gmYOAy/dbTxeev/LJovLQdOqY2b1c7Y74KZSOtVlzOyeLXl9GsLiuuRy2BBwOywdQkoQrsch1OV34crhCH783GhdZWMLqSyCboeel9dKrtvYi0vXdGFDb2sm5G+8bDW+8+4r8RevvhCOjgGakxQKxXmCLj+9r1YOIU2TYeImIVBtBlg5n3VBqLrAaokSkdRzBPtLHEKHgP5tAASwwF3GGIZpM/TMW4v1qnIW922hj1ZdqfM5DHe6cHQqDk1eWz/5wCQcNkGbb+qe0EgH71ah1pxt4BJiQaiV6CVjDdqFg4Mk6pS6V+oqGTtYHjKsnCw504R07jjwl6uAY4/QBKtadw2zEybQZwqVNuUlbHoZWbTXXkNfl5bopKPWJ68QckI1Bvzm88DnL6PHrXKBACNDaGoffeyyCJRWlAZWJ2eamwBWCpVmh1BrcXgM14E6Z3wR4NlvAX9zgaHI53PkdqvnvAoO0Bht5uKdmqeb2hKV5EX8Lr3kqF64ZOzMI4RAr2yxrkKlAWAmlsZULAMhgO6ACys6vbogNBPLoMvvqs+BWAlPiUMoUdshNBCmsXp6LomkLBvzusjxA5efzqFv/Q5w9wf137ki9zjScALrrsOjh2eKStX6Qh7dITQ2n0K/ucRWTeyABh1CHYZwU4kv3gJ87iL6d+JRoEO6Pcy/VygAf7cdePzfjMd0h1CdIq7TR12izE0XvvEa4L5P1Pf7pViESgNAp986L2ymwdLCO7YN4Nh0AgcmrHdVzSwkc0tSLgYA14704NvvvmJpulEGB8gBnJwpzxMMDhR39FJk4oCWL37fe7fQJpTVhlx4NV3ba5xPlihhSjmQgv3Fi5qpA0D3iJyvzRu/wzAM0y54Oqw3fswOIcA6zuG+T+Idxz+CeCaP6ORJAMDTcx584x2X4YrhiKlkbDkEIVV1cP7nCLEg1EoyMQCi8cnAtR8Dfuc/yx+vq2TsQHkZlS4ImVwuM4cpmPnk47JkbAAVMVvgA700+SoUpENIumR2fxB4231Az2YShkprQzOxyq9DoJ92BE8/RYLTa74IbLvL+meVQ0hlFPl7Kh+3ErnUBScx29wE0Ok12swrcqnauRlMYzg8xiJTLQJe+2Xg8t+n8aNEHdVdoJ5FqBB0Pkw1UzJWPZx2sXQHXIimjbyXeuCSseWhL+SB3SbgdtgQ9jphE+QCmoql0elzwWG3YVWXDyeUIBTPNNxhrAy9Dl+KHMmZmiUuqgX4iZkkEhkaVz4lCLkDtEkx/jwwKZ2YmoYdid/g4fxW/MfT0/jB06dw6cZVAASQWkBP0I2JaBqapmEimtKFMQB0PVU0ErBfq2QslwbGXwC2vAJ41b8Ar/4CcMMf0/eKuq5N0UL85OPGY42Weap7klnwn9wHTL5U3++XYhEqDVBemFV5qCoZq8chBACXrKGNkudO1u7StpDKIuhpfbnYkmO+b2dLmgesvhI4+lB511QrN+fVHwbedo91Kfyl7wTefn9zYr8QwFvvAa76EH1tdgilozSXiQwb4pSwGe2KGYZh2oFKBobEDJVqh1fT11aOz/Hn0ZkiIWh2/DgAwBUewGXr5PxHVZssi0NoPfDyfwCGdp35v32GYUGolaRjpGA2ukvsjwC9m8sf94SrT6QTM+SwKC2j0kvG0sU/C9DiIDVXvWTMHGIa6AOg0QQ6mzTKppxeYOWllMbu7ylXfTPxymqucghNHwT6tpIYVEk8UhlCyklSbSfY7BDKZ2m3rpnMAOUQMtv0OUOo9Ti9JoeQXAT0bwN2vJE+VzlAqtSx3lyGyIbmS8aWqFwMgOE0aaBsbDqegd9lh8dpX6rDYizoC7nhc9ohhIDNJtDld2EqlsF0LK2XkK3q8hWVjC26E1xpHX6itsPR73agy+/CidkEklIQ8qqx4grSc0XHDOF1ch9CqZN42nc5Pv6952ATAn90+xa9rKs36MHEQgoz8QyyeQ39oUoOoQbEcTVRrFT2pDplbvotYPvrgQtfC4RW0PfMGyLqHmM+txst81TijXIfapq8j85W/p1qWIRKAyQIzVUpGasnQwgA1nZTS/cXR2tnMC0ks0vmEFpS9Pv2OF3rzXmCG2+nzYGjDxX/jpUQ6A3L0i0L3EFgcEfzx9h/geFiDvRTSXM2Zcpw3GCMQecZDD5lGIY5G6i08aMqNVSkh5UgFB2FK09zqejUScThxcq+XuP7y+kQcnqAnW8yHKLnMSwItZJMhTKpZnGHZBviCsGaM4fpY2nJmNqdypsEITWZP/owfawqCJU4hACalGWtJ79lFmpAhkpXyBsI9lOt/fSh8mMvRf1f4lP0sdrE399NnauiY0Y2TbMlY9CKBTXOEGo9DrchVJoXAaosUHcIJcp/phqR9cDcseKSyXpIzS9ZhzGAckwA6lZVLzPxjC4kMWeOK9ZFcPmwISZH/G5My5Ixlee0qsuH2UQWC6msdAgtUhDSHULzQCFPH+twOA51enFiJoFElnJwfC4porsDVG6j5Y3zbP89AIBr7ngj7DaBj9yyEYNhL4379AL6QtTG/vQcOST1jmu5dHHHskZLxrRCWcczHXOnTP13LEIqlQt16qAhLjVaMlbqEMrEyDlrFrsawbxJYqI/5MGpOaMxQSqbx57js5iNZ2AT9XcCs9sENvaH8GIdncYWUrmWt5w/IwTNDqGS5gFrr6HXVwWNKxp931uJHnY9btyjIuuN85cDpRmGaTeqlYx5O8ng4PCUmwc0DYiOw5aNYyDkRmb2FMa0TqzvM62l9Vy5ZRCE2ggWhFpJNVdMM+iT4qj191VZTFmGkEWotNoBXSBbXnVByJwhJAWhdBVBKNAPTOwFnviyIaJkotUdQpkoTfarhUQDplBpKQhVKw2w2el4Y2PGAqhSNlE11AQ/Z+o0xhlCrcfhNdpUmifRLh/QsdLYfVW7+fW6Ero30AJ09kj5904+SXlaVixxyVhEDyeuP0doOtYCoYFpmDddsQb/9mbDIqw6xE3H0ugOGoIQAByfTrRGENK7jC0AyTkAWl2C9spOH07NJnWHkF4y5goYmwbJWRKZ9t8H9G/Dru0X4slP3YS3XbWWvi8bGKzt9iNX0DD2xA/gQ8oQhNT1VDk2Gym98Zj+X2amDgKjz1p3yiwtnwOMiWQmapQQN1oyVuoQUg5F9VGhacDeu6t3OdOkc9biurShL4CpWEZ3BH354aN4zT/9Gs+fXkDY52oo+HnrYAgvnJ6vGSxNDqFzsWRMzkXmT1CWkFlsdHqBddeRIGT+/6v33b101+uKmDulTh8EIICutcY450BphmHajdKSsaMPG+5kX8TIjy0zD0RpI6CQw45BH7ToOMYLYYyYGxioteRylIy1ESwItZJ0ldycZjDvGFsxexSAADrXFD+uZwiZS8ZKJryBKoKQ3mVMAL5u+jQTrTj5xcCFNJm7+0MUCAwYbeetMOcXVWsjDxgLkNQ8HU8twU2Vo6kd36YdQihuPc8ZQq3HLLCVTqLNOUBKEK3kOCtFjSmrsrFvvxm4+w+tfy81v7QZQtJZ0kiwdEtKkZhFEwm4cWouibGFlN7qfaUUhA5NxhBL5xb/PtkdVOaVnDEE8DpKXoe6vDg5m0Q8TYKQXl7o8ps2BWRp1InHgHXXAzDaowPQJ3PrewPYJI7j5qc/gHfYf4I+lSGkrqdKwG9k0avuNUqcUtz/P4Fvvp7O89JOmbo4Zi4ZM1nN1bndaMmYEp6VQ0gJXblUcTv68ReAb70ReOrrlZ8rnyXh2UIc29BH16r943TteuTwNDQN+NWByYaFwy0DISykckWOIysWUtlz0yHk9NDGzYlH6Wt/d/H3199IIv78CeMx9b4v4fW6IrpDaIzGbnglzQ3UGORAaYZh2g1zyVhqHvjaK4Bf/lVx6Xugv7xkzPT1zj4HOrU5TKEDI32m+b6a+7NDaElhQaiVvO5rwJt/0Lrns5oUm4mO0uTJUTLBtMoQKrXE1xMq7fQZJ2ImXlkUuf6PgT86Qq6OfdLaXTVU2tThrLuGQ0gIQxRyhwBbjSEb6KfSAt0h1CJBKJtqLEiVqY15LJWOlch6suNrGk28gequttLfBcqDpQt5IHoaOPJLwyFgJjHd3HipE+UQaqT1/Ew8zR3GzgIifhdG51NIZQu4fRuNw1UREheeOj4HAOhqxfsU7KMJknLD1DHmhzp9yOQLODZDY9oIlS4RUKf2U/mYVS28pwNIzWG4N4CbbE8CAG6070FvsMQhpFrHNnItXLObSn9Ly37iU8DCKWDfPeVO0dI8JYCuA0Je/1WZWWqBJom2OjO2VNmpEn/M90Xz50qQKz1mM3opa7k4tqGXJq4HxqPI5Qt48ig9dzav1Z0fpNgySK9FtbKxQkFDLL10XcaWnEA/cPi/6fPhG4q/p/IVzQK/7gxbhpIxJXAqh5C63yhxih1CDMO0G56wcV0++ACVYk/tL55XBy0EoZjx9dYegZBIYAE+rO81l4yxQ+hM0LQgJIRYKYT4uRBirxDiBSHEB+XjXUKI+4UQB+THJmp2zlFcvuZKlCphlaNgJjpmvWBQAlFpqLSaDNuc1Z0zyrnh8hknYjpGE2CrHB0h6PlGbgUO/5wcHfmMkQxfihKj7G4gNFT5OBSq9Xw9u4GqA4hyRLXSIcSCUGup6hDaQKHg8UnjBlKvIOTpAPy95Q6h+CTt6OfTxuJDoWlUVtPMeKkTn8sOj9Omdw4z87HvPos/u/vFkkPSWtO9ilk0yv2zZSCEXavpGh/yONHpc+KZk3NFP7MoggNkqVZ5OdWcnJKVnXS92j9GbpSikjEzE3J8WZ1Hcncv5HHiNtfTAIDttsNwJWVplhJL1OK8kUWvOwisuYrK1cyo+1pyptwpanfQ8ReVjI0B3RvpvqHO7UZdfbpDSJWMmcKkEyZBSP3dw/9d7Bwyo9xXFveFgQ4Pgm4H9o/HsHc0ingmr78vnf7GRJvN/SHYBPBCFUEoms5B04DQudhlDDDGZO/WcsFSiYVTFoLQEjYBqIgvQptU0ZIcRDVf4wwhhmHaDT3zNmfc66f207XaV0UQMn29qdOGIBKAuwNel2mThzOEzgiLcQjlAHxY07TNAC4H8F4hxBYAHwfwoKZpGwA8KL9mmsEqR8FMbMx6wWCVIZScAQYvAiDrOKt1wVALdafPUGQzMXLJVCubGrmdRCPlEqpYMiaPOTJc2/EDGDlC9ewGBvtle2K5kGmqy5haNJSWjLEg1FIcNRxCAC38oqO0CPSE639u5TAyYw6z23dP8fdS8+SeWEKHkBAC3QG3Zaj0rw5M4rEjxS6+hVQO2bzGJWNnASrY+y1XroEwXTtXdfn0luAtEe4CfTROdYdQX/Wfh1G6tn+cQpu95rbzZsZfkM9p4Q5V9f+xCWzRDuLu/OX0uJrYKbGkdyt9bPRaOHIbuXrM56T5vmbVXEB2PtOJjgGhQbpvqOdJzzcmCugZQjUcQkqsyqWAI7+wfq4qDiEhBNb3BXBgIorHpDvoTVdQ291GS8a8LjtWdvlwcLI8lFvTNPz7o8fxwIskIJ6zDiE1J9h4W/n3Ar20uVTaXc7mXJ4ybpuNztPRZ6mUXglWukOIS8YYhmkz1PosOQsc+Cm5eaOjALRih1AmSgYDhUkQ6sIC3CIHb7BkHr6cXcbaiKYFIU3TRjVN2yM/jwLYC2AFgFcA+Kr8sa8CeOUij7F9qVkyVskhJCfredPCMzEDhAZo962W00J3CPlNDqFo5VBpxZqraDL03Hfk71c4eb2dVEJQq8OYwlwyVgv1f5vcSyJCM/ZtXVCTgpCmsUNoKajmEOo2C0LjtUXMUrrXG2UlCnXj6VxDC91CgT7+5p8XlznVAJGAG1MlJWOZXAGjCylMRFNFj5+apfHXG2KH0HJzw6ZevOuadXj5jsGix//HZauwa00n7tjWj62DLXArBGXJa3SMrp915GatCNM1+fnTdJ/Qu4y5SiZRVR1CFCqN/ffBBg2fz70cU/Zeo2SqzCHU4EJ8RC70zUJsat7oImlVOuzpIMFHER0jMcucL5ZaaKxsqLTLmDlbz/y5uufa3cC9nwD+8x3FjlvA2DCo8FqM9AZxYDyG3xyexqouH1510QoA1JK+UVZ1+XB8utyp9MWHjuCT338On/7h8wBwbmYIAcaYHLEQhISQIqDpeq46Qi5Xe/dgP3D0Ifpcudvc7BBiGKZNUYL4wQdIFNryCuN7amNeGRjMwdJmx9DCaQDAddtLHMOq2oRLxpaUlmQICSHWALgIwKMA+jRNGwVINALQW+F33iWEeEII8cTk5GQrDuP8Q51gViVj+RyVwFjt9qpJdqlDyNsFXPFeYOfvVv+75gwhj0mUqhQqrXB6gOHrgUMP0teVTl4hgCs/AFz0O9WPQ2FvoGSsRy5YDv2MFvfNTBhLHUJqIcCCUGtRY0nYyju4daykcTx1gHYZqmVeWRHolyVips406saz+eVAfIIWgE98GfjVXxmlI0voEAKAbr+rrGTs9FwSmgZMxTLIF4zjfeoEHdP2ofCSHhNTm/4ODz55x2YjsFny25eswn+86wp8/o0Xw+9uQblOsJ+E6Kl9dZdIepx29IXciKZyeN2uIXT65PVSCUFKxJnYSx/9FrdkT4gcckcfQtoRxIvaahwL7gROP0XfT8zQdTG8Gtj1NmD9zY39vzpX02aEer58juzl298AbHklsOoK62NSLqJCniaRwT4gtMJwgKaj9YfNA8bPKsEnMQNAmD6XqL973cdoQ+K57wCT+4qfKyvvrxXuiRv6ApiOZ3D/i+O4YVMvRnqDeMOlK3Hj5tqur1LWRPw4Nl2ce/bYkRl85sd7EfG7EJcd5s7JLmMAsOm3gJ1vBlZcbP397g0lGUILy1MuptjxRmqmsf4mYOgSeoy7jDEM066o67GKY7j4Lcb3fDJKJdBDH+OmNX90FPo9WApCkUjJHKX/AuCC1wCrrmzlETMlLHr2IIQIAPhPAB/SNG1B1LkA1zTtXwH8KwDs2rWrej/VdsXchrgUlYdiVVJQGiqdzxl1nJf9Xu2/qwQllSFkd9EEXMvX3hkeuQ146W75+1XU3Bv/Z+3jUNgaKBkb2kWL+uSMUd7QKKocQheEKmdFMItAL030lwt3NjvQtY5KQ2LjxqK20efOZ41MLSUIDWynj7Ex+hefMnYsmikxbIBIwKU7ORQnZmnnP1+gzKAe2dZ8z7E5RPwurI7wAqNtUMLn6aeBvvqvX//fay4EAFy30TSRUoJ8ZAMJMekF6hpZ2oQAMO41p55EJjwMxASSHeuAY/eS6JKQGwo2G3Dn3zTxH5PHoVweapOjdzNw+Xusf94dMsKdE9N0/wkO0HmciZLYm4lZh2RXwumlBXtSCsDJGaBjiDpYqccAul+6gsDVHwbWXA188ebydrl6yZj1PfFCKeS+fPsgPnnHZthsAn/x6gvrP1YTqyM+LKRymEtk9O5wn71/H3qCbnzlrZfgZZ8jt8o56xAaupj+VSKyHnjuu7Js3UPjZzk6jCkueTv9M6OOh7uMMQzTbqjr36knaa6ghHLA2GhVH82bL7Fx2gCeP05NJoBysd/lB+760tIcN6OzKIeQEMIJEoO+oWna9+TD40KIAfn9AQATizvENsbuoMWyVcmYnjFh4ZwobTufbND9IIQst5ILdW8XsHBSPncNQWjDLcbnrar3bMQhZLMbx9Bs+U9pqLQShDhDqLWosVTJYh+RZV+qVKSh57bI0YqNAf4eYwEZHZMikUYlhsAZKRmbjmWgmZxLJ2aMrKpJU0v6PcdnsXN1J+oV2ZnzAOUKSs4Ud2OswXUbe4vFIMC4/gb7TTX8Fc4jdW2dPgBX7wj8Ljv8AxvlY4foeNQuX7OYOwfWEwrs6TB+Tt3vAn0kdGkFuj6nY43byL1dxoQ0IV9nV7B4kmoWHNT7YM4gA0wbBdb3xEvXduGnf3AN/va3d8DlWJwZe5XMiTomy8Z+fWgKvzk8g/dcO4ytgx0Y7iERouNczRCqRWQ9AA2YOUxfq5Kxswk3dxljGKZNUdfj6QN0vXb5yc0LGPNq9dFcnh0dNSIilCB0tl3b24TFdBkTAL4IYK+maZ81fetHAFRN0u8C+GHzh8fAEyrOUVCo3UrLUGklCMkJazP5KA6PsVD3delWvpoOoWCfYftuVb2nEoTqtYirYMpmO76pCb7aAVbCEDuEWos5vNwKtYBMLzS0OC56bnOOVlSGsKtF9/xJo/REldO0skugBb1BN3IFDcdnjDwQ5RACoOcITcfSODIVx8Wr26dJI4Pi63m9XfUqoa6/wQFTl48K55FpAubuH8Hjn7oJO3bsogemDxoOocUQWU+Onti44RCqNvFTJWOaZtx/ggOG0JWJ0b9K3Swr4es07onJGXptfF3FodJmwUG9D6XdUWo4hABgpC8Im23xgu7qCAk+hyZjeN+/78GbvvgYeoNu/I/LSNy+dWs/bALo8J3PghColFLTlr9kzArdIcSCEMMwbYb5eqyu1+qjmjsoB7661+ZzlJmofk7d55fT/dnGLGbbajeANwG4QQjxtPx3B4C/BHCzEOIAgJvl10yzmHdJzegOIYtFg54hJN0GauezkcWuy2+c4N4uYF4qt/WEiY7cTh9bdVI3UjIGAMM30u/4e5r7e+r/qAQ1LhlbGtTrXMliH1lPZSJAEw6hElEUkFlE/Ya4NP688fzjL1KWUSOdzJrg1q39cNlt+OdfGN2WTswkdAfBhHQI7Tk+BwAsCLUbZsFmsYKQGsuhweIuH9V+FgAi6+FzOSAiwwAECUKx8cWXU6pdwKkDRhl0tXuEp4OEo2+8Fvjm6+mx0EBxo4NMsw4huUOphC5fV3motLr/Odz0M0oQSs4Bf3MBcOjn9PUZ6HSlHEL//uhx3P3sKF63ayW+8+4r9Eyr992wHt94x+XnbslYLdRY/M5bgH+9Vgp24WU+qBLU/OpsE6oYhmGWGvO9XN3ru0do3aSy+1wBWpslZoBnvw38WTdlCYZX07q1UskYc0ZoOkNI07SHoCdBlXFjs8/LlOAOWWcIRccBCGrJWooQdBLmVcmYcgg1MKF/zb+Z7H6dwHE5Ga5n8nv5u4GutY1lO1TDLodpvQKTJwS88duUQdMMeqi03AFWLRIbCS9lalPLIWTuPNTo4rg0Rwugc6Z/m7HAO/208b2p/bTAsLUkZ78ig2Ev3nDpSnzj0ePYuaoTF63qxInZJC5c0YEnjs3qJWN7js/CYRPYtoJ3StoKd5AcL5lo4yJoKYMXAa/6V2DkVuCZb9JjVo5SwHp3z+ml2v6DDwJzx4BL37W441HPO33QEOurTfzcIXL4Hbyfsuk23Ul5P0oAik9R6Vijpcm+LmBUlkAnZui+aC4jA6QrscStpQSh2aOUObT/Pvr6DAhCXpcdvUE3njg2i6DbgT95+Ra4HUbAuc/lwBXDS5t/tqy4g8BdXwRe+jHw/H/SY2dbWUGgB/jtr1PmFMMwTDthNYe46g+oYkPFHghhuHFPPUnz9Os+Bmx/PfCrvzbWquwQWhbO0ZYUbYQnVLxzqYiOAv5uo5yqFLu73CHUSMnYmquMz30RmngDtTOEAJq8bbur/r9VC1uDJWMAMHxD83/P7iS3iOoio0r2+CLVWurJEFI0LAiV5GgV8tRZTC2yg/3kEFIUskueH6R47/Xr8Z0nT+Kj330WHqcNDpsNd144gH3jUV0Qev7UPDb2B8u6WjFtQLAPmI42XiZZihDA9t+mz321HEKma2uXqeVrZBg4LJ0wG29f3PGEhmgCOH3QOD+rOoRMx3T9H1NXJ8AQgJRLttEQX1+EJp65NO1O+jrp9ZkxXHtILdDupiLYTxlkgDFpjdZZRt0iVkd8mIimcdOWviIxqG1QXWaUIHQ27iJv/q3lPgKGYZgzj8q8zcaNuXvHCvpnRm2+2OZpg+eqP6DH3QG6two7B/MvE0u7Hc4snkolY7Hx6otkh7s8Q6jZDAjz752hyW8R9gZLxhaLEORaUdlB9QSgMo1j7jJmhS9ilAU0KgjZS0rGVFc+tcgO9hvfE3bj750BekMe/OKj1+M/33MlbEIgls5hZZcPvUE3JqIpaJqG50/NszuoXdFFy0U6hMzUGyodGioWaJVLL7JBlu0sApuNxKbpg3WWjIWNY+rfZjyunJoqR69R56a3i8q+4lPG194uIFHSZcx8vVfdzYBiJxFQ3yZJC1A5QrdfsMhSwnOZ0AAwsIM+5w0ahmGYswdPBwBRvTrD10WNjqIla1iVBegOlncdZs4ILAid7bhDQHwa2Ht38b+pA5Xt/wDtxOZkoG5imuozm1Vdzc6J5eigYVMlY+Ez9zcdHqNkTF+8sCDUUpw1HEJC0E6D3d34e1/qECrtymdeGPdsoo+LDc1tgJ6gGxev7sSHbqIF96ouH3qCbkwspHF6PoXZRBZbWRBqT3TRcpEOITO1HEIODzkxu9cXP652+lRQ/2KJSEFIhUpXE3OUIDNya/EEscwh1ETJmLljlQqVTs9TSVI6Vt7WPNBHAlShUNyeHsK41iwxF6/uxECHB9eMNJmNd74wIsci348ZhmHOHjwhKjOvZhzwdtKaVGV6KtT6lIX+ZYNLxs52OoZoovqtN5Z/b8PNlX/P4TIcELPHaELbrOpa5BBahmDlRruMtQKnz3j9UlwytiTUyhACgBU7KUek0bGrMoRUjpbqXhCSQpBadPu6gfBKYOKFM1YyZuZtu9eiJ+jGzVv6cP+L43j6xByeP0Xj7YJBXvC0Jb2byBXTysyyyHo6JzrXWH9fCPre4M7ixwcvAiCALa9szXF0bwD2/YTcOU5/5ZJnQGbQCWDrq4ofVxPHqHIINREqDQCTL9FHXzcQltf6//gfwO4PAYVcseAQHKDHEtPFDiGn74ztZr7h0lV4/SUrIdp993TLy4Ff/l8KImUYhmHODjrX1N4g8UWAE4/RusosCKn7OAv9ywYLQmc7uz9EO2Iqw8dMz8bKv+fwkDsin6VuKFsWUdtuLqVZFofQGS4ZA0jh1kOlF6isaDn+7+czeoZQFefazX9W3Dq+7ucu6bQ3fZA+KiurOUtIiUNL3HLeCofdhlddNASAWtJPRtN4/tQ87DaBzQN8Y2xLdn8IuOSdrX3OjXcAf7i3uuj5zgfLy59WXgp85AAF5raCyHoSVsaeq309790EfPQgZeWZcZc6hBptOy/vZycfl8c0DKzeDQzuAL7xOpqsAiUlY6r1/Ghxe/ozvEHS9mIQAPRtBT6y/4yV+DIMwzB1cNeXULnXlMTXRXmeQLFTXzl93bzxvlywIHS2Y3cA/Rc0/nsON7kjjj9CDqORRQSCmhcRy9F6Xc8QOoMXCqfHCJVOLdDihSfjraUeh5DT09yiS+8yJt/D6YPkBFCij1rgBfuNm9IyOITM9ATdSGbz+NWBKazvCXCgdLtidwLecGufU3X3qEal62urxCCAsogAYPRpspbXolQMAgwBSGX6NBwqLa8BJx6ja09wgF6f3s0kQh19iL5vfj3U9SI2Lkuw5f2VNwmWB6txwTAMwywf9dyLzRUn5sYZyhHNlRjLBmcIna+oLmP77qX8oHXXNf9cZ0OotM15ZsUop8+UITTPF6mloFaG0GLQBSHpLpo+ZN21LNBvZLWcwQwhKzb00Q7J0yfmsHUFu4OY8xAVTJ1NNH9NtTvo/FZdv5otGZs9QsdjFvoj643rvpUgFB2lkrHezXSPXY4NEoZhGIY5FzFvTBU5hFSGEM99lwt2CJ2vONxAJgbsvwdYe03jk2Yzyx4q7aTJ+Zl06Dg8QDpKn6cXuMPYUqAWU5W6jC0GuyoZkw6hqQPAyC3G9y0dQstbgnDDpj78+ANX4f4Xx3Hr1jbuJMScv/hkR6/kzOImfq4AkJgyPm/0GBTKsaR/beqkZr7mq53M6Bgdu7+byk+rZSAxDMMwDGNg3ngtCpVWJWO81louWBA6X3F4aBG8cBK4+K2Ley7VShA4Yx1Vilh7TWsDVuvB6aNW5YAsGWOHUMsJ9JJzbeWlrX9uc8lYap5qloscQoPA8A3A8PVA9wgwdCkFWC8zWwc7sHWQxxpzHtO9ATjx6OKuqS5/84KQO0SdKwu54msCUPy1+fgcbsDfC8wdI4dQ9wjlDmWTzR0/wzAMw7Qb5o3XopIxFSrN89/lggWh8xWHi8QgoHr4dD3Y7JS9kkstT47OzjfRvzOJOVQ6NQ90rT2zf78dcLiBN/9w6Z4boEDq6UP0udkNYHcAb/q+8fU77l+a42AYppjIehKEFrMTqDYIHB46lxtBCNqlLBWJgeJrRKmDKbIemD5Mbee9XcDVf9j4cTMMwzBMu6Icuu5QceWKygbkkrFlgzOEzlfM2Qalk95m8HW1V16COVSaS8bOPZQglEsZHcZacR4wDLM41Hm42JIx88dGUZPS7pJrQnDAKIsuveZHhoHJvXQ/WOYAeoZhGIY551AlY2Z3EGCIQ7zWWjZYEDpfUQtimwMIr17883m72qujSlGo9AKr1ucadlPb+emDgLCxy4thzgZ0QWgR1nB98tikIKQmpaUisc0GdA0Dwl7eMSWyntxBgNGtkGEYhmGY+vCGAYji/CDAFCrNJWPLBQtC5yt2KQh1rm3cUm+FL7I8HcaWC4eH3CWFAu0I80Xq3EII+R5KQahj5fLkXzEMU4wSYRazE6g7hJrMlvN1Af4e6+t693raACgtj+42lZOxQ4hhGIZhGsNmJ1GoVBDitvPLDmcIna+oxW+rymSu+gMjxLMdcPpIEErPA9DYxnguYneTIBSfKrenMgyzPPRuBm75DLDlFc0/h2uRDqHdHwKipyt/b9Od5Y+b76VeFoQYhmEYpmHu+Kvytenq3cANnwJWX7k8x8SwIHTeovJ+SjMSmmXVZa15nnMFp3z9YhP0kUvGzj0cbhL1MjHedWCYswUhgCvfv7jnUEJQaVlXvay8pPL3BnfQv1I611DpqVZghxDDMAzDNMO2u8ofc7iBaz565o+F0eGSsfOVVjuE2g2VlxQdo48sKJx7ODzUZSwTbz58lmGYs4/Fhko3g8MNhFfR5+bWuQzDMAzDMOcwLAidr+iC0IbqP8dYo/KSYuP0kUvGzj0cLln2FzPqkxmGOfdZbKh0s6j7KZeMMQzDMAxznsCC0PmKL0IdxrpHlvtIzk0cUhDSHUIsCJ1zqFDpTJQdQgxzPrHYUOlm6dtKHcZcbdRxk2EYhmGY8xrOEDpf2fZaYMUuINCz3EdyblLqEPKEl+1QmCZRGULpWPNZIwzDnH0sNlS6Wa75CLDzzWf2bzIMwzAMwywhLAidrzjcQO+m5T6KcxcVKq0cQlwydu5hdwOpeUDLn/mFI8MwS8diQ6Wb/rtBLj9lGIZhGOa8gkvGGMYKFSqtO4RYEDrncLiBxDR9fqZLSxiGWTqWI1SaYRiGYRjmPIQFIYaxwlwy5vAYId3MuYPDYwhC7BBimPMH5dJhtw7DMAzDMMyiYEGIYaxQodKzR4Fg/7IeCtMkDheVjAHsJGCY84nOtUBoCOjdstxHwjAMwzAMc07DGUIMY4VyCOUzwPqblvdYmOZweIzPOVSaYc4f/BHgD19Y7qNgGIZhGIY552GHEMNYoQQhABi5ffmOg2kec5kfl5YwDMMwDMMwDMMUwYIQw1ihBCGnH1hz1fIeC9McdpMgxCVjDMMwDMMwDMMwRbAgxDBWqAyh4euNFvTMuUWRQ4gFIYZhGIZhGIZhGDOcIcQwVtgdwNUfBjbesdxHwjRLUYYQC0IMwzAMwzAMwzBmWBBimErc+OnlPgJmMTi4ZIxhGIZhGIZhGKYSXDLGMMz5iRKE7C5qQc8wDMMwDMMwDMPosCDEMMz5iSoZY3cQwzAMwzAMwzBMGSwIMQxzfqIcQhwozTAMwzAMwzAMUwYLQgzDnJ+otvOu4PIeB8MwDMMwDMMwzFkIC0IMw5yfKIeQy7+8x8EwDMMwDMMwDHMWwoIQwzDnJypDiEvGGIZhGIZhGIZhymBBiGGY8xPVWYxDpRmGYRiGYRiGYcpgQYhhmPMT3SHEGUIMwzAMwzAMwzClsCDEMMz5CbedZxiGYRiGYRiGqQgLQgzDnJ/YVckYh0ozDMMwDMMwDMOUwoIQwzDnJxwqzTAMwzAMwzAMUxEWhBiGOT/R285zhhDDMAzDMAzDMEwpLAgxDHN+EhwANt0JrNm93EfCMAzDMAzDMAxz1uFY7gNgGIZZEhwu4PXfWO6jYBiGYRiGYRiGOSthhxDDMAzDMAzDMAzDMEybwYIQwzAMwzAMwzAMwzBMm8GCEMMwDMMwDMMwDMMwTJvBghDDMAzDMAzDMAzDMEybwYIQwzAMwzAMwzAMwzBMm8GCEMMwDMMwDMMwDMMwTJvBghDDMAzDMAzDMAzDMEybwYIQwzAMwzAMwzAMwzBMm8GCEMMwDMMwDMMwDMMwTJvBghDDMAzDMAzDMAzDMEybwYIQwzAMwzAMwzAMwzBMm8GCEMMwDMMwDMMwDMMwTJvBghDDMAzDMAzDMAzDMEybwYIQwzAMwzAMwzAMwzBMm8GCEMMwDMMwDMMwDMMwTJvBghDDMAzDMAzDMAzDMEybwYIQwzAMwzAMwzAMwzBMm8GCEMMwDMMwDMMwDMMwTJvBghDDMAzDMAzDMAzDMEybwYIQwzAMwzAMwzAMwzBMm8GCEMMwDMMwDMMwDMMwTJvBghDDMAzDMAzDMAzDMEybwYIQwzAMwzAMwzAMwzBMmyE0TVvuY4AQYhLAseU+jhbRDWBquQ+COafgMcM0Co8ZplF4zDCNwmOGaQYeN0yj8JhhGoXHTOOs1jStx+obZ4UgdD4hhHhC07Rdy30czLkDjxmmUXjMMI3CY4ZpFB4zTDPwuGEahccM0yg8ZloLl4wxDMMwDMMwDMMwDMO0GSwIMQzDMAzDMAzDMAzDtBksCLWef13uA2DOOXjMMI3CY4ZpFB4zTKPwmGGagccN0yg8ZphG4THTQjhDiGEYhmEYhmEYhmEYps1ghxDDMAzDMAzDMAzDMEybwYIQwzAMwzAMwzAMwzBMm8GCUIsQQtwmhNgnhDgohPj4ch8Pc/YghPiSEGJCCPG86bEuIcT9QogD8mOn6XufkONonxDi1uU5ama5EEKsFEL8XAixVwjxghDig/JxHjNMRYQQHiHEY0KIZ+S4+VP5OI8bpiJCCLsQ4ikhxN3yax4vTFWEEEeFEM8JIZ4WQjwhH+Nxw1RECBEWQnxXCPGSnNtcwWOGqYQQYqO8vqh/C0KID/GYWTpYEGoBQgg7gH8EcDuALQDeIITYsrxHxZxFfAXAbSWPfRzAg5qmbQDwoPwacty8HsBW+Tufl+OLaR9yAD6sadpmAJcDeK8cFzxmmGqkAdygadp2ADsA3CaEuBw8bpjqfBDAXtPXPF6Yerhe07Qdmqbtkl/zuGGq8XcA7tU0bROA7aBrDo8ZxhJN0/bJ68sOABcDSAD4PnjMLBksCLWGSwEc1DTtsKZpGQD/AeAVy3xMzFmCpmm/BDBT8vArAHxVfv5VAK80Pf4fmqalNU07AuAgaHwxbYKmaaOapu2Rn0dBE6cV4DHDVEEjYvJLp/yngccNUwEhxBCAlwH4gulhHi9MM/C4YSwRQoQAXAPgiwCgaVpG07Q58Jhh6uNGAIc0TTsGHjNLBgtCrWEFgBOmr0/KxximEn2apo0CJAAA6JWP81hidIQQawBcBOBR8JhhaiDLf54GMAHgfk3TeNww1fhbAH8EoGB6jMcLUwsNwE+FEE8KId4lH+Nxw1RiHYBJAF+W5alfEEL4wWOGqY/XA/im/JzHzBLBglBrEBaPaWf8KJjzAR5LDABACBEA8J8APqRp2kK1H7V4jMdMG6JpWl5arIcAXCqEuKDKj/O4aWOEEHcCmNA07cl6f8XiMR4v7cluTdN2gmIS3iuEuKbKz/K4YRwAdgL4J03TLgIQhyz1qQCPGQYAIIRwAXg5gO/U+lGLx3jMNAALQq3hJICVpq+HAJxepmNhzg3GhRADACA/TsjHeSwxEEI4QWLQNzRN+558mMcMUxfSjv/foFp6HjeMFbsBvFwIcRRU5n6DEOLr4PHC1EDTtNPy4wQo1+NS8LhhKnMSwEnpWAWA74IEIh4zTC1uB7BH07Rx+TWPmSWCBaHW8DiADUKItVLNfD2AHy3zMTFnNz8C8Lvy898F8EPT468XQriFEGsBbADw2DIcH7NMCCEEqNZ+r6ZpnzV9i8cMUxEhRI8QIiw/9wK4CcBL4HHDWKBp2ic0TRvSNG0NaM7yM03Tfgc8XpgqCCH8Qoig+hzALQCeB48bpgKapo0BOCGE2CgfuhHAi+Axw9TmDTDKxQAeM0uGY7kP4HxA07ScEOJ9AO4DYAfwJU3TXljmw2LOEoQQ3wRwHYBuIcRJAP8LwF8C+LYQ4u0AjgN4LQBomvaCEOLboJtlDsB7NU3LL8uBM8vFbgBvAvCczIMBgE+CxwxTnQEAX5WdNWwAvq1p2t1CiEfA44apH77OMNXoA/B92reAA8C/a5p2rxDicfC4YSrzfgDfkJvmhwG8FfI+xWOGsUII4QNwM4DfMz3M96clQmgal9gxDMMwDMMwDMMwDMO0E1wyxjAMwzAMwzAMwzAM02awIMQwDMMwDMMwDMMwDNNmsCDEMAzDMAzDMAzDMAzTZrAgxDAMwzAMwzAMwzAM02awIMQwDMMwDMMwDMMwDNNmsCDEMAzDMAzDMAzDMAzTZrAgxDAMwzAMwzAMwzAM02b8/w6G1mhxqZKaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(ensemble_result)\n",
    "plt.plot(np.reshape(val_y, [30 * 24]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.48697192],\n",
       "       [0.48697192, 1.        ]])"
      ]
     },
     "execution_count": 887,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(ensenble_result,\n",
    "np.reshape(val_y, [30 * 24]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class auto_encoder(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "                 dense_dim):        \n",
    "        super(auto_encoder, self).__init__()\n",
    "        self.dense_dim = dense_dim\n",
    "     \n",
    "    def build(self, input_shape):\n",
    "    \n",
    "        self.input_dense = tf.keras.layers.Dense(self.dense_dim, \n",
    "                                      activation = \"relu\")\n",
    "        self.dense_input_1 = tf.keras.layers.Dense(int(self.dense_dim / 2),\n",
    "                                                  activation = \"relu\")\n",
    "        self.dense_input_2 = tf.keras.layers.Dense(int(self.dense_dim / 4),\n",
    "                                                  activation = \"relu\")\n",
    "        self.dense_embedding = tf.keras.layers.Dense(int(self.dense_dim / 6),\n",
    "                                                    activation = \"relu\")\n",
    "        self.dense_output_1 = tf.keras.layers.Dense(int(self.dense_dim / 4),\n",
    "                                                  activation = \"relu\")\n",
    "        self.dense_output_2 = tf.keras.layers.Dense(int(self.dense_dim / 2),\n",
    "                                          activation = \"relu\")\n",
    "        self.output_dense = tf.keras.layers.Dense(self.dense_dim,\n",
    "                                                 activation = \"relu\")\n",
    "        self.ae_output = tf.keras.layers.Dense(input_shape[-1],\n",
    "                                      activation = \"relu\")\n",
    "    \n",
    "    def call(self, input_tensor):       \n",
    "        input_output = self.input_dense(input_tensor)        \n",
    "        output = self.dense_input_1(input_output)\n",
    "        output = self.dense_input_2(output)\n",
    "        output = self.dense_embedding(output)        \n",
    "        output = self.dense_output_1(output)        \n",
    "        output = self.dense_output_2(output)        \n",
    "        output = self.output_dense(output)        \n",
    "        output = self.ae_output(output)        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "AE_LSTM = auto_encoder(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def training_auto_encoder(inp , tar):\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        output = AE_LSTM(inp)\n",
    "\n",
    "        loss =  loss_function(tar, output)\n",
    "    \n",
    "    gradients = tape.gradient(loss, AE_LSTM.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, AE_LSTM.trainable_variables))\n",
    "  \n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy_function(tar * (train_max_dangjin - train_min_dangjin) + train_min_dangjin, \n",
    "                                     output * (train_max_dangjin - train_min_dangjin) + train_min_dangjin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 5 Loss 0.0601 Accuracy 20.5978\n",
      "Epoch 1 Batch 10 Loss 0.0597 Accuracy 22.2142\n",
      "Epoch 1 Batch 15 Loss 0.0581 Accuracy 22.2586\n",
      "Time taken for 1 epoch: 0.32 secs\n",
      "\n",
      "Epoch 2 Batch 5 Loss 0.0584 Accuracy 22.1824\n",
      "Epoch 2 Batch 10 Loss 0.0586 Accuracy 22.2349\n",
      "Epoch 2 Batch 15 Loss 0.0580 Accuracy 22.2132\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 3 Batch 5 Loss 0.0582 Accuracy 22.1758\n",
      "Epoch 3 Batch 10 Loss 0.0583 Accuracy 22.1822\n",
      "Epoch 3 Batch 15 Loss 0.0579 Accuracy 22.1669\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 4 Batch 5 Loss 0.0581 Accuracy 22.1444\n",
      "Epoch 4 Batch 10 Loss 0.0582 Accuracy 22.1438\n",
      "Epoch 4 Batch 15 Loss 0.0579 Accuracy 22.1333\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 5 Batch 5 Loss 0.0580 Accuracy 22.1185\n",
      "Epoch 5 Batch 10 Loss 0.0581 Accuracy 22.1166\n",
      "Epoch 5 Batch 15 Loss 0.0579 Accuracy 22.1082\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 6 Batch 5 Loss 0.0579 Accuracy 22.0969\n",
      "Epoch 6 Batch 10 Loss 0.0580 Accuracy 22.0939\n",
      "Epoch 6 Batch 15 Loss 0.0578 Accuracy 22.0868\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 7 Batch 5 Loss 0.0579 Accuracy 22.0778\n",
      "Epoch 7 Batch 10 Loss 0.0579 Accuracy 22.0749\n",
      "Epoch 7 Batch 15 Loss 0.0578 Accuracy 22.0690\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 8 Batch 5 Loss 0.0579 Accuracy 22.0618\n",
      "Epoch 8 Batch 10 Loss 0.0579 Accuracy 22.0593\n",
      "Epoch 8 Batch 15 Loss 0.0578 Accuracy 22.0547\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 9 Batch 5 Loss 0.0578 Accuracy 22.0490\n",
      "Epoch 9 Batch 10 Loss 0.0579 Accuracy 22.0467\n",
      "Epoch 9 Batch 15 Loss 0.0578 Accuracy 22.0428\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 10 Batch 5 Loss 0.0578 Accuracy 22.0380\n",
      "Epoch 10 Batch 10 Loss 0.0579 Accuracy 22.0362\n",
      "Epoch 10 Batch 15 Loss 0.0578 Accuracy 22.0332\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 11 Batch 5 Loss 0.0579 Accuracy 22.0295\n",
      "Epoch 11 Batch 10 Loss 0.0579 Accuracy 22.0280\n",
      "Epoch 11 Batch 15 Loss 0.0578 Accuracy 22.0254\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 12 Batch 5 Loss 0.0578 Accuracy 22.0222\n",
      "Epoch 12 Batch 10 Loss 0.0579 Accuracy 22.0209\n",
      "Epoch 12 Batch 15 Loss 0.0578 Accuracy 22.0185\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 13 Batch 5 Loss 0.0578 Accuracy 22.0156\n",
      "Epoch 13 Batch 10 Loss 0.0579 Accuracy 22.0143\n",
      "Epoch 13 Batch 15 Loss 0.0578 Accuracy 22.0122\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 14 Batch 5 Loss 0.0578 Accuracy 22.0095\n",
      "Epoch 14 Batch 10 Loss 0.0578 Accuracy 22.0081\n",
      "Epoch 14 Batch 15 Loss 0.0578 Accuracy 22.0061\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 15 Batch 5 Loss 0.0578 Accuracy 22.0036\n",
      "Epoch 15 Batch 10 Loss 0.0578 Accuracy 22.0024\n",
      "Epoch 15 Batch 15 Loss 0.0577 Accuracy 22.0005\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 16 Batch 5 Loss 0.0578 Accuracy 21.9984\n",
      "Epoch 16 Batch 10 Loss 0.0578 Accuracy 21.9972\n",
      "Epoch 16 Batch 15 Loss 0.0577 Accuracy 21.9954\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 17 Batch 5 Loss 0.0578 Accuracy 21.9934\n",
      "Epoch 17 Batch 10 Loss 0.0578 Accuracy 21.9923\n",
      "Epoch 17 Batch 15 Loss 0.0577 Accuracy 21.9907\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 18 Batch 5 Loss 0.0578 Accuracy 21.9889\n",
      "Epoch 18 Batch 10 Loss 0.0578 Accuracy 21.9878\n",
      "Epoch 18 Batch 15 Loss 0.0577 Accuracy 21.9864\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 19 Batch 5 Loss 0.0578 Accuracy 21.9847\n",
      "Epoch 19 Batch 10 Loss 0.0578 Accuracy 21.9837\n",
      "Epoch 19 Batch 15 Loss 0.0577 Accuracy 21.9824\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 20 Batch 5 Loss 0.0578 Accuracy 21.9809\n",
      "Epoch 20 Batch 10 Loss 0.0578 Accuracy 21.9800\n",
      "Epoch 20 Batch 15 Loss 0.0577 Accuracy 21.9788\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 21 Batch 5 Loss 0.0578 Accuracy 21.9774\n",
      "Epoch 21 Batch 10 Loss 0.0578 Accuracy 21.9766\n",
      "Epoch 21 Batch 15 Loss 0.0577 Accuracy 21.9755\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 22 Batch 5 Loss 0.0578 Accuracy 21.9742\n",
      "Epoch 22 Batch 10 Loss 0.0578 Accuracy 21.9734\n",
      "Epoch 22 Batch 15 Loss 0.0577 Accuracy 21.9724\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 23 Batch 5 Loss 0.0578 Accuracy 21.9713\n",
      "Epoch 23 Batch 10 Loss 0.0578 Accuracy 21.9706\n",
      "Epoch 23 Batch 15 Loss 0.0577 Accuracy 21.9697\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 24 Batch 5 Loss 0.0578 Accuracy 21.9686\n",
      "Epoch 24 Batch 10 Loss 0.0578 Accuracy 21.9679\n",
      "Epoch 24 Batch 15 Loss 0.0577 Accuracy 21.9671\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 25 Batch 5 Loss 0.0578 Accuracy 21.9661\n",
      "Epoch 25 Batch 10 Loss 0.0578 Accuracy 21.9655\n",
      "Epoch 25 Batch 15 Loss 0.0577 Accuracy 21.9647\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 26 Batch 5 Loss 0.0577 Accuracy 21.9637\n",
      "Epoch 26 Batch 10 Loss 0.0578 Accuracy 21.9632\n",
      "Epoch 26 Batch 15 Loss 0.0577 Accuracy 21.9624\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 27 Batch 5 Loss 0.0577 Accuracy 21.9615\n",
      "Epoch 27 Batch 10 Loss 0.0578 Accuracy 21.9609\n",
      "Epoch 27 Batch 15 Loss 0.0577 Accuracy 21.9601\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 28 Batch 5 Loss 0.0577 Accuracy 21.9593\n",
      "Epoch 28 Batch 10 Loss 0.0577 Accuracy 21.9587\n",
      "Epoch 28 Batch 15 Loss 0.0577 Accuracy 21.9580\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 29 Batch 5 Loss 0.0577 Accuracy 21.9572\n",
      "Epoch 29 Batch 10 Loss 0.0577 Accuracy 21.9566\n",
      "Epoch 29 Batch 15 Loss 0.0577 Accuracy 21.9559\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 30 Batch 5 Loss 0.0577 Accuracy 21.9552\n",
      "Epoch 30 Batch 10 Loss 0.0577 Accuracy 21.9546\n",
      "Epoch 30 Batch 15 Loss 0.0577 Accuracy 21.9540\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 31 Batch 5 Loss 0.0577 Accuracy 21.9532\n",
      "Epoch 31 Batch 10 Loss 0.0577 Accuracy 21.9527\n",
      "Epoch 31 Batch 15 Loss 0.0577 Accuracy 21.9521\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 32 Batch 5 Loss 0.0577 Accuracy 21.9514\n",
      "Epoch 32 Batch 10 Loss 0.0577 Accuracy 21.9510\n",
      "Epoch 32 Batch 15 Loss 0.0577 Accuracy 21.9504\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 33 Batch 5 Loss 0.0577 Accuracy 21.9498\n",
      "Epoch 33 Batch 10 Loss 0.0577 Accuracy 21.9494\n",
      "Epoch 33 Batch 15 Loss 0.0577 Accuracy 21.9489\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 34 Batch 5 Loss 0.0577 Accuracy 21.9483\n",
      "Epoch 34 Batch 10 Loss 0.0577 Accuracy 21.9479\n",
      "Epoch 34 Batch 15 Loss 0.0577 Accuracy 21.9475\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 35 Batch 5 Loss 0.0577 Accuracy 21.9469\n",
      "Epoch 35 Batch 10 Loss 0.0577 Accuracy 21.9466\n",
      "Epoch 35 Batch 15 Loss 0.0577 Accuracy 21.9461\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 36 Batch 5 Loss 0.0577 Accuracy 21.9456\n",
      "Epoch 36 Batch 10 Loss 0.0577 Accuracy 21.9452\n",
      "Epoch 36 Batch 15 Loss 0.0577 Accuracy 21.9448\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 37 Batch 5 Loss 0.0577 Accuracy 21.9443\n",
      "Epoch 37 Batch 10 Loss 0.0577 Accuracy 21.9440\n",
      "Epoch 37 Batch 15 Loss 0.0577 Accuracy 21.9436\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 38 Batch 5 Loss 0.0577 Accuracy 21.9432\n",
      "Epoch 38 Batch 10 Loss 0.0577 Accuracy 21.9429\n",
      "Epoch 38 Batch 15 Loss 0.0577 Accuracy 21.9425\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 39 Batch 5 Loss 0.0577 Accuracy 21.9421\n",
      "Epoch 39 Batch 10 Loss 0.0577 Accuracy 21.9418\n",
      "Epoch 39 Batch 15 Loss 0.0577 Accuracy 21.9414\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 40 Batch 5 Loss 0.0577 Accuracy 21.9410\n",
      "Epoch 40 Batch 10 Loss 0.0577 Accuracy 21.9407\n",
      "Epoch 40 Batch 15 Loss 0.0577 Accuracy 21.9403\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 41 Batch 5 Loss 0.0577 Accuracy 21.9399\n",
      "Epoch 41 Batch 10 Loss 0.0577 Accuracy 21.9396\n",
      "Epoch 41 Batch 15 Loss 0.0577 Accuracy 21.9393\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 42 Batch 5 Loss 0.0577 Accuracy 21.9389\n",
      "Epoch 42 Batch 10 Loss 0.0577 Accuracy 21.9386\n",
      "Epoch 42 Batch 15 Loss 0.0577 Accuracy 21.9383\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 43 Batch 5 Loss 0.0577 Accuracy 21.9379\n",
      "Epoch 43 Batch 10 Loss 0.0577 Accuracy 21.9377\n",
      "Epoch 43 Batch 15 Loss 0.0577 Accuracy 21.9374\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 44 Batch 5 Loss 0.0577 Accuracy 21.9370\n",
      "Epoch 44 Batch 10 Loss 0.0577 Accuracy 21.9368\n",
      "Epoch 44 Batch 15 Loss 0.0577 Accuracy 21.9365\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 45 Batch 5 Loss 0.0577 Accuracy 21.9362\n",
      "Epoch 45 Batch 10 Loss 0.0577 Accuracy 21.9360\n",
      "Epoch 45 Batch 15 Loss 0.0577 Accuracy 21.9357\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 46 Batch 5 Loss 0.0577 Accuracy 21.9354\n",
      "Epoch 46 Batch 10 Loss 0.0577 Accuracy 21.9352\n",
      "Epoch 46 Batch 15 Loss 0.0577 Accuracy 21.9350\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 47 Batch 5 Loss 0.0577 Accuracy 21.9347\n",
      "Epoch 47 Batch 10 Loss 0.0577 Accuracy 21.9345\n",
      "Epoch 47 Batch 15 Loss 0.0577 Accuracy 21.9342\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 48 Batch 5 Loss 0.0577 Accuracy 21.9339\n",
      "Epoch 48 Batch 10 Loss 0.0577 Accuracy 21.9338\n",
      "Epoch 48 Batch 15 Loss 0.0577 Accuracy 21.9335\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 49 Batch 5 Loss 0.0577 Accuracy 21.9333\n",
      "Epoch 49 Batch 10 Loss 0.0577 Accuracy 21.9331\n",
      "Epoch 49 Batch 15 Loss 0.0577 Accuracy 21.9329\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 50 Batch 5 Loss 0.0577 Accuracy 21.9326\n",
      "Epoch 50 Batch 10 Loss 0.0577 Accuracy 21.9325\n",
      "Epoch 50 Batch 15 Loss 0.0577 Accuracy 21.9323\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 51 Batch 5 Loss 0.0577 Accuracy 21.9320\n",
      "Epoch 51 Batch 10 Loss 0.0577 Accuracy 21.9319\n",
      "Epoch 51 Batch 15 Loss 0.0577 Accuracy 21.9317\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 52 Batch 5 Loss 0.0577 Accuracy 21.9314\n",
      "Epoch 52 Batch 10 Loss 0.0577 Accuracy 21.9313\n",
      "Epoch 52 Batch 15 Loss 0.0577 Accuracy 21.9311\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 53 Batch 5 Loss 0.0577 Accuracy 21.9308\n",
      "Epoch 53 Batch 10 Loss 0.0577 Accuracy 21.9307\n",
      "Epoch 53 Batch 15 Loss 0.0577 Accuracy 21.9305\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 54 Batch 5 Loss 0.0577 Accuracy 21.9303\n",
      "Epoch 54 Batch 10 Loss 0.0577 Accuracy 21.9301\n",
      "Epoch 54 Batch 15 Loss 0.0577 Accuracy 21.9299\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 55 Batch 5 Loss 0.0577 Accuracy 21.9297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Batch 10 Loss 0.0577 Accuracy 21.9296\n",
      "Epoch 55 Batch 15 Loss 0.0577 Accuracy 21.9294\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 56 Batch 5 Loss 0.0577 Accuracy 21.9292\n",
      "Epoch 56 Batch 10 Loss 0.0577 Accuracy 21.9290\n",
      "Epoch 56 Batch 15 Loss 0.0577 Accuracy 21.9289\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 57 Batch 5 Loss 0.0577 Accuracy 21.9287\n",
      "Epoch 57 Batch 10 Loss 0.0577 Accuracy 21.9286\n",
      "Epoch 57 Batch 15 Loss 0.0577 Accuracy 21.9284\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 58 Batch 5 Loss 0.0577 Accuracy 21.9282\n",
      "Epoch 58 Batch 10 Loss 0.0577 Accuracy 21.9281\n",
      "Epoch 58 Batch 15 Loss 0.0577 Accuracy 21.9279\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 59 Batch 5 Loss 0.0577 Accuracy 21.9278\n",
      "Epoch 59 Batch 10 Loss 0.0577 Accuracy 21.9277\n",
      "Epoch 59 Batch 15 Loss 0.0577 Accuracy 21.9275\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 60 Batch 5 Loss 0.0577 Accuracy 21.9274\n",
      "Epoch 60 Batch 10 Loss 0.0577 Accuracy 21.9272\n",
      "Epoch 60 Batch 15 Loss 0.0577 Accuracy 21.9271\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 61 Batch 5 Loss 0.0577 Accuracy 21.9269\n",
      "Epoch 61 Batch 10 Loss 0.0577 Accuracy 21.9268\n",
      "Epoch 61 Batch 15 Loss 0.0577 Accuracy 21.9267\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 62 Batch 5 Loss 0.0577 Accuracy 21.9265\n",
      "Epoch 62 Batch 10 Loss 0.0578 Accuracy 21.9265\n",
      "Epoch 62 Batch 15 Loss 0.0577 Accuracy 21.9263\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 63 Batch 5 Loss 0.0577 Accuracy 21.9262\n",
      "Epoch 63 Batch 10 Loss 0.0578 Accuracy 21.9261\n",
      "Epoch 63 Batch 15 Loss 0.0577 Accuracy 21.9260\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 64 Batch 5 Loss 0.0577 Accuracy 21.9258\n",
      "Epoch 64 Batch 10 Loss 0.0578 Accuracy 21.9257\n",
      "Epoch 64 Batch 15 Loss 0.0577 Accuracy 21.9256\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 65 Batch 5 Loss 0.0577 Accuracy 21.9255\n",
      "Epoch 65 Batch 10 Loss 0.0578 Accuracy 21.9254\n",
      "Epoch 65 Batch 15 Loss 0.0577 Accuracy 21.9253\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 66 Batch 5 Loss 0.0577 Accuracy 21.9252\n",
      "Epoch 66 Batch 10 Loss 0.0578 Accuracy 21.9251\n",
      "Epoch 66 Batch 15 Loss 0.0577 Accuracy 21.9250\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 67 Batch 5 Loss 0.0577 Accuracy 21.9249\n",
      "Epoch 67 Batch 10 Loss 0.0578 Accuracy 21.9248\n",
      "Epoch 67 Batch 15 Loss 0.0577 Accuracy 21.9247\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 68 Batch 5 Loss 0.0577 Accuracy 21.9245\n",
      "Epoch 68 Batch 10 Loss 0.0578 Accuracy 21.9245\n",
      "Epoch 68 Batch 15 Loss 0.0577 Accuracy 21.9244\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 69 Batch 5 Loss 0.0577 Accuracy 21.9242\n",
      "Epoch 69 Batch 10 Loss 0.0578 Accuracy 21.9242\n",
      "Epoch 69 Batch 15 Loss 0.0577 Accuracy 21.9241\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 70 Batch 5 Loss 0.0577 Accuracy 21.9239\n",
      "Epoch 70 Batch 10 Loss 0.0578 Accuracy 21.9239\n",
      "Epoch 70 Batch 15 Loss 0.0577 Accuracy 21.9238\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 71 Batch 5 Loss 0.0577 Accuracy 21.9236\n",
      "Epoch 71 Batch 10 Loss 0.0577 Accuracy 21.9236\n",
      "Epoch 71 Batch 15 Loss 0.0577 Accuracy 21.9235\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 72 Batch 5 Loss 0.0577 Accuracy 21.9234\n",
      "Epoch 72 Batch 10 Loss 0.0577 Accuracy 21.9233\n",
      "Epoch 72 Batch 15 Loss 0.0577 Accuracy 21.9232\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 73 Batch 5 Loss 0.0577 Accuracy 21.9231\n",
      "Epoch 73 Batch 10 Loss 0.0577 Accuracy 21.9230\n",
      "Epoch 73 Batch 15 Loss 0.0577 Accuracy 21.9229\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 74 Batch 5 Loss 0.0577 Accuracy 21.9228\n",
      "Epoch 74 Batch 10 Loss 0.0577 Accuracy 21.9227\n",
      "Epoch 74 Batch 15 Loss 0.0577 Accuracy 21.9226\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 75 Batch 5 Loss 0.0577 Accuracy 21.9225\n",
      "Epoch 75 Batch 10 Loss 0.0577 Accuracy 21.9224\n",
      "Epoch 75 Batch 15 Loss 0.0577 Accuracy 21.9223\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 76 Batch 5 Loss 0.0577 Accuracy 21.9222\n",
      "Epoch 76 Batch 10 Loss 0.0577 Accuracy 21.9221\n",
      "Epoch 76 Batch 15 Loss 0.0577 Accuracy 21.9221\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 77 Batch 5 Loss 0.0577 Accuracy 21.9219\n",
      "Epoch 77 Batch 10 Loss 0.0577 Accuracy 21.9219\n",
      "Epoch 77 Batch 15 Loss 0.0577 Accuracy 21.9218\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 78 Batch 5 Loss 0.0577 Accuracy 21.9217\n",
      "Epoch 78 Batch 10 Loss 0.0577 Accuracy 21.9216\n",
      "Epoch 78 Batch 15 Loss 0.0577 Accuracy 21.9215\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 79 Batch 5 Loss 0.0577 Accuracy 21.9214\n",
      "Epoch 79 Batch 10 Loss 0.0577 Accuracy 21.9214\n",
      "Epoch 79 Batch 15 Loss 0.0577 Accuracy 21.9213\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 80 Batch 5 Loss 0.0577 Accuracy 21.9212\n",
      "Epoch 80 Batch 10 Loss 0.0577 Accuracy 21.9211\n",
      "Epoch 80 Batch 15 Loss 0.0577 Accuracy 21.9210\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 81 Batch 5 Loss 0.0577 Accuracy 21.9209\n",
      "Epoch 81 Batch 10 Loss 0.0577 Accuracy 21.9209\n",
      "Epoch 81 Batch 15 Loss 0.0577 Accuracy 21.9208\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 82 Batch 5 Loss 0.0577 Accuracy 21.9207\n",
      "Epoch 82 Batch 10 Loss 0.0577 Accuracy 21.9206\n",
      "Epoch 82 Batch 15 Loss 0.0577 Accuracy 21.9205\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 83 Batch 5 Loss 0.0577 Accuracy 21.9204\n",
      "Epoch 83 Batch 10 Loss 0.0577 Accuracy 21.9204\n",
      "Epoch 83 Batch 15 Loss 0.0577 Accuracy 21.9203\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 84 Batch 5 Loss 0.0577 Accuracy 21.9202\n",
      "Epoch 84 Batch 10 Loss 0.0577 Accuracy 21.9201\n",
      "Epoch 84 Batch 15 Loss 0.0577 Accuracy 21.9201\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 85 Batch 5 Loss 0.0577 Accuracy 21.9200\n",
      "Epoch 85 Batch 10 Loss 0.0577 Accuracy 21.9199\n",
      "Epoch 85 Batch 15 Loss 0.0577 Accuracy 21.9198\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 86 Batch 5 Loss 0.0577 Accuracy 21.9197\n",
      "Epoch 86 Batch 10 Loss 0.0577 Accuracy 21.9197\n",
      "Epoch 86 Batch 15 Loss 0.0577 Accuracy 21.9196\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 87 Batch 5 Loss 0.0577 Accuracy 21.9195\n",
      "Epoch 87 Batch 10 Loss 0.0577 Accuracy 21.9194\n",
      "Epoch 87 Batch 15 Loss 0.0577 Accuracy 21.9193\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 88 Batch 5 Loss 0.0577 Accuracy 21.9192\n",
      "Epoch 88 Batch 10 Loss 0.0577 Accuracy 21.9192\n",
      "Epoch 88 Batch 15 Loss 0.0577 Accuracy 21.9191\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 89 Batch 5 Loss 0.0577 Accuracy 21.9190\n",
      "Epoch 89 Batch 10 Loss 0.0577 Accuracy 21.9189\n",
      "Epoch 89 Batch 15 Loss 0.0577 Accuracy 21.9189\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 90 Batch 5 Loss 0.0577 Accuracy 21.9188\n",
      "Epoch 90 Batch 10 Loss 0.0577 Accuracy 21.9187\n",
      "Epoch 90 Batch 15 Loss 0.0577 Accuracy 21.9186\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 91 Batch 5 Loss 0.0577 Accuracy 21.9185\n",
      "Epoch 91 Batch 10 Loss 0.0577 Accuracy 21.9185\n",
      "Epoch 91 Batch 15 Loss 0.0577 Accuracy 21.9184\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 92 Batch 5 Loss 0.0577 Accuracy 21.9183\n",
      "Epoch 92 Batch 10 Loss 0.0577 Accuracy 21.9182\n",
      "Epoch 92 Batch 15 Loss 0.0577 Accuracy 21.9181\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 93 Batch 5 Loss 0.0577 Accuracy 21.9180\n",
      "Epoch 93 Batch 10 Loss 0.0577 Accuracy 21.9180\n",
      "Epoch 93 Batch 15 Loss 0.0577 Accuracy 21.9179\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 94 Batch 5 Loss 0.0577 Accuracy 21.9178\n",
      "Epoch 94 Batch 10 Loss 0.0577 Accuracy 21.9177\n",
      "Epoch 94 Batch 15 Loss 0.0577 Accuracy 21.9177\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 95 Batch 5 Loss 0.0577 Accuracy 21.9176\n",
      "Epoch 95 Batch 10 Loss 0.0577 Accuracy 21.9175\n",
      "Epoch 95 Batch 15 Loss 0.0577 Accuracy 21.9174\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 96 Batch 5 Loss 0.0577 Accuracy 21.9174\n",
      "Epoch 96 Batch 10 Loss 0.0577 Accuracy 21.9173\n",
      "Epoch 96 Batch 15 Loss 0.0577 Accuracy 21.9172\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 97 Batch 5 Loss 0.0577 Accuracy 21.9171\n",
      "Epoch 97 Batch 10 Loss 0.0577 Accuracy 21.9171\n",
      "Epoch 97 Batch 15 Loss 0.0577 Accuracy 21.9170\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 98 Batch 5 Loss 0.0577 Accuracy 21.9169\n",
      "Epoch 98 Batch 10 Loss 0.0577 Accuracy 21.9169\n",
      "Epoch 98 Batch 15 Loss 0.0577 Accuracy 21.9168\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 99 Batch 5 Loss 0.0577 Accuracy 21.9167\n",
      "Epoch 99 Batch 10 Loss 0.0577 Accuracy 21.9166\n",
      "Epoch 99 Batch 15 Loss 0.0577 Accuracy 21.9166\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 100 Batch 5 Loss 0.0577 Accuracy 21.9165\n",
      "Epoch 100 Batch 10 Loss 0.0577 Accuracy 21.9164\n",
      "Epoch 100 Batch 15 Loss 0.0577 Accuracy 21.9164\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 101 Batch 5 Loss 0.0577 Accuracy 21.9163\n",
      "Epoch 101 Batch 10 Loss 0.0577 Accuracy 21.9162\n",
      "Epoch 101 Batch 15 Loss 0.0577 Accuracy 21.9162\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 102 Batch 5 Loss 0.0577 Accuracy 21.9161\n",
      "Epoch 102 Batch 10 Loss 0.0577 Accuracy 21.9160\n",
      "Epoch 102 Batch 15 Loss 0.0577 Accuracy 21.9160\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 103 Batch 5 Loss 0.0577 Accuracy 21.9159\n",
      "Epoch 103 Batch 10 Loss 0.0577 Accuracy 21.9159\n",
      "Epoch 103 Batch 15 Loss 0.0577 Accuracy 21.9158\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 104 Batch 5 Loss 0.0577 Accuracy 21.9157\n",
      "Epoch 104 Batch 10 Loss 0.0577 Accuracy 21.9157\n",
      "Epoch 104 Batch 15 Loss 0.0577 Accuracy 21.9156\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 105 Batch 5 Loss 0.0577 Accuracy 21.9155\n",
      "Epoch 105 Batch 10 Loss 0.0577 Accuracy 21.9155\n",
      "Epoch 105 Batch 15 Loss 0.0577 Accuracy 21.9154\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 106 Batch 5 Loss 0.0577 Accuracy 21.9153\n",
      "Epoch 106 Batch 10 Loss 0.0577 Accuracy 21.9153\n",
      "Epoch 106 Batch 15 Loss 0.0577 Accuracy 21.9152\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 107 Batch 5 Loss 0.0577 Accuracy 21.9152\n",
      "Epoch 107 Batch 10 Loss 0.0577 Accuracy 21.9151\n",
      "Epoch 107 Batch 15 Loss 0.0577 Accuracy 21.9151\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 108 Batch 5 Loss 0.0577 Accuracy 21.9150\n",
      "Epoch 108 Batch 10 Loss 0.0577 Accuracy 21.9149\n",
      "Epoch 108 Batch 15 Loss 0.0577 Accuracy 21.9149\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 109 Batch 5 Loss 0.0577 Accuracy 21.9148\n",
      "Epoch 109 Batch 10 Loss 0.0577 Accuracy 21.9148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109 Batch 15 Loss 0.0577 Accuracy 21.9147\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 110 Batch 5 Loss 0.0577 Accuracy 21.9147\n",
      "Epoch 110 Batch 10 Loss 0.0577 Accuracy 21.9146\n",
      "Epoch 110 Batch 15 Loss 0.0577 Accuracy 21.9146\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 111 Batch 5 Loss 0.0577 Accuracy 21.9145\n",
      "Epoch 111 Batch 10 Loss 0.0577 Accuracy 21.9144\n",
      "Epoch 111 Batch 15 Loss 0.0577 Accuracy 21.9144\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 112 Batch 5 Loss 0.0577 Accuracy 21.9143\n",
      "Epoch 112 Batch 10 Loss 0.0577 Accuracy 21.9143\n",
      "Epoch 112 Batch 15 Loss 0.0577 Accuracy 21.9142\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 113 Batch 5 Loss 0.0577 Accuracy 21.9142\n",
      "Epoch 113 Batch 10 Loss 0.0577 Accuracy 21.9141\n",
      "Epoch 113 Batch 15 Loss 0.0577 Accuracy 21.9141\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 114 Batch 5 Loss 0.0577 Accuracy 21.9140\n",
      "Epoch 114 Batch 10 Loss 0.0577 Accuracy 21.9139\n",
      "Epoch 114 Batch 15 Loss 0.0577 Accuracy 21.9139\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 115 Batch 5 Loss 0.0577 Accuracy 21.9138\n",
      "Epoch 115 Batch 10 Loss 0.0577 Accuracy 21.9138\n",
      "Epoch 115 Batch 15 Loss 0.0577 Accuracy 21.9137\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 116 Batch 5 Loss 0.0577 Accuracy 21.9137\n",
      "Epoch 116 Batch 10 Loss 0.0577 Accuracy 21.9136\n",
      "Epoch 116 Batch 15 Loss 0.0577 Accuracy 21.9136\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 117 Batch 5 Loss 0.0577 Accuracy 21.9135\n",
      "Epoch 117 Batch 10 Loss 0.0577 Accuracy 21.9135\n",
      "Epoch 117 Batch 15 Loss 0.0577 Accuracy 21.9134\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 118 Batch 5 Loss 0.0577 Accuracy 21.9134\n",
      "Epoch 118 Batch 10 Loss 0.0577 Accuracy 21.9133\n",
      "Epoch 118 Batch 15 Loss 0.0577 Accuracy 21.9133\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 119 Batch 5 Loss 0.0577 Accuracy 21.9132\n",
      "Epoch 119 Batch 10 Loss 0.0577 Accuracy 21.9132\n",
      "Epoch 119 Batch 15 Loss 0.0577 Accuracy 21.9131\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 120 Batch 5 Loss 0.0577 Accuracy 21.9130\n",
      "Epoch 120 Batch 10 Loss 0.0577 Accuracy 21.9130\n",
      "Epoch 120 Batch 15 Loss 0.0577 Accuracy 21.9129\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 121 Batch 5 Loss 0.0577 Accuracy 21.9129\n",
      "Epoch 121 Batch 10 Loss 0.0577 Accuracy 21.9128\n",
      "Epoch 121 Batch 15 Loss 0.0577 Accuracy 21.9128\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 122 Batch 5 Loss 0.0577 Accuracy 21.9127\n",
      "Epoch 122 Batch 10 Loss 0.0577 Accuracy 21.9127\n",
      "Epoch 122 Batch 15 Loss 0.0577 Accuracy 21.9126\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 123 Batch 5 Loss 0.0577 Accuracy 21.9126\n",
      "Epoch 123 Batch 10 Loss 0.0577 Accuracy 21.9125\n",
      "Epoch 123 Batch 15 Loss 0.0577 Accuracy 21.9125\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 124 Batch 5 Loss 0.0577 Accuracy 21.9124\n",
      "Epoch 124 Batch 10 Loss 0.0577 Accuracy 21.9124\n",
      "Epoch 124 Batch 15 Loss 0.0577 Accuracy 21.9123\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 125 Batch 5 Loss 0.0577 Accuracy 21.9123\n",
      "Epoch 125 Batch 10 Loss 0.0577 Accuracy 21.9122\n",
      "Epoch 125 Batch 15 Loss 0.0577 Accuracy 21.9122\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 126 Batch 5 Loss 0.0577 Accuracy 21.9121\n",
      "Epoch 126 Batch 10 Loss 0.0577 Accuracy 21.9121\n",
      "Epoch 126 Batch 15 Loss 0.0577 Accuracy 21.9120\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 127 Batch 5 Loss 0.0577 Accuracy 21.9120\n",
      "Epoch 127 Batch 10 Loss 0.0577 Accuracy 21.9119\n",
      "Epoch 127 Batch 15 Loss 0.0577 Accuracy 21.9119\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 128 Batch 5 Loss 0.0577 Accuracy 21.9118\n",
      "Epoch 128 Batch 10 Loss 0.0577 Accuracy 21.9118\n",
      "Epoch 128 Batch 15 Loss 0.0577 Accuracy 21.9117\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 129 Batch 5 Loss 0.0577 Accuracy 21.9117\n",
      "Epoch 129 Batch 10 Loss 0.0577 Accuracy 21.9116\n",
      "Epoch 129 Batch 15 Loss 0.0577 Accuracy 21.9116\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 130 Batch 5 Loss 0.0577 Accuracy 21.9115\n",
      "Epoch 130 Batch 10 Loss 0.0577 Accuracy 21.9115\n",
      "Epoch 130 Batch 15 Loss 0.0577 Accuracy 21.9115\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 131 Batch 5 Loss 0.0577 Accuracy 21.9114\n",
      "Epoch 131 Batch 10 Loss 0.0577 Accuracy 21.9114\n",
      "Epoch 131 Batch 15 Loss 0.0577 Accuracy 21.9113\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 132 Batch 5 Loss 0.0577 Accuracy 21.9113\n",
      "Epoch 132 Batch 10 Loss 0.0577 Accuracy 21.9112\n",
      "Epoch 132 Batch 15 Loss 0.0577 Accuracy 21.9112\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 133 Batch 5 Loss 0.0577 Accuracy 21.9111\n",
      "Epoch 133 Batch 10 Loss 0.0577 Accuracy 21.9111\n",
      "Epoch 133 Batch 15 Loss 0.0577 Accuracy 21.9111\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 134 Batch 5 Loss 0.0577 Accuracy 21.9110\n",
      "Epoch 134 Batch 10 Loss 0.0577 Accuracy 21.9110\n",
      "Epoch 134 Batch 15 Loss 0.0577 Accuracy 21.9109\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 135 Batch 5 Loss 0.0577 Accuracy 21.9109\n",
      "Epoch 135 Batch 10 Loss 0.0577 Accuracy 21.9108\n",
      "Epoch 135 Batch 15 Loss 0.0577 Accuracy 21.9108\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 136 Batch 5 Loss 0.0577 Accuracy 21.9108\n",
      "Epoch 136 Batch 10 Loss 0.0577 Accuracy 21.9107\n",
      "Epoch 136 Batch 15 Loss 0.0577 Accuracy 21.9107\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 137 Batch 5 Loss 0.0577 Accuracy 21.9106\n",
      "Epoch 137 Batch 10 Loss 0.0577 Accuracy 21.9106\n",
      "Epoch 137 Batch 15 Loss 0.0577 Accuracy 21.9106\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 138 Batch 5 Loss 0.0577 Accuracy 21.9105\n",
      "Epoch 138 Batch 10 Loss 0.0577 Accuracy 21.9105\n",
      "Epoch 138 Batch 15 Loss 0.0577 Accuracy 21.9104\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 139 Batch 5 Loss 0.0577 Accuracy 21.9104\n",
      "Epoch 139 Batch 10 Loss 0.0577 Accuracy 21.9104\n",
      "Epoch 139 Batch 15 Loss 0.0577 Accuracy 21.9103\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 140 Batch 5 Loss 0.0577 Accuracy 21.9103\n",
      "Epoch 140 Batch 10 Loss 0.0577 Accuracy 21.9102\n",
      "Epoch 140 Batch 15 Loss 0.0577 Accuracy 21.9102\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 141 Batch 5 Loss 0.0577 Accuracy 21.9101\n",
      "Epoch 141 Batch 10 Loss 0.0577 Accuracy 21.9101\n",
      "Epoch 141 Batch 15 Loss 0.0577 Accuracy 21.9101\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 142 Batch 5 Loss 0.0577 Accuracy 21.9100\n",
      "Epoch 142 Batch 10 Loss 0.0577 Accuracy 21.9100\n",
      "Epoch 142 Batch 15 Loss 0.0577 Accuracy 21.9099\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 143 Batch 5 Loss 0.0577 Accuracy 21.9099\n",
      "Epoch 143 Batch 10 Loss 0.0577 Accuracy 21.9099\n",
      "Epoch 143 Batch 15 Loss 0.0577 Accuracy 21.9098\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 144 Batch 5 Loss 0.0577 Accuracy 21.9098\n",
      "Epoch 144 Batch 10 Loss 0.0577 Accuracy 21.9097\n",
      "Epoch 144 Batch 15 Loss 0.0577 Accuracy 21.9097\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 145 Batch 5 Loss 0.0577 Accuracy 21.9096\n",
      "Epoch 145 Batch 10 Loss 0.0577 Accuracy 21.9096\n",
      "Epoch 145 Batch 15 Loss 0.0577 Accuracy 21.9096\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 146 Batch 5 Loss 0.0577 Accuracy 21.9095\n",
      "Epoch 146 Batch 10 Loss 0.0577 Accuracy 21.9095\n",
      "Epoch 146 Batch 15 Loss 0.0577 Accuracy 21.9095\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 147 Batch 5 Loss 0.0577 Accuracy 21.9094\n",
      "Epoch 147 Batch 10 Loss 0.0577 Accuracy 21.9094\n",
      "Epoch 147 Batch 15 Loss 0.0577 Accuracy 21.9093\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 148 Batch 5 Loss 0.0577 Accuracy 21.9093\n",
      "Epoch 148 Batch 10 Loss 0.0577 Accuracy 21.9093\n",
      "Epoch 148 Batch 15 Loss 0.0577 Accuracy 21.9092\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 149 Batch 5 Loss 0.0577 Accuracy 21.9092\n",
      "Epoch 149 Batch 10 Loss 0.0577 Accuracy 21.9092\n",
      "Epoch 149 Batch 15 Loss 0.0577 Accuracy 21.9091\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 150 Batch 5 Loss 0.0577 Accuracy 21.9091\n",
      "Epoch 150 Batch 10 Loss 0.0577 Accuracy 21.9090\n",
      "Epoch 150 Batch 15 Loss 0.0577 Accuracy 21.9090\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 151 Batch 5 Loss 0.0577 Accuracy 21.9090\n",
      "Epoch 151 Batch 10 Loss 0.0577 Accuracy 21.9089\n",
      "Epoch 151 Batch 15 Loss 0.0577 Accuracy 21.9089\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 152 Batch 5 Loss 0.0577 Accuracy 21.9089\n",
      "Epoch 152 Batch 10 Loss 0.0577 Accuracy 21.9088\n",
      "Epoch 152 Batch 15 Loss 0.0577 Accuracy 21.9088\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 153 Batch 5 Loss 0.0577 Accuracy 21.9087\n",
      "Epoch 153 Batch 10 Loss 0.0577 Accuracy 21.9087\n",
      "Epoch 153 Batch 15 Loss 0.0577 Accuracy 21.9087\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 154 Batch 5 Loss 0.0577 Accuracy 21.9086\n",
      "Epoch 154 Batch 10 Loss 0.0577 Accuracy 21.9086\n",
      "Epoch 154 Batch 15 Loss 0.0577 Accuracy 21.9086\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 155 Batch 5 Loss 0.0577 Accuracy 21.9085\n",
      "Epoch 155 Batch 10 Loss 0.0577 Accuracy 21.9085\n",
      "Epoch 155 Batch 15 Loss 0.0577 Accuracy 21.9085\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 156 Batch 5 Loss 0.0577 Accuracy 21.9084\n",
      "Epoch 156 Batch 10 Loss 0.0577 Accuracy 21.9084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156 Batch 15 Loss 0.0577 Accuracy 21.9084\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 157 Batch 5 Loss 0.0577 Accuracy 21.9083\n",
      "Epoch 157 Batch 10 Loss 0.0577 Accuracy 21.9083\n",
      "Epoch 157 Batch 15 Loss 0.0577 Accuracy 21.9083\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 158 Batch 5 Loss 0.0577 Accuracy 21.9082\n",
      "Epoch 158 Batch 10 Loss 0.0577 Accuracy 21.9082\n",
      "Epoch 158 Batch 15 Loss 0.0577 Accuracy 21.9082\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 159 Batch 5 Loss 0.0577 Accuracy 21.9081\n",
      "Epoch 159 Batch 10 Loss 0.0577 Accuracy 21.9081\n",
      "Epoch 159 Batch 15 Loss 0.0577 Accuracy 21.9081\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 160 Batch 5 Loss 0.0577 Accuracy 21.9080\n",
      "Epoch 160 Batch 10 Loss 0.0577 Accuracy 21.9080\n",
      "Epoch 160 Batch 15 Loss 0.0577 Accuracy 21.9080\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 161 Batch 5 Loss 0.0577 Accuracy 21.9079\n",
      "Epoch 161 Batch 10 Loss 0.0577 Accuracy 21.9079\n",
      "Epoch 161 Batch 15 Loss 0.0577 Accuracy 21.9079\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 162 Batch 5 Loss 0.0577 Accuracy 21.9078\n",
      "Epoch 162 Batch 10 Loss 0.0577 Accuracy 21.9078\n",
      "Epoch 162 Batch 15 Loss 0.0577 Accuracy 21.9078\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 163 Batch 5 Loss 0.0577 Accuracy 21.9077\n",
      "Epoch 163 Batch 10 Loss 0.0577 Accuracy 21.9077\n",
      "Epoch 163 Batch 15 Loss 0.0577 Accuracy 21.9077\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 164 Batch 5 Loss 0.0577 Accuracy 21.9076\n",
      "Epoch 164 Batch 10 Loss 0.0577 Accuracy 21.9076\n",
      "Epoch 164 Batch 15 Loss 0.0577 Accuracy 21.9076\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 165 Batch 5 Loss 0.0577 Accuracy 21.9075\n",
      "Epoch 165 Batch 10 Loss 0.0577 Accuracy 21.9075\n",
      "Epoch 165 Batch 15 Loss 0.0577 Accuracy 21.9075\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 166 Batch 5 Loss 0.0577 Accuracy 21.9074\n",
      "Epoch 166 Batch 10 Loss 0.0577 Accuracy 21.9074\n",
      "Epoch 166 Batch 15 Loss 0.0577 Accuracy 21.9074\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 167 Batch 5 Loss 0.0577 Accuracy 21.9074\n",
      "Epoch 167 Batch 10 Loss 0.0577 Accuracy 21.9073\n",
      "Epoch 167 Batch 15 Loss 0.0577 Accuracy 21.9073\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 168 Batch 5 Loss 0.0577 Accuracy 21.9073\n",
      "Epoch 168 Batch 10 Loss 0.0577 Accuracy 21.9072\n",
      "Epoch 168 Batch 15 Loss 0.0577 Accuracy 21.9072\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 169 Batch 5 Loss 0.0577 Accuracy 21.9072\n",
      "Epoch 169 Batch 10 Loss 0.0577 Accuracy 21.9072\n",
      "Epoch 169 Batch 15 Loss 0.0577 Accuracy 21.9071\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 170 Batch 5 Loss 0.0577 Accuracy 21.9071\n",
      "Epoch 170 Batch 10 Loss 0.0577 Accuracy 21.9071\n",
      "Epoch 170 Batch 15 Loss 0.0577 Accuracy 21.9070\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 171 Batch 5 Loss 0.0577 Accuracy 21.9070\n",
      "Epoch 171 Batch 10 Loss 0.0577 Accuracy 21.9070\n",
      "Epoch 171 Batch 15 Loss 0.0577 Accuracy 21.9070\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 172 Batch 5 Loss 0.0577 Accuracy 21.9069\n",
      "Epoch 172 Batch 10 Loss 0.0577 Accuracy 21.9069\n",
      "Epoch 172 Batch 15 Loss 0.0577 Accuracy 21.9069\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 173 Batch 5 Loss 0.0577 Accuracy 21.9068\n",
      "Epoch 173 Batch 10 Loss 0.0577 Accuracy 21.9068\n",
      "Epoch 173 Batch 15 Loss 0.0577 Accuracy 21.9068\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 174 Batch 5 Loss 0.0577 Accuracy 21.9068\n",
      "Epoch 174 Batch 10 Loss 0.0577 Accuracy 21.9067\n",
      "Epoch 174 Batch 15 Loss 0.0577 Accuracy 21.9067\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 175 Batch 5 Loss 0.0577 Accuracy 21.9067\n",
      "Epoch 175 Batch 10 Loss 0.0577 Accuracy 21.9067\n",
      "Epoch 175 Batch 15 Loss 0.0577 Accuracy 21.9066\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 176 Batch 5 Loss 0.0577 Accuracy 21.9066\n",
      "Epoch 176 Batch 10 Loss 0.0577 Accuracy 21.9066\n",
      "Epoch 176 Batch 15 Loss 0.0577 Accuracy 21.9065\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 177 Batch 5 Loss 0.0577 Accuracy 21.9065\n",
      "Epoch 177 Batch 10 Loss 0.0577 Accuracy 21.9065\n",
      "Epoch 177 Batch 15 Loss 0.0577 Accuracy 21.9065\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 178 Batch 5 Loss 0.0577 Accuracy 21.9064\n",
      "Epoch 178 Batch 10 Loss 0.0577 Accuracy 21.9064\n",
      "Epoch 178 Batch 15 Loss 0.0577 Accuracy 21.9064\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 179 Batch 5 Loss 0.0577 Accuracy 21.9064\n",
      "Epoch 179 Batch 10 Loss 0.0577 Accuracy 21.9063\n",
      "Epoch 179 Batch 15 Loss 0.0577 Accuracy 21.9063\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 180 Batch 5 Loss 0.0577 Accuracy 21.9063\n",
      "Epoch 180 Batch 10 Loss 0.0577 Accuracy 21.9063\n",
      "Epoch 180 Batch 15 Loss 0.0577 Accuracy 21.9062\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 181 Batch 5 Loss 0.0577 Accuracy 21.9062\n",
      "Epoch 181 Batch 10 Loss 0.0577 Accuracy 21.9062\n",
      "Epoch 181 Batch 15 Loss 0.0577 Accuracy 21.9062\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 182 Batch 5 Loss 0.0577 Accuracy 21.9061\n",
      "Epoch 182 Batch 10 Loss 0.0577 Accuracy 21.9061\n",
      "Epoch 182 Batch 15 Loss 0.0577 Accuracy 21.9061\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 183 Batch 5 Loss 0.0577 Accuracy 21.9061\n",
      "Epoch 183 Batch 10 Loss 0.0577 Accuracy 21.9060\n",
      "Epoch 183 Batch 15 Loss 0.0577 Accuracy 21.9060\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 184 Batch 5 Loss 0.0577 Accuracy 21.9060\n",
      "Epoch 184 Batch 10 Loss 0.0577 Accuracy 21.9060\n",
      "Epoch 184 Batch 15 Loss 0.0577 Accuracy 21.9059\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 185 Batch 5 Loss 0.0577 Accuracy 21.9059\n",
      "Epoch 185 Batch 10 Loss 0.0577 Accuracy 21.9059\n",
      "Epoch 185 Batch 15 Loss 0.0577 Accuracy 21.9059\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 186 Batch 5 Loss 0.0577 Accuracy 21.9058\n",
      "Epoch 186 Batch 10 Loss 0.0577 Accuracy 21.9058\n",
      "Epoch 186 Batch 15 Loss 0.0577 Accuracy 21.9058\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 187 Batch 5 Loss 0.0577 Accuracy 21.9058\n",
      "Epoch 187 Batch 10 Loss 0.0577 Accuracy 21.9058\n",
      "Epoch 187 Batch 15 Loss 0.0577 Accuracy 21.9057\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 188 Batch 5 Loss 0.0577 Accuracy 21.9057\n",
      "Epoch 188 Batch 10 Loss 0.0577 Accuracy 21.9057\n",
      "Epoch 188 Batch 15 Loss 0.0577 Accuracy 21.9057\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 189 Batch 5 Loss 0.0577 Accuracy 21.9056\n",
      "Epoch 189 Batch 10 Loss 0.0577 Accuracy 21.9056\n",
      "Epoch 189 Batch 15 Loss 0.0577 Accuracy 21.9056\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 190 Batch 5 Loss 0.0577 Accuracy 21.9056\n",
      "Epoch 190 Batch 10 Loss 0.0577 Accuracy 21.9055\n",
      "Epoch 190 Batch 15 Loss 0.0577 Accuracy 21.9055\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 191 Batch 5 Loss 0.0577 Accuracy 21.9055\n",
      "Epoch 191 Batch 10 Loss 0.0577 Accuracy 21.9055\n",
      "Epoch 191 Batch 15 Loss 0.0577 Accuracy 21.9055\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 192 Batch 5 Loss 0.0577 Accuracy 21.9054\n",
      "Epoch 192 Batch 10 Loss 0.0577 Accuracy 21.9054\n",
      "Epoch 192 Batch 15 Loss 0.0577 Accuracy 21.9054\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 193 Batch 5 Loss 0.0577 Accuracy 21.9054\n",
      "Epoch 193 Batch 10 Loss 0.0577 Accuracy 21.9053\n",
      "Epoch 193 Batch 15 Loss 0.0577 Accuracy 21.9053\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 194 Batch 5 Loss 0.0577 Accuracy 21.9053\n",
      "Epoch 194 Batch 10 Loss 0.0577 Accuracy 21.9053\n",
      "Epoch 194 Batch 15 Loss 0.0577 Accuracy 21.9053\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 195 Batch 5 Loss 0.0577 Accuracy 21.9052\n",
      "Epoch 195 Batch 10 Loss 0.0577 Accuracy 21.9052\n",
      "Epoch 195 Batch 15 Loss 0.0577 Accuracy 21.9052\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 196 Batch 5 Loss 0.0577 Accuracy 21.9052\n",
      "Epoch 196 Batch 10 Loss 0.0577 Accuracy 21.9051\n",
      "Epoch 196 Batch 15 Loss 0.0577 Accuracy 21.9051\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 197 Batch 5 Loss 0.0577 Accuracy 21.9051\n",
      "Epoch 197 Batch 10 Loss 0.0577 Accuracy 21.9051\n",
      "Epoch 197 Batch 15 Loss 0.0577 Accuracy 21.9050\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 198 Batch 5 Loss 0.0577 Accuracy 21.9050\n",
      "Epoch 198 Batch 10 Loss 0.0577 Accuracy 21.9050\n",
      "Epoch 198 Batch 15 Loss 0.0577 Accuracy 21.9050\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 199 Batch 5 Loss 0.0577 Accuracy 21.9049\n",
      "Epoch 199 Batch 10 Loss 0.0577 Accuracy 21.9049\n",
      "Epoch 199 Batch 15 Loss 0.0577 Accuracy 21.9049\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 200 Batch 5 Loss 0.0577 Accuracy 21.9049\n",
      "Epoch 200 Batch 10 Loss 0.0577 Accuracy 21.9049\n",
      "Epoch 200 Batch 15 Loss 0.0577 Accuracy 21.9048\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 201 Batch 5 Loss 0.0577 Accuracy 21.9048\n",
      "Epoch 201 Batch 10 Loss 0.0577 Accuracy 21.9048\n",
      "Epoch 201 Batch 15 Loss 0.0577 Accuracy 21.9048\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 202 Batch 5 Loss 0.0577 Accuracy 21.9047\n",
      "Epoch 202 Batch 10 Loss 0.0577 Accuracy 21.9047\n",
      "Epoch 202 Batch 15 Loss 0.0577 Accuracy 21.9047\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 203 Batch 5 Loss 0.0577 Accuracy 21.9047\n",
      "Epoch 203 Batch 10 Loss 0.0577 Accuracy 21.9046\n",
      "Epoch 203 Batch 15 Loss 0.0577 Accuracy 21.9046\n",
      "Time taken for 1 epoch: 0.02 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 204 Batch 5 Loss 0.0577 Accuracy 21.9046\n",
      "Epoch 204 Batch 10 Loss 0.0577 Accuracy 21.9046\n",
      "Epoch 204 Batch 15 Loss 0.0577 Accuracy 21.9046\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 205 Batch 5 Loss 0.0577 Accuracy 21.9045\n",
      "Epoch 205 Batch 10 Loss 0.0577 Accuracy 21.9045\n",
      "Epoch 205 Batch 15 Loss 0.0577 Accuracy 21.9045\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 206 Batch 5 Loss 0.0577 Accuracy 21.9045\n",
      "Epoch 206 Batch 10 Loss 0.0577 Accuracy 21.9045\n",
      "Epoch 206 Batch 15 Loss 0.0577 Accuracy 21.9044\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 207 Batch 5 Loss 0.0577 Accuracy 21.9044\n",
      "Epoch 207 Batch 10 Loss 0.0577 Accuracy 21.9044\n",
      "Epoch 207 Batch 15 Loss 0.0577 Accuracy 21.9044\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 208 Batch 5 Loss 0.0577 Accuracy 21.9043\n",
      "Epoch 208 Batch 10 Loss 0.0577 Accuracy 21.9043\n",
      "Epoch 208 Batch 15 Loss 0.0577 Accuracy 21.9043\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 209 Batch 5 Loss 0.0577 Accuracy 21.9043\n",
      "Epoch 209 Batch 10 Loss 0.0577 Accuracy 21.9043\n",
      "Epoch 209 Batch 15 Loss 0.0577 Accuracy 21.9042\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 210 Batch 5 Loss 0.0577 Accuracy 21.9042\n",
      "Epoch 210 Batch 10 Loss 0.0577 Accuracy 21.9042\n",
      "Epoch 210 Batch 15 Loss 0.0577 Accuracy 21.9042\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 211 Batch 5 Loss 0.0577 Accuracy 21.9042\n",
      "Epoch 211 Batch 10 Loss 0.0577 Accuracy 21.9041\n",
      "Epoch 211 Batch 15 Loss 0.0577 Accuracy 21.9041\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 212 Batch 5 Loss 0.0577 Accuracy 21.9041\n",
      "Epoch 212 Batch 10 Loss 0.0577 Accuracy 21.9041\n",
      "Epoch 212 Batch 15 Loss 0.0577 Accuracy 21.9040\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 213 Batch 5 Loss 0.0577 Accuracy 21.9040\n",
      "Epoch 213 Batch 10 Loss 0.0577 Accuracy 21.9040\n",
      "Epoch 213 Batch 15 Loss 0.0577 Accuracy 21.9040\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 214 Batch 5 Loss 0.0577 Accuracy 21.9040\n",
      "Epoch 214 Batch 10 Loss 0.0577 Accuracy 21.9039\n",
      "Epoch 214 Batch 15 Loss 0.0577 Accuracy 21.9039\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 215 Batch 5 Loss 0.0577 Accuracy 21.9039\n",
      "Epoch 215 Batch 10 Loss 0.0577 Accuracy 21.9039\n",
      "Epoch 215 Batch 15 Loss 0.0577 Accuracy 21.9039\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 216 Batch 5 Loss 0.0577 Accuracy 21.9038\n",
      "Epoch 216 Batch 10 Loss 0.0577 Accuracy 21.9038\n",
      "Epoch 216 Batch 15 Loss 0.0577 Accuracy 21.9038\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 217 Batch 5 Loss 0.0577 Accuracy 21.9038\n",
      "Epoch 217 Batch 10 Loss 0.0577 Accuracy 21.9038\n",
      "Epoch 217 Batch 15 Loss 0.0577 Accuracy 21.9037\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 218 Batch 5 Loss 0.0577 Accuracy 21.9037\n",
      "Epoch 218 Batch 10 Loss 0.0577 Accuracy 21.9037\n",
      "Epoch 218 Batch 15 Loss 0.0577 Accuracy 21.9037\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 219 Batch 5 Loss 0.0577 Accuracy 21.9037\n",
      "Epoch 219 Batch 10 Loss 0.0577 Accuracy 21.9036\n",
      "Epoch 219 Batch 15 Loss 0.0577 Accuracy 21.9036\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 220 Batch 5 Loss 0.0577 Accuracy 21.9036\n",
      "Epoch 220 Batch 10 Loss 0.0577 Accuracy 21.9036\n",
      "Epoch 220 Batch 15 Loss 0.0577 Accuracy 21.9036\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 221 Batch 5 Loss 0.0577 Accuracy 21.9035\n",
      "Epoch 221 Batch 10 Loss 0.0577 Accuracy 21.9035\n",
      "Epoch 221 Batch 15 Loss 0.0577 Accuracy 21.9035\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 222 Batch 5 Loss 0.0577 Accuracy 21.9035\n",
      "Epoch 222 Batch 10 Loss 0.0577 Accuracy 21.9035\n",
      "Epoch 222 Batch 15 Loss 0.0577 Accuracy 21.9034\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 223 Batch 5 Loss 0.0577 Accuracy 21.9034\n",
      "Epoch 223 Batch 10 Loss 0.0577 Accuracy 21.9034\n",
      "Epoch 223 Batch 15 Loss 0.0577 Accuracy 21.9034\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 224 Batch 5 Loss 0.0577 Accuracy 21.9034\n",
      "Epoch 224 Batch 10 Loss 0.0577 Accuracy 21.9034\n",
      "Epoch 224 Batch 15 Loss 0.0577 Accuracy 21.9033\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 225 Batch 5 Loss 0.0577 Accuracy 21.9033\n",
      "Epoch 225 Batch 10 Loss 0.0577 Accuracy 21.9033\n",
      "Epoch 225 Batch 15 Loss 0.0577 Accuracy 21.9033\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 226 Batch 5 Loss 0.0577 Accuracy 21.9033\n",
      "Epoch 226 Batch 10 Loss 0.0577 Accuracy 21.9032\n",
      "Epoch 226 Batch 15 Loss 0.0577 Accuracy 21.9032\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 227 Batch 5 Loss 0.0577 Accuracy 21.9032\n",
      "Epoch 227 Batch 10 Loss 0.0577 Accuracy 21.9032\n",
      "Epoch 227 Batch 15 Loss 0.0577 Accuracy 21.9032\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 228 Batch 5 Loss 0.0577 Accuracy 21.9032\n",
      "Epoch 228 Batch 10 Loss 0.0577 Accuracy 21.9031\n",
      "Epoch 228 Batch 15 Loss 0.0577 Accuracy 21.9031\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 229 Batch 5 Loss 0.0577 Accuracy 21.9031\n",
      "Epoch 229 Batch 10 Loss 0.0577 Accuracy 21.9031\n",
      "Epoch 229 Batch 15 Loss 0.0577 Accuracy 21.9031\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 230 Batch 5 Loss 0.0577 Accuracy 21.9031\n",
      "Epoch 230 Batch 10 Loss 0.0577 Accuracy 21.9030\n",
      "Epoch 230 Batch 15 Loss 0.0577 Accuracy 21.9030\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 231 Batch 5 Loss 0.0577 Accuracy 21.9030\n",
      "Epoch 231 Batch 10 Loss 0.0577 Accuracy 21.9030\n",
      "Epoch 231 Batch 15 Loss 0.0577 Accuracy 21.9030\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 232 Batch 5 Loss 0.0577 Accuracy 21.9030\n",
      "Epoch 232 Batch 10 Loss 0.0577 Accuracy 21.9029\n",
      "Epoch 232 Batch 15 Loss 0.0577 Accuracy 21.9029\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 233 Batch 5 Loss 0.0577 Accuracy 21.9029\n",
      "Epoch 233 Batch 10 Loss 0.0577 Accuracy 21.9029\n",
      "Epoch 233 Batch 15 Loss 0.0577 Accuracy 21.9029\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 234 Batch 5 Loss 0.0577 Accuracy 21.9028\n",
      "Epoch 234 Batch 10 Loss 0.0577 Accuracy 21.9028\n",
      "Epoch 234 Batch 15 Loss 0.0577 Accuracy 21.9028\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 235 Batch 5 Loss 0.0577 Accuracy 21.9028\n",
      "Epoch 235 Batch 10 Loss 0.0577 Accuracy 21.9028\n",
      "Epoch 235 Batch 15 Loss 0.0577 Accuracy 21.9028\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 236 Batch 5 Loss 0.0577 Accuracy 21.9028\n",
      "Epoch 236 Batch 10 Loss 0.0577 Accuracy 21.9027\n",
      "Epoch 236 Batch 15 Loss 0.0577 Accuracy 21.9027\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 237 Batch 5 Loss 0.0577 Accuracy 21.9027\n",
      "Epoch 237 Batch 10 Loss 0.0577 Accuracy 21.9027\n",
      "Epoch 237 Batch 15 Loss 0.0577 Accuracy 21.9027\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 238 Batch 5 Loss 0.0577 Accuracy 21.9027\n",
      "Epoch 238 Batch 10 Loss 0.0577 Accuracy 21.9026\n",
      "Epoch 238 Batch 15 Loss 0.0577 Accuracy 21.9026\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 239 Batch 5 Loss 0.0577 Accuracy 21.9026\n",
      "Epoch 239 Batch 10 Loss 0.0577 Accuracy 21.9026\n",
      "Epoch 239 Batch 15 Loss 0.0577 Accuracy 21.9026\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 240 Batch 5 Loss 0.0577 Accuracy 21.9026\n",
      "Epoch 240 Batch 10 Loss 0.0577 Accuracy 21.9025\n",
      "Epoch 240 Batch 15 Loss 0.0577 Accuracy 21.9025\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 241 Batch 5 Loss 0.0577 Accuracy 21.9025\n",
      "Epoch 241 Batch 10 Loss 0.0577 Accuracy 21.9025\n",
      "Epoch 241 Batch 15 Loss 0.0577 Accuracy 21.9025\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 242 Batch 5 Loss 0.0577 Accuracy 21.9025\n",
      "Epoch 242 Batch 10 Loss 0.0577 Accuracy 21.9024\n",
      "Epoch 242 Batch 15 Loss 0.0577 Accuracy 21.9024\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 243 Batch 5 Loss 0.0577 Accuracy 21.9024\n",
      "Epoch 243 Batch 10 Loss 0.0577 Accuracy 21.9024\n",
      "Epoch 243 Batch 15 Loss 0.0577 Accuracy 21.9024\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 244 Batch 5 Loss 0.0577 Accuracy 21.9024\n",
      "Epoch 244 Batch 10 Loss 0.0577 Accuracy 21.9024\n",
      "Epoch 244 Batch 15 Loss 0.0577 Accuracy 21.9023\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 245 Batch 5 Loss 0.0577 Accuracy 21.9023\n",
      "Epoch 245 Batch 10 Loss 0.0577 Accuracy 21.9023\n",
      "Epoch 245 Batch 15 Loss 0.0577 Accuracy 21.9023\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 246 Batch 5 Loss 0.0577 Accuracy 21.9023\n",
      "Epoch 246 Batch 10 Loss 0.0577 Accuracy 21.9023\n",
      "Epoch 246 Batch 15 Loss 0.0577 Accuracy 21.9022\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 247 Batch 5 Loss 0.0577 Accuracy 21.9022\n",
      "Epoch 247 Batch 10 Loss 0.0577 Accuracy 21.9022\n",
      "Epoch 247 Batch 15 Loss 0.0577 Accuracy 21.9022\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 248 Batch 5 Loss 0.0577 Accuracy 21.9022\n",
      "Epoch 248 Batch 10 Loss 0.0577 Accuracy 21.9022\n",
      "Epoch 248 Batch 15 Loss 0.0577 Accuracy 21.9022\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 249 Batch 5 Loss 0.0577 Accuracy 21.9021\n",
      "Epoch 249 Batch 10 Loss 0.0577 Accuracy 21.9021\n",
      "Epoch 249 Batch 15 Loss 0.0577 Accuracy 21.9021\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 250 Batch 5 Loss 0.0577 Accuracy 21.9021\n",
      "Epoch 250 Batch 10 Loss 0.0577 Accuracy 21.9021\n",
      "Epoch 250 Batch 15 Loss 0.0577 Accuracy 21.9021\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 251 Batch 5 Loss 0.0577 Accuracy 21.9021\n",
      "Epoch 251 Batch 10 Loss 0.0577 Accuracy 21.9020\n",
      "Epoch 251 Batch 15 Loss 0.0577 Accuracy 21.9020\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 252 Batch 5 Loss 0.0577 Accuracy 21.9020\n",
      "Epoch 252 Batch 10 Loss 0.0577 Accuracy 21.9020\n",
      "Epoch 252 Batch 15 Loss 0.0577 Accuracy 21.9020\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 253 Batch 5 Loss 0.0577 Accuracy 21.9020\n",
      "Epoch 253 Batch 10 Loss 0.0577 Accuracy 21.9020\n",
      "Epoch 253 Batch 15 Loss 0.0577 Accuracy 21.9019\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 254 Batch 5 Loss 0.0577 Accuracy 21.9019\n",
      "Epoch 254 Batch 10 Loss 0.0577 Accuracy 21.9019\n",
      "Epoch 254 Batch 15 Loss 0.0577 Accuracy 21.9019\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 255 Batch 5 Loss 0.0577 Accuracy 21.9019\n",
      "Epoch 255 Batch 10 Loss 0.0577 Accuracy 21.9019\n",
      "Epoch 255 Batch 15 Loss 0.0577 Accuracy 21.9019\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256 Batch 5 Loss 0.0577 Accuracy 21.9018\n",
      "Epoch 256 Batch 10 Loss 0.0577 Accuracy 21.9018\n",
      "Epoch 256 Batch 15 Loss 0.0577 Accuracy 21.9018\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 257 Batch 5 Loss 0.0577 Accuracy 21.9018\n",
      "Epoch 257 Batch 10 Loss 0.0577 Accuracy 21.9018\n",
      "Epoch 257 Batch 15 Loss 0.0577 Accuracy 21.9018\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 258 Batch 5 Loss 0.0577 Accuracy 21.9018\n",
      "Epoch 258 Batch 10 Loss 0.0577 Accuracy 21.9017\n",
      "Epoch 258 Batch 15 Loss 0.0577 Accuracy 21.9017\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 259 Batch 5 Loss 0.0577 Accuracy 21.9017\n",
      "Epoch 259 Batch 10 Loss 0.0577 Accuracy 21.9017\n",
      "Epoch 259 Batch 15 Loss 0.0577 Accuracy 21.9017\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 260 Batch 5 Loss 0.0577 Accuracy 21.9017\n",
      "Epoch 260 Batch 10 Loss 0.0577 Accuracy 21.9017\n",
      "Epoch 260 Batch 15 Loss 0.0577 Accuracy 21.9016\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 261 Batch 5 Loss 0.0577 Accuracy 21.9016\n",
      "Epoch 261 Batch 10 Loss 0.0577 Accuracy 21.9016\n",
      "Epoch 261 Batch 15 Loss 0.0577 Accuracy 21.9016\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 262 Batch 5 Loss 0.0577 Accuracy 21.9016\n",
      "Epoch 262 Batch 10 Loss 0.0577 Accuracy 21.9016\n",
      "Epoch 262 Batch 15 Loss 0.0577 Accuracy 21.9016\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 263 Batch 5 Loss 0.0577 Accuracy 21.9015\n",
      "Epoch 263 Batch 10 Loss 0.0577 Accuracy 21.9015\n",
      "Epoch 263 Batch 15 Loss 0.0577 Accuracy 21.9015\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 264 Batch 5 Loss 0.0577 Accuracy 21.9015\n",
      "Epoch 264 Batch 10 Loss 0.0577 Accuracy 21.9015\n",
      "Epoch 264 Batch 15 Loss 0.0577 Accuracy 21.9015\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 265 Batch 5 Loss 0.0577 Accuracy 21.9015\n",
      "Epoch 265 Batch 10 Loss 0.0577 Accuracy 21.9014\n",
      "Epoch 265 Batch 15 Loss 0.0577 Accuracy 21.9014\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 266 Batch 5 Loss 0.0577 Accuracy 21.9014\n",
      "Epoch 266 Batch 10 Loss 0.0577 Accuracy 21.9014\n",
      "Epoch 266 Batch 15 Loss 0.0577 Accuracy 21.9014\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 267 Batch 5 Loss 0.0577 Accuracy 21.9014\n",
      "Epoch 267 Batch 10 Loss 0.0577 Accuracy 21.9014\n",
      "Epoch 267 Batch 15 Loss 0.0577 Accuracy 21.9014\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 268 Batch 5 Loss 0.0577 Accuracy 21.9013\n",
      "Epoch 268 Batch 10 Loss 0.0577 Accuracy 21.9013\n",
      "Epoch 268 Batch 15 Loss 0.0577 Accuracy 21.9013\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 269 Batch 5 Loss 0.0577 Accuracy 21.9013\n",
      "Epoch 269 Batch 10 Loss 0.0577 Accuracy 21.9013\n",
      "Epoch 269 Batch 15 Loss 0.0577 Accuracy 21.9013\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 270 Batch 5 Loss 0.0577 Accuracy 21.9013\n",
      "Epoch 270 Batch 10 Loss 0.0577 Accuracy 21.9012\n",
      "Epoch 270 Batch 15 Loss 0.0577 Accuracy 21.9012\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 271 Batch 5 Loss 0.0577 Accuracy 21.9012\n",
      "Epoch 271 Batch 10 Loss 0.0577 Accuracy 21.9012\n",
      "Epoch 271 Batch 15 Loss 0.0577 Accuracy 21.9012\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 272 Batch 5 Loss 0.0577 Accuracy 21.9012\n",
      "Epoch 272 Batch 10 Loss 0.0577 Accuracy 21.9012\n",
      "Epoch 272 Batch 15 Loss 0.0577 Accuracy 21.9012\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 273 Batch 5 Loss 0.0577 Accuracy 21.9011\n",
      "Epoch 273 Batch 10 Loss 0.0577 Accuracy 21.9011\n",
      "Epoch 273 Batch 15 Loss 0.0577 Accuracy 21.9011\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 274 Batch 5 Loss 0.0577 Accuracy 21.9011\n",
      "Epoch 274 Batch 10 Loss 0.0577 Accuracy 21.9011\n",
      "Epoch 274 Batch 15 Loss 0.0577 Accuracy 21.9011\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 275 Batch 5 Loss 0.0577 Accuracy 21.9011\n",
      "Epoch 275 Batch 10 Loss 0.0577 Accuracy 21.9011\n",
      "Epoch 275 Batch 15 Loss 0.0577 Accuracy 21.9010\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 276 Batch 5 Loss 0.0577 Accuracy 21.9010\n",
      "Epoch 276 Batch 10 Loss 0.0577 Accuracy 21.9010\n",
      "Epoch 276 Batch 15 Loss 0.0577 Accuracy 21.9010\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 277 Batch 5 Loss 0.0577 Accuracy 21.9010\n",
      "Epoch 277 Batch 10 Loss 0.0577 Accuracy 21.9010\n",
      "Epoch 277 Batch 15 Loss 0.0577 Accuracy 21.9010\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 278 Batch 5 Loss 0.0577 Accuracy 21.9010\n",
      "Epoch 278 Batch 10 Loss 0.0577 Accuracy 21.9009\n",
      "Epoch 278 Batch 15 Loss 0.0577 Accuracy 21.9009\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 279 Batch 5 Loss 0.0577 Accuracy 21.9009\n",
      "Epoch 279 Batch 10 Loss 0.0577 Accuracy 21.9009\n",
      "Epoch 279 Batch 15 Loss 0.0577 Accuracy 21.9009\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 280 Batch 5 Loss 0.0577 Accuracy 21.9009\n",
      "Epoch 280 Batch 10 Loss 0.0577 Accuracy 21.9009\n",
      "Epoch 280 Batch 15 Loss 0.0577 Accuracy 21.9009\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 281 Batch 5 Loss 0.0577 Accuracy 21.9008\n",
      "Epoch 281 Batch 10 Loss 0.0577 Accuracy 21.9008\n",
      "Epoch 281 Batch 15 Loss 0.0577 Accuracy 21.9008\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 282 Batch 5 Loss 0.0577 Accuracy 21.9008\n",
      "Epoch 282 Batch 10 Loss 0.0577 Accuracy 21.9008\n",
      "Epoch 282 Batch 15 Loss 0.0577 Accuracy 21.9008\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 283 Batch 5 Loss 0.0577 Accuracy 21.9008\n",
      "Epoch 283 Batch 10 Loss 0.0577 Accuracy 21.9008\n",
      "Epoch 283 Batch 15 Loss 0.0577 Accuracy 21.9007\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 284 Batch 5 Loss 0.0577 Accuracy 21.9007\n",
      "Epoch 284 Batch 10 Loss 0.0577 Accuracy 21.9007\n",
      "Epoch 284 Batch 15 Loss 0.0577 Accuracy 21.9007\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 285 Batch 5 Loss 0.0577 Accuracy 21.9007\n",
      "Epoch 285 Batch 10 Loss 0.0577 Accuracy 21.9007\n",
      "Epoch 285 Batch 15 Loss 0.0577 Accuracy 21.9007\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 286 Batch 5 Loss 0.0577 Accuracy 21.9007\n",
      "Epoch 286 Batch 10 Loss 0.0577 Accuracy 21.9007\n",
      "Epoch 286 Batch 15 Loss 0.0577 Accuracy 21.9006\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 287 Batch 5 Loss 0.0577 Accuracy 21.9006\n",
      "Epoch 287 Batch 10 Loss 0.0577 Accuracy 21.9006\n",
      "Epoch 287 Batch 15 Loss 0.0577 Accuracy 21.9006\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 288 Batch 5 Loss 0.0577 Accuracy 21.9006\n",
      "Epoch 288 Batch 10 Loss 0.0577 Accuracy 21.9006\n",
      "Epoch 288 Batch 15 Loss 0.0577 Accuracy 21.9006\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 289 Batch 5 Loss 0.0577 Accuracy 21.9006\n",
      "Epoch 289 Batch 10 Loss 0.0577 Accuracy 21.9005\n",
      "Epoch 289 Batch 15 Loss 0.0577 Accuracy 21.9005\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 290 Batch 5 Loss 0.0577 Accuracy 21.9005\n",
      "Epoch 290 Batch 10 Loss 0.0577 Accuracy 21.9005\n",
      "Epoch 290 Batch 15 Loss 0.0577 Accuracy 21.9005\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 291 Batch 5 Loss 0.0577 Accuracy 21.9005\n",
      "Epoch 291 Batch 10 Loss 0.0577 Accuracy 21.9005\n",
      "Epoch 291 Batch 15 Loss 0.0577 Accuracy 21.9005\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 292 Batch 5 Loss 0.0577 Accuracy 21.9005\n",
      "Epoch 292 Batch 10 Loss 0.0577 Accuracy 21.9004\n",
      "Epoch 292 Batch 15 Loss 0.0577 Accuracy 21.9004\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 293 Batch 5 Loss 0.0577 Accuracy 21.9004\n",
      "Epoch 293 Batch 10 Loss 0.0577 Accuracy 21.9004\n",
      "Epoch 293 Batch 15 Loss 0.0577 Accuracy 21.9004\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 294 Batch 5 Loss 0.0577 Accuracy 21.9004\n",
      "Epoch 294 Batch 10 Loss 0.0577 Accuracy 21.9004\n",
      "Epoch 294 Batch 15 Loss 0.0577 Accuracy 21.9004\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 295 Batch 5 Loss 0.0577 Accuracy 21.9004\n",
      "Epoch 295 Batch 10 Loss 0.0577 Accuracy 21.9003\n",
      "Epoch 295 Batch 15 Loss 0.0577 Accuracy 21.9003\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 296 Batch 5 Loss 0.0577 Accuracy 21.9003\n",
      "Epoch 296 Batch 10 Loss 0.0577 Accuracy 21.9003\n",
      "Epoch 296 Batch 15 Loss 0.0577 Accuracy 21.9003\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 297 Batch 5 Loss 0.0577 Accuracy 21.9003\n",
      "Epoch 297 Batch 10 Loss 0.0577 Accuracy 21.9003\n",
      "Epoch 297 Batch 15 Loss 0.0577 Accuracy 21.9003\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 298 Batch 5 Loss 0.0577 Accuracy 21.9003\n",
      "Epoch 298 Batch 10 Loss 0.0577 Accuracy 21.9002\n",
      "Epoch 298 Batch 15 Loss 0.0577 Accuracy 21.9002\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 299 Batch 5 Loss 0.0577 Accuracy 21.9002\n",
      "Epoch 299 Batch 10 Loss 0.0577 Accuracy 21.9002\n",
      "Epoch 299 Batch 15 Loss 0.0577 Accuracy 21.9002\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 300 Batch 5 Loss 0.0577 Accuracy 21.9002\n",
      "Epoch 300 Batch 10 Loss 0.0577 Accuracy 21.9002\n",
      "Epoch 300 Batch 15 Loss 0.0577 Accuracy 21.9002\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 301 Batch 5 Loss 0.0577 Accuracy 21.9002\n",
      "Epoch 301 Batch 10 Loss 0.0577 Accuracy 21.9002\n",
      "Epoch 301 Batch 15 Loss 0.0577 Accuracy 21.9001\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 302 Batch 5 Loss 0.0577 Accuracy 21.9001\n",
      "Epoch 302 Batch 10 Loss 0.0577 Accuracy 21.9001\n",
      "Epoch 302 Batch 15 Loss 0.0577 Accuracy 21.9001\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 303 Batch 5 Loss 0.0577 Accuracy 21.9001\n",
      "Epoch 303 Batch 10 Loss 0.0577 Accuracy 21.9001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303 Batch 15 Loss 0.0577 Accuracy 21.9001\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 304 Batch 5 Loss 0.0577 Accuracy 21.9001\n",
      "Epoch 304 Batch 10 Loss 0.0577 Accuracy 21.9001\n",
      "Epoch 304 Batch 15 Loss 0.0577 Accuracy 21.9000\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 305 Batch 5 Loss 0.0577 Accuracy 21.9000\n",
      "Epoch 305 Batch 10 Loss 0.0577 Accuracy 21.9000\n",
      "Epoch 305 Batch 15 Loss 0.0577 Accuracy 21.9000\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 306 Batch 5 Loss 0.0577 Accuracy 21.9000\n",
      "Epoch 306 Batch 10 Loss 0.0577 Accuracy 21.9000\n",
      "Epoch 306 Batch 15 Loss 0.0577 Accuracy 21.9000\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 307 Batch 5 Loss 0.0577 Accuracy 21.9000\n",
      "Epoch 307 Batch 10 Loss 0.0577 Accuracy 21.9000\n",
      "Epoch 307 Batch 15 Loss 0.0577 Accuracy 21.9000\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 308 Batch 5 Loss 0.0577 Accuracy 21.8999\n",
      "Epoch 308 Batch 10 Loss 0.0577 Accuracy 21.8999\n",
      "Epoch 308 Batch 15 Loss 0.0577 Accuracy 21.8999\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 309 Batch 5 Loss 0.0577 Accuracy 21.8999\n",
      "Epoch 309 Batch 10 Loss 0.0577 Accuracy 21.8999\n",
      "Epoch 309 Batch 15 Loss 0.0577 Accuracy 21.8999\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 310 Batch 5 Loss 0.0577 Accuracy 21.8999\n",
      "Epoch 310 Batch 10 Loss 0.0577 Accuracy 21.8999\n",
      "Epoch 310 Batch 15 Loss 0.0577 Accuracy 21.8999\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 311 Batch 5 Loss 0.0577 Accuracy 21.8999\n",
      "Epoch 311 Batch 10 Loss 0.0577 Accuracy 21.8998\n",
      "Epoch 311 Batch 15 Loss 0.0577 Accuracy 21.8998\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 312 Batch 5 Loss 0.0577 Accuracy 21.8998\n",
      "Epoch 312 Batch 10 Loss 0.0577 Accuracy 21.8998\n",
      "Epoch 312 Batch 15 Loss 0.0577 Accuracy 21.8998\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 313 Batch 5 Loss 0.0577 Accuracy 21.8998\n",
      "Epoch 313 Batch 10 Loss 0.0577 Accuracy 21.8998\n",
      "Epoch 313 Batch 15 Loss 0.0577 Accuracy 21.8998\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 314 Batch 5 Loss 0.0577 Accuracy 21.8998\n",
      "Epoch 314 Batch 10 Loss 0.0577 Accuracy 21.8998\n",
      "Epoch 314 Batch 15 Loss 0.0577 Accuracy 21.8997\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 315 Batch 5 Loss 0.0577 Accuracy 21.8997\n",
      "Epoch 315 Batch 10 Loss 0.0577 Accuracy 21.8997\n",
      "Epoch 315 Batch 15 Loss 0.0577 Accuracy 21.8997\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 316 Batch 5 Loss 0.0577 Accuracy 21.8997\n",
      "Epoch 316 Batch 10 Loss 0.0577 Accuracy 21.8997\n",
      "Epoch 316 Batch 15 Loss 0.0577 Accuracy 21.8997\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 317 Batch 5 Loss 0.0577 Accuracy 21.8997\n",
      "Epoch 317 Batch 10 Loss 0.0577 Accuracy 21.8997\n",
      "Epoch 317 Batch 15 Loss 0.0577 Accuracy 21.8997\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 318 Batch 5 Loss 0.0577 Accuracy 21.8997\n",
      "Epoch 318 Batch 10 Loss 0.0577 Accuracy 21.8996\n",
      "Epoch 318 Batch 15 Loss 0.0577 Accuracy 21.8996\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 319 Batch 5 Loss 0.0577 Accuracy 21.8996\n",
      "Epoch 319 Batch 10 Loss 0.0577 Accuracy 21.8996\n",
      "Epoch 319 Batch 15 Loss 0.0577 Accuracy 21.8996\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 320 Batch 5 Loss 0.0577 Accuracy 21.8996\n",
      "Epoch 320 Batch 10 Loss 0.0577 Accuracy 21.8996\n",
      "Epoch 320 Batch 15 Loss 0.0577 Accuracy 21.8996\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 321 Batch 5 Loss 0.0577 Accuracy 21.8996\n",
      "Epoch 321 Batch 10 Loss 0.0577 Accuracy 21.8996\n",
      "Epoch 321 Batch 15 Loss 0.0577 Accuracy 21.8995\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 322 Batch 5 Loss 0.0577 Accuracy 21.8995\n",
      "Epoch 322 Batch 10 Loss 0.0577 Accuracy 21.8995\n",
      "Epoch 322 Batch 15 Loss 0.0577 Accuracy 21.8995\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 323 Batch 5 Loss 0.0577 Accuracy 21.8995\n",
      "Epoch 323 Batch 10 Loss 0.0577 Accuracy 21.8995\n",
      "Epoch 323 Batch 15 Loss 0.0577 Accuracy 21.8995\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 324 Batch 5 Loss 0.0577 Accuracy 21.8995\n",
      "Epoch 324 Batch 10 Loss 0.0577 Accuracy 21.8995\n",
      "Epoch 324 Batch 15 Loss 0.0577 Accuracy 21.8995\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 325 Batch 5 Loss 0.0577 Accuracy 21.8995\n",
      "Epoch 325 Batch 10 Loss 0.0577 Accuracy 21.8994\n",
      "Epoch 325 Batch 15 Loss 0.0577 Accuracy 21.8994\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 326 Batch 5 Loss 0.0577 Accuracy 21.8994\n",
      "Epoch 326 Batch 10 Loss 0.0577 Accuracy 21.8994\n",
      "Epoch 326 Batch 15 Loss 0.0577 Accuracy 21.8994\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 327 Batch 5 Loss 0.0577 Accuracy 21.8994\n",
      "Epoch 327 Batch 10 Loss 0.0577 Accuracy 21.8994\n",
      "Epoch 327 Batch 15 Loss 0.0577 Accuracy 21.8994\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 328 Batch 5 Loss 0.0577 Accuracy 21.8994\n",
      "Epoch 328 Batch 10 Loss 0.0577 Accuracy 21.8994\n",
      "Epoch 328 Batch 15 Loss 0.0577 Accuracy 21.8994\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 329 Batch 5 Loss 0.0577 Accuracy 21.8993\n",
      "Epoch 329 Batch 10 Loss 0.0577 Accuracy 21.8993\n",
      "Epoch 329 Batch 15 Loss 0.0577 Accuracy 21.8993\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 330 Batch 5 Loss 0.0577 Accuracy 21.8993\n",
      "Epoch 330 Batch 10 Loss 0.0577 Accuracy 21.8993\n",
      "Epoch 330 Batch 15 Loss 0.0577 Accuracy 21.8993\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 331 Batch 5 Loss 0.0577 Accuracy 21.8993\n",
      "Epoch 331 Batch 10 Loss 0.0577 Accuracy 21.8993\n",
      "Epoch 331 Batch 15 Loss 0.0577 Accuracy 21.8993\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 332 Batch 5 Loss 0.0577 Accuracy 21.8993\n",
      "Epoch 332 Batch 10 Loss 0.0577 Accuracy 21.8993\n",
      "Epoch 332 Batch 15 Loss 0.0577 Accuracy 21.8993\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 333 Batch 5 Loss 0.0577 Accuracy 21.8992\n",
      "Epoch 333 Batch 10 Loss 0.0577 Accuracy 21.8992\n",
      "Epoch 333 Batch 15 Loss 0.0577 Accuracy 21.8992\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 334 Batch 5 Loss 0.0577 Accuracy 21.8992\n",
      "Epoch 334 Batch 10 Loss 0.0577 Accuracy 21.8992\n",
      "Epoch 334 Batch 15 Loss 0.0577 Accuracy 21.8992\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 335 Batch 5 Loss 0.0577 Accuracy 21.8992\n",
      "Epoch 335 Batch 10 Loss 0.0577 Accuracy 21.8992\n",
      "Epoch 335 Batch 15 Loss 0.0577 Accuracy 21.8992\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 336 Batch 5 Loss 0.0577 Accuracy 21.8992\n",
      "Epoch 336 Batch 10 Loss 0.0577 Accuracy 21.8992\n",
      "Epoch 336 Batch 15 Loss 0.0577 Accuracy 21.8992\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 337 Batch 5 Loss 0.0577 Accuracy 21.8991\n",
      "Epoch 337 Batch 10 Loss 0.0577 Accuracy 21.8991\n",
      "Epoch 337 Batch 15 Loss 0.0577 Accuracy 21.8991\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 338 Batch 5 Loss 0.0577 Accuracy 21.8991\n",
      "Epoch 338 Batch 10 Loss 0.0577 Accuracy 21.8991\n",
      "Epoch 338 Batch 15 Loss 0.0577 Accuracy 21.8991\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 339 Batch 5 Loss 0.0577 Accuracy 21.8991\n",
      "Epoch 339 Batch 10 Loss 0.0577 Accuracy 21.8991\n",
      "Epoch 339 Batch 15 Loss 0.0577 Accuracy 21.8991\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 340 Batch 5 Loss 0.0577 Accuracy 21.8991\n",
      "Epoch 340 Batch 10 Loss 0.0577 Accuracy 21.8991\n",
      "Epoch 340 Batch 15 Loss 0.0577 Accuracy 21.8990\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 341 Batch 5 Loss 0.0577 Accuracy 21.8990\n",
      "Epoch 341 Batch 10 Loss 0.0577 Accuracy 21.8990\n",
      "Epoch 341 Batch 15 Loss 0.0577 Accuracy 21.8990\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 342 Batch 5 Loss 0.0577 Accuracy 21.8990\n",
      "Epoch 342 Batch 10 Loss 0.0577 Accuracy 21.8990\n",
      "Epoch 342 Batch 15 Loss 0.0577 Accuracy 21.8990\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 343 Batch 5 Loss 0.0577 Accuracy 21.8990\n",
      "Epoch 343 Batch 10 Loss 0.0577 Accuracy 21.8990\n",
      "Epoch 343 Batch 15 Loss 0.0577 Accuracy 21.8990\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 344 Batch 5 Loss 0.0577 Accuracy 21.8990\n",
      "Epoch 344 Batch 10 Loss 0.0577 Accuracy 21.8990\n",
      "Epoch 344 Batch 15 Loss 0.0577 Accuracy 21.8990\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 345 Batch 5 Loss 0.0577 Accuracy 21.8989\n",
      "Epoch 345 Batch 10 Loss 0.0577 Accuracy 21.8989\n",
      "Epoch 345 Batch 15 Loss 0.0577 Accuracy 21.8989\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 346 Batch 5 Loss 0.0577 Accuracy 21.8989\n",
      "Epoch 346 Batch 10 Loss 0.0577 Accuracy 21.8989\n",
      "Epoch 346 Batch 15 Loss 0.0577 Accuracy 21.8989\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 347 Batch 5 Loss 0.0577 Accuracy 21.8989\n",
      "Epoch 347 Batch 10 Loss 0.0577 Accuracy 21.8989\n",
      "Epoch 347 Batch 15 Loss 0.0577 Accuracy 21.8989\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 348 Batch 5 Loss 0.0577 Accuracy 21.8989\n",
      "Epoch 348 Batch 10 Loss 0.0577 Accuracy 21.8989\n",
      "Epoch 348 Batch 15 Loss 0.0577 Accuracy 21.8989\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 349 Batch 5 Loss 0.0577 Accuracy 21.8988\n",
      "Epoch 349 Batch 10 Loss 0.0577 Accuracy 21.8988\n",
      "Epoch 349 Batch 15 Loss 0.0577 Accuracy 21.8988\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 350 Batch 5 Loss 0.0577 Accuracy 21.8988\n",
      "Epoch 350 Batch 10 Loss 0.0577 Accuracy 21.8988\n",
      "Epoch 350 Batch 15 Loss 0.0577 Accuracy 21.8988\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351 Batch 5 Loss 0.0577 Accuracy 21.8988\n",
      "Epoch 351 Batch 10 Loss 0.0577 Accuracy 21.8988\n",
      "Epoch 351 Batch 15 Loss 0.0577 Accuracy 21.8988\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 352 Batch 5 Loss 0.0577 Accuracy 21.8988\n",
      "Epoch 352 Batch 10 Loss 0.0577 Accuracy 21.8988\n",
      "Epoch 352 Batch 15 Loss 0.0577 Accuracy 21.8988\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 353 Batch 5 Loss 0.0577 Accuracy 21.8988\n",
      "Epoch 353 Batch 10 Loss 0.0577 Accuracy 21.8987\n",
      "Epoch 353 Batch 15 Loss 0.0577 Accuracy 21.8987\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 354 Batch 5 Loss 0.0577 Accuracy 21.8987\n",
      "Epoch 354 Batch 10 Loss 0.0577 Accuracy 21.8987\n",
      "Epoch 354 Batch 15 Loss 0.0577 Accuracy 21.8987\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 355 Batch 5 Loss 0.0577 Accuracy 21.8987\n",
      "Epoch 355 Batch 10 Loss 0.0577 Accuracy 21.8987\n",
      "Epoch 355 Batch 15 Loss 0.0577 Accuracy 21.8987\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 356 Batch 5 Loss 0.0577 Accuracy 21.8987\n",
      "Epoch 356 Batch 10 Loss 0.0577 Accuracy 21.8987\n",
      "Epoch 356 Batch 15 Loss 0.0577 Accuracy 21.8987\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 357 Batch 5 Loss 0.0577 Accuracy 21.8987\n",
      "Epoch 357 Batch 10 Loss 0.0577 Accuracy 21.8987\n",
      "Epoch 357 Batch 15 Loss 0.0577 Accuracy 21.8986\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 358 Batch 5 Loss 0.0577 Accuracy 21.8986\n",
      "Epoch 358 Batch 10 Loss 0.0577 Accuracy 21.8986\n",
      "Epoch 358 Batch 15 Loss 0.0577 Accuracy 21.8986\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 359 Batch 5 Loss 0.0577 Accuracy 21.8986\n",
      "Epoch 359 Batch 10 Loss 0.0577 Accuracy 21.8986\n",
      "Epoch 359 Batch 15 Loss 0.0577 Accuracy 21.8986\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 360 Batch 5 Loss 0.0577 Accuracy 21.8986\n",
      "Epoch 360 Batch 10 Loss 0.0577 Accuracy 21.8986\n",
      "Epoch 360 Batch 15 Loss 0.0577 Accuracy 21.8986\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 361 Batch 5 Loss 0.0577 Accuracy 21.8986\n",
      "Epoch 361 Batch 10 Loss 0.0577 Accuracy 21.8986\n",
      "Epoch 361 Batch 15 Loss 0.0577 Accuracy 21.8986\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 362 Batch 5 Loss 0.0577 Accuracy 21.8986\n",
      "Epoch 362 Batch 10 Loss 0.0577 Accuracy 21.8985\n",
      "Epoch 362 Batch 15 Loss 0.0577 Accuracy 21.8985\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 363 Batch 5 Loss 0.0577 Accuracy 21.8985\n",
      "Epoch 363 Batch 10 Loss 0.0577 Accuracy 21.8985\n",
      "Epoch 363 Batch 15 Loss 0.0577 Accuracy 21.8985\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 364 Batch 5 Loss 0.0577 Accuracy 21.8985\n",
      "Epoch 364 Batch 10 Loss 0.0577 Accuracy 21.8985\n",
      "Epoch 364 Batch 15 Loss 0.0577 Accuracy 21.8985\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 365 Batch 5 Loss 0.0577 Accuracy 21.8985\n",
      "Epoch 365 Batch 10 Loss 0.0577 Accuracy 21.8985\n",
      "Epoch 365 Batch 15 Loss 0.0577 Accuracy 21.8985\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 366 Batch 5 Loss 0.0577 Accuracy 21.8985\n",
      "Epoch 366 Batch 10 Loss 0.0577 Accuracy 21.8985\n",
      "Epoch 366 Batch 15 Loss 0.0577 Accuracy 21.8985\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 367 Batch 5 Loss 0.0577 Accuracy 21.8984\n",
      "Epoch 367 Batch 10 Loss 0.0577 Accuracy 21.8984\n",
      "Epoch 367 Batch 15 Loss 0.0577 Accuracy 21.8984\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 368 Batch 5 Loss 0.0577 Accuracy 21.8984\n",
      "Epoch 368 Batch 10 Loss 0.0577 Accuracy 21.8984\n",
      "Epoch 368 Batch 15 Loss 0.0577 Accuracy 21.8984\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 369 Batch 5 Loss 0.0577 Accuracy 21.8984\n",
      "Epoch 369 Batch 10 Loss 0.0577 Accuracy 21.8984\n",
      "Epoch 369 Batch 15 Loss 0.0577 Accuracy 21.8984\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 370 Batch 5 Loss 0.0577 Accuracy 21.8984\n",
      "Epoch 370 Batch 10 Loss 0.0577 Accuracy 21.8984\n",
      "Epoch 370 Batch 15 Loss 0.0577 Accuracy 21.8984\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 371 Batch 5 Loss 0.0577 Accuracy 21.8984\n",
      "Epoch 371 Batch 10 Loss 0.0577 Accuracy 21.8984\n",
      "Epoch 371 Batch 15 Loss 0.0577 Accuracy 21.8983\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 372 Batch 5 Loss 0.0577 Accuracy 21.8983\n",
      "Epoch 372 Batch 10 Loss 0.0577 Accuracy 21.8983\n",
      "Epoch 372 Batch 15 Loss 0.0577 Accuracy 21.8983\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 373 Batch 5 Loss 0.0577 Accuracy 21.8983\n",
      "Epoch 373 Batch 10 Loss 0.0577 Accuracy 21.8983\n",
      "Epoch 373 Batch 15 Loss 0.0577 Accuracy 21.8983\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 374 Batch 5 Loss 0.0577 Accuracy 21.8983\n",
      "Epoch 374 Batch 10 Loss 0.0577 Accuracy 21.8983\n",
      "Epoch 374 Batch 15 Loss 0.0577 Accuracy 21.8983\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 375 Batch 5 Loss 0.0577 Accuracy 21.8983\n",
      "Epoch 375 Batch 10 Loss 0.0577 Accuracy 21.8983\n",
      "Epoch 375 Batch 15 Loss 0.0577 Accuracy 21.8983\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 376 Batch 5 Loss 0.0577 Accuracy 21.8983\n",
      "Epoch 376 Batch 10 Loss 0.0577 Accuracy 21.8983\n",
      "Epoch 376 Batch 15 Loss 0.0577 Accuracy 21.8982\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 377 Batch 5 Loss 0.0577 Accuracy 21.8982\n",
      "Epoch 377 Batch 10 Loss 0.0577 Accuracy 21.8982\n",
      "Epoch 377 Batch 15 Loss 0.0577 Accuracy 21.8982\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 378 Batch 5 Loss 0.0577 Accuracy 21.8982\n",
      "Epoch 378 Batch 10 Loss 0.0577 Accuracy 21.8982\n",
      "Epoch 378 Batch 15 Loss 0.0577 Accuracy 21.8982\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 379 Batch 5 Loss 0.0577 Accuracy 21.8982\n",
      "Epoch 379 Batch 10 Loss 0.0577 Accuracy 21.8982\n",
      "Epoch 379 Batch 15 Loss 0.0577 Accuracy 21.8982\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 380 Batch 5 Loss 0.0577 Accuracy 21.8982\n",
      "Epoch 380 Batch 10 Loss 0.0577 Accuracy 21.8982\n",
      "Epoch 380 Batch 15 Loss 0.0577 Accuracy 21.8982\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 381 Batch 5 Loss 0.0577 Accuracy 21.8982\n",
      "Epoch 381 Batch 10 Loss 0.0577 Accuracy 21.8981\n",
      "Epoch 381 Batch 15 Loss 0.0577 Accuracy 21.8981\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 382 Batch 5 Loss 0.0577 Accuracy 21.8981\n",
      "Epoch 382 Batch 10 Loss 0.0577 Accuracy 21.8981\n",
      "Epoch 382 Batch 15 Loss 0.0577 Accuracy 21.8981\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 383 Batch 5 Loss 0.0577 Accuracy 21.8981\n",
      "Epoch 383 Batch 10 Loss 0.0577 Accuracy 21.8981\n",
      "Epoch 383 Batch 15 Loss 0.0577 Accuracy 21.8981\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 384 Batch 5 Loss 0.0577 Accuracy 21.8981\n",
      "Epoch 384 Batch 10 Loss 0.0577 Accuracy 21.8981\n",
      "Epoch 384 Batch 15 Loss 0.0577 Accuracy 21.8981\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 385 Batch 5 Loss 0.0577 Accuracy 21.8981\n",
      "Epoch 385 Batch 10 Loss 0.0577 Accuracy 21.8981\n",
      "Epoch 385 Batch 15 Loss 0.0577 Accuracy 21.8981\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 386 Batch 5 Loss 0.0577 Accuracy 21.8981\n",
      "Epoch 386 Batch 10 Loss 0.0577 Accuracy 21.8981\n",
      "Epoch 386 Batch 15 Loss 0.0577 Accuracy 21.8980\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 387 Batch 5 Loss 0.0577 Accuracy 21.8980\n",
      "Epoch 387 Batch 10 Loss 0.0577 Accuracy 21.8980\n",
      "Epoch 387 Batch 15 Loss 0.0577 Accuracy 21.8980\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 388 Batch 5 Loss 0.0577 Accuracy 21.8980\n",
      "Epoch 388 Batch 10 Loss 0.0577 Accuracy 21.8980\n",
      "Epoch 388 Batch 15 Loss 0.0577 Accuracy 21.8980\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 389 Batch 5 Loss 0.0577 Accuracy 21.8980\n",
      "Epoch 389 Batch 10 Loss 0.0577 Accuracy 21.8980\n",
      "Epoch 389 Batch 15 Loss 0.0577 Accuracy 21.8980\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 390 Batch 5 Loss 0.0577 Accuracy 21.8980\n",
      "Epoch 390 Batch 10 Loss 0.0577 Accuracy 21.8980\n",
      "Epoch 390 Batch 15 Loss 0.0577 Accuracy 21.8980\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 391 Batch 5 Loss 0.0577 Accuracy 21.8980\n",
      "Epoch 391 Batch 10 Loss 0.0577 Accuracy 21.8980\n",
      "Epoch 391 Batch 15 Loss 0.0577 Accuracy 21.8980\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 392 Batch 5 Loss 0.0577 Accuracy 21.8979\n",
      "Epoch 392 Batch 10 Loss 0.0577 Accuracy 21.8979\n",
      "Epoch 392 Batch 15 Loss 0.0577 Accuracy 21.8979\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 393 Batch 5 Loss 0.0577 Accuracy 21.8979\n",
      "Epoch 393 Batch 10 Loss 0.0577 Accuracy 21.8979\n",
      "Epoch 393 Batch 15 Loss 0.0577 Accuracy 21.8979\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 394 Batch 5 Loss 0.0577 Accuracy 21.8979\n",
      "Epoch 394 Batch 10 Loss 0.0577 Accuracy 21.8979\n",
      "Epoch 394 Batch 15 Loss 0.0577 Accuracy 21.8979\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 395 Batch 5 Loss 0.0577 Accuracy 21.8979\n",
      "Epoch 395 Batch 10 Loss 0.0577 Accuracy 21.8979\n",
      "Epoch 395 Batch 15 Loss 0.0577 Accuracy 21.8979\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 396 Batch 5 Loss 0.0577 Accuracy 21.8979\n",
      "Epoch 396 Batch 10 Loss 0.0577 Accuracy 21.8979\n",
      "Epoch 396 Batch 15 Loss 0.0577 Accuracy 21.8979\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 397 Batch 5 Loss 0.0577 Accuracy 21.8979\n",
      "Epoch 397 Batch 10 Loss 0.0577 Accuracy 21.8978\n",
      "Epoch 397 Batch 15 Loss 0.0577 Accuracy 21.8978\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398 Batch 5 Loss 0.0577 Accuracy 21.8978\n",
      "Epoch 398 Batch 10 Loss 0.0577 Accuracy 21.8978\n",
      "Epoch 398 Batch 15 Loss 0.0577 Accuracy 21.8978\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 399 Batch 5 Loss 0.0577 Accuracy 21.8978\n",
      "Epoch 399 Batch 10 Loss 0.0577 Accuracy 21.8978\n",
      "Epoch 399 Batch 15 Loss 0.0577 Accuracy 21.8978\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 400 Batch 5 Loss 0.0577 Accuracy 21.8978\n",
      "Epoch 400 Batch 10 Loss 0.0577 Accuracy 21.8978\n",
      "Epoch 400 Batch 15 Loss 0.0577 Accuracy 21.8978\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 401 Batch 5 Loss 0.0577 Accuracy 21.8978\n",
      "Epoch 401 Batch 10 Loss 0.0577 Accuracy 21.8978\n",
      "Epoch 401 Batch 15 Loss 0.0577 Accuracy 21.8978\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 402 Batch 5 Loss 0.0577 Accuracy 21.8978\n",
      "Epoch 402 Batch 10 Loss 0.0577 Accuracy 21.8978\n",
      "Epoch 402 Batch 15 Loss 0.0577 Accuracy 21.8977\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 403 Batch 5 Loss 0.0577 Accuracy 21.8977\n",
      "Epoch 403 Batch 10 Loss 0.0577 Accuracy 21.8977\n",
      "Epoch 403 Batch 15 Loss 0.0577 Accuracy 21.8977\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 404 Batch 5 Loss 0.0577 Accuracy 21.8977\n",
      "Epoch 404 Batch 10 Loss 0.0577 Accuracy 21.8977\n",
      "Epoch 404 Batch 15 Loss 0.0577 Accuracy 21.8977\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 405 Batch 5 Loss 0.0577 Accuracy 21.8977\n",
      "Epoch 405 Batch 10 Loss 0.0577 Accuracy 21.8977\n",
      "Epoch 405 Batch 15 Loss 0.0577 Accuracy 21.8977\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 406 Batch 5 Loss 0.0577 Accuracy 21.8977\n",
      "Epoch 406 Batch 10 Loss 0.0577 Accuracy 21.8977\n",
      "Epoch 406 Batch 15 Loss 0.0577 Accuracy 21.8977\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 407 Batch 5 Loss 0.0577 Accuracy 21.8977\n",
      "Epoch 407 Batch 10 Loss 0.0577 Accuracy 21.8977\n",
      "Epoch 407 Batch 15 Loss 0.0577 Accuracy 21.8977\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 408 Batch 5 Loss 0.0577 Accuracy 21.8977\n",
      "Epoch 408 Batch 10 Loss 0.0577 Accuracy 21.8976\n",
      "Epoch 408 Batch 15 Loss 0.0577 Accuracy 21.8976\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 409 Batch 5 Loss 0.0577 Accuracy 21.8976\n",
      "Epoch 409 Batch 10 Loss 0.0577 Accuracy 21.8976\n",
      "Epoch 409 Batch 15 Loss 0.0577 Accuracy 21.8976\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 410 Batch 5 Loss 0.0577 Accuracy 21.8976\n",
      "Epoch 410 Batch 10 Loss 0.0577 Accuracy 21.8976\n",
      "Epoch 410 Batch 15 Loss 0.0577 Accuracy 21.8976\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 411 Batch 5 Loss 0.0577 Accuracy 21.8976\n",
      "Epoch 411 Batch 10 Loss 0.0577 Accuracy 21.8976\n",
      "Epoch 411 Batch 15 Loss 0.0577 Accuracy 21.8976\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 412 Batch 5 Loss 0.0577 Accuracy 21.8976\n",
      "Epoch 412 Batch 10 Loss 0.0577 Accuracy 21.8976\n",
      "Epoch 412 Batch 15 Loss 0.0577 Accuracy 21.8976\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 413 Batch 5 Loss 0.0577 Accuracy 21.8976\n",
      "Epoch 413 Batch 10 Loss 0.0577 Accuracy 21.8976\n",
      "Epoch 413 Batch 15 Loss 0.0577 Accuracy 21.8976\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 414 Batch 5 Loss 0.0577 Accuracy 21.8976\n",
      "Epoch 414 Batch 10 Loss 0.0577 Accuracy 21.8975\n",
      "Epoch 414 Batch 15 Loss 0.0577 Accuracy 21.8975\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 415 Batch 5 Loss 0.0577 Accuracy 21.8975\n",
      "Epoch 415 Batch 10 Loss 0.0577 Accuracy 21.8975\n",
      "Epoch 415 Batch 15 Loss 0.0577 Accuracy 21.8975\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 416 Batch 5 Loss 0.0577 Accuracy 21.8975\n",
      "Epoch 416 Batch 10 Loss 0.0577 Accuracy 21.8975\n",
      "Epoch 416 Batch 15 Loss 0.0577 Accuracy 21.8975\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 417 Batch 5 Loss 0.0577 Accuracy 21.8975\n",
      "Epoch 417 Batch 10 Loss 0.0577 Accuracy 21.8975\n",
      "Epoch 417 Batch 15 Loss 0.0577 Accuracy 21.8975\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 418 Batch 5 Loss 0.0577 Accuracy 21.8975\n",
      "Epoch 418 Batch 10 Loss 0.0577 Accuracy 21.8975\n",
      "Epoch 418 Batch 15 Loss 0.0577 Accuracy 21.8975\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 419 Batch 5 Loss 0.0577 Accuracy 21.8975\n",
      "Epoch 419 Batch 10 Loss 0.0577 Accuracy 21.8975\n",
      "Epoch 419 Batch 15 Loss 0.0577 Accuracy 21.8975\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 420 Batch 5 Loss 0.0577 Accuracy 21.8975\n",
      "Epoch 420 Batch 10 Loss 0.0577 Accuracy 21.8974\n",
      "Epoch 420 Batch 15 Loss 0.0577 Accuracy 21.8974\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 421 Batch 5 Loss 0.0577 Accuracy 21.8974\n",
      "Epoch 421 Batch 10 Loss 0.0577 Accuracy 21.8974\n",
      "Epoch 421 Batch 15 Loss 0.0577 Accuracy 21.8974\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 422 Batch 5 Loss 0.0577 Accuracy 21.8974\n",
      "Epoch 422 Batch 10 Loss 0.0577 Accuracy 21.8974\n",
      "Epoch 422 Batch 15 Loss 0.0577 Accuracy 21.8974\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 423 Batch 5 Loss 0.0577 Accuracy 21.8974\n",
      "Epoch 423 Batch 10 Loss 0.0577 Accuracy 21.8974\n",
      "Epoch 423 Batch 15 Loss 0.0577 Accuracy 21.8974\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 424 Batch 5 Loss 0.0577 Accuracy 21.8974\n",
      "Epoch 424 Batch 10 Loss 0.0577 Accuracy 21.8974\n",
      "Epoch 424 Batch 15 Loss 0.0577 Accuracy 21.8974\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 425 Batch 5 Loss 0.0577 Accuracy 21.8974\n",
      "Epoch 425 Batch 10 Loss 0.0577 Accuracy 21.8974\n",
      "Epoch 425 Batch 15 Loss 0.0577 Accuracy 21.8974\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 426 Batch 5 Loss 0.0577 Accuracy 21.8974\n",
      "Epoch 426 Batch 10 Loss 0.0577 Accuracy 21.8974\n",
      "Epoch 426 Batch 15 Loss 0.0577 Accuracy 21.8973\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 427 Batch 5 Loss 0.0577 Accuracy 21.8973\n",
      "Epoch 427 Batch 10 Loss 0.0577 Accuracy 21.8973\n",
      "Epoch 427 Batch 15 Loss 0.0577 Accuracy 21.8973\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 428 Batch 5 Loss 0.0577 Accuracy 21.8973\n",
      "Epoch 428 Batch 10 Loss 0.0577 Accuracy 21.8973\n",
      "Epoch 428 Batch 15 Loss 0.0577 Accuracy 21.8973\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 429 Batch 5 Loss 0.0577 Accuracy 21.8973\n",
      "Epoch 429 Batch 10 Loss 0.0577 Accuracy 21.8973\n",
      "Epoch 429 Batch 15 Loss 0.0577 Accuracy 21.8973\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 430 Batch 5 Loss 0.0577 Accuracy 21.8973\n",
      "Epoch 430 Batch 10 Loss 0.0577 Accuracy 21.8973\n",
      "Epoch 430 Batch 15 Loss 0.0577 Accuracy 21.8973\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 431 Batch 5 Loss 0.0577 Accuracy 21.8973\n",
      "Epoch 431 Batch 10 Loss 0.0577 Accuracy 21.8973\n",
      "Epoch 431 Batch 15 Loss 0.0577 Accuracy 21.8973\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 432 Batch 5 Loss 0.0577 Accuracy 21.8973\n",
      "Epoch 432 Batch 10 Loss 0.0577 Accuracy 21.8973\n",
      "Epoch 432 Batch 15 Loss 0.0577 Accuracy 21.8973\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 433 Batch 5 Loss 0.0577 Accuracy 21.8972\n",
      "Epoch 433 Batch 10 Loss 0.0577 Accuracy 21.8972\n",
      "Epoch 433 Batch 15 Loss 0.0577 Accuracy 21.8972\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 434 Batch 5 Loss 0.0577 Accuracy 21.8972\n",
      "Epoch 434 Batch 10 Loss 0.0577 Accuracy 21.8972\n",
      "Epoch 434 Batch 15 Loss 0.0577 Accuracy 21.8972\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 435 Batch 5 Loss 0.0577 Accuracy 21.8972\n",
      "Epoch 435 Batch 10 Loss 0.0577 Accuracy 21.8972\n",
      "Epoch 435 Batch 15 Loss 0.0577 Accuracy 21.8972\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 436 Batch 5 Loss 0.0577 Accuracy 21.8972\n",
      "Epoch 436 Batch 10 Loss 0.0577 Accuracy 21.8972\n",
      "Epoch 436 Batch 15 Loss 0.0577 Accuracy 21.8972\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 437 Batch 5 Loss 0.0577 Accuracy 21.8972\n",
      "Epoch 437 Batch 10 Loss 0.0577 Accuracy 21.8972\n",
      "Epoch 437 Batch 15 Loss 0.0577 Accuracy 21.8972\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 438 Batch 5 Loss 0.0577 Accuracy 21.8972\n",
      "Epoch 438 Batch 10 Loss 0.0577 Accuracy 21.8972\n",
      "Epoch 438 Batch 15 Loss 0.0577 Accuracy 21.8972\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 439 Batch 5 Loss 0.0577 Accuracy 21.8972\n",
      "Epoch 439 Batch 10 Loss 0.0577 Accuracy 21.8972\n",
      "Epoch 439 Batch 15 Loss 0.0577 Accuracy 21.8971\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 440 Batch 5 Loss 0.0577 Accuracy 21.8971\n",
      "Epoch 440 Batch 10 Loss 0.0577 Accuracy 21.8971\n",
      "Epoch 440 Batch 15 Loss 0.0577 Accuracy 21.8971\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 441 Batch 5 Loss 0.0577 Accuracy 21.8971\n",
      "Epoch 441 Batch 10 Loss 0.0577 Accuracy 21.8971\n",
      "Epoch 441 Batch 15 Loss 0.0577 Accuracy 21.8971\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 442 Batch 5 Loss 0.0577 Accuracy 21.8971\n",
      "Epoch 442 Batch 10 Loss 0.0577 Accuracy 21.8971\n",
      "Epoch 442 Batch 15 Loss 0.0577 Accuracy 21.8971\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 443 Batch 5 Loss 0.0577 Accuracy 21.8971\n",
      "Epoch 443 Batch 10 Loss 0.0577 Accuracy 21.8971\n",
      "Epoch 443 Batch 15 Loss 0.0577 Accuracy 21.8971\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 444 Batch 5 Loss 0.0577 Accuracy 21.8971\n",
      "Epoch 444 Batch 10 Loss 0.0577 Accuracy 21.8971\n",
      "Epoch 444 Batch 15 Loss 0.0577 Accuracy 21.8971\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 445 Batch 5 Loss 0.0577 Accuracy 21.8971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445 Batch 10 Loss 0.0577 Accuracy 21.8971\n",
      "Epoch 445 Batch 15 Loss 0.0577 Accuracy 21.8971\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 446 Batch 5 Loss 0.0577 Accuracy 21.8971\n",
      "Epoch 446 Batch 10 Loss 0.0577 Accuracy 21.8971\n",
      "Epoch 446 Batch 15 Loss 0.0577 Accuracy 21.8970\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 447 Batch 5 Loss 0.0577 Accuracy 21.8970\n",
      "Epoch 447 Batch 10 Loss 0.0577 Accuracy 21.8970\n",
      "Epoch 447 Batch 15 Loss 0.0577 Accuracy 21.8970\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 448 Batch 5 Loss 0.0577 Accuracy 21.8970\n",
      "Epoch 448 Batch 10 Loss 0.0577 Accuracy 21.8970\n",
      "Epoch 448 Batch 15 Loss 0.0577 Accuracy 21.8970\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 449 Batch 5 Loss 0.0577 Accuracy 21.8970\n",
      "Epoch 449 Batch 10 Loss 0.0577 Accuracy 21.8970\n",
      "Epoch 449 Batch 15 Loss 0.0577 Accuracy 21.8970\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 450 Batch 5 Loss 0.0577 Accuracy 21.8970\n",
      "Epoch 450 Batch 10 Loss 0.0577 Accuracy 21.8970\n",
      "Epoch 450 Batch 15 Loss 0.0577 Accuracy 21.8970\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 451 Batch 5 Loss 0.0577 Accuracy 21.8970\n",
      "Epoch 451 Batch 10 Loss 0.0577 Accuracy 21.8970\n",
      "Epoch 451 Batch 15 Loss 0.0577 Accuracy 21.8970\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 452 Batch 5 Loss 0.0577 Accuracy 21.8970\n",
      "Epoch 452 Batch 10 Loss 0.0577 Accuracy 21.8970\n",
      "Epoch 452 Batch 15 Loss 0.0577 Accuracy 21.8970\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 453 Batch 5 Loss 0.0577 Accuracy 21.8970\n",
      "Epoch 453 Batch 10 Loss 0.0577 Accuracy 21.8970\n",
      "Epoch 453 Batch 15 Loss 0.0577 Accuracy 21.8969\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 454 Batch 5 Loss 0.0577 Accuracy 21.8969\n",
      "Epoch 454 Batch 10 Loss 0.0577 Accuracy 21.8969\n",
      "Epoch 454 Batch 15 Loss 0.0577 Accuracy 21.8969\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 455 Batch 5 Loss 0.0577 Accuracy 21.8969\n",
      "Epoch 455 Batch 10 Loss 0.0577 Accuracy 21.8969\n",
      "Epoch 455 Batch 15 Loss 0.0577 Accuracy 21.8969\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 456 Batch 5 Loss 0.0577 Accuracy 21.8969\n",
      "Epoch 456 Batch 10 Loss 0.0577 Accuracy 21.8969\n",
      "Epoch 456 Batch 15 Loss 0.0577 Accuracy 21.8969\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 457 Batch 5 Loss 0.0577 Accuracy 21.8969\n",
      "Epoch 457 Batch 10 Loss 0.0577 Accuracy 21.8969\n",
      "Epoch 457 Batch 15 Loss 0.0577 Accuracy 21.8969\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 458 Batch 5 Loss 0.0577 Accuracy 21.8969\n",
      "Epoch 458 Batch 10 Loss 0.0577 Accuracy 21.8969\n",
      "Epoch 458 Batch 15 Loss 0.0577 Accuracy 21.8969\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 459 Batch 5 Loss 0.0577 Accuracy 21.8969\n",
      "Epoch 459 Batch 10 Loss 0.0577 Accuracy 21.8969\n",
      "Epoch 459 Batch 15 Loss 0.0577 Accuracy 21.8969\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 460 Batch 5 Loss 0.0577 Accuracy 21.8969\n",
      "Epoch 460 Batch 10 Loss 0.0577 Accuracy 21.8969\n",
      "Epoch 460 Batch 15 Loss 0.0577 Accuracy 21.8969\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 461 Batch 5 Loss 0.0577 Accuracy 21.8968\n",
      "Epoch 461 Batch 10 Loss 0.0577 Accuracy 21.8968\n",
      "Epoch 461 Batch 15 Loss 0.0577 Accuracy 21.8968\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 462 Batch 5 Loss 0.0577 Accuracy 21.8968\n",
      "Epoch 462 Batch 10 Loss 0.0577 Accuracy 21.8968\n",
      "Epoch 462 Batch 15 Loss 0.0577 Accuracy 21.8968\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 463 Batch 5 Loss 0.0577 Accuracy 21.8968\n",
      "Epoch 463 Batch 10 Loss 0.0577 Accuracy 21.8968\n",
      "Epoch 463 Batch 15 Loss 0.0577 Accuracy 21.8968\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 464 Batch 5 Loss 0.0577 Accuracy 21.8968\n",
      "Epoch 464 Batch 10 Loss 0.0577 Accuracy 21.8968\n",
      "Epoch 464 Batch 15 Loss 0.0577 Accuracy 21.8968\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 465 Batch 5 Loss 0.0577 Accuracy 21.8968\n",
      "Epoch 465 Batch 10 Loss 0.0577 Accuracy 21.8968\n",
      "Epoch 465 Batch 15 Loss 0.0577 Accuracy 21.8968\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 466 Batch 5 Loss 0.0577 Accuracy 21.8968\n",
      "Epoch 466 Batch 10 Loss 0.0577 Accuracy 21.8968\n",
      "Epoch 466 Batch 15 Loss 0.0577 Accuracy 21.8968\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 467 Batch 5 Loss 0.0577 Accuracy 21.8968\n",
      "Epoch 467 Batch 10 Loss 0.0577 Accuracy 21.8968\n",
      "Epoch 467 Batch 15 Loss 0.0577 Accuracy 21.8968\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 468 Batch 5 Loss 0.0577 Accuracy 21.8968\n",
      "Epoch 468 Batch 10 Loss 0.0577 Accuracy 21.8967\n",
      "Epoch 468 Batch 15 Loss 0.0577 Accuracy 21.8967\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 469 Batch 5 Loss 0.0577 Accuracy 21.8967\n",
      "Epoch 469 Batch 10 Loss 0.0577 Accuracy 21.8967\n",
      "Epoch 469 Batch 15 Loss 0.0577 Accuracy 21.8967\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 470 Batch 5 Loss 0.0577 Accuracy 21.8967\n",
      "Epoch 470 Batch 10 Loss 0.0577 Accuracy 21.8967\n",
      "Epoch 470 Batch 15 Loss 0.0577 Accuracy 21.8967\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 471 Batch 5 Loss 0.0577 Accuracy 21.8967\n",
      "Epoch 471 Batch 10 Loss 0.0577 Accuracy 21.8967\n",
      "Epoch 471 Batch 15 Loss 0.0577 Accuracy 21.8967\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 472 Batch 5 Loss 0.0577 Accuracy 21.8967\n",
      "Epoch 472 Batch 10 Loss 0.0577 Accuracy 21.8967\n",
      "Epoch 472 Batch 15 Loss 0.0577 Accuracy 21.8967\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 473 Batch 5 Loss 0.0577 Accuracy 21.8967\n",
      "Epoch 473 Batch 10 Loss 0.0577 Accuracy 21.8967\n",
      "Epoch 473 Batch 15 Loss 0.0577 Accuracy 21.8967\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 474 Batch 5 Loss 0.0577 Accuracy 21.8967\n",
      "Epoch 474 Batch 10 Loss 0.0577 Accuracy 21.8967\n",
      "Epoch 474 Batch 15 Loss 0.0577 Accuracy 21.8967\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 475 Batch 5 Loss 0.0577 Accuracy 21.8967\n",
      "Epoch 475 Batch 10 Loss 0.0577 Accuracy 21.8967\n",
      "Epoch 475 Batch 15 Loss 0.0577 Accuracy 21.8967\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 476 Batch 5 Loss 0.0577 Accuracy 21.8967\n",
      "Epoch 476 Batch 10 Loss 0.0577 Accuracy 21.8966\n",
      "Epoch 476 Batch 15 Loss 0.0577 Accuracy 21.8966\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 477 Batch 5 Loss 0.0577 Accuracy 21.8966\n",
      "Epoch 477 Batch 10 Loss 0.0577 Accuracy 21.8966\n",
      "Epoch 477 Batch 15 Loss 0.0577 Accuracy 21.8966\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 478 Batch 5 Loss 0.0577 Accuracy 21.8966\n",
      "Epoch 478 Batch 10 Loss 0.0577 Accuracy 21.8966\n",
      "Epoch 478 Batch 15 Loss 0.0577 Accuracy 21.8966\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 479 Batch 5 Loss 0.0577 Accuracy 21.8966\n",
      "Epoch 479 Batch 10 Loss 0.0577 Accuracy 21.8966\n",
      "Epoch 479 Batch 15 Loss 0.0577 Accuracy 21.8966\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 480 Batch 5 Loss 0.0577 Accuracy 21.8966\n",
      "Epoch 480 Batch 10 Loss 0.0577 Accuracy 21.8966\n",
      "Epoch 480 Batch 15 Loss 0.0577 Accuracy 21.8966\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 481 Batch 5 Loss 0.0577 Accuracy 21.8966\n",
      "Epoch 481 Batch 10 Loss 0.0577 Accuracy 21.8966\n",
      "Epoch 481 Batch 15 Loss 0.0577 Accuracy 21.8966\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 482 Batch 5 Loss 0.0577 Accuracy 21.8966\n",
      "Epoch 482 Batch 10 Loss 0.0577 Accuracy 21.8966\n",
      "Epoch 482 Batch 15 Loss 0.0577 Accuracy 21.8966\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 483 Batch 5 Loss 0.0577 Accuracy 21.8966\n",
      "Epoch 483 Batch 10 Loss 0.0577 Accuracy 21.8966\n",
      "Epoch 483 Batch 15 Loss 0.0577 Accuracy 21.8966\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 484 Batch 5 Loss 0.0577 Accuracy 21.8966\n",
      "Epoch 484 Batch 10 Loss 0.0577 Accuracy 21.8965\n",
      "Epoch 484 Batch 15 Loss 0.0577 Accuracy 21.8965\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 485 Batch 5 Loss 0.0577 Accuracy 21.8965\n",
      "Epoch 485 Batch 10 Loss 0.0577 Accuracy 21.8965\n",
      "Epoch 485 Batch 15 Loss 0.0577 Accuracy 21.8965\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 486 Batch 5 Loss 0.0577 Accuracy 21.8965\n",
      "Epoch 486 Batch 10 Loss 0.0577 Accuracy 21.8965\n",
      "Epoch 486 Batch 15 Loss 0.0577 Accuracy 21.8965\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 487 Batch 5 Loss 0.0577 Accuracy 21.8965\n",
      "Epoch 487 Batch 10 Loss 0.0577 Accuracy 21.8965\n",
      "Epoch 487 Batch 15 Loss 0.0577 Accuracy 21.8965\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 488 Batch 5 Loss 0.0577 Accuracy 21.8965\n",
      "Epoch 488 Batch 10 Loss 0.0577 Accuracy 21.8965\n",
      "Epoch 488 Batch 15 Loss 0.0577 Accuracy 21.8965\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 489 Batch 5 Loss 0.0577 Accuracy 21.8965\n",
      "Epoch 489 Batch 10 Loss 0.0577 Accuracy 21.8965\n",
      "Epoch 489 Batch 15 Loss 0.0577 Accuracy 21.8965\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 490 Batch 5 Loss 0.0577 Accuracy 21.8965\n",
      "Epoch 490 Batch 10 Loss 0.0577 Accuracy 21.8965\n",
      "Epoch 490 Batch 15 Loss 0.0577 Accuracy 21.8965\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 491 Batch 5 Loss 0.0577 Accuracy 21.8965\n",
      "Epoch 491 Batch 10 Loss 0.0577 Accuracy 21.8965\n",
      "Epoch 491 Batch 15 Loss 0.0577 Accuracy 21.8965\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 492 Batch 5 Loss 0.0577 Accuracy 21.8965\n",
      "Epoch 492 Batch 10 Loss 0.0577 Accuracy 21.8965\n",
      "Epoch 492 Batch 15 Loss 0.0577 Accuracy 21.8964\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 493 Batch 5 Loss 0.0577 Accuracy 21.8964\n",
      "Epoch 493 Batch 10 Loss 0.0577 Accuracy 21.8964\n",
      "Epoch 493 Batch 15 Loss 0.0577 Accuracy 21.8964\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 494 Batch 5 Loss 0.0577 Accuracy 21.8964\n",
      "Epoch 494 Batch 10 Loss 0.0577 Accuracy 21.8964\n",
      "Epoch 494 Batch 15 Loss 0.0577 Accuracy 21.8964\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 495 Batch 5 Loss 0.0577 Accuracy 21.8964\n",
      "Epoch 495 Batch 10 Loss 0.0577 Accuracy 21.8964\n",
      "Epoch 495 Batch 15 Loss 0.0577 Accuracy 21.8964\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 496 Batch 5 Loss 0.0577 Accuracy 21.8964\n",
      "Epoch 496 Batch 10 Loss 0.0577 Accuracy 21.8964\n",
      "Epoch 496 Batch 15 Loss 0.0577 Accuracy 21.8964\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 497 Batch 5 Loss 0.0577 Accuracy 21.8964\n",
      "Epoch 497 Batch 10 Loss 0.0577 Accuracy 21.8964\n",
      "Epoch 497 Batch 15 Loss 0.0577 Accuracy 21.8964\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 498 Batch 5 Loss 0.0577 Accuracy 21.8964\n",
      "Epoch 498 Batch 10 Loss 0.0577 Accuracy 21.8964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 498 Batch 15 Loss 0.0577 Accuracy 21.8964\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 499 Batch 5 Loss 0.0577 Accuracy 21.8964\n",
      "Epoch 499 Batch 10 Loss 0.0577 Accuracy 21.8964\n",
      "Epoch 499 Batch 15 Loss 0.0577 Accuracy 21.8964\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 500 Batch 5 Loss 0.0577 Accuracy 21.8964\n",
      "Epoch 500 Batch 10 Loss 0.0577 Accuracy 21.8964\n",
      "Epoch 500 Batch 15 Loss 0.0577 Accuracy 21.8964\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 501 Batch 5 Loss 0.0577 Accuracy 21.8963\n",
      "Epoch 501 Batch 10 Loss 0.0577 Accuracy 21.8963\n",
      "Epoch 501 Batch 15 Loss 0.0577 Accuracy 21.8963\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 502 Batch 5 Loss 0.0577 Accuracy 21.8963\n",
      "Epoch 502 Batch 10 Loss 0.0577 Accuracy 21.8963\n",
      "Epoch 502 Batch 15 Loss 0.0577 Accuracy 21.8963\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 503 Batch 5 Loss 0.0577 Accuracy 21.8963\n",
      "Epoch 503 Batch 10 Loss 0.0577 Accuracy 21.8963\n",
      "Epoch 503 Batch 15 Loss 0.0577 Accuracy 21.8963\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 504 Batch 5 Loss 0.0577 Accuracy 21.8963\n",
      "Epoch 504 Batch 10 Loss 0.0577 Accuracy 21.8963\n",
      "Epoch 504 Batch 15 Loss 0.0577 Accuracy 21.8963\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 505 Batch 5 Loss 0.0577 Accuracy 21.8963\n",
      "Epoch 505 Batch 10 Loss 0.0577 Accuracy 21.8963\n",
      "Epoch 505 Batch 15 Loss 0.0577 Accuracy 21.8963\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 506 Batch 5 Loss 0.0577 Accuracy 21.8963\n",
      "Epoch 506 Batch 10 Loss 0.0577 Accuracy 21.8963\n",
      "Epoch 506 Batch 15 Loss 0.0577 Accuracy 21.8963\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 507 Batch 5 Loss 0.0577 Accuracy 21.8963\n",
      "Epoch 507 Batch 10 Loss 0.0577 Accuracy 21.8963\n",
      "Epoch 507 Batch 15 Loss 0.0577 Accuracy 21.8963\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 508 Batch 5 Loss 0.0577 Accuracy 21.8963\n",
      "Epoch 508 Batch 10 Loss 0.0577 Accuracy 21.8963\n",
      "Epoch 508 Batch 15 Loss 0.0577 Accuracy 21.8963\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 509 Batch 5 Loss 0.0577 Accuracy 21.8963\n",
      "Epoch 509 Batch 10 Loss 0.0577 Accuracy 21.8963\n",
      "Epoch 509 Batch 15 Loss 0.0577 Accuracy 21.8963\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 510 Batch 5 Loss 0.0577 Accuracy 21.8962\n",
      "Epoch 510 Batch 10 Loss 0.0577 Accuracy 21.8962\n",
      "Epoch 510 Batch 15 Loss 0.0577 Accuracy 21.8962\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 511 Batch 5 Loss 0.0577 Accuracy 21.8962\n",
      "Epoch 511 Batch 10 Loss 0.0577 Accuracy 21.8962\n",
      "Epoch 511 Batch 15 Loss 0.0577 Accuracy 21.8962\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 512 Batch 5 Loss 0.0577 Accuracy 21.8962\n",
      "Epoch 512 Batch 10 Loss 0.0577 Accuracy 21.8962\n",
      "Epoch 512 Batch 15 Loss 0.0577 Accuracy 21.8962\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 513 Batch 5 Loss 0.0577 Accuracy 21.8962\n",
      "Epoch 513 Batch 10 Loss 0.0577 Accuracy 21.8962\n",
      "Epoch 513 Batch 15 Loss 0.0577 Accuracy 21.8962\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 514 Batch 5 Loss 0.0577 Accuracy 21.8962\n",
      "Epoch 514 Batch 10 Loss 0.0577 Accuracy 21.8962\n",
      "Epoch 514 Batch 15 Loss 0.0577 Accuracy 21.8962\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 515 Batch 5 Loss 0.0577 Accuracy 21.8962\n",
      "Epoch 515 Batch 10 Loss 0.0577 Accuracy 21.8962\n",
      "Epoch 515 Batch 15 Loss 0.0577 Accuracy 21.8962\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 516 Batch 5 Loss 0.0577 Accuracy 21.8962\n",
      "Epoch 516 Batch 10 Loss 0.0577 Accuracy 21.8962\n",
      "Epoch 516 Batch 15 Loss 0.0577 Accuracy 21.8962\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 517 Batch 5 Loss 0.0577 Accuracy 21.8962\n",
      "Epoch 517 Batch 10 Loss 0.0577 Accuracy 21.8962\n",
      "Epoch 517 Batch 15 Loss 0.0577 Accuracy 21.8962\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 518 Batch 5 Loss 0.0577 Accuracy 21.8962\n",
      "Epoch 518 Batch 10 Loss 0.0577 Accuracy 21.8962\n",
      "Epoch 518 Batch 15 Loss 0.0577 Accuracy 21.8962\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 519 Batch 5 Loss 0.0577 Accuracy 21.8962\n",
      "Epoch 519 Batch 10 Loss 0.0577 Accuracy 21.8961\n",
      "Epoch 519 Batch 15 Loss 0.0577 Accuracy 21.8961\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 520 Batch 5 Loss 0.0577 Accuracy 21.8961\n",
      "Epoch 520 Batch 10 Loss 0.0577 Accuracy 21.8961\n",
      "Epoch 520 Batch 15 Loss 0.0577 Accuracy 21.8961\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 521 Batch 5 Loss 0.0577 Accuracy 21.8961\n",
      "Epoch 521 Batch 10 Loss 0.0577 Accuracy 21.8961\n",
      "Epoch 521 Batch 15 Loss 0.0577 Accuracy 21.8961\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 522 Batch 5 Loss 0.0577 Accuracy 21.8961\n",
      "Epoch 522 Batch 10 Loss 0.0577 Accuracy 21.8961\n",
      "Epoch 522 Batch 15 Loss 0.0577 Accuracy 21.8961\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 523 Batch 5 Loss 0.0577 Accuracy 21.8961\n",
      "Epoch 523 Batch 10 Loss 0.0577 Accuracy 21.8961\n",
      "Epoch 523 Batch 15 Loss 0.0577 Accuracy 21.8961\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 524 Batch 5 Loss 0.0577 Accuracy 21.8961\n",
      "Epoch 524 Batch 10 Loss 0.0577 Accuracy 21.8961\n",
      "Epoch 524 Batch 15 Loss 0.0577 Accuracy 21.8961\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 525 Batch 5 Loss 0.0577 Accuracy 21.8961\n",
      "Epoch 525 Batch 10 Loss 0.0577 Accuracy 21.8961\n",
      "Epoch 525 Batch 15 Loss 0.0577 Accuracy 21.8961\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 526 Batch 5 Loss 0.0577 Accuracy 21.8961\n",
      "Epoch 526 Batch 10 Loss 0.0577 Accuracy 21.8961\n",
      "Epoch 526 Batch 15 Loss 0.0577 Accuracy 21.8961\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 527 Batch 5 Loss 0.0577 Accuracy 21.8961\n",
      "Epoch 527 Batch 10 Loss 0.0577 Accuracy 21.8961\n",
      "Epoch 527 Batch 15 Loss 0.0577 Accuracy 21.8961\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 528 Batch 5 Loss 0.0577 Accuracy 21.8961\n",
      "Epoch 528 Batch 10 Loss 0.0577 Accuracy 21.8961\n",
      "Epoch 528 Batch 15 Loss 0.0577 Accuracy 21.8960\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 529 Batch 5 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 529 Batch 10 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 529 Batch 15 Loss 0.0577 Accuracy 21.8960\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 530 Batch 5 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 530 Batch 10 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 530 Batch 15 Loss 0.0577 Accuracy 21.8960\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 531 Batch 5 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 531 Batch 10 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 531 Batch 15 Loss 0.0577 Accuracy 21.8960\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 532 Batch 5 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 532 Batch 10 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 532 Batch 15 Loss 0.0577 Accuracy 21.8960\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 533 Batch 5 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 533 Batch 10 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 533 Batch 15 Loss 0.0577 Accuracy 21.8960\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 534 Batch 5 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 534 Batch 10 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 534 Batch 15 Loss 0.0577 Accuracy 21.8960\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 535 Batch 5 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 535 Batch 10 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 535 Batch 15 Loss 0.0577 Accuracy 21.8960\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 536 Batch 5 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 536 Batch 10 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 536 Batch 15 Loss 0.0577 Accuracy 21.8960\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 537 Batch 5 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 537 Batch 10 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 537 Batch 15 Loss 0.0577 Accuracy 21.8960\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 538 Batch 5 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 538 Batch 10 Loss 0.0577 Accuracy 21.8960\n",
      "Epoch 538 Batch 15 Loss 0.0577 Accuracy 21.8959\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 539 Batch 5 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 539 Batch 10 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 539 Batch 15 Loss 0.0577 Accuracy 21.8959\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 540 Batch 5 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 540 Batch 10 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 540 Batch 15 Loss 0.0577 Accuracy 21.8959\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 541 Batch 5 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 541 Batch 10 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 541 Batch 15 Loss 0.0577 Accuracy 21.8959\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 542 Batch 5 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 542 Batch 10 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 542 Batch 15 Loss 0.0577 Accuracy 21.8959\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 543 Batch 5 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 543 Batch 10 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 543 Batch 15 Loss 0.0577 Accuracy 21.8959\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 544 Batch 5 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 544 Batch 10 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 544 Batch 15 Loss 0.0577 Accuracy 21.8959\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 545 Batch 5 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 545 Batch 10 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 545 Batch 15 Loss 0.0577 Accuracy 21.8959\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546 Batch 5 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 546 Batch 10 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 546 Batch 15 Loss 0.0577 Accuracy 21.8959\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 547 Batch 5 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 547 Batch 10 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 547 Batch 15 Loss 0.0577 Accuracy 21.8959\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 548 Batch 5 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 548 Batch 10 Loss 0.0577 Accuracy 21.8959\n",
      "Epoch 548 Batch 15 Loss 0.0577 Accuracy 21.8959\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 549 Batch 5 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 549 Batch 10 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 549 Batch 15 Loss 0.0577 Accuracy 21.8958\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 550 Batch 5 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 550 Batch 10 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 550 Batch 15 Loss 0.0577 Accuracy 21.8958\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 551 Batch 5 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 551 Batch 10 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 551 Batch 15 Loss 0.0577 Accuracy 21.8958\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 552 Batch 5 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 552 Batch 10 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 552 Batch 15 Loss 0.0577 Accuracy 21.8958\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 553 Batch 5 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 553 Batch 10 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 553 Batch 15 Loss 0.0577 Accuracy 21.8958\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 554 Batch 5 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 554 Batch 10 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 554 Batch 15 Loss 0.0577 Accuracy 21.8958\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 555 Batch 5 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 555 Batch 10 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 555 Batch 15 Loss 0.0577 Accuracy 21.8958\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 556 Batch 5 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 556 Batch 10 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 556 Batch 15 Loss 0.0577 Accuracy 21.8958\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 557 Batch 5 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 557 Batch 10 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 557 Batch 15 Loss 0.0577 Accuracy 21.8958\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 558 Batch 5 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 558 Batch 10 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 558 Batch 15 Loss 0.0577 Accuracy 21.8958\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 559 Batch 5 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 559 Batch 10 Loss 0.0577 Accuracy 21.8958\n",
      "Epoch 559 Batch 15 Loss 0.0577 Accuracy 21.8957\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 560 Batch 5 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 560 Batch 10 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 560 Batch 15 Loss 0.0577 Accuracy 21.8957\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 561 Batch 5 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 561 Batch 10 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 561 Batch 15 Loss 0.0577 Accuracy 21.8957\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 562 Batch 5 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 562 Batch 10 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 562 Batch 15 Loss 0.0577 Accuracy 21.8957\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 563 Batch 5 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 563 Batch 10 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 563 Batch 15 Loss 0.0577 Accuracy 21.8957\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 564 Batch 5 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 564 Batch 10 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 564 Batch 15 Loss 0.0577 Accuracy 21.8957\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 565 Batch 5 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 565 Batch 10 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 565 Batch 15 Loss 0.0577 Accuracy 21.8957\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 566 Batch 5 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 566 Batch 10 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 566 Batch 15 Loss 0.0577 Accuracy 21.8957\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 567 Batch 5 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 567 Batch 10 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 567 Batch 15 Loss 0.0577 Accuracy 21.8957\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 568 Batch 5 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 568 Batch 10 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 568 Batch 15 Loss 0.0577 Accuracy 21.8957\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 569 Batch 5 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 569 Batch 10 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 569 Batch 15 Loss 0.0577 Accuracy 21.8957\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 570 Batch 5 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 570 Batch 10 Loss 0.0577 Accuracy 21.8957\n",
      "Epoch 570 Batch 15 Loss 0.0577 Accuracy 21.8956\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 571 Batch 5 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 571 Batch 10 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 571 Batch 15 Loss 0.0577 Accuracy 21.8956\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 572 Batch 5 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 572 Batch 10 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 572 Batch 15 Loss 0.0577 Accuracy 21.8956\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 573 Batch 5 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 573 Batch 10 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 573 Batch 15 Loss 0.0577 Accuracy 21.8956\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 574 Batch 5 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 574 Batch 10 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 574 Batch 15 Loss 0.0577 Accuracy 21.8956\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 575 Batch 5 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 575 Batch 10 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 575 Batch 15 Loss 0.0577 Accuracy 21.8956\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 576 Batch 5 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 576 Batch 10 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 576 Batch 15 Loss 0.0577 Accuracy 21.8956\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 577 Batch 5 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 577 Batch 10 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 577 Batch 15 Loss 0.0577 Accuracy 21.8956\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 578 Batch 5 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 578 Batch 10 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 578 Batch 15 Loss 0.0577 Accuracy 21.8956\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 579 Batch 5 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 579 Batch 10 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 579 Batch 15 Loss 0.0577 Accuracy 21.8956\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 580 Batch 5 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 580 Batch 10 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 580 Batch 15 Loss 0.0577 Accuracy 21.8956\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 581 Batch 5 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 581 Batch 10 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 581 Batch 15 Loss 0.0577 Accuracy 21.8956\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 582 Batch 5 Loss 0.0577 Accuracy 21.8956\n",
      "Epoch 582 Batch 10 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 582 Batch 15 Loss 0.0577 Accuracy 21.8955\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 583 Batch 5 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 583 Batch 10 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 583 Batch 15 Loss 0.0577 Accuracy 21.8955\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 584 Batch 5 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 584 Batch 10 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 584 Batch 15 Loss 0.0577 Accuracy 21.8955\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 585 Batch 5 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 585 Batch 10 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 585 Batch 15 Loss 0.0577 Accuracy 21.8955\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 586 Batch 5 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 586 Batch 10 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 586 Batch 15 Loss 0.0577 Accuracy 21.8955\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 587 Batch 5 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 587 Batch 10 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 587 Batch 15 Loss 0.0577 Accuracy 21.8955\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 588 Batch 5 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 588 Batch 10 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 588 Batch 15 Loss 0.0577 Accuracy 21.8955\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 589 Batch 5 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 589 Batch 10 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 589 Batch 15 Loss 0.0577 Accuracy 21.8955\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 590 Batch 5 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 590 Batch 10 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 590 Batch 15 Loss 0.0577 Accuracy 21.8955\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 591 Batch 5 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 591 Batch 10 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 591 Batch 15 Loss 0.0577 Accuracy 21.8955\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 592 Batch 5 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 592 Batch 10 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 592 Batch 15 Loss 0.0577 Accuracy 21.8955\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 593 Batch 5 Loss 0.0577 Accuracy 21.8955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 593 Batch 10 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 593 Batch 15 Loss 0.0577 Accuracy 21.8955\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 594 Batch 5 Loss 0.0577 Accuracy 21.8955\n",
      "Epoch 594 Batch 10 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 594 Batch 15 Loss 0.0577 Accuracy 21.8954\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 595 Batch 5 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 595 Batch 10 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 595 Batch 15 Loss 0.0577 Accuracy 21.8954\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 596 Batch 5 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 596 Batch 10 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 596 Batch 15 Loss 0.0577 Accuracy 21.8954\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 597 Batch 5 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 597 Batch 10 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 597 Batch 15 Loss 0.0577 Accuracy 21.8954\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 598 Batch 5 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 598 Batch 10 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 598 Batch 15 Loss 0.0577 Accuracy 21.8954\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 599 Batch 5 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 599 Batch 10 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 599 Batch 15 Loss 0.0577 Accuracy 21.8954\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 600 Batch 5 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 600 Batch 10 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 600 Batch 15 Loss 0.0577 Accuracy 21.8954\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 601 Batch 5 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 601 Batch 10 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 601 Batch 15 Loss 0.0577 Accuracy 21.8954\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 602 Batch 5 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 602 Batch 10 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 602 Batch 15 Loss 0.0577 Accuracy 21.8954\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 603 Batch 5 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 603 Batch 10 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 603 Batch 15 Loss 0.0577 Accuracy 21.8954\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 604 Batch 5 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 604 Batch 10 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 604 Batch 15 Loss 0.0577 Accuracy 21.8954\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 605 Batch 5 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 605 Batch 10 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 605 Batch 15 Loss 0.0577 Accuracy 21.8954\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 606 Batch 5 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 606 Batch 10 Loss 0.0577 Accuracy 21.8954\n",
      "Epoch 606 Batch 15 Loss 0.0577 Accuracy 21.8954\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 607 Batch 5 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 607 Batch 10 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 607 Batch 15 Loss 0.0577 Accuracy 21.8953\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 608 Batch 5 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 608 Batch 10 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 608 Batch 15 Loss 0.0577 Accuracy 21.8953\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 609 Batch 5 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 609 Batch 10 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 609 Batch 15 Loss 0.0577 Accuracy 21.8953\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 610 Batch 5 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 610 Batch 10 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 610 Batch 15 Loss 0.0577 Accuracy 21.8953\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 611 Batch 5 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 611 Batch 10 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 611 Batch 15 Loss 0.0577 Accuracy 21.8953\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 612 Batch 5 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 612 Batch 10 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 612 Batch 15 Loss 0.0577 Accuracy 21.8953\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 613 Batch 5 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 613 Batch 10 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 613 Batch 15 Loss 0.0577 Accuracy 21.8953\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 614 Batch 5 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 614 Batch 10 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 614 Batch 15 Loss 0.0577 Accuracy 21.8953\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 615 Batch 5 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 615 Batch 10 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 615 Batch 15 Loss 0.0577 Accuracy 21.8953\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 616 Batch 5 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 616 Batch 10 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 616 Batch 15 Loss 0.0577 Accuracy 21.8953\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 617 Batch 5 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 617 Batch 10 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 617 Batch 15 Loss 0.0577 Accuracy 21.8953\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 618 Batch 5 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 618 Batch 10 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 618 Batch 15 Loss 0.0577 Accuracy 21.8953\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 619 Batch 5 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 619 Batch 10 Loss 0.0577 Accuracy 21.8953\n",
      "Epoch 619 Batch 15 Loss 0.0577 Accuracy 21.8953\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 620 Batch 5 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 620 Batch 10 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 620 Batch 15 Loss 0.0577 Accuracy 21.8952\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 621 Batch 5 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 621 Batch 10 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 621 Batch 15 Loss 0.0577 Accuracy 21.8952\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 622 Batch 5 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 622 Batch 10 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 622 Batch 15 Loss 0.0577 Accuracy 21.8952\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 623 Batch 5 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 623 Batch 10 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 623 Batch 15 Loss 0.0577 Accuracy 21.8952\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 624 Batch 5 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 624 Batch 10 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 624 Batch 15 Loss 0.0577 Accuracy 21.8952\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 625 Batch 5 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 625 Batch 10 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 625 Batch 15 Loss 0.0577 Accuracy 21.8952\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 626 Batch 5 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 626 Batch 10 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 626 Batch 15 Loss 0.0577 Accuracy 21.8952\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 627 Batch 5 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 627 Batch 10 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 627 Batch 15 Loss 0.0577 Accuracy 21.8952\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 628 Batch 5 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 628 Batch 10 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 628 Batch 15 Loss 0.0577 Accuracy 21.8952\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 629 Batch 5 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 629 Batch 10 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 629 Batch 15 Loss 0.0577 Accuracy 21.8952\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 630 Batch 5 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 630 Batch 10 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 630 Batch 15 Loss 0.0577 Accuracy 21.8952\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 631 Batch 5 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 631 Batch 10 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 631 Batch 15 Loss 0.0577 Accuracy 21.8952\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 632 Batch 5 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 632 Batch 10 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 632 Batch 15 Loss 0.0577 Accuracy 21.8952\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 633 Batch 5 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 633 Batch 10 Loss 0.0577 Accuracy 21.8952\n",
      "Epoch 633 Batch 15 Loss 0.0577 Accuracy 21.8951\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 634 Batch 5 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 634 Batch 10 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 634 Batch 15 Loss 0.0577 Accuracy 21.8951\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 635 Batch 5 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 635 Batch 10 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 635 Batch 15 Loss 0.0577 Accuracy 21.8951\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 636 Batch 5 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 636 Batch 10 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 636 Batch 15 Loss 0.0577 Accuracy 21.8951\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 637 Batch 5 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 637 Batch 10 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 637 Batch 15 Loss 0.0577 Accuracy 21.8951\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 638 Batch 5 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 638 Batch 10 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 638 Batch 15 Loss 0.0577 Accuracy 21.8951\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 639 Batch 5 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 639 Batch 10 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 639 Batch 15 Loss 0.0577 Accuracy 21.8951\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 640 Batch 5 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 640 Batch 10 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 640 Batch 15 Loss 0.0577 Accuracy 21.8951\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 641 Batch 5 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 641 Batch 10 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 641 Batch 15 Loss 0.0577 Accuracy 21.8951\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 642 Batch 5 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 642 Batch 10 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 642 Batch 15 Loss 0.0577 Accuracy 21.8951\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 643 Batch 5 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 643 Batch 10 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 643 Batch 15 Loss 0.0577 Accuracy 21.8951\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 644 Batch 5 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 644 Batch 10 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 644 Batch 15 Loss 0.0577 Accuracy 21.8951\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 645 Batch 5 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 645 Batch 10 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 645 Batch 15 Loss 0.0577 Accuracy 21.8951\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 646 Batch 5 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 646 Batch 10 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 646 Batch 15 Loss 0.0577 Accuracy 21.8951\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 647 Batch 5 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 647 Batch 10 Loss 0.0577 Accuracy 21.8951\n",
      "Epoch 647 Batch 15 Loss 0.0577 Accuracy 21.8951\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 648 Batch 5 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 648 Batch 10 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 648 Batch 15 Loss 0.0577 Accuracy 21.8950\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 649 Batch 5 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 649 Batch 10 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 649 Batch 15 Loss 0.0577 Accuracy 21.8950\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 650 Batch 5 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 650 Batch 10 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 650 Batch 15 Loss 0.0577 Accuracy 21.8950\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 651 Batch 5 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 651 Batch 10 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 651 Batch 15 Loss 0.0577 Accuracy 21.8950\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 652 Batch 5 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 652 Batch 10 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 652 Batch 15 Loss 0.0577 Accuracy 21.8950\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 653 Batch 5 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 653 Batch 10 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 653 Batch 15 Loss 0.0577 Accuracy 21.8950\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 654 Batch 5 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 654 Batch 10 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 654 Batch 15 Loss 0.0577 Accuracy 21.8950\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 655 Batch 5 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 655 Batch 10 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 655 Batch 15 Loss 0.0577 Accuracy 21.8950\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 656 Batch 5 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 656 Batch 10 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 656 Batch 15 Loss 0.0577 Accuracy 21.8950\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 657 Batch 5 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 657 Batch 10 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 657 Batch 15 Loss 0.0577 Accuracy 21.8950\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 658 Batch 5 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 658 Batch 10 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 658 Batch 15 Loss 0.0577 Accuracy 21.8950\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 659 Batch 5 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 659 Batch 10 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 659 Batch 15 Loss 0.0577 Accuracy 21.8950\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 660 Batch 5 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 660 Batch 10 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 660 Batch 15 Loss 0.0577 Accuracy 21.8950\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 661 Batch 5 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 661 Batch 10 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 661 Batch 15 Loss 0.0577 Accuracy 21.8950\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 662 Batch 5 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 662 Batch 10 Loss 0.0577 Accuracy 21.8950\n",
      "Epoch 662 Batch 15 Loss 0.0577 Accuracy 21.8950\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 663 Batch 5 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 663 Batch 10 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 663 Batch 15 Loss 0.0577 Accuracy 21.8949\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 664 Batch 5 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 664 Batch 10 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 664 Batch 15 Loss 0.0577 Accuracy 21.8949\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 665 Batch 5 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 665 Batch 10 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 665 Batch 15 Loss 0.0577 Accuracy 21.8949\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 666 Batch 5 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 666 Batch 10 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 666 Batch 15 Loss 0.0577 Accuracy 21.8949\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 667 Batch 5 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 667 Batch 10 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 667 Batch 15 Loss 0.0577 Accuracy 21.8949\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 668 Batch 5 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 668 Batch 10 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 668 Batch 15 Loss 0.0577 Accuracy 21.8949\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 669 Batch 5 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 669 Batch 10 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 669 Batch 15 Loss 0.0577 Accuracy 21.8949\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 670 Batch 5 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 670 Batch 10 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 670 Batch 15 Loss 0.0577 Accuracy 21.8949\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 671 Batch 5 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 671 Batch 10 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 671 Batch 15 Loss 0.0577 Accuracy 21.8949\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 672 Batch 5 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 672 Batch 10 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 672 Batch 15 Loss 0.0577 Accuracy 21.8949\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 673 Batch 5 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 673 Batch 10 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 673 Batch 15 Loss 0.0577 Accuracy 21.8949\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 674 Batch 5 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 674 Batch 10 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 674 Batch 15 Loss 0.0577 Accuracy 21.8949\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 675 Batch 5 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 675 Batch 10 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 675 Batch 15 Loss 0.0577 Accuracy 21.8949\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 676 Batch 5 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 676 Batch 10 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 676 Batch 15 Loss 0.0577 Accuracy 21.8949\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 677 Batch 5 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 677 Batch 10 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 677 Batch 15 Loss 0.0577 Accuracy 21.8949\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 678 Batch 5 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 678 Batch 10 Loss 0.0577 Accuracy 21.8949\n",
      "Epoch 678 Batch 15 Loss 0.0577 Accuracy 21.8948\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 679 Batch 5 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 679 Batch 10 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 679 Batch 15 Loss 0.0577 Accuracy 21.8948\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 680 Batch 5 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 680 Batch 10 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 680 Batch 15 Loss 0.0577 Accuracy 21.8948\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 681 Batch 5 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 681 Batch 10 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 681 Batch 15 Loss 0.0577 Accuracy 21.8948\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 682 Batch 5 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 682 Batch 10 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 682 Batch 15 Loss 0.0577 Accuracy 21.8948\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 683 Batch 5 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 683 Batch 10 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 683 Batch 15 Loss 0.0577 Accuracy 21.8948\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 684 Batch 5 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 684 Batch 10 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 684 Batch 15 Loss 0.0577 Accuracy 21.8948\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 685 Batch 5 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 685 Batch 10 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 685 Batch 15 Loss 0.0577 Accuracy 21.8948\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 686 Batch 5 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 686 Batch 10 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 686 Batch 15 Loss 0.0577 Accuracy 21.8948\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 687 Batch 5 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 687 Batch 10 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 687 Batch 15 Loss 0.0577 Accuracy 21.8948\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 688 Batch 5 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 688 Batch 10 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 688 Batch 15 Loss 0.0577 Accuracy 21.8948\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 689 Batch 5 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 689 Batch 10 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 689 Batch 15 Loss 0.0577 Accuracy 21.8948\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 690 Batch 5 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 690 Batch 10 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 690 Batch 15 Loss 0.0577 Accuracy 21.8948\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 691 Batch 5 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 691 Batch 10 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 691 Batch 15 Loss 0.0577 Accuracy 21.8948\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 692 Batch 5 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 692 Batch 10 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 692 Batch 15 Loss 0.0577 Accuracy 21.8948\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 693 Batch 5 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 693 Batch 10 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 693 Batch 15 Loss 0.0577 Accuracy 21.8948\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 694 Batch 5 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 694 Batch 10 Loss 0.0577 Accuracy 21.8948\n",
      "Epoch 694 Batch 15 Loss 0.0577 Accuracy 21.8948\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 695 Batch 5 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 695 Batch 10 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 695 Batch 15 Loss 0.0577 Accuracy 21.8947\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 696 Batch 5 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 696 Batch 10 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 696 Batch 15 Loss 0.0577 Accuracy 21.8947\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 697 Batch 5 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 697 Batch 10 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 697 Batch 15 Loss 0.0577 Accuracy 21.8947\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 698 Batch 5 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 698 Batch 10 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 698 Batch 15 Loss 0.0577 Accuracy 21.8947\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 699 Batch 5 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 699 Batch 10 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 699 Batch 15 Loss 0.0577 Accuracy 21.8947\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 700 Batch 5 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 700 Batch 10 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 700 Batch 15 Loss 0.0577 Accuracy 21.8947\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 701 Batch 5 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 701 Batch 10 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 701 Batch 15 Loss 0.0577 Accuracy 21.8947\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 702 Batch 5 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 702 Batch 10 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 702 Batch 15 Loss 0.0577 Accuracy 21.8947\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 703 Batch 5 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 703 Batch 10 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 703 Batch 15 Loss 0.0577 Accuracy 21.8947\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 704 Batch 5 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 704 Batch 10 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 704 Batch 15 Loss 0.0577 Accuracy 21.8947\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 705 Batch 5 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 705 Batch 10 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 705 Batch 15 Loss 0.0577 Accuracy 21.8947\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 706 Batch 5 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 706 Batch 10 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 706 Batch 15 Loss 0.0577 Accuracy 21.8947\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 707 Batch 5 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 707 Batch 10 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 707 Batch 15 Loss 0.0577 Accuracy 21.8947\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 708 Batch 5 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 708 Batch 10 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 708 Batch 15 Loss 0.0577 Accuracy 21.8947\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 709 Batch 5 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 709 Batch 10 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 709 Batch 15 Loss 0.0577 Accuracy 21.8947\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 710 Batch 5 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 710 Batch 10 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 710 Batch 15 Loss 0.0577 Accuracy 21.8947\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 711 Batch 5 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 711 Batch 10 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 711 Batch 15 Loss 0.0577 Accuracy 21.8947\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 712 Batch 5 Loss 0.0577 Accuracy 21.8947\n",
      "Epoch 712 Batch 10 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 712 Batch 15 Loss 0.0577 Accuracy 21.8946\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 713 Batch 5 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 713 Batch 10 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 713 Batch 15 Loss 0.0577 Accuracy 21.8946\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 714 Batch 5 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 714 Batch 10 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 714 Batch 15 Loss 0.0577 Accuracy 21.8946\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 715 Batch 5 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 715 Batch 10 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 715 Batch 15 Loss 0.0577 Accuracy 21.8946\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 716 Batch 5 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 716 Batch 10 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 716 Batch 15 Loss 0.0577 Accuracy 21.8946\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 717 Batch 5 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 717 Batch 10 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 717 Batch 15 Loss 0.0577 Accuracy 21.8946\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 718 Batch 5 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 718 Batch 10 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 718 Batch 15 Loss 0.0577 Accuracy 21.8946\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 719 Batch 5 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 719 Batch 10 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 719 Batch 15 Loss 0.0577 Accuracy 21.8946\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 720 Batch 5 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 720 Batch 10 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 720 Batch 15 Loss 0.0577 Accuracy 21.8946\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 721 Batch 5 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 721 Batch 10 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 721 Batch 15 Loss 0.0577 Accuracy 21.8946\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 722 Batch 5 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 722 Batch 10 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 722 Batch 15 Loss 0.0577 Accuracy 21.8946\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 723 Batch 5 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 723 Batch 10 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 723 Batch 15 Loss 0.0577 Accuracy 21.8946\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 724 Batch 5 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 724 Batch 10 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 724 Batch 15 Loss 0.0577 Accuracy 21.8946\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 725 Batch 5 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 725 Batch 10 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 725 Batch 15 Loss 0.0577 Accuracy 21.8946\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 726 Batch 5 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 726 Batch 10 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 726 Batch 15 Loss 0.0577 Accuracy 21.8946\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 727 Batch 5 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 727 Batch 10 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 727 Batch 15 Loss 0.0577 Accuracy 21.8946\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 728 Batch 5 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 728 Batch 10 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 728 Batch 15 Loss 0.0577 Accuracy 21.8946\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 729 Batch 5 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 729 Batch 10 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 729 Batch 15 Loss 0.0577 Accuracy 21.8946\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 730 Batch 5 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 730 Batch 10 Loss 0.0577 Accuracy 21.8946\n",
      "Epoch 730 Batch 15 Loss 0.0577 Accuracy 21.8945\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 731 Batch 5 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 731 Batch 10 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 731 Batch 15 Loss 0.0577 Accuracy 21.8945\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 732 Batch 5 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 732 Batch 10 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 732 Batch 15 Loss 0.0577 Accuracy 21.8945\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 733 Batch 5 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 733 Batch 10 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 733 Batch 15 Loss 0.0577 Accuracy 21.8945\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 734 Batch 5 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 734 Batch 10 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 734 Batch 15 Loss 0.0577 Accuracy 21.8945\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 735 Batch 5 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 735 Batch 10 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 735 Batch 15 Loss 0.0577 Accuracy 21.8945\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 736 Batch 5 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 736 Batch 10 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 736 Batch 15 Loss 0.0577 Accuracy 21.8945\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 737 Batch 5 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 737 Batch 10 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 737 Batch 15 Loss 0.0577 Accuracy 21.8945\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 738 Batch 5 Loss 0.0577 Accuracy 21.8945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 738 Batch 10 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 738 Batch 15 Loss 0.0577 Accuracy 21.8945\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 739 Batch 5 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 739 Batch 10 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 739 Batch 15 Loss 0.0577 Accuracy 21.8945\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 740 Batch 5 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 740 Batch 10 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 740 Batch 15 Loss 0.0577 Accuracy 21.8945\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 741 Batch 5 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 741 Batch 10 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 741 Batch 15 Loss 0.0577 Accuracy 21.8945\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 742 Batch 5 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 742 Batch 10 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 742 Batch 15 Loss 0.0577 Accuracy 21.8945\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 743 Batch 5 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 743 Batch 10 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 743 Batch 15 Loss 0.0577 Accuracy 21.8945\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 744 Batch 5 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 744 Batch 10 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 744 Batch 15 Loss 0.0577 Accuracy 21.8945\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 745 Batch 5 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 745 Batch 10 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 745 Batch 15 Loss 0.0577 Accuracy 21.8945\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 746 Batch 5 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 746 Batch 10 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 746 Batch 15 Loss 0.0577 Accuracy 21.8945\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 747 Batch 5 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 747 Batch 10 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 747 Batch 15 Loss 0.0577 Accuracy 21.8945\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 748 Batch 5 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 748 Batch 10 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 748 Batch 15 Loss 0.0577 Accuracy 21.8945\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 749 Batch 5 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 749 Batch 10 Loss 0.0577 Accuracy 21.8945\n",
      "Epoch 749 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 750 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 750 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 750 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 751 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 751 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 751 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 752 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 752 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 752 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 753 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 753 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 753 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 754 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 754 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 754 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 755 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 755 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 755 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 756 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 756 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 756 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 757 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 757 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 757 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 758 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 758 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 758 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 759 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 759 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 759 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 760 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 760 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 760 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 761 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 761 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 761 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 762 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 762 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 762 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 763 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 763 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 763 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 764 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 764 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 764 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 765 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 765 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 765 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 766 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 766 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 766 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 767 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 767 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 767 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 768 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 768 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 768 Batch 15 Loss 0.0577 Accuracy 21.8944\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 769 Batch 5 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 769 Batch 10 Loss 0.0577 Accuracy 21.8944\n",
      "Epoch 769 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 770 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 770 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 770 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 771 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 771 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 771 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 772 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 772 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 772 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 773 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 773 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 773 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 774 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 774 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 774 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 775 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 775 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 775 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 776 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 776 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 776 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 777 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 777 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 777 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 778 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 778 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 778 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 779 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 779 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 779 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 780 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 780 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 780 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 781 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 781 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 781 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 782 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 782 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 782 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 783 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 783 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 783 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 784 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 784 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 784 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 785 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 785 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 785 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 786 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 786 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 786 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 787 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 787 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 787 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 788 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 788 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 788 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 789 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 789 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 789 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 790 Batch 5 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 790 Batch 10 Loss 0.0577 Accuracy 21.8943\n",
      "Epoch 790 Batch 15 Loss 0.0577 Accuracy 21.8943\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 791 Batch 5 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 791 Batch 10 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 791 Batch 15 Loss 0.0577 Accuracy 21.8942\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 792 Batch 5 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 792 Batch 10 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 792 Batch 15 Loss 0.0577 Accuracy 21.8942\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 793 Batch 5 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 793 Batch 10 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 793 Batch 15 Loss 0.0577 Accuracy 21.8942\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 794 Batch 5 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 794 Batch 10 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 794 Batch 15 Loss 0.0577 Accuracy 21.8942\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 795 Batch 5 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 795 Batch 10 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 795 Batch 15 Loss 0.0577 Accuracy 21.8942\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 796 Batch 5 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 796 Batch 10 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 796 Batch 15 Loss 0.0577 Accuracy 21.8942\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 797 Batch 5 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 797 Batch 10 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 797 Batch 15 Loss 0.0577 Accuracy 21.8942\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 798 Batch 5 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 798 Batch 10 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 798 Batch 15 Loss 0.0577 Accuracy 21.8942\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 799 Batch 5 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 799 Batch 10 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 799 Batch 15 Loss 0.0577 Accuracy 21.8942\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 800 Batch 5 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 800 Batch 10 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 800 Batch 15 Loss 0.0577 Accuracy 21.8942\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 801 Batch 5 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 801 Batch 10 Loss 0.0577 Accuracy 21.8942\n",
      "Epoch 801 Batch 15 Loss 0.0577 Accuracy 21.8941\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 802 Batch 5 Loss 0.0577 Accuracy 21.8941\n",
      "Epoch 802 Batch 10 Loss 0.0577 Accuracy 21.8941\n",
      "Epoch 802 Batch 15 Loss 0.0577 Accuracy 21.8941\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 803 Batch 5 Loss 0.0577 Accuracy 21.8941\n",
      "Epoch 803 Batch 10 Loss 0.0577 Accuracy 21.8941\n",
      "Epoch 803 Batch 15 Loss 0.0577 Accuracy 21.8941\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 804 Batch 5 Loss 0.0577 Accuracy 21.8941\n",
      "Epoch 804 Batch 10 Loss 0.0577 Accuracy 21.8941\n",
      "Epoch 804 Batch 15 Loss 0.0577 Accuracy 21.8941\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 805 Batch 5 Loss 0.0577 Accuracy 21.8941\n",
      "Epoch 805 Batch 10 Loss 0.0577 Accuracy 21.8941\n",
      "Epoch 805 Batch 15 Loss 0.0577 Accuracy 21.8941\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 806 Batch 5 Loss 0.0577 Accuracy 21.8940\n",
      "Epoch 806 Batch 10 Loss 0.0577 Accuracy 21.8940\n",
      "Epoch 806 Batch 15 Loss 0.0577 Accuracy 21.8940\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 807 Batch 5 Loss 0.0577 Accuracy 21.8940\n",
      "Epoch 807 Batch 10 Loss 0.0577 Accuracy 21.8940\n",
      "Epoch 807 Batch 15 Loss 0.0577 Accuracy 21.8940\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 808 Batch 5 Loss 0.0577 Accuracy 21.8940\n",
      "Epoch 808 Batch 10 Loss 0.0577 Accuracy 21.8940\n",
      "Epoch 808 Batch 15 Loss 0.0577 Accuracy 21.8940\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 809 Batch 5 Loss 0.0577 Accuracy 21.8940\n",
      "Epoch 809 Batch 10 Loss 0.0577 Accuracy 21.8940\n",
      "Epoch 809 Batch 15 Loss 0.0577 Accuracy 21.8940\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 810 Batch 5 Loss 0.0577 Accuracy 21.8939\n",
      "Epoch 810 Batch 10 Loss 0.0577 Accuracy 21.8939\n",
      "Epoch 810 Batch 15 Loss 0.0577 Accuracy 21.8939\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 811 Batch 5 Loss 0.0577 Accuracy 21.8939\n",
      "Epoch 811 Batch 10 Loss 0.0577 Accuracy 21.8939\n",
      "Epoch 811 Batch 15 Loss 0.0577 Accuracy 21.8939\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 812 Batch 5 Loss 0.0577 Accuracy 21.8939\n",
      "Epoch 812 Batch 10 Loss 0.0577 Accuracy 21.8939\n",
      "Epoch 812 Batch 15 Loss 0.0577 Accuracy 21.8939\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 813 Batch 5 Loss 0.0577 Accuracy 21.8939\n",
      "Epoch 813 Batch 10 Loss 0.0577 Accuracy 21.8939\n",
      "Epoch 813 Batch 15 Loss 0.0577 Accuracy 21.8939\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 814 Batch 5 Loss 0.0577 Accuracy 21.8939\n",
      "Epoch 814 Batch 10 Loss 0.0577 Accuracy 21.8938\n",
      "Epoch 814 Batch 15 Loss 0.0577 Accuracy 21.8938\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 815 Batch 5 Loss 0.0577 Accuracy 21.8938\n",
      "Epoch 815 Batch 10 Loss 0.0577 Accuracy 21.8938\n",
      "Epoch 815 Batch 15 Loss 0.0577 Accuracy 21.8938\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 816 Batch 5 Loss 0.0577 Accuracy 21.8938\n",
      "Epoch 816 Batch 10 Loss 0.0577 Accuracy 21.8938\n",
      "Epoch 816 Batch 15 Loss 0.0577 Accuracy 21.8938\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 817 Batch 5 Loss 0.0577 Accuracy 21.8938\n",
      "Epoch 817 Batch 10 Loss 0.0577 Accuracy 21.8938\n",
      "Epoch 817 Batch 15 Loss 0.0577 Accuracy 21.8938\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 818 Batch 5 Loss 0.0577 Accuracy 21.8938\n",
      "Epoch 818 Batch 10 Loss 0.0577 Accuracy 21.8938\n",
      "Epoch 818 Batch 15 Loss 0.0577 Accuracy 21.8937\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 819 Batch 5 Loss 0.0577 Accuracy 21.8937\n",
      "Epoch 819 Batch 10 Loss 0.0577 Accuracy 21.8937\n",
      "Epoch 819 Batch 15 Loss 0.0577 Accuracy 21.8937\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 820 Batch 5 Loss 0.0577 Accuracy 21.8937\n",
      "Epoch 820 Batch 10 Loss 0.0577 Accuracy 21.8937\n",
      "Epoch 820 Batch 15 Loss 0.0577 Accuracy 21.8937\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 821 Batch 5 Loss 0.0577 Accuracy 21.8937\n",
      "Epoch 821 Batch 10 Loss 0.0577 Accuracy 21.8937\n",
      "Epoch 821 Batch 15 Loss 0.0577 Accuracy 21.8937\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 822 Batch 5 Loss 0.0577 Accuracy 21.8937\n",
      "Epoch 822 Batch 10 Loss 0.0577 Accuracy 21.8937\n",
      "Epoch 822 Batch 15 Loss 0.0577 Accuracy 21.8937\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 823 Batch 5 Loss 0.0577 Accuracy 21.8937\n",
      "Epoch 823 Batch 10 Loss 0.0577 Accuracy 21.8936\n",
      "Epoch 823 Batch 15 Loss 0.0577 Accuracy 21.8936\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 824 Batch 5 Loss 0.0577 Accuracy 21.8936\n",
      "Epoch 824 Batch 10 Loss 0.0577 Accuracy 21.8936\n",
      "Epoch 824 Batch 15 Loss 0.0577 Accuracy 21.8936\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 825 Batch 5 Loss 0.0577 Accuracy 21.8936\n",
      "Epoch 825 Batch 10 Loss 0.0577 Accuracy 21.8936\n",
      "Epoch 825 Batch 15 Loss 0.0577 Accuracy 21.8936\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 826 Batch 5 Loss 0.0577 Accuracy 21.8936\n",
      "Epoch 826 Batch 10 Loss 0.0577 Accuracy 21.8936\n",
      "Epoch 826 Batch 15 Loss 0.0577 Accuracy 21.8936\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 827 Batch 5 Loss 0.0577 Accuracy 21.8936\n",
      "Epoch 827 Batch 10 Loss 0.0577 Accuracy 21.8936\n",
      "Epoch 827 Batch 15 Loss 0.0577 Accuracy 21.8935\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 828 Batch 5 Loss 0.0577 Accuracy 21.8935\n",
      "Epoch 828 Batch 10 Loss 0.0577 Accuracy 21.8935\n",
      "Epoch 828 Batch 15 Loss 0.0577 Accuracy 21.8935\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 829 Batch 5 Loss 0.0577 Accuracy 21.8935\n",
      "Epoch 829 Batch 10 Loss 0.0577 Accuracy 21.8935\n",
      "Epoch 829 Batch 15 Loss 0.0577 Accuracy 21.8935\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 830 Batch 5 Loss 0.0577 Accuracy 21.8935\n",
      "Epoch 830 Batch 10 Loss 0.0577 Accuracy 21.8935\n",
      "Epoch 830 Batch 15 Loss 0.0577 Accuracy 21.8935\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 831 Batch 5 Loss 0.0577 Accuracy 21.8935\n",
      "Epoch 831 Batch 10 Loss 0.0577 Accuracy 21.8935\n",
      "Epoch 831 Batch 15 Loss 0.0577 Accuracy 21.8935\n",
      "Time taken for 1 epoch: 0.02 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 832 Batch 5 Loss 0.0577 Accuracy 21.8934\n",
      "Epoch 832 Batch 10 Loss 0.0577 Accuracy 21.8934\n",
      "Epoch 832 Batch 15 Loss 0.0577 Accuracy 21.8934\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 833 Batch 5 Loss 0.0577 Accuracy 21.8934\n",
      "Epoch 833 Batch 10 Loss 0.0577 Accuracy 21.8934\n",
      "Epoch 833 Batch 15 Loss 0.0577 Accuracy 21.8934\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 834 Batch 5 Loss 0.0577 Accuracy 21.8934\n",
      "Epoch 834 Batch 10 Loss 0.0577 Accuracy 21.8934\n",
      "Epoch 834 Batch 15 Loss 0.0577 Accuracy 21.8934\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 835 Batch 5 Loss 0.0577 Accuracy 21.8934\n",
      "Epoch 835 Batch 10 Loss 0.0577 Accuracy 21.8934\n",
      "Epoch 835 Batch 15 Loss 0.0577 Accuracy 21.8934\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 836 Batch 5 Loss 0.0577 Accuracy 21.8934\n",
      "Epoch 836 Batch 10 Loss 0.0577 Accuracy 21.8934\n",
      "Epoch 836 Batch 15 Loss 0.0577 Accuracy 21.8933\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 837 Batch 5 Loss 0.0577 Accuracy 21.8933\n",
      "Epoch 837 Batch 10 Loss 0.0577 Accuracy 21.8933\n",
      "Epoch 837 Batch 15 Loss 0.0577 Accuracy 21.8933\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 838 Batch 5 Loss 0.0577 Accuracy 21.8933\n",
      "Epoch 838 Batch 10 Loss 0.0577 Accuracy 21.8933\n",
      "Epoch 838 Batch 15 Loss 0.0577 Accuracy 21.8933\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 839 Batch 5 Loss 0.0577 Accuracy 21.8933\n",
      "Epoch 839 Batch 10 Loss 0.0577 Accuracy 21.8933\n",
      "Epoch 839 Batch 15 Loss 0.0577 Accuracy 21.8933\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 840 Batch 5 Loss 0.0577 Accuracy 21.8933\n",
      "Epoch 840 Batch 10 Loss 0.0577 Accuracy 21.8933\n",
      "Epoch 840 Batch 15 Loss 0.0577 Accuracy 21.8933\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 841 Batch 5 Loss 0.0577 Accuracy 21.8933\n",
      "Epoch 841 Batch 10 Loss 0.0577 Accuracy 21.8932\n",
      "Epoch 841 Batch 15 Loss 0.0577 Accuracy 21.8932\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 842 Batch 5 Loss 0.0577 Accuracy 21.8932\n",
      "Epoch 842 Batch 10 Loss 0.0577 Accuracy 21.8932\n",
      "Epoch 842 Batch 15 Loss 0.0577 Accuracy 21.8932\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 843 Batch 5 Loss 0.0577 Accuracy 21.8932\n",
      "Epoch 843 Batch 10 Loss 0.0577 Accuracy 21.8932\n",
      "Epoch 843 Batch 15 Loss 0.0577 Accuracy 21.8932\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 844 Batch 5 Loss 0.0577 Accuracy 21.8932\n",
      "Epoch 844 Batch 10 Loss 0.0577 Accuracy 21.8932\n",
      "Epoch 844 Batch 15 Loss 0.0577 Accuracy 21.8932\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 845 Batch 5 Loss 0.0577 Accuracy 21.8932\n",
      "Epoch 845 Batch 10 Loss 0.0577 Accuracy 21.8932\n",
      "Epoch 845 Batch 15 Loss 0.0577 Accuracy 21.8932\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 846 Batch 5 Loss 0.0577 Accuracy 21.8931\n",
      "Epoch 846 Batch 10 Loss 0.0577 Accuracy 21.8931\n",
      "Epoch 846 Batch 15 Loss 0.0577 Accuracy 21.8931\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 847 Batch 5 Loss 0.0577 Accuracy 21.8931\n",
      "Epoch 847 Batch 10 Loss 0.0577 Accuracy 21.8931\n",
      "Epoch 847 Batch 15 Loss 0.0577 Accuracy 21.8931\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 848 Batch 5 Loss 0.0577 Accuracy 21.8931\n",
      "Epoch 848 Batch 10 Loss 0.0577 Accuracy 21.8931\n",
      "Epoch 848 Batch 15 Loss 0.0577 Accuracy 21.8931\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 849 Batch 5 Loss 0.0577 Accuracy 21.8931\n",
      "Epoch 849 Batch 10 Loss 0.0577 Accuracy 21.8931\n",
      "Epoch 849 Batch 15 Loss 0.0577 Accuracy 21.8931\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 850 Batch 5 Loss 0.0577 Accuracy 21.8931\n",
      "Epoch 850 Batch 10 Loss 0.0577 Accuracy 21.8930\n",
      "Epoch 850 Batch 15 Loss 0.0577 Accuracy 21.8930\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 851 Batch 5 Loss 0.0577 Accuracy 21.8930\n",
      "Epoch 851 Batch 10 Loss 0.0577 Accuracy 21.8930\n",
      "Epoch 851 Batch 15 Loss 0.0577 Accuracy 21.8930\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 852 Batch 5 Loss 0.0577 Accuracy 21.8930\n",
      "Epoch 852 Batch 10 Loss 0.0577 Accuracy 21.8930\n",
      "Epoch 852 Batch 15 Loss 0.0577 Accuracy 21.8930\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 853 Batch 5 Loss 0.0577 Accuracy 21.8930\n",
      "Epoch 853 Batch 10 Loss 0.0577 Accuracy 21.8930\n",
      "Epoch 853 Batch 15 Loss 0.0577 Accuracy 21.8930\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 854 Batch 5 Loss 0.0577 Accuracy 21.8930\n",
      "Epoch 854 Batch 10 Loss 0.0577 Accuracy 21.8930\n",
      "Epoch 854 Batch 15 Loss 0.0577 Accuracy 21.8930\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 855 Batch 5 Loss 0.0577 Accuracy 21.8930\n",
      "Epoch 855 Batch 10 Loss 0.0577 Accuracy 21.8929\n",
      "Epoch 855 Batch 15 Loss 0.0577 Accuracy 21.8929\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 856 Batch 5 Loss 0.0577 Accuracy 21.8929\n",
      "Epoch 856 Batch 10 Loss 0.0577 Accuracy 21.8929\n",
      "Epoch 856 Batch 15 Loss 0.0577 Accuracy 21.8929\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 857 Batch 5 Loss 0.0577 Accuracy 21.8929\n",
      "Epoch 857 Batch 10 Loss 0.0577 Accuracy 21.8929\n",
      "Epoch 857 Batch 15 Loss 0.0577 Accuracy 21.8929\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 858 Batch 5 Loss 0.0577 Accuracy 21.8929\n",
      "Epoch 858 Batch 10 Loss 0.0577 Accuracy 21.8929\n",
      "Epoch 858 Batch 15 Loss 0.0577 Accuracy 21.8929\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 859 Batch 5 Loss 0.0577 Accuracy 21.8929\n",
      "Epoch 859 Batch 10 Loss 0.0577 Accuracy 21.8929\n",
      "Epoch 859 Batch 15 Loss 0.0577 Accuracy 21.8929\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 860 Batch 5 Loss 0.0577 Accuracy 21.8928\n",
      "Epoch 860 Batch 10 Loss 0.0577 Accuracy 21.8928\n",
      "Epoch 860 Batch 15 Loss 0.0577 Accuracy 21.8928\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 861 Batch 5 Loss 0.0577 Accuracy 21.8928\n",
      "Epoch 861 Batch 10 Loss 0.0577 Accuracy 21.8928\n",
      "Epoch 861 Batch 15 Loss 0.0577 Accuracy 21.8928\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 862 Batch 5 Loss 0.0577 Accuracy 21.8928\n",
      "Epoch 862 Batch 10 Loss 0.0577 Accuracy 21.8928\n",
      "Epoch 862 Batch 15 Loss 0.0577 Accuracy 21.8928\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 863 Batch 5 Loss 0.0577 Accuracy 21.8928\n",
      "Epoch 863 Batch 10 Loss 0.0577 Accuracy 21.8928\n",
      "Epoch 863 Batch 15 Loss 0.0577 Accuracy 21.8928\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 864 Batch 5 Loss 0.0577 Accuracy 21.8928\n",
      "Epoch 864 Batch 10 Loss 0.0577 Accuracy 21.8928\n",
      "Epoch 864 Batch 15 Loss 0.0577 Accuracy 21.8927\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 865 Batch 5 Loss 0.0577 Accuracy 21.8927\n",
      "Epoch 865 Batch 10 Loss 0.0577 Accuracy 21.8927\n",
      "Epoch 865 Batch 15 Loss 0.0577 Accuracy 21.8927\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 866 Batch 5 Loss 0.0577 Accuracy 21.8927\n",
      "Epoch 866 Batch 10 Loss 0.0577 Accuracy 21.8927\n",
      "Epoch 866 Batch 15 Loss 0.0577 Accuracy 21.8927\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 867 Batch 5 Loss 0.0577 Accuracy 21.8927\n",
      "Epoch 867 Batch 10 Loss 0.0577 Accuracy 21.8927\n",
      "Epoch 867 Batch 15 Loss 0.0577 Accuracy 21.8927\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 868 Batch 5 Loss 0.0577 Accuracy 21.8927\n",
      "Epoch 868 Batch 10 Loss 0.0577 Accuracy 21.8927\n",
      "Epoch 868 Batch 15 Loss 0.0577 Accuracy 21.8927\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 869 Batch 5 Loss 0.0577 Accuracy 21.8927\n",
      "Epoch 869 Batch 10 Loss 0.0577 Accuracy 21.8927\n",
      "Epoch 869 Batch 15 Loss 0.0577 Accuracy 21.8926\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 870 Batch 5 Loss 0.0577 Accuracy 21.8926\n",
      "Epoch 870 Batch 10 Loss 0.0577 Accuracy 21.8926\n",
      "Epoch 870 Batch 15 Loss 0.0577 Accuracy 21.8926\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 871 Batch 5 Loss 0.0577 Accuracy 21.8926\n",
      "Epoch 871 Batch 10 Loss 0.0577 Accuracy 21.8926\n",
      "Epoch 871 Batch 15 Loss 0.0577 Accuracy 21.8926\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 872 Batch 5 Loss 0.0577 Accuracy 21.8926\n",
      "Epoch 872 Batch 10 Loss 0.0577 Accuracy 21.8926\n",
      "Epoch 872 Batch 15 Loss 0.0577 Accuracy 21.8926\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 873 Batch 5 Loss 0.0577 Accuracy 21.8926\n",
      "Epoch 873 Batch 10 Loss 0.0577 Accuracy 21.8926\n",
      "Epoch 873 Batch 15 Loss 0.0577 Accuracy 21.8926\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 874 Batch 5 Loss 0.0577 Accuracy 21.8926\n",
      "Epoch 874 Batch 10 Loss 0.0577 Accuracy 21.8926\n",
      "Epoch 874 Batch 15 Loss 0.0577 Accuracy 21.8925\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 875 Batch 5 Loss 0.0577 Accuracy 21.8925\n",
      "Epoch 875 Batch 10 Loss 0.0577 Accuracy 21.8925\n",
      "Epoch 875 Batch 15 Loss 0.0577 Accuracy 21.8925\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 876 Batch 5 Loss 0.0577 Accuracy 21.8925\n",
      "Epoch 876 Batch 10 Loss 0.0577 Accuracy 21.8925\n",
      "Epoch 876 Batch 15 Loss 0.0577 Accuracy 21.8925\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 877 Batch 5 Loss 0.0577 Accuracy 21.8925\n",
      "Epoch 877 Batch 10 Loss 0.0577 Accuracy 21.8925\n",
      "Epoch 877 Batch 15 Loss 0.0577 Accuracy 21.8925\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 878 Batch 5 Loss 0.0577 Accuracy 21.8925\n",
      "Epoch 878 Batch 10 Loss 0.0577 Accuracy 21.8925\n",
      "Epoch 878 Batch 15 Loss 0.0577 Accuracy 21.8925\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 879 Batch 5 Loss 0.0577 Accuracy 21.8925\n",
      "Epoch 879 Batch 10 Loss 0.0577 Accuracy 21.8925\n",
      "Epoch 879 Batch 15 Loss 0.0577 Accuracy 21.8924\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 880 Batch 5 Loss 0.0577 Accuracy 21.8924\n",
      "Epoch 880 Batch 10 Loss 0.0577 Accuracy 21.8924\n",
      "Epoch 880 Batch 15 Loss 0.0577 Accuracy 21.8924\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 881 Batch 5 Loss 0.0577 Accuracy 21.8924\n",
      "Epoch 881 Batch 10 Loss 0.0577 Accuracy 21.8924\n",
      "Epoch 881 Batch 15 Loss 0.0577 Accuracy 21.8924\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 882 Batch 5 Loss 0.0577 Accuracy 21.8924\n",
      "Epoch 882 Batch 10 Loss 0.0577 Accuracy 21.8924\n",
      "Epoch 882 Batch 15 Loss 0.0577 Accuracy 21.8924\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 883 Batch 5 Loss 0.0577 Accuracy 21.8924\n",
      "Epoch 883 Batch 10 Loss 0.0577 Accuracy 21.8924\n",
      "Epoch 883 Batch 15 Loss 0.0577 Accuracy 21.8924\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 884 Batch 5 Loss 0.0577 Accuracy 21.8924\n",
      "Epoch 884 Batch 10 Loss 0.0577 Accuracy 21.8924\n",
      "Epoch 884 Batch 15 Loss 0.0577 Accuracy 21.8923\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 885 Batch 5 Loss 0.0577 Accuracy 21.8923\n",
      "Epoch 885 Batch 10 Loss 0.0577 Accuracy 21.8923\n",
      "Epoch 885 Batch 15 Loss 0.0577 Accuracy 21.8923\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 886 Batch 5 Loss 0.0577 Accuracy 21.8923\n",
      "Epoch 886 Batch 10 Loss 0.0577 Accuracy 21.8923\n",
      "Epoch 886 Batch 15 Loss 0.0577 Accuracy 21.8923\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 887 Batch 5 Loss 0.0577 Accuracy 21.8923\n",
      "Epoch 887 Batch 10 Loss 0.0577 Accuracy 21.8923\n",
      "Epoch 887 Batch 15 Loss 0.0577 Accuracy 21.8923\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 888 Batch 5 Loss 0.0577 Accuracy 21.8923\n",
      "Epoch 888 Batch 10 Loss 0.0577 Accuracy 21.8923\n",
      "Epoch 888 Batch 15 Loss 0.0577 Accuracy 21.8923\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 889 Batch 5 Loss 0.0577 Accuracy 21.8923\n",
      "Epoch 889 Batch 10 Loss 0.0577 Accuracy 21.8923\n",
      "Epoch 889 Batch 15 Loss 0.0577 Accuracy 21.8923\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 890 Batch 5 Loss 0.0577 Accuracy 21.8922\n",
      "Epoch 890 Batch 10 Loss 0.0577 Accuracy 21.8922\n",
      "Epoch 890 Batch 15 Loss 0.0577 Accuracy 21.8922\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 891 Batch 5 Loss 0.0577 Accuracy 21.8922\n",
      "Epoch 891 Batch 10 Loss 0.0577 Accuracy 21.8922\n",
      "Epoch 891 Batch 15 Loss 0.0577 Accuracy 21.8922\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 892 Batch 5 Loss 0.0577 Accuracy 21.8922\n",
      "Epoch 892 Batch 10 Loss 0.0577 Accuracy 21.8922\n",
      "Epoch 892 Batch 15 Loss 0.0577 Accuracy 21.8922\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 893 Batch 5 Loss 0.0577 Accuracy 21.8922\n",
      "Epoch 893 Batch 10 Loss 0.0577 Accuracy 21.8922\n",
      "Epoch 893 Batch 15 Loss 0.0577 Accuracy 21.8922\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 894 Batch 5 Loss 0.0577 Accuracy 21.8922\n",
      "Epoch 894 Batch 10 Loss 0.0577 Accuracy 21.8922\n",
      "Epoch 894 Batch 15 Loss 0.0577 Accuracy 21.8922\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 895 Batch 5 Loss 0.0577 Accuracy 21.8921\n",
      "Epoch 895 Batch 10 Loss 0.0577 Accuracy 21.8921\n",
      "Epoch 895 Batch 15 Loss 0.0577 Accuracy 21.8921\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 896 Batch 5 Loss 0.0577 Accuracy 21.8921\n",
      "Epoch 896 Batch 10 Loss 0.0577 Accuracy 21.8921\n",
      "Epoch 896 Batch 15 Loss 0.0577 Accuracy 21.8921\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 897 Batch 5 Loss 0.0577 Accuracy 21.8921\n",
      "Epoch 897 Batch 10 Loss 0.0577 Accuracy 21.8921\n",
      "Epoch 897 Batch 15 Loss 0.0577 Accuracy 21.8921\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 898 Batch 5 Loss 0.0577 Accuracy 21.8921\n",
      "Epoch 898 Batch 10 Loss 0.0577 Accuracy 21.8921\n",
      "Epoch 898 Batch 15 Loss 0.0577 Accuracy 21.8921\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 899 Batch 5 Loss 0.0577 Accuracy 21.8921\n",
      "Epoch 899 Batch 10 Loss 0.0577 Accuracy 21.8921\n",
      "Epoch 899 Batch 15 Loss 0.0577 Accuracy 21.8921\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 900 Batch 5 Loss 0.0577 Accuracy 21.8921\n",
      "Epoch 900 Batch 10 Loss 0.0577 Accuracy 21.8920\n",
      "Epoch 900 Batch 15 Loss 0.0577 Accuracy 21.8920\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 901 Batch 5 Loss 0.0577 Accuracy 21.8920\n",
      "Epoch 901 Batch 10 Loss 0.0577 Accuracy 21.8920\n",
      "Epoch 901 Batch 15 Loss 0.0577 Accuracy 21.8920\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 902 Batch 5 Loss 0.0577 Accuracy 21.8920\n",
      "Epoch 902 Batch 10 Loss 0.0577 Accuracy 21.8920\n",
      "Epoch 902 Batch 15 Loss 0.0577 Accuracy 21.8920\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 903 Batch 5 Loss 0.0577 Accuracy 21.8920\n",
      "Epoch 903 Batch 10 Loss 0.0577 Accuracy 21.8920\n",
      "Epoch 903 Batch 15 Loss 0.0577 Accuracy 21.8920\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 904 Batch 5 Loss 0.0577 Accuracy 21.8920\n",
      "Epoch 904 Batch 10 Loss 0.0577 Accuracy 21.8920\n",
      "Epoch 904 Batch 15 Loss 0.0577 Accuracy 21.8920\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 905 Batch 5 Loss 0.0577 Accuracy 21.8920\n",
      "Epoch 905 Batch 10 Loss 0.0577 Accuracy 21.8920\n",
      "Epoch 905 Batch 15 Loss 0.0577 Accuracy 21.8919\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 906 Batch 5 Loss 0.0577 Accuracy 21.8919\n",
      "Epoch 906 Batch 10 Loss 0.0577 Accuracy 21.8919\n",
      "Epoch 906 Batch 15 Loss 0.0577 Accuracy 21.8919\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 907 Batch 5 Loss 0.0577 Accuracy 21.8919\n",
      "Epoch 907 Batch 10 Loss 0.0577 Accuracy 21.8919\n",
      "Epoch 907 Batch 15 Loss 0.0577 Accuracy 21.8919\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 908 Batch 5 Loss 0.0577 Accuracy 21.8919\n",
      "Epoch 908 Batch 10 Loss 0.0577 Accuracy 21.8919\n",
      "Epoch 908 Batch 15 Loss 0.0577 Accuracy 21.8919\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 909 Batch 5 Loss 0.0577 Accuracy 21.8919\n",
      "Epoch 909 Batch 10 Loss 0.0577 Accuracy 21.8919\n",
      "Epoch 909 Batch 15 Loss 0.0577 Accuracy 21.8919\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 910 Batch 5 Loss 0.0577 Accuracy 21.8919\n",
      "Epoch 910 Batch 10 Loss 0.0577 Accuracy 21.8919\n",
      "Epoch 910 Batch 15 Loss 0.0577 Accuracy 21.8919\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 911 Batch 5 Loss 0.0577 Accuracy 21.8918\n",
      "Epoch 911 Batch 10 Loss 0.0577 Accuracy 21.8918\n",
      "Epoch 911 Batch 15 Loss 0.0577 Accuracy 21.8918\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 912 Batch 5 Loss 0.0577 Accuracy 21.8918\n",
      "Epoch 912 Batch 10 Loss 0.0577 Accuracy 21.8918\n",
      "Epoch 912 Batch 15 Loss 0.0577 Accuracy 21.8918\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 913 Batch 5 Loss 0.0577 Accuracy 21.8918\n",
      "Epoch 913 Batch 10 Loss 0.0577 Accuracy 21.8918\n",
      "Epoch 913 Batch 15 Loss 0.0577 Accuracy 21.8918\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 914 Batch 5 Loss 0.0577 Accuracy 21.8918\n",
      "Epoch 914 Batch 10 Loss 0.0577 Accuracy 21.8918\n",
      "Epoch 914 Batch 15 Loss 0.0577 Accuracy 21.8918\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 915 Batch 5 Loss 0.0577 Accuracy 21.8918\n",
      "Epoch 915 Batch 10 Loss 0.0577 Accuracy 21.8918\n",
      "Epoch 915 Batch 15 Loss 0.0577 Accuracy 21.8918\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 916 Batch 5 Loss 0.0577 Accuracy 21.8918\n",
      "Epoch 916 Batch 10 Loss 0.0577 Accuracy 21.8917\n",
      "Epoch 916 Batch 15 Loss 0.0577 Accuracy 21.8917\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 917 Batch 5 Loss 0.0577 Accuracy 21.8917\n",
      "Epoch 917 Batch 10 Loss 0.0577 Accuracy 21.8917\n",
      "Epoch 917 Batch 15 Loss 0.0577 Accuracy 21.8917\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 918 Batch 5 Loss 0.0577 Accuracy 21.8917\n",
      "Epoch 918 Batch 10 Loss 0.0577 Accuracy 21.8917\n",
      "Epoch 918 Batch 15 Loss 0.0577 Accuracy 21.8917\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 919 Batch 5 Loss 0.0577 Accuracy 21.8917\n",
      "Epoch 919 Batch 10 Loss 0.0577 Accuracy 21.8917\n",
      "Epoch 919 Batch 15 Loss 0.0577 Accuracy 21.8917\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 920 Batch 5 Loss 0.0577 Accuracy 21.8917\n",
      "Epoch 920 Batch 10 Loss 0.0577 Accuracy 21.8917\n",
      "Epoch 920 Batch 15 Loss 0.0577 Accuracy 21.8917\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 921 Batch 5 Loss 0.0577 Accuracy 21.8917\n",
      "Epoch 921 Batch 10 Loss 0.0577 Accuracy 21.8917\n",
      "Epoch 921 Batch 15 Loss 0.0577 Accuracy 21.8917\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 922 Batch 5 Loss 0.0577 Accuracy 21.8916\n",
      "Epoch 922 Batch 10 Loss 0.0577 Accuracy 21.8916\n",
      "Epoch 922 Batch 15 Loss 0.0577 Accuracy 21.8916\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 923 Batch 5 Loss 0.0577 Accuracy 21.8916\n",
      "Epoch 923 Batch 10 Loss 0.0577 Accuracy 21.8916\n",
      "Epoch 923 Batch 15 Loss 0.0577 Accuracy 21.8916\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 924 Batch 5 Loss 0.0577 Accuracy 21.8916\n",
      "Epoch 924 Batch 10 Loss 0.0577 Accuracy 21.8916\n",
      "Epoch 924 Batch 15 Loss 0.0577 Accuracy 21.8916\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 925 Batch 5 Loss 0.0577 Accuracy 21.8916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 925 Batch 10 Loss 0.0577 Accuracy 21.8916\n",
      "Epoch 925 Batch 15 Loss 0.0577 Accuracy 21.8916\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 926 Batch 5 Loss 0.0577 Accuracy 21.8916\n",
      "Epoch 926 Batch 10 Loss 0.0577 Accuracy 21.8916\n",
      "Epoch 926 Batch 15 Loss 0.0577 Accuracy 21.8916\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 927 Batch 5 Loss 0.0577 Accuracy 21.8916\n",
      "Epoch 927 Batch 10 Loss 0.0577 Accuracy 21.8916\n",
      "Epoch 927 Batch 15 Loss 0.0577 Accuracy 21.8915\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 928 Batch 5 Loss 0.0577 Accuracy 21.8915\n",
      "Epoch 928 Batch 10 Loss 0.0577 Accuracy 21.8915\n",
      "Epoch 928 Batch 15 Loss 0.0577 Accuracy 21.8915\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 929 Batch 5 Loss 0.0577 Accuracy 21.8915\n",
      "Epoch 929 Batch 10 Loss 0.0577 Accuracy 21.8915\n",
      "Epoch 929 Batch 15 Loss 0.0577 Accuracy 21.8915\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 930 Batch 5 Loss 0.0577 Accuracy 21.8915\n",
      "Epoch 930 Batch 10 Loss 0.0577 Accuracy 21.8915\n",
      "Epoch 930 Batch 15 Loss 0.0577 Accuracy 21.8915\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 931 Batch 5 Loss 0.0577 Accuracy 21.8915\n",
      "Epoch 931 Batch 10 Loss 0.0577 Accuracy 21.8915\n",
      "Epoch 931 Batch 15 Loss 0.0577 Accuracy 21.8915\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 932 Batch 5 Loss 0.0577 Accuracy 21.8915\n",
      "Epoch 932 Batch 10 Loss 0.0577 Accuracy 21.8915\n",
      "Epoch 932 Batch 15 Loss 0.0577 Accuracy 21.8915\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 933 Batch 5 Loss 0.0577 Accuracy 21.8914\n",
      "Epoch 933 Batch 10 Loss 0.0577 Accuracy 21.8914\n",
      "Epoch 933 Batch 15 Loss 0.0577 Accuracy 21.8914\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 934 Batch 5 Loss 0.0577 Accuracy 21.8914\n",
      "Epoch 934 Batch 10 Loss 0.0577 Accuracy 21.8914\n",
      "Epoch 934 Batch 15 Loss 0.0577 Accuracy 21.8914\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 935 Batch 5 Loss 0.0577 Accuracy 21.8914\n",
      "Epoch 935 Batch 10 Loss 0.0577 Accuracy 21.8914\n",
      "Epoch 935 Batch 15 Loss 0.0577 Accuracy 21.8914\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 936 Batch 5 Loss 0.0577 Accuracy 21.8914\n",
      "Epoch 936 Batch 10 Loss 0.0577 Accuracy 21.8914\n",
      "Epoch 936 Batch 15 Loss 0.0577 Accuracy 21.8914\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 937 Batch 5 Loss 0.0577 Accuracy 21.8914\n",
      "Epoch 937 Batch 10 Loss 0.0577 Accuracy 21.8914\n",
      "Epoch 937 Batch 15 Loss 0.0577 Accuracy 21.8914\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 938 Batch 5 Loss 0.0577 Accuracy 21.8914\n",
      "Epoch 938 Batch 10 Loss 0.0577 Accuracy 21.8914\n",
      "Epoch 938 Batch 15 Loss 0.0577 Accuracy 21.8913\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 939 Batch 5 Loss 0.0577 Accuracy 21.8913\n",
      "Epoch 939 Batch 10 Loss 0.0577 Accuracy 21.8913\n",
      "Epoch 939 Batch 15 Loss 0.0577 Accuracy 21.8913\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 940 Batch 5 Loss 0.0577 Accuracy 21.8913\n",
      "Epoch 940 Batch 10 Loss 0.0577 Accuracy 21.8913\n",
      "Epoch 940 Batch 15 Loss 0.0577 Accuracy 21.8913\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 941 Batch 5 Loss 0.0577 Accuracy 21.8913\n",
      "Epoch 941 Batch 10 Loss 0.0577 Accuracy 21.8913\n",
      "Epoch 941 Batch 15 Loss 0.0577 Accuracy 21.8913\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 942 Batch 5 Loss 0.0577 Accuracy 21.8913\n",
      "Epoch 942 Batch 10 Loss 0.0577 Accuracy 21.8913\n",
      "Epoch 942 Batch 15 Loss 0.0577 Accuracy 21.8913\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 943 Batch 5 Loss 0.0577 Accuracy 21.8913\n",
      "Epoch 943 Batch 10 Loss 0.0577 Accuracy 21.8913\n",
      "Epoch 943 Batch 15 Loss 0.0577 Accuracy 21.8913\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 944 Batch 5 Loss 0.0577 Accuracy 21.8913\n",
      "Epoch 944 Batch 10 Loss 0.0577 Accuracy 21.8913\n",
      "Epoch 944 Batch 15 Loss 0.0577 Accuracy 21.8912\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 945 Batch 5 Loss 0.0577 Accuracy 21.8912\n",
      "Epoch 945 Batch 10 Loss 0.0577 Accuracy 21.8912\n",
      "Epoch 945 Batch 15 Loss 0.0577 Accuracy 21.8912\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 946 Batch 5 Loss 0.0577 Accuracy 21.8912\n",
      "Epoch 946 Batch 10 Loss 0.0577 Accuracy 21.8912\n",
      "Epoch 946 Batch 15 Loss 0.0577 Accuracy 21.8912\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 947 Batch 5 Loss 0.0577 Accuracy 21.8912\n",
      "Epoch 947 Batch 10 Loss 0.0577 Accuracy 21.8912\n",
      "Epoch 947 Batch 15 Loss 0.0577 Accuracy 21.8912\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 948 Batch 5 Loss 0.0577 Accuracy 21.8912\n",
      "Epoch 948 Batch 10 Loss 0.0577 Accuracy 21.8912\n",
      "Epoch 948 Batch 15 Loss 0.0577 Accuracy 21.8912\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 949 Batch 5 Loss 0.0577 Accuracy 21.8912\n",
      "Epoch 949 Batch 10 Loss 0.0577 Accuracy 21.8912\n",
      "Epoch 949 Batch 15 Loss 0.0577 Accuracy 21.8912\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 950 Batch 5 Loss 0.0577 Accuracy 21.8912\n",
      "Epoch 950 Batch 10 Loss 0.0577 Accuracy 21.8911\n",
      "Epoch 950 Batch 15 Loss 0.0577 Accuracy 21.8911\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 951 Batch 5 Loss 0.0577 Accuracy 21.8911\n",
      "Epoch 951 Batch 10 Loss 0.0577 Accuracy 21.8911\n",
      "Epoch 951 Batch 15 Loss 0.0577 Accuracy 21.8911\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 952 Batch 5 Loss 0.0577 Accuracy 21.8911\n",
      "Epoch 952 Batch 10 Loss 0.0577 Accuracy 21.8911\n",
      "Epoch 952 Batch 15 Loss 0.0577 Accuracy 21.8911\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 953 Batch 5 Loss 0.0577 Accuracy 21.8911\n",
      "Epoch 953 Batch 10 Loss 0.0577 Accuracy 21.8911\n",
      "Epoch 953 Batch 15 Loss 0.0577 Accuracy 21.8911\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 954 Batch 5 Loss 0.0577 Accuracy 21.8911\n",
      "Epoch 954 Batch 10 Loss 0.0577 Accuracy 21.8911\n",
      "Epoch 954 Batch 15 Loss 0.0577 Accuracy 21.8911\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 955 Batch 5 Loss 0.0577 Accuracy 21.8911\n",
      "Epoch 955 Batch 10 Loss 0.0577 Accuracy 21.8911\n",
      "Epoch 955 Batch 15 Loss 0.0577 Accuracy 21.8911\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 956 Batch 5 Loss 0.0577 Accuracy 21.8911\n",
      "Epoch 956 Batch 10 Loss 0.0577 Accuracy 21.8910\n",
      "Epoch 956 Batch 15 Loss 0.0577 Accuracy 21.8910\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 957 Batch 5 Loss 0.0577 Accuracy 21.8910\n",
      "Epoch 957 Batch 10 Loss 0.0577 Accuracy 21.8910\n",
      "Epoch 957 Batch 15 Loss 0.0577 Accuracy 21.8910\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 958 Batch 5 Loss 0.0577 Accuracy 21.8910\n",
      "Epoch 958 Batch 10 Loss 0.0577 Accuracy 21.8910\n",
      "Epoch 958 Batch 15 Loss 0.0577 Accuracy 21.8910\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 959 Batch 5 Loss 0.0577 Accuracy 21.8910\n",
      "Epoch 959 Batch 10 Loss 0.0577 Accuracy 21.8910\n",
      "Epoch 959 Batch 15 Loss 0.0577 Accuracy 21.8910\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 960 Batch 5 Loss 0.0577 Accuracy 21.8910\n",
      "Epoch 960 Batch 10 Loss 0.0577 Accuracy 21.8910\n",
      "Epoch 960 Batch 15 Loss 0.0577 Accuracy 21.8910\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 961 Batch 5 Loss 0.0577 Accuracy 21.8910\n",
      "Epoch 961 Batch 10 Loss 0.0577 Accuracy 21.8910\n",
      "Epoch 961 Batch 15 Loss 0.0577 Accuracy 21.8910\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 962 Batch 5 Loss 0.0577 Accuracy 21.8910\n",
      "Epoch 962 Batch 10 Loss 0.0577 Accuracy 21.8909\n",
      "Epoch 962 Batch 15 Loss 0.0577 Accuracy 21.8909\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 963 Batch 5 Loss 0.0577 Accuracy 21.8909\n",
      "Epoch 963 Batch 10 Loss 0.0577 Accuracy 21.8909\n",
      "Epoch 963 Batch 15 Loss 0.0577 Accuracy 21.8909\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 964 Batch 5 Loss 0.0577 Accuracy 21.8909\n",
      "Epoch 964 Batch 10 Loss 0.0577 Accuracy 21.8909\n",
      "Epoch 964 Batch 15 Loss 0.0577 Accuracy 21.8909\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 965 Batch 5 Loss 0.0577 Accuracy 21.8909\n",
      "Epoch 965 Batch 10 Loss 0.0577 Accuracy 21.8909\n",
      "Epoch 965 Batch 15 Loss 0.0577 Accuracy 21.8909\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 966 Batch 5 Loss 0.0577 Accuracy 21.8909\n",
      "Epoch 966 Batch 10 Loss 0.0577 Accuracy 21.8909\n",
      "Epoch 966 Batch 15 Loss 0.0577 Accuracy 21.8909\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 967 Batch 5 Loss 0.0577 Accuracy 21.8909\n",
      "Epoch 967 Batch 10 Loss 0.0577 Accuracy 21.8909\n",
      "Epoch 967 Batch 15 Loss 0.0577 Accuracy 21.8909\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 968 Batch 5 Loss 0.0577 Accuracy 21.8909\n",
      "Epoch 968 Batch 10 Loss 0.0577 Accuracy 21.8908\n",
      "Epoch 968 Batch 15 Loss 0.0577 Accuracy 21.8908\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 969 Batch 5 Loss 0.0577 Accuracy 21.8908\n",
      "Epoch 969 Batch 10 Loss 0.0577 Accuracy 21.8908\n",
      "Epoch 969 Batch 15 Loss 0.0577 Accuracy 21.8908\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 970 Batch 5 Loss 0.0577 Accuracy 21.8908\n",
      "Epoch 970 Batch 10 Loss 0.0577 Accuracy 21.8908\n",
      "Epoch 970 Batch 15 Loss 0.0577 Accuracy 21.8908\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 971 Batch 5 Loss 0.0577 Accuracy 21.8908\n",
      "Epoch 971 Batch 10 Loss 0.0577 Accuracy 21.8908\n",
      "Epoch 971 Batch 15 Loss 0.0577 Accuracy 21.8908\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 972 Batch 5 Loss 0.0577 Accuracy 21.8908\n",
      "Epoch 972 Batch 10 Loss 0.0577 Accuracy 21.8908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 972 Batch 15 Loss 0.0577 Accuracy 21.8908\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 973 Batch 5 Loss 0.0577 Accuracy 21.8908\n",
      "Epoch 973 Batch 10 Loss 0.0577 Accuracy 21.8908\n",
      "Epoch 973 Batch 15 Loss 0.0577 Accuracy 21.8908\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 974 Batch 5 Loss 0.0577 Accuracy 21.8908\n",
      "Epoch 974 Batch 10 Loss 0.0577 Accuracy 21.8908\n",
      "Epoch 974 Batch 15 Loss 0.0577 Accuracy 21.8907\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 975 Batch 5 Loss 0.0577 Accuracy 21.8907\n",
      "Epoch 975 Batch 10 Loss 0.0577 Accuracy 21.8907\n",
      "Epoch 975 Batch 15 Loss 0.0577 Accuracy 21.8907\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 976 Batch 5 Loss 0.0577 Accuracy 21.8907\n",
      "Epoch 976 Batch 10 Loss 0.0577 Accuracy 21.8907\n",
      "Epoch 976 Batch 15 Loss 0.0577 Accuracy 21.8907\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 977 Batch 5 Loss 0.0577 Accuracy 21.8907\n",
      "Epoch 977 Batch 10 Loss 0.0577 Accuracy 21.8907\n",
      "Epoch 977 Batch 15 Loss 0.0577 Accuracy 21.8907\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 978 Batch 5 Loss 0.0577 Accuracy 21.8907\n",
      "Epoch 978 Batch 10 Loss 0.0577 Accuracy 21.8907\n",
      "Epoch 978 Batch 15 Loss 0.0577 Accuracy 21.8907\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 979 Batch 5 Loss 0.0577 Accuracy 21.8907\n",
      "Epoch 979 Batch 10 Loss 0.0577 Accuracy 21.8907\n",
      "Epoch 979 Batch 15 Loss 0.0577 Accuracy 21.8907\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 980 Batch 5 Loss 0.0577 Accuracy 21.8907\n",
      "Epoch 980 Batch 10 Loss 0.0577 Accuracy 21.8907\n",
      "Epoch 980 Batch 15 Loss 0.0577 Accuracy 21.8906\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 981 Batch 5 Loss 0.0577 Accuracy 21.8906\n",
      "Epoch 981 Batch 10 Loss 0.0577 Accuracy 21.8906\n",
      "Epoch 981 Batch 15 Loss 0.0577 Accuracy 21.8906\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 982 Batch 5 Loss 0.0577 Accuracy 21.8906\n",
      "Epoch 982 Batch 10 Loss 0.0577 Accuracy 21.8906\n",
      "Epoch 982 Batch 15 Loss 0.0577 Accuracy 21.8906\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 983 Batch 5 Loss 0.0577 Accuracy 21.8906\n",
      "Epoch 983 Batch 10 Loss 0.0577 Accuracy 21.8906\n",
      "Epoch 983 Batch 15 Loss 0.0577 Accuracy 21.8906\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 984 Batch 5 Loss 0.0577 Accuracy 21.8906\n",
      "Epoch 984 Batch 10 Loss 0.0577 Accuracy 21.8906\n",
      "Epoch 984 Batch 15 Loss 0.0577 Accuracy 21.8906\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 985 Batch 5 Loss 0.0577 Accuracy 21.8906\n",
      "Epoch 985 Batch 10 Loss 0.0577 Accuracy 21.8906\n",
      "Epoch 985 Batch 15 Loss 0.0577 Accuracy 21.8906\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 986 Batch 5 Loss 0.0577 Accuracy 21.8906\n",
      "Epoch 986 Batch 10 Loss 0.0577 Accuracy 21.8906\n",
      "Epoch 986 Batch 15 Loss 0.0577 Accuracy 21.8906\n",
      "Time taken for 1 epoch: 0.03 secs\n",
      "\n",
      "Epoch 987 Batch 5 Loss 0.0577 Accuracy 21.8905\n",
      "Epoch 987 Batch 10 Loss 0.0577 Accuracy 21.8905\n",
      "Epoch 987 Batch 15 Loss 0.0577 Accuracy 21.8905\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 988 Batch 5 Loss 0.0577 Accuracy 21.8905\n",
      "Epoch 988 Batch 10 Loss 0.0577 Accuracy 21.8905\n",
      "Epoch 988 Batch 15 Loss 0.0577 Accuracy 21.8905\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 989 Batch 5 Loss 0.0577 Accuracy 21.8905\n",
      "Epoch 989 Batch 10 Loss 0.0577 Accuracy 21.8905\n",
      "Epoch 989 Batch 15 Loss 0.0577 Accuracy 21.8905\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 990 Batch 5 Loss 0.0577 Accuracy 21.8905\n",
      "Epoch 990 Batch 10 Loss 0.0577 Accuracy 21.8905\n",
      "Epoch 990 Batch 15 Loss 0.0577 Accuracy 21.8905\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 991 Batch 5 Loss 0.0577 Accuracy 21.8905\n",
      "Epoch 991 Batch 10 Loss 0.0577 Accuracy 21.8905\n",
      "Epoch 991 Batch 15 Loss 0.0577 Accuracy 21.8905\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 992 Batch 5 Loss 0.0577 Accuracy 21.8905\n",
      "Epoch 992 Batch 10 Loss 0.0577 Accuracy 21.8905\n",
      "Epoch 992 Batch 15 Loss 0.0577 Accuracy 21.8905\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 993 Batch 5 Loss 0.0577 Accuracy 21.8905\n",
      "Epoch 993 Batch 10 Loss 0.0577 Accuracy 21.8904\n",
      "Epoch 993 Batch 15 Loss 0.0577 Accuracy 21.8904\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 994 Batch 5 Loss 0.0577 Accuracy 21.8904\n",
      "Epoch 994 Batch 10 Loss 0.0577 Accuracy 21.8904\n",
      "Epoch 994 Batch 15 Loss 0.0577 Accuracy 21.8904\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 995 Batch 5 Loss 0.0577 Accuracy 21.8904\n",
      "Epoch 995 Batch 10 Loss 0.0577 Accuracy 21.8904\n",
      "Epoch 995 Batch 15 Loss 0.0577 Accuracy 21.8904\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 996 Batch 5 Loss 0.0577 Accuracy 21.8904\n",
      "Epoch 996 Batch 10 Loss 0.0577 Accuracy 21.8904\n",
      "Epoch 996 Batch 15 Loss 0.0577 Accuracy 21.8904\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 997 Batch 5 Loss 0.0577 Accuracy 21.8904\n",
      "Epoch 997 Batch 10 Loss 0.0577 Accuracy 21.8904\n",
      "Epoch 997 Batch 15 Loss 0.0577 Accuracy 21.8904\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 998 Batch 5 Loss 0.0577 Accuracy 21.8904\n",
      "Epoch 998 Batch 10 Loss 0.0577 Accuracy 21.8904\n",
      "Epoch 998 Batch 15 Loss 0.0577 Accuracy 21.8904\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 999 Batch 5 Loss 0.0577 Accuracy 21.8904\n",
      "Epoch 999 Batch 10 Loss 0.0577 Accuracy 21.8904\n",
      "Epoch 999 Batch 15 Loss 0.0577 Accuracy 21.8904\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n",
      "Epoch 1000 Batch 5 Loss 0.0577 Accuracy 21.8903\n",
      "Epoch 1000 Batch 10 Loss 0.0577 Accuracy 21.8903\n",
      "Epoch 1000 Batch 15 Loss 0.0577 Accuracy 21.8903\n",
      "Time taken for 1 epoch: 0.02 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name = \"test_loss\")\n",
    "test_accuracy = tf.keras.metrics.Mean(name = \"test_accuracy\")\n",
    " \n",
    "loss_function = tf.keras.losses.MeanAbsoluteError(reduction = tf.keras.losses.Reduction.NONE)\n",
    "accuracy_function = tf.keras.metrics.MeanAbsoluteError()\n",
    " \n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    i = 1\n",
    "\n",
    "    while True:\n",
    "\n",
    "        inp = X_train_dangjin_scaled[(i - 1) * batch_size : (i * batch_size)].copy()\n",
    "        inp[:,[0,1,2,4,5,7,8,10,11,13,14,16,17,19,20,22,23],:] = 0\n",
    "        inp = tf.Variable(inp, dtype = tf.float32)\n",
    "        \n",
    "        tar = tf.Variable(X_train_dangjin_scaled[(i - 1) * batch_size : (i * batch_size)], dtype = tf.float32)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        training_auto_encoder(inp, tar)\n",
    "\n",
    "        if i % 5 == 0:\n",
    "            print(f'Epoch {epoch + 1} Batch {i} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "\n",
    "        if i > int(len(X_train_dangjin_scaled) / batch_size) :\n",
    "            print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')\n",
    "            #test_accuracy(X_test_scaled, y_test_scaled)\n",
    "            #print(f'TestLoss {test_loss.result():.4f} TestAccuracy {test_accuracy.result():.4f}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08410229, 0.05299235, 0.65726338, 0.29607171, 0.07724756],\n",
       "       [0.08383865, 0.05193778, 0.05088321, 0.29870815, 0.07461113],\n",
       "       [0.08410229, 0.0551015 , 0.57817031, 0.30134458, 0.07724756],\n",
       "       [0.08331136, 0.05246507, 0.94727129, 0.30925389, 0.06670182],\n",
       "       [0.08726602, 0.05852887, 0.5254416 , 0.30925389, 0.07461113],\n",
       "       [0.08436594, 0.05958344, 0.57817031, 0.30925389, 0.06406538],\n",
       "       [0.08647509, 0.06432903, 0.57817031, 0.30925389, 0.07724756],\n",
       "       [0.08410229, 0.06195624, 0.57817031, 0.30925389, 0.06670182],\n",
       "       [0.08542051, 0.0593198 , 0.57817031, 0.30925389, 0.07724756],\n",
       "       [0.08568416, 0.05852887, 0.57817031, 0.30925389, 0.06933825],\n",
       "       [0.08621144, 0.05826523, 0.57817031, 0.30925389, 0.07724756],\n",
       "       [0.0859478 , 0.05589243, 0.65726338, 0.30925389, 0.07461113],\n",
       "       [0.08489322, 0.05852887, 0.7627208 , 0.30925389, 0.07724756],\n",
       "       [0.08331136, 0.05641972, 0.65726338, 0.30925389, 0.06406538],\n",
       "       [0.08225679, 0.05826523, 0.7627208 , 0.30925389, 0.06670182],\n",
       "       [0.07962035, 0.05536515, 0.89454258, 0.30925389, 0.07724756],\n",
       "       [0.07698392, 0.05826523, 0.89454258, 0.30925389, 0.07197469],\n",
       "       [0.07355655, 0.0551015 , 1.        , 0.30925389, 0.06933825],\n",
       "       [0.07355655, 0.05536515, 0.94727129, 0.30925389, 0.06933825],\n",
       "       [0.07012919, 0.05483786, 0.18270498, 0.30925389, 0.07724756],\n",
       "       [0.07065647, 0.05193778, 0.05088321, 0.30925389, 0.06406538],\n",
       "       [0.07012919, 0.05351964, 0.94727129, 0.30925389, 0.07461113],\n",
       "       [0.06749275, 0.05721065, 0.94727129, 0.30398102, 0.07197469],\n",
       "       [0.06749275, 0.05800158, 0.94727129, 0.2802531 , 0.07461113]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dangjin_scaled[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_test = X_test_dangjin_scaled[(i - 1) * batch_size : (i * batch_size)].copy()\n",
    "inp_test[:,[0,1,2,4,5,7,8,10,11,13,14,16,17,19,20,22,23],:] = 0\n",
    "inp_test = tf.Variable(inp, dtype = tf.float32)\n",
    "\n",
    "tar_test = tf.Variable(X_test_dangjin_scaled[(i - 1) * batch_size : (i * batch_size)], dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "slice index 1 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-215-079126d5ae09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_max_dangjin\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtrain_min_dangjin\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtrain_min_dangjin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"red\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtar_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_max_dangjin\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtrain_min_dangjin\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtrain_min_dangjin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"green\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_SliceHelperVar\u001b[1;34m(var, slice_spec)\u001b[0m\n\u001b[0;32m   1222\u001b[0m   \"\"\"\n\u001b[0;32m   1223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1224\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_slice_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[1;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[0;32m    971\u001b[0m       \u001b[0mvar_empty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m       \u001b[0mpacked_begin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpacked_end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpacked_strides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvar_empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m     return strided_slice(\n\u001b[0m\u001b[0;32m    974\u001b[0m         \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m         \u001b[0mpacked_begin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[0mstrides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1140\u001b[1;33m   op = gen_array_ops.strided_slice(\n\u001b[0m\u001b[0;32m   1141\u001b[0m       \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mbegin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[1;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[0;32m  10155\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10156\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10157\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10158\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10159\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mbegin_mask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6652\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6653\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6654\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: slice index 1 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(AE(inp_test)[1,:,2] * (train_max_dangjin - train_min_dangjin) + train_min_dangjin, color = \"red\")\n",
    "plt.plot(tar_test[1,:,2] * (train_max_dangjin - train_min_dangjin) + train_min_dangjin, color = \"green\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
